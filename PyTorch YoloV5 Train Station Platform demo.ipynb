{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch YoloV5 Train Station Platform demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of a computer vision application to **detect the presence of a train on a platform and to count the number of people on the platform**. <br>\n",
    "This usecase can be useful for public transportation for passengers crowd counting.\n",
    "\n",
    "We are going to use **YoloV5** to detect persons and train. Results will be saved into an **Azure ML experiment.**\n",
    "We can use different versions of YoloV5 with PyTorch.\n",
    "\n",
    "We can **blur** the frames from the video for people privacy concerns. There are many ways to do it. In this example we will blur all the frames without degrading the quality of the images for the CV model. We can as well decide to blur only the detected faces (and not the full image)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install moviepy\n",
    "#%pip install xlwt\n",
    "#%pip install -U numpy\n",
    "#%pip install 'matplotlib>=3.2.2'\n",
    "#%pip install 'torchvision>=0.8.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import os.path\n",
    "import urllib\n",
    "import torch\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import moviepy\n",
    "from moviepy.editor import *\n",
    "import xlwt\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "import shutil\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using Python: 3.8.5 (default, Sep  4 2020, 07:30:14) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"You are using Python:\", sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open CV version: 4.5.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Open CV version:\", cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is: Wed 20 Apr 2022 13:08:03\n"
     ]
    }
   ],
   "source": [
    "print(\"Today is:\", datetime.datetime.now().strftime(\"%a %d %b %Y %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML version: 1.39.0\n",
      "This notebook was made with Azure ML version 1.39.0\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "print(\"Azure ML version:\", azureml.core.VERSION)\n",
    "print(\"This notebook was made with Azure ML version 1.39.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML GPU compute instance:\n",
      "\n",
      "Wed Apr 20 13:08:03 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           On   | 00000001:00:00.0 Off |                    0 |\n",
      "| N/A   47C    P0    55W / 149W |   1439MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla K80           On   | 00000002:00:00.0 Off |                    0 |\n",
      "| N/A   27C    P8    33W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla K80           On   | 00000003:00:00.0 Off |                    0 |\n",
      "| N/A   33C    P8    26W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla K80           On   | 00000004:00:00.0 Off |                    0 |\n",
      "| N/A   27C    P8    33W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     47851      C   ...s/azureml_py38/bin/python     1434MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "\n",
    "if gpu_info.find('failed') >= 0:\n",
    "    print('Please select an Azure ML GPU compute instance')\n",
    "else:\n",
    "    print(\"Azure ML GPU compute instance:\\n\")\n",
    "    print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Azure ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = os.environ.get(\"SUBSCRIPTION_ID\", \"tobecompleted\")\n",
    "resource_group = os.environ.get(\"RESOURCE_GROUP\", \"azuremlvision-rg\")\n",
    "workspace_name = os.environ.get(\"WORKSPACE_NAME\", \"azuremlvision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML Workspace found: OK\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "try:\n",
    "    ws = Workspace(subscription_id = subscription_id, \n",
    "                   resource_group = resource_group, \n",
    "                   workspace_name = workspace_name)\n",
    "    ws.write_config()\n",
    "    print(\"Azure ML Workspace found: OK\")\n",
    "\n",
    "except:\n",
    "    print(\"Error: Azure ML Workspace not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML Workspace: azuremlvision\n",
      "Region: westeurope\n",
      "Ressource Group: azuremlvision-rg\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "print('Azure ML Workspace: ' + ws.name, \n",
    "      'Region: ' + ws.location, \n",
    "      'Ressource Group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMLexperiment = 'TrainPlatform'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import experiment\n",
    "experiment = Experiment(workspace=ws, name = AMLexperiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will create or use the Azure ML experiment: TrainPlatform\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>TrainPlatform</td><td>azuremlvision</td><td><a href=\"https://ml.azure.com/experiments/id/3ca29690-d32d-4cdf-8c52-610318ce7c7e?wsid=/subscriptions/70b8f39e-8863-49f7-b6ba-34a80799550c/resourcegroups/azuremlvision-rg/workspaces/azuremlvision&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: TrainPlatform,\n",
       "Workspace: azuremlvision)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"We will create or use the Azure ML experiment:\", AMLexperiment)\n",
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creation of directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdir(dirname):\n",
    "    # Function to create a directory if needed\n",
    "    import os.path\n",
    "    from os import path\n",
    "    \n",
    "    if path.os.path.isdir(dirname):\n",
    "        print(\"Directory:\", dirname, \"exists!\\n\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Creating directory:\", dirname)\n",
    "        os.mkdir(dirname)\n",
    "        print(\"Done!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbfiles(mydir):\n",
    "    # Display number of images per dir\n",
    "    for root, _, files in os.walk(mydir):\n",
    "        print(\"Directory:\", root, \"has\", len(files), \"files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatdate(ts):\n",
    "    # Formatting date\n",
    "    return datetime.datetime.fromtimestamp(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirfiles(MYDIR):\n",
    "    # Display list of giles\n",
    "    for item in os.scandir(MYDIR):\n",
    "         print(formatdate(item.stat().st_atime), item.stat().st_size, item.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filenameordernumber():\n",
    "    # Just to have the same length for the filenames\n",
    "    if len(str(framenumber)) == 1:\n",
    "        framenumberstr = '00000000' + str(framenumber)\n",
    "    if len(str(framenumber)) == 2:\n",
    "        framenumberstr = '0000000' + str(framenumber)\n",
    "    if len(str(framenumber)) == 3:\n",
    "        framenumberstr = '000000' + str(framenumber)\n",
    "    if len(str(framenumber)) == 4:\n",
    "        framenumberstr = '00000' + str(framenumber)\n",
    "    if len(str(framenumber)) == 5:\n",
    "        framenumberstr = '0000' + str(framenumber)\n",
    "    if len(str(framenumber)) == 6:\n",
    "        framenumberstr = '000' + str(framenumber)\n",
    "    if len(str(framenumber)) == 7:\n",
    "        framenumberstr = '00' + str(framenumber)\n",
    "    if len(str(framenumber)) == 8:\n",
    "        framenumberstr = '0' + str(framenumber)\n",
    "    \n",
    "    return framenumberstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_info(sample_image):\n",
    "    %matplotlib inline\n",
    "    # Displaying image\n",
    "    img = cv2.imread(sample_image)\n",
    "    height, width, chanels = img.shape\n",
    "    print(\"Image:\", sample_image, 'w =', width, 'h =', height, 'c =', chanels, '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory: images\n",
      "Done!\n",
      "\n",
      "Creating directory: images/captures\n",
      "Done!\n",
      "\n",
      "Creating directory: results\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Directories to create if needed\n",
    "IMAGES_DIR = 'images' # to save the processed images by Yolo\n",
    "CAPTURES_DIR = 'images/captures' # to save the captured frames\n",
    "VIDEO_DIR = 'videos' # To save the sample video\n",
    "RESULTS_DIR = 'results'\n",
    "\n",
    "createdir(IMAGES_DIR)\n",
    "createdir(CAPTURES_DIR)\n",
    "createdir(RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Video information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 root root 6723193 Apr 15 09:51 videos/subway.mp4\r\n"
     ]
    }
   ],
   "source": [
    "!ls videos/*.* -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MP4FILE = 'subway.mp4'\n",
    "VIDEOFILE = VIDEO_DIR + '/' + MP4FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mVideo File : videos/subway.mp4\n",
      "\n",
      "- Width: 766 \n",
      "- Height: 1080\n",
      "- FPS = 25\n",
      "- Duration in seconds : 43.36\n",
      "- Number of frames = 1084\n"
     ]
    }
   ],
   "source": [
    "MYVIDEOFILE = VideoFileClip(VIDEOFILE)\n",
    "\n",
    "fps = MYVIDEOFILE.fps\n",
    "w = MYVIDEOFILE.w\n",
    "h = MYVIDEOFILE.h\n",
    "duration = MYVIDEOFILE.duration\n",
    "nbframes = int(fps * duration)\n",
    "\n",
    "print(\"\\033[1;31;34mVideo File :\", VIDEOFILE)\n",
    "print(\"\\n- Width:\", w, \"\\n- Height:\", h)\n",
    "print(\"- FPS =\", round(fps))\n",
    "print(\"- Duration in seconds :\", duration)\n",
    "print(\"- Number of frames =\", nbframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analysing a video file or a streaming video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's use now the same video but with a different time length. We have an initial long video. **So we will create first a video clip in order to reduce the time**. We will not analyse all the frames (we have a FPS = 30). We can decide to extract only some frames. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will create a new videoclip from the initial video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "startvideo = 1 # in seconds\n",
    "endvideo = 43 # in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are going to create a sample video starting at 1 seconds and ending at 43 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"We are going to create a sample video starting at\", startvideo, \n",
    "      \"seconds and ending at\", endvideo, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample video duration = 42 seconds\n"
     ]
    }
   ],
   "source": [
    "MYVIDEOFILE = VideoFileClip(VIDEOFILE)\n",
    "SAMPLEVIDEO_FILE = MYVIDEOFILE.subclip(startvideo, endvideo)\n",
    "\n",
    "clipduration = SAMPLEVIDEO_FILE.duration # Compute the duration in secs\n",
    "print(\"Sample video duration =\", clipduration, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video results/sample_subway.mp4.\n",
      "MoviePy - Writing audio in sample_subwayTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video results/sample_subway.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready results/sample_subway.mp4\n"
     ]
    }
   ],
   "source": [
    "# Saving the sample video\n",
    "SAMPLEVIDEO_FILENAME = RESULTS_DIR + \"/sample_\" + MP4FILE\n",
    "SAMPLEVIDEO_FILE.write_videofile(SAMPLEVIDEO_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 root root 8.4M Apr 20 13:08 results/sample_subway.mp4\r\n"
     ]
    }
   ],
   "source": [
    "!ls results/*.* -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Video informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling frame (number of extracted frame)\n",
    "sampling_frames = 1 # so 30 frames for each 1 second (we have here FPS = 30)\n",
    "\n",
    "# Width & Height of the video\n",
    "MYVIDEOFILE = VideoFileClip(SAMPLEVIDEO_FILENAME)\n",
    "w = MYVIDEOFILE.w\n",
    "h = MYVIDEOFILE.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mVideo Clip: results/sample_subway.mp4\n",
      "- Video input size: width = 766 height = 1080\n",
      "- FPS = 25\n",
      "- Duration in seconds = 42.03\n",
      "- Number of frames = 1050\n",
      "\n",
      "Output:\n",
      "- Sampling Frames = 1\n",
      "- Number of frames to analyse = 1050\n",
      "- Video will be processed each 0.04 seconds\n"
     ]
    }
   ],
   "source": [
    "MYVIDEOFILE = VideoFileClip(SAMPLEVIDEO_FILENAME)\n",
    "\n",
    "fps = MYVIDEOFILE.fps\n",
    "duration = MYVIDEOFILE.duration\n",
    "nbframes = int(fps * duration)\n",
    "duration_sec = duration\n",
    "nbprocessedframes = nbframes / sampling_frames\n",
    "nbframespersec = sampling_frames / fps\n",
    "\n",
    "print(\"\\033[1;31;34mVideo Clip:\", SAMPLEVIDEO_FILENAME)\n",
    "print(\"- Video input size: width =\", w, \"height =\", h)\n",
    "print(\"- FPS =\", round(fps))\n",
    "print(\"- Duration in seconds =\", duration_sec)\n",
    "print(\"- Number of frames =\", nbframes)\n",
    "print(\"\\nOutput:\")\n",
    "print(\"- Sampling Frames =\", sampling_frames)\n",
    "print(\"- Number of frames to analyse =\", int(nbprocessedframes))\n",
    "print(\"- Video will be processed each\", round(nbframespersec, 2), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File results/sample_subway.mp4 exists\n"
     ]
    }
   ],
   "source": [
    "WEBCAM = SAMPLEVIDEO_FILENAME # Or you can use a RTSP link to connec to a webcam or a live video camera\n",
    "\n",
    "if os.path.exists(WEBCAM) == True :\n",
    "    print(\"File\", WEBCAM, \"exists\")\n",
    "\n",
    "if os.path.exists(WEBCAM) == False :\n",
    "    print(\"File\", WEBCAM, \"did not exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying initial video\n",
    "#from IPython.display import Video\n",
    "#Video(SAMPLEVIDEO_FILENAME, embed=True, width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Yolo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory: yolo\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "YOLODIR = 'yolo'\n",
    "createdir(YOLODIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolomodelversion = 'yolov5x6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's download the yolov5x6 yolo model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/azureuser/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-4-13 torch 1.8.1+cu102 CUDA:0 (Tesla K80, 11441MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5x6.pt to yolov5x6.pt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f61f4ad355d45f88e45f1b5e97d7f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/270M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "YOLOv5x6 summary: 574 layers, 140730220 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 0:00:20.463235\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's download the\", yolomodelversion, 'yolo model')\n",
    "t1 = datetime.datetime.now()\n",
    "os.chdir(YOLODIR)\n",
    "model = torch.hub.load('ultralytics/yolov5', yolomodelversion, pretrained=True)\n",
    "print(\"Done in\", datetime.datetime.now() - t1)\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 root root 270M Apr 20 13:09 yolo/yolov5x6.pt\r\n"
     ]
    }
   ],
   "source": [
    "!ls yolo/*.* -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Yolo object detection function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calling_yolov5_model(image):\n",
    "    \n",
    "    # Yolo model options\n",
    "    min_conf = 0.3\n",
    "    iou = 0.45\n",
    "    \n",
    "    # Colors definition\n",
    "    color_lime = (0, 255, 0)\n",
    "    color_cyan = (255, 255, 0)\n",
    "    color_red = (0, 0, 255)\n",
    "    color_orange = (0, 140, 255)\n",
    "    color_pink = (147, 20, 255)\n",
    "    \n",
    "    # OpenCV options\n",
    "    fontsize1 = 0.8\n",
    "    fontsize2 = 0.8\n",
    "    fontsize3 = 0.7\n",
    "    fonttype1 = 2\n",
    "    fonttype2 = 2\n",
    "    rectsize1 = 2\n",
    "    rectsize2 = 4\n",
    "\n",
    "    # Init values\n",
    "    nbpersons = 0\n",
    "    trainstatus = 0\n",
    "    \n",
    "    # Density values\n",
    "    lowlevel = 5 # For density\n",
    "    avglevel = 10 # For density\n",
    "    platform_edge = 50 # lane between the train and the platform (no need to count people in the train!)\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    print(now)\n",
    "    \n",
    "    # Settings\n",
    "    model.conf = min_conf # confidence threshold (0-1)\n",
    "    model.iou = iou # NMS IoU threshold (0-1)\n",
    "    model.classes = [0, 6] # Persons and trains to detect\n",
    "    \n",
    "    # Model\n",
    "    print(\"\\033[1;31;34m\")\n",
    "    print(\"-\" * 30, \"Analyzing\", image, \"-\" * 30, '\\n')\n",
    "    yolocv = model(image)\n",
    "    yolocv.print()\n",
    "    yoloarray = yolocv.xyxy[0].cpu().detach().numpy()\n",
    "    \n",
    "    i = 1\n",
    "    print(\"\\033[1;31;34mNumber of detected objects =\", len(yoloarray), '\\n')\n",
    "\n",
    "    img = cv2.imread(image) # The initial frame\n",
    "    # We can blur the whole image to prevent people privacy\n",
    "    img = cv2.blur(img, (10, 10))\n",
    "\n",
    "    while i <= len(yoloarray):\n",
    "        x1 = int(yoloarray[i-1][0])\n",
    "        y1 = int(yoloarray[i-1][1])\n",
    "        x2 = int(yoloarray[i-1][2])\n",
    "        y2 = int(yoloarray[i-1][3])\n",
    "        confidence = yoloarray[i-1][4]\n",
    "        tag = yoloarray[i-1][5]\n",
    "    \n",
    "        if tag == 0:\n",
    "            tagname = 'person'\n",
    "      \n",
    "        if tag == 6:\n",
    "            tagname = 'train' \n",
    "                \n",
    "        xcenter = int((x1 + x2 ) / 2)\n",
    "        ycenter = int((y1 + y2 ) / 2)\n",
    "        msg = tagname + ' = ' + str(round(confidence, 2))\n",
    "        \n",
    "        print(i, \"\\tObject:\", tagname, \n",
    "              \"\\tConfidence =\", round(confidence, 4), \n",
    "              \"\\tBbox: [\", x1, '\\t', y1, '\\t', x2, '\\t', y2, ']')\n",
    "        \n",
    "        if tag == 0: # To detect a Person\n",
    "            if xcenter >= platform_edge :\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), color_lime, rectsize1)\n",
    "                cv2.circle(img, (xcenter, ycenter), 10, color_red, -1)\n",
    "                cv2.putText(img, msg, (xcenter - 100, ycenter + 50), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                            fontsize3, color_lime, fonttype1, cv2.LINE_AA)\n",
    "                nbpersons +=1\n",
    "        \n",
    "        if tag == 6: # To detect Train\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), color_cyan, rectsize1)\n",
    "            cv2.putText(img, msg, (xcenter - 100, ycenter), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        fontsize1, color_cyan, fonttype1, cv2.LINE_AA)\n",
    "            \n",
    "            msgtrain = 'Train is on the platform!'\n",
    "            trainstatus = 1\n",
    "            cv2.putText(img, msgtrain, (25, 250), cv2.FONT_HERSHEY_SIMPLEX, 1.2, color_cyan, fonttype1, cv2.LINE_AA)    \n",
    "        \n",
    "        i +=1\n",
    "        del x1, y1, x2, y2\n",
    "    \n",
    "    msg1 = 'CCTV Cam 1' # Top Message\n",
    "    cv2.putText(img, msg1, (25, 50), cv2.FONT_HERSHEY_SIMPLEX, fontsize2, \n",
    "                color_lime, fonttype2, cv2.LINE_AA)\n",
    "    \n",
    "    msg2 = str(datetime.datetime.now().strftime(\"%a %d %b %Y %H:%M\")) # Current date\n",
    "    cv2.putText(img, msg2, (25, 80), cv2.FONT_HERSHEY_SIMPLEX, fontsize2, \n",
    "                color_lime, fonttype2, cv2.LINE_AA)\n",
    "    \n",
    "    msg3 = 'Number of persons = ' + str(nbpersons) # Number of people\n",
    "    cv2.putText(img, msg3, (25, 150), cv2.FONT_HERSHEY_SIMPLEX, fontsize2, color_lime, fonttype2, cv2.LINE_AA)\n",
    "    \n",
    "    if nbpersons == 0:\n",
    "        personsdensitymsg = 'Platform is empty'\n",
    "        colordensity = color_pink\n",
    "        \n",
    "    if nbpersons >= 1 and nbpersons <= lowlevel:\n",
    "        personsdensitymsg = 'Low density of persons in the platform'\n",
    "        colordensity = color_cyan\n",
    "    \n",
    "    if nbpersons > lowlevel and nbpersons <= avglevel:\n",
    "        personsdensitymsg = 'Moderate density of persons in the platform'\n",
    "        colordensity = color_orange\n",
    "        \n",
    "    if nbpersons > avglevel:\n",
    "        personsdensitymsg = 'High density of persons in the platform'\n",
    "        colordensity = color_red   \n",
    "\n",
    "    cv2.putText(img, personsdensitymsg, (25, 180), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                fontsize2, colordensity, fonttype2, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.putText(img, 'Powered by Azure ML', (25, 1050), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                fontsize1, color_cyan, fonttype1, cv2.LINE_AA)\n",
    "    \n",
    "    df = yolocv.pandas().xyxy[0]\n",
    "    print(\"\\033[1;31;91m\")\n",
    "    print(\"Results:\")\n",
    "    print(df['name'].value_counts(sort=True))\n",
    "    print()\n",
    "    \n",
    "    return img, nbpersons, trainstatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results/sample_subway.mp4'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input file or RTSP to analyse\n",
    "WEBCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 root root 8.4M Apr 20 13:08 results/sample_subway.mp4\r\n"
     ]
    }
   ],
   "source": [
    "!ls results/*.* -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>TrainPlatform</td><td>azuremlvision</td><td><a href=\"https://ml.azure.com/experiments/id/3ca29690-d32d-4cdf-8c52-610318ce7c7e?wsid=/subscriptions/70b8f39e-8863-49f7-b6ba-34a80799550c/resourcegroups/azuremlvision-rg/workspaces/azuremlvision&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: TrainPlatform,\n",
       "Workspace: azuremlvision)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting to log values into Azure ML\n",
    "run = experiment.start_logging(snapshot_directory = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's analyse the video to detect the number of persons on the platform and if a train is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mProcessing the video:  results/sample_subway.mp4 for every 1 frame(s) \n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000001 / 1050\n",
      "Frames to be processed: 1049  | To do: 99.9 % | Done: 0.1 %\n",
      "\n",
      "2022-04-20 13:10:29.108386\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000001.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 98.8ms pre-process, 238.4ms inference, 39.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.893 \tBbox: [ 475 \t 481 \t 628 \t 769 ]\n",
      "2 \tObject: person \tConfidence = 0.8887 \tBbox: [ 372 \t 740 \t 668 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8739 \tBbox: [ 505 \t 86 \t 582 \t 299 ]\n",
      "4 \tObject: person \tConfidence = 0.8715 \tBbox: [ 429 \t 152 \t 522 \t 395 ]\n",
      "5 \tObject: person \tConfidence = 0.8485 \tBbox: [ 563 \t 29 \t 639 \t 260 ]\n",
      "6 \tObject: person \tConfidence = 0.7633 \tBbox: [ 438 \t 0 \t 487 \t 139 ]\n",
      "7 \tObject: person \tConfidence = 0.7566 \tBbox: [ 515 \t 0 \t 542 \t 51 ]\n",
      "8 \tObject: person \tConfidence = 0.5134 \tBbox: [ 557 \t 3 \t 601 \t 100 ]\n",
      "9 \tObject: person \tConfidence = 0.3371 \tBbox: [ 477 \t 0 \t 506 \t 95 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000002 / 1050\n",
      "Frames to be processed: 1048  | To do: 99.81 % | Done: 0.19 %\n",
      "\n",
      "2022-04-20 13:10:29.835754\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000002.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons\n",
      "Speed: 28.7ms pre-process, 214.2ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8983 \tBbox: [ 475 \t 481 \t 627 \t 769 ]\n",
      "2 \tObject: person \tConfidence = 0.8959 \tBbox: [ 372 \t 739 \t 669 \t 1079 ]\n",
      "3 \tObject: person \tConfidence = 0.8761 \tBbox: [ 505 \t 86 \t 588 \t 299 ]\n",
      "4 \tObject: person \tConfidence = 0.8668 \tBbox: [ 429 \t 151 \t 524 \t 395 ]\n",
      "5 \tObject: person \tConfidence = 0.8474 \tBbox: [ 563 \t 29 \t 640 \t 260 ]\n",
      "6 \tObject: person \tConfidence = 0.7588 \tBbox: [ 437 \t 0 \t 487 \t 139 ]\n",
      "7 \tObject: person \tConfidence = 0.7526 \tBbox: [ 515 \t 0 \t 541 \t 49 ]\n",
      "8 \tObject: person \tConfidence = 0.5403 \tBbox: [ 557 \t 4 \t 601 \t 99 ]\n",
      "9 \tObject: person \tConfidence = 0.3414 \tBbox: [ 561 \t 0 \t 603 \t 26 ]\n",
      "10 \tObject: person \tConfidence = 0.3263 \tBbox: [ 475 \t 0 \t 506 \t 103 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000003 / 1050\n",
      "Frames to be processed: 1047  | To do: 99.71 % | Done: 0.29 %\n",
      "\n",
      "2022-04-20 13:10:30.319849\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000003.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 26.3ms pre-process, 196.0ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9052 \tBbox: [ 371 \t 739 \t 668 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.903 \tBbox: [ 475 \t 480 \t 627 \t 768 ]\n",
      "3 \tObject: person \tConfidence = 0.8787 \tBbox: [ 508 \t 90 \t 586 \t 296 ]\n",
      "4 \tObject: person \tConfidence = 0.8516 \tBbox: [ 430 \t 151 \t 522 \t 396 ]\n",
      "5 \tObject: person \tConfidence = 0.8389 \tBbox: [ 564 \t 29 \t 640 \t 260 ]\n",
      "6 \tObject: person \tConfidence = 0.7587 \tBbox: [ 437 \t 0 \t 488 \t 139 ]\n",
      "7 \tObject: person \tConfidence = 0.7555 \tBbox: [ 511 \t 0 \t 541 \t 49 ]\n",
      "8 \tObject: person \tConfidence = 0.6073 \tBbox: [ 558 \t 6 \t 599 \t 98 ]\n",
      "9 \tObject: person \tConfidence = 0.318 \tBbox: [ 475 \t 0 \t 505 \t 103 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000004 / 1050\n",
      "Frames to be processed: 1046  | To do: 99.62 % | Done: 0.38 %\n",
      "\n",
      "2022-04-20 13:10:30.746577\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000004.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 24.6ms pre-process, 178.2ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9102 \tBbox: [ 371 \t 739 \t 669 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9033 \tBbox: [ 475 \t 480 \t 627 \t 768 ]\n",
      "3 \tObject: person \tConfidence = 0.8793 \tBbox: [ 509 \t 95 \t 586 \t 303 ]\n",
      "4 \tObject: person \tConfidence = 0.8575 \tBbox: [ 430 \t 150 \t 522 \t 396 ]\n",
      "5 \tObject: person \tConfidence = 0.8418 \tBbox: [ 563 \t 29 \t 639 \t 261 ]\n",
      "6 \tObject: person \tConfidence = 0.7568 \tBbox: [ 511 \t 0 \t 540 \t 49 ]\n",
      "7 \tObject: person \tConfidence = 0.7451 \tBbox: [ 437 \t 0 \t 487 \t 139 ]\n",
      "8 \tObject: person \tConfidence = 0.6358 \tBbox: [ 557 \t 5 \t 599 \t 100 ]\n",
      "9 \tObject: person \tConfidence = 0.3936 \tBbox: [ 474 \t 0 \t 506 \t 104 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000005 / 1050\n",
      "Frames to be processed: 1045  | To do: 99.52 % | Done: 0.48 %\n",
      "\n",
      "2022-04-20 13:10:31.168296\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000005.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 23.5ms pre-process, 182.0ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9034 \tBbox: [ 475 \t 480 \t 627 \t 767 ]\n",
      "2 \tObject: person \tConfidence = 0.9033 \tBbox: [ 371 \t 739 \t 667 \t 1079 ]\n",
      "3 \tObject: person \tConfidence = 0.8872 \tBbox: [ 510 \t 98 \t 587 \t 326 ]\n",
      "4 \tObject: person \tConfidence = 0.8656 \tBbox: [ 431 \t 150 \t 522 \t 397 ]\n",
      "5 \tObject: person \tConfidence = 0.8526 \tBbox: [ 563 \t 28 \t 638 \t 262 ]\n",
      "6 \tObject: person \tConfidence = 0.7567 \tBbox: [ 509 \t 0 \t 539 \t 51 ]\n",
      "7 \tObject: person \tConfidence = 0.7271 \tBbox: [ 436 \t 0 \t 487 \t 139 ]\n",
      "8 \tObject: person \tConfidence = 0.5454 \tBbox: [ 557 \t 2 \t 599 \t 106 ]\n",
      "9 \tObject: person \tConfidence = 0.3141 \tBbox: [ 474 \t 0 \t 504 \t 104 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000006 / 1050\n",
      "Frames to be processed: 1044  | To do: 99.43 % | Done: 0.57 %\n",
      "\n",
      "2022-04-20 13:10:31.641336\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000006.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 26.0ms pre-process, 173.4ms inference, 10.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9027 \tBbox: [ 371 \t 739 \t 665 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8945 \tBbox: [ 474 \t 480 \t 626 \t 769 ]\n",
      "3 \tObject: person \tConfidence = 0.8713 \tBbox: [ 511 \t 103 \t 588 \t 328 ]\n",
      "4 \tObject: person \tConfidence = 0.8617 \tBbox: [ 431 \t 150 \t 521 \t 398 ]\n",
      "5 \tObject: person \tConfidence = 0.8449 \tBbox: [ 562 \t 30 \t 637 \t 262 ]\n",
      "6 \tObject: person \tConfidence = 0.7645 \tBbox: [ 508 \t 0 \t 538 \t 50 ]\n",
      "7 \tObject: person \tConfidence = 0.7503 \tBbox: [ 436 \t 0 \t 489 \t 139 ]\n",
      "8 \tObject: person \tConfidence = 0.6109 \tBbox: [ 557 \t 4 \t 598 \t 107 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000007 / 1050\n",
      "Frames to be processed: 1043  | To do: 99.33 % | Done: 0.67 %\n",
      "\n",
      "2022-04-20 13:10:32.070582\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000007.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 25.9ms pre-process, 175.1ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9012 \tBbox: [ 370 \t 738 \t 664 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8949 \tBbox: [ 474 \t 480 \t 627 \t 768 ]\n",
      "3 \tObject: person \tConfidence = 0.8872 \tBbox: [ 508 \t 107 \t 590 \t 336 ]\n",
      "4 \tObject: person \tConfidence = 0.8719 \tBbox: [ 430 \t 150 \t 521 \t 398 ]\n",
      "5 \tObject: person \tConfidence = 0.8495 \tBbox: [ 560 \t 29 \t 637 \t 261 ]\n",
      "6 \tObject: person \tConfidence = 0.764 \tBbox: [ 508 \t 0 \t 537 \t 49 ]\n",
      "7 \tObject: person \tConfidence = 0.7389 \tBbox: [ 436 \t 0 \t 487 \t 139 ]\n",
      "8 \tObject: person \tConfidence = 0.5826 \tBbox: [ 556 \t 3 \t 598 \t 107 ]\n",
      "9 \tObject: person \tConfidence = 0.3464 \tBbox: [ 474 \t 0 \t 505 \t 104 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000008 / 1050\n",
      "Frames to be processed: 1042  | To do: 99.24 % | Done: 0.76 %\n",
      "\n",
      "2022-04-20 13:10:32.502715\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000008.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 29.4ms pre-process, 176.9ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9014 \tBbox: [ 371 \t 738 \t 664 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.898 \tBbox: [ 474 \t 480 \t 626 \t 769 ]\n",
      "3 \tObject: person \tConfidence = 0.8902 \tBbox: [ 512 \t 114 \t 592 \t 347 ]\n",
      "4 \tObject: person \tConfidence = 0.8759 \tBbox: [ 429 \t 150 \t 521 \t 397 ]\n",
      "5 \tObject: person \tConfidence = 0.8623 \tBbox: [ 558 \t 29 \t 636 \t 262 ]\n",
      "6 \tObject: person \tConfidence = 0.7672 \tBbox: [ 436 \t 0 \t 486 \t 139 ]\n",
      "7 \tObject: person \tConfidence = 0.7491 \tBbox: [ 509 \t 0 \t 535 \t 50 ]\n",
      "8 \tObject: person \tConfidence = 0.5599 \tBbox: [ 556 \t 3 \t 599 \t 110 ]\n",
      "9 \tObject: person \tConfidence = 0.3359 \tBbox: [ 474 \t 0 \t 504 \t 103 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000009 / 1050\n",
      "Frames to be processed: 1041  | To do: 99.14 % | Done: 0.86 %\n",
      "\n",
      "2022-04-20 13:10:33.077285\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000009.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 28.1ms pre-process, 179.7ms inference, 4.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9041 \tBbox: [ 371 \t 738 \t 665 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8965 \tBbox: [ 473 \t 480 \t 626 \t 769 ]\n",
      "3 \tObject: person \tConfidence = 0.8933 \tBbox: [ 513 \t 116 \t 593 \t 349 ]\n",
      "4 \tObject: person \tConfidence = 0.8737 \tBbox: [ 430 \t 150 \t 522 \t 397 ]\n",
      "5 \tObject: person \tConfidence = 0.8411 \tBbox: [ 560 \t 29 \t 637 \t 262 ]\n",
      "6 \tObject: person \tConfidence = 0.7665 \tBbox: [ 435 \t 0 \t 485 \t 138 ]\n",
      "7 \tObject: person \tConfidence = 0.7241 \tBbox: [ 509 \t 0 \t 535 \t 49 ]\n",
      "8 \tObject: person \tConfidence = 0.5456 \tBbox: [ 556 \t 3 \t 599 \t 113 ]\n",
      "9 \tObject: person \tConfidence = 0.3746 \tBbox: [ 474 \t 0 \t 504 \t 104 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000010 / 1050\n",
      "Frames to be processed: 1040  | To do: 99.05 % | Done: 0.95 %\n",
      "\n",
      "2022-04-20 13:10:33.507164\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000010.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 28.5ms pre-process, 175.0ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9051 \tBbox: [ 371 \t 738 \t 665 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8968 \tBbox: [ 473 \t 480 \t 626 \t 769 ]\n",
      "3 \tObject: person \tConfidence = 0.887 \tBbox: [ 514 \t 116 \t 595 \t 349 ]\n",
      "4 \tObject: person \tConfidence = 0.875 \tBbox: [ 429 \t 150 \t 521 \t 396 ]\n",
      "5 \tObject: person \tConfidence = 0.8106 \tBbox: [ 562 \t 30 \t 637 \t 261 ]\n",
      "6 \tObject: person \tConfidence = 0.7773 \tBbox: [ 435 \t 0 \t 485 \t 138 ]\n",
      "7 \tObject: person \tConfidence = 0.7173 \tBbox: [ 509 \t 0 \t 533 \t 49 ]\n",
      "8 \tObject: person \tConfidence = 0.5779 \tBbox: [ 555 \t 4 \t 599 \t 113 ]\n",
      "9 \tObject: person \tConfidence = 0.4224 \tBbox: [ 473 \t 0 \t 503 \t 105 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000011 / 1050\n",
      "Frames to be processed: 1039  | To do: 98.95 % | Done: 1.05 %\n",
      "\n",
      "2022-04-20 13:10:33.947874\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000011.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 25.5ms pre-process, 178.9ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9048 \tBbox: [ 371 \t 738 \t 665 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8989 \tBbox: [ 516 \t 116 \t 597 \t 349 ]\n",
      "3 \tObject: person \tConfidence = 0.8966 \tBbox: [ 473 \t 480 \t 626 \t 769 ]\n",
      "4 \tObject: person \tConfidence = 0.873 \tBbox: [ 430 \t 150 \t 521 \t 397 ]\n",
      "5 \tObject: person \tConfidence = 0.8169 \tBbox: [ 560 \t 29 \t 637 \t 261 ]\n",
      "6 \tObject: person \tConfidence = 0.7874 \tBbox: [ 435 \t 0 \t 485 \t 139 ]\n",
      "7 \tObject: person \tConfidence = 0.7034 \tBbox: [ 509 \t 0 \t 533 \t 48 ]\n",
      "8 \tObject: person \tConfidence = 0.5769 \tBbox: [ 555 \t 4 \t 598 \t 114 ]\n",
      "9 \tObject: person \tConfidence = 0.3994 \tBbox: [ 473 \t 0 \t 502 \t 105 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000012 / 1050\n",
      "Frames to be processed: 1038  | To do: 98.86 % | Done: 1.14 %\n",
      "\n",
      "2022-04-20 13:10:34.494852\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000012.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 29.3ms pre-process, 178.9ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9013 \tBbox: [ 371 \t 738 \t 666 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8988 \tBbox: [ 517 \t 115 \t 598 \t 348 ]\n",
      "3 \tObject: person \tConfidence = 0.894 \tBbox: [ 473 \t 480 \t 626 \t 769 ]\n",
      "4 \tObject: person \tConfidence = 0.8737 \tBbox: [ 430 \t 150 \t 521 \t 397 ]\n",
      "5 \tObject: person \tConfidence = 0.794 \tBbox: [ 434 \t 0 \t 485 \t 139 ]\n",
      "6 \tObject: person \tConfidence = 0.7859 \tBbox: [ 564 \t 30 \t 638 \t 261 ]\n",
      "7 \tObject: person \tConfidence = 0.7037 \tBbox: [ 508 \t 0 \t 532 \t 47 ]\n",
      "8 \tObject: person \tConfidence = 0.563 \tBbox: [ 555 \t 4 \t 599 \t 116 ]\n",
      "9 \tObject: person \tConfidence = 0.4245 \tBbox: [ 473 \t 0 \t 502 \t 104 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000013 / 1050\n",
      "Frames to be processed: 1037  | To do: 98.76 % | Done: 1.24 %\n",
      "\n",
      "2022-04-20 13:10:34.941065\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000013.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 26.9ms pre-process, 180.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9033 \tBbox: [ 371 \t 738 \t 667 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8925 \tBbox: [ 473 \t 480 \t 626 \t 769 ]\n",
      "3 \tObject: person \tConfidence = 0.8858 \tBbox: [ 518 \t 118 \t 606 \t 348 ]\n",
      "4 \tObject: person \tConfidence = 0.8715 \tBbox: [ 430 \t 150 \t 521 \t 396 ]\n",
      "5 \tObject: person \tConfidence = 0.7997 \tBbox: [ 434 \t 0 \t 485 \t 138 ]\n",
      "6 \tObject: person \tConfidence = 0.7588 \tBbox: [ 566 \t 31 \t 638 \t 260 ]\n",
      "7 \tObject: person \tConfidence = 0.7419 \tBbox: [ 507 \t 0 \t 531 \t 44 ]\n",
      "8 \tObject: person \tConfidence = 0.6233 \tBbox: [ 554 \t 6 \t 600 \t 123 ]\n",
      "9 \tObject: person \tConfidence = 0.4194 \tBbox: [ 473 \t 0 \t 501 \t 105 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000014 / 1050\n",
      "Frames to be processed: 1036  | To do: 98.67 % | Done: 1.33 %\n",
      "\n",
      "2022-04-20 13:10:35.433308\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000014.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 25.1ms pre-process, 176.5ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9045 \tBbox: [ 371 \t 738 \t 667 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8956 \tBbox: [ 473 \t 480 \t 626 \t 769 ]\n",
      "3 \tObject: person \tConfidence = 0.8918 \tBbox: [ 518 \t 122 \t 610 \t 351 ]\n",
      "4 \tObject: person \tConfidence = 0.8737 \tBbox: [ 430 \t 150 \t 521 \t 397 ]\n",
      "5 \tObject: person \tConfidence = 0.7785 \tBbox: [ 434 \t 0 \t 486 \t 138 ]\n",
      "6 \tObject: person \tConfidence = 0.7542 \tBbox: [ 559 \t 29 \t 638 \t 260 ]\n",
      "7 \tObject: person \tConfidence = 0.7272 \tBbox: [ 507 \t 0 \t 531 \t 41 ]\n",
      "8 \tObject: person \tConfidence = 0.5883 \tBbox: [ 554 \t 4 \t 600 \t 122 ]\n",
      "9 \tObject: person \tConfidence = 0.3635 \tBbox: [ 474 \t 0 \t 501 \t 105 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000015 / 1050\n",
      "Frames to be processed: 1035  | To do: 98.57 % | Done: 1.43 %\n",
      "\n",
      "2022-04-20 13:10:35.899626\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000015.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 24.6ms pre-process, 168.6ms inference, 4.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9121 \tBbox: [ 370 \t 738 \t 668 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9015 \tBbox: [ 472 \t 479 \t 626 \t 768 ]\n",
      "3 \tObject: person \tConfidence = 0.8945 \tBbox: [ 519 \t 128 \t 609 \t 363 ]\n",
      "4 \tObject: person \tConfidence = 0.8768 \tBbox: [ 430 \t 150 \t 521 \t 395 ]\n",
      "5 \tObject: person \tConfidence = 0.7898 \tBbox: [ 434 \t 0 \t 485 \t 138 ]\n",
      "6 \tObject: person \tConfidence = 0.762 \tBbox: [ 555 \t 31 \t 637 \t 258 ]\n",
      "7 \tObject: person \tConfidence = 0.7074 \tBbox: [ 506 \t 0 \t 530 \t 40 ]\n",
      "8 \tObject: person \tConfidence = 0.5904 \tBbox: [ 553 \t 8 \t 601 \t 127 ]\n",
      "9 \tObject: person \tConfidence = 0.3608 \tBbox: [ 472 \t 0 \t 502 \t 105 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000016 / 1050\n",
      "Frames to be processed: 1034  | To do: 98.48 % | Done: 1.52 %\n",
      "\n",
      "2022-04-20 13:10:36.321749\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000016.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 32.0ms pre-process, 167.4ms inference, 3.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9148 \tBbox: [ 370 \t 738 \t 667 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8996 \tBbox: [ 520 \t 130 \t 611 \t 372 ]\n",
      "3 \tObject: person \tConfidence = 0.8961 \tBbox: [ 473 \t 480 \t 626 \t 768 ]\n",
      "4 \tObject: person \tConfidence = 0.8805 \tBbox: [ 430 \t 150 \t 521 \t 394 ]\n",
      "5 \tObject: person \tConfidence = 0.7884 \tBbox: [ 433 \t 0 \t 484 \t 138 ]\n",
      "6 \tObject: person \tConfidence = 0.6968 \tBbox: [ 561 \t 31 \t 638 \t 257 ]\n",
      "7 \tObject: person \tConfidence = 0.6877 \tBbox: [ 506 \t 0 \t 530 \t 39 ]\n",
      "8 \tObject: person \tConfidence = 0.6606 \tBbox: [ 553 \t 9 \t 601 \t 134 ]\n",
      "9 \tObject: person \tConfidence = 0.3364 \tBbox: [ 467 \t 0 \t 502 \t 106 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000017 / 1050\n",
      "Frames to be processed: 1033  | To do: 98.38 % | Done: 1.62 %\n",
      "\n",
      "2022-04-20 13:10:36.847584\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000017.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 31.3ms pre-process, 174.3ms inference, 4.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9131 \tBbox: [ 370 \t 737 \t 668 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9 \tBbox: [ 521 \t 134 \t 612 \t 377 ]\n",
      "3 \tObject: person \tConfidence = 0.8924 \tBbox: [ 473 \t 480 \t 626 \t 768 ]\n",
      "4 \tObject: person \tConfidence = 0.8791 \tBbox: [ 430 \t 150 \t 521 \t 394 ]\n",
      "5 \tObject: person \tConfidence = 0.789 \tBbox: [ 433 \t 0 \t 484 \t 138 ]\n",
      "6 \tObject: person \tConfidence = 0.6878 \tBbox: [ 553 \t 31 \t 638 \t 253 ]\n",
      "7 \tObject: person \tConfidence = 0.6466 \tBbox: [ 506 \t 0 \t 528 \t 39 ]\n",
      "8 \tObject: person \tConfidence = 0.6005 \tBbox: [ 554 \t 6 \t 600 \t 132 ]\n",
      "9 \tObject: person \tConfidence = 0.3678 \tBbox: [ 470 \t 0 \t 503 \t 105 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000018 / 1050\n",
      "Frames to be processed: 1032  | To do: 98.29 % | Done: 1.71 %\n",
      "\n",
      "2022-04-20 13:10:37.345513\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000018.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 26.8ms pre-process, 174.7ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9144 \tBbox: [ 370 \t 736 \t 668 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8896 \tBbox: [ 473 \t 480 \t 626 \t 767 ]\n",
      "3 \tObject: person \tConfidence = 0.8769 \tBbox: [ 430 \t 150 \t 521 \t 395 ]\n",
      "4 \tObject: person \tConfidence = 0.8682 \tBbox: [ 528 \t 143 \t 615 \t 391 ]\n",
      "5 \tObject: person \tConfidence = 0.7888 \tBbox: [ 433 \t 0 \t 484 \t 138 ]\n",
      "6 \tObject: person \tConfidence = 0.7059 \tBbox: [ 553 \t 31 \t 636 \t 192 ]\n",
      "7 \tObject: person \tConfidence = 0.661 \tBbox: [ 506 \t 0 \t 528 \t 38 ]\n",
      "8 \tObject: person \tConfidence = 0.5174 \tBbox: [ 554 \t 5 \t 600 \t 128 ]\n",
      "9 \tObject: person \tConfidence = 0.4517 \tBbox: [ 467 \t 0 \t 504 \t 105 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000019 / 1050\n",
      "Frames to be processed: 1031  | To do: 98.19 % | Done: 1.81 %\n",
      "\n",
      "2022-04-20 13:10:37.797162\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000019.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 27.6ms pre-process, 180.6ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9136 \tBbox: [ 370 \t 736 \t 668 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.887 \tBbox: [ 473 \t 479 \t 626 \t 767 ]\n",
      "3 \tObject: person \tConfidence = 0.8774 \tBbox: [ 429 \t 150 \t 521 \t 395 ]\n",
      "4 \tObject: person \tConfidence = 0.8709 \tBbox: [ 531 \t 147 \t 618 \t 396 ]\n",
      "5 \tObject: person \tConfidence = 0.7931 \tBbox: [ 433 \t 0 \t 483 \t 138 ]\n",
      "6 \tObject: person \tConfidence = 0.7018 \tBbox: [ 555 \t 31 \t 636 \t 206 ]\n",
      "7 \tObject: person \tConfidence = 0.6508 \tBbox: [ 506 \t 0 \t 528 \t 38 ]\n",
      "8 \tObject: person \tConfidence = 0.542 \tBbox: [ 553 \t 6 \t 599 \t 136 ]\n",
      "9 \tObject: person \tConfidence = 0.4773 \tBbox: [ 466 \t 0 \t 504 \t 105 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000020 / 1050\n",
      "Frames to be processed: 1030  | To do: 98.1 % | Done: 1.9 %\n",
      "\n",
      "2022-04-20 13:10:38.212198\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000020.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 25.9ms pre-process, 173.1ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9125 \tBbox: [ 369 \t 736 \t 668 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9002 \tBbox: [ 474 \t 479 \t 626 \t 766 ]\n",
      "3 \tObject: person \tConfidence = 0.8974 \tBbox: [ 533 \t 151 \t 621 \t 403 ]\n",
      "4 \tObject: person \tConfidence = 0.8811 \tBbox: [ 428 \t 150 \t 521 \t 395 ]\n",
      "5 \tObject: person \tConfidence = 0.7994 \tBbox: [ 433 \t 0 \t 483 \t 138 ]\n",
      "6 \tObject: person \tConfidence = 0.715 \tBbox: [ 558 \t 30 \t 636 \t 210 ]\n",
      "7 \tObject: person \tConfidence = 0.6416 \tBbox: [ 506 \t 0 \t 528 \t 37 ]\n",
      "8 \tObject: person \tConfidence = 0.5643 \tBbox: [ 552 \t 8 \t 599 \t 139 ]\n",
      "9 \tObject: person \tConfidence = 0.4734 \tBbox: [ 466 \t 0 \t 504 \t 105 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000021 / 1050\n",
      "Frames to be processed: 1029  | To do: 98.0 % | Done: 2.0 %\n",
      "\n",
      "2022-04-20 13:10:38.682024\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000021.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 30.6ms pre-process, 177.5ms inference, 11.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9213 \tBbox: [ 369 \t 735 \t 669 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8948 \tBbox: [ 534 \t 153 \t 625 \t 406 ]\n",
      "3 \tObject: person \tConfidence = 0.8912 \tBbox: [ 473 \t 478 \t 626 \t 766 ]\n",
      "4 \tObject: person \tConfidence = 0.8773 \tBbox: [ 429 \t 150 \t 521 \t 394 ]\n",
      "5 \tObject: person \tConfidence = 0.7918 \tBbox: [ 433 \t 0 \t 484 \t 138 ]\n",
      "6 \tObject: person \tConfidence = 0.7503 \tBbox: [ 562 \t 31 \t 637 \t 205 ]\n",
      "7 \tObject: person \tConfidence = 0.6082 \tBbox: [ 506 \t 0 \t 528 \t 37 ]\n",
      "8 \tObject: person \tConfidence = 0.5999 \tBbox: [ 552 \t 7 \t 599 \t 139 ]\n",
      "9 \tObject: person \tConfidence = 0.4759 \tBbox: [ 466 \t 0 \t 505 \t 105 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000022 / 1050\n",
      "Frames to be processed: 1028  | To do: 97.9 % | Done: 2.1 %\n",
      "\n",
      "2022-04-20 13:10:39.135451\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000022.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 26.0ms pre-process, 180.0ms inference, 3.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.92 \tBbox: [ 370 \t 734 \t 670 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8971 \tBbox: [ 534 \t 154 \t 628 \t 406 ]\n",
      "3 \tObject: person \tConfidence = 0.892 \tBbox: [ 473 \t 478 \t 626 \t 765 ]\n",
      "4 \tObject: person \tConfidence = 0.8766 \tBbox: [ 429 \t 150 \t 521 \t 395 ]\n",
      "5 \tObject: person \tConfidence = 0.7838 \tBbox: [ 433 \t 0 \t 483 \t 138 ]\n",
      "6 \tObject: person \tConfidence = 0.6942 \tBbox: [ 561 \t 32 \t 637 \t 205 ]\n",
      "7 \tObject: person \tConfidence = 0.5717 \tBbox: [ 506 \t 0 \t 527 \t 36 ]\n",
      "8 \tObject: person \tConfidence = 0.5582 \tBbox: [ 552 \t 6 \t 600 \t 142 ]\n",
      "9 \tObject: person \tConfidence = 0.5348 \tBbox: [ 465 \t 0 \t 504 \t 105 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000023 / 1050\n",
      "Frames to be processed: 1027  | To do: 97.81 % | Done: 2.19 %\n",
      "\n",
      "2022-04-20 13:10:39.594534\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000023.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 25.0ms pre-process, 172.0ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9238 \tBbox: [ 370 \t 734 \t 670 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8949 \tBbox: [ 537 \t 156 \t 634 \t 406 ]\n",
      "3 \tObject: person \tConfidence = 0.8942 \tBbox: [ 473 \t 478 \t 626 \t 764 ]\n",
      "4 \tObject: person \tConfidence = 0.8806 \tBbox: [ 428 \t 149 \t 521 \t 395 ]\n",
      "5 \tObject: person \tConfidence = 0.7871 \tBbox: [ 433 \t 0 \t 483 \t 137 ]\n",
      "6 \tObject: person \tConfidence = 0.6425 \tBbox: [ 562 \t 34 \t 638 \t 205 ]\n",
      "7 \tObject: person \tConfidence = 0.5842 \tBbox: [ 551 \t 6 \t 602 \t 147 ]\n",
      "8 \tObject: person \tConfidence = 0.565 \tBbox: [ 466 \t 0 \t 505 \t 104 ]\n",
      "9 \tObject: person \tConfidence = 0.5387 \tBbox: [ 507 \t 0 \t 527 \t 34 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000024 / 1050\n",
      "Frames to be processed: 1026  | To do: 97.71 % | Done: 2.29 %\n",
      "\n",
      "2022-04-20 13:10:40.065163\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000024.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 30.9ms pre-process, 174.6ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9229 \tBbox: [ 369 \t 734 \t 670 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9053 \tBbox: [ 537 \t 156 \t 636 \t 407 ]\n",
      "3 \tObject: person \tConfidence = 0.8965 \tBbox: [ 473 \t 478 \t 626 \t 763 ]\n",
      "4 \tObject: person \tConfidence = 0.881 \tBbox: [ 428 \t 149 \t 521 \t 396 ]\n",
      "5 \tObject: person \tConfidence = 0.7787 \tBbox: [ 434 \t 0 \t 482 \t 138 ]\n",
      "6 \tObject: person \tConfidence = 0.6162 \tBbox: [ 561 \t 33 \t 638 \t 205 ]\n",
      "7 \tObject: person \tConfidence = 0.6137 \tBbox: [ 465 \t 0 \t 505 \t 105 ]\n",
      "8 \tObject: person \tConfidence = 0.6108 \tBbox: [ 551 \t 5 \t 601 \t 144 ]\n",
      "9 \tObject: person \tConfidence = 0.5276 \tBbox: [ 508 \t 0 \t 527 \t 33 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000025 / 1050\n",
      "Frames to be processed: 1025  | To do: 97.62 % | Done: 2.38 %\n",
      "\n",
      "2022-04-20 13:10:40.556516\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000025.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 23.9ms pre-process, 176.1ms inference, 2.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9252 \tBbox: [ 369 \t 734 \t 670 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9054 \tBbox: [ 541 \t 156 \t 639 \t 408 ]\n",
      "3 \tObject: person \tConfidence = 0.894 \tBbox: [ 473 \t 479 \t 626 \t 762 ]\n",
      "4 \tObject: person \tConfidence = 0.8838 \tBbox: [ 427 \t 149 \t 521 \t 396 ]\n",
      "5 \tObject: person \tConfidence = 0.7837 \tBbox: [ 433 \t 0 \t 482 \t 137 ]\n",
      "6 \tObject: person \tConfidence = 0.6082 \tBbox: [ 551 \t 6 \t 601 \t 146 ]\n",
      "7 \tObject: person \tConfidence = 0.6041 \tBbox: [ 559 \t 33 \t 639 \t 200 ]\n",
      "8 \tObject: person \tConfidence = 0.6005 \tBbox: [ 465 \t 0 \t 505 \t 105 ]\n",
      "9 \tObject: person \tConfidence = 0.5559 \tBbox: [ 508 \t 0 \t 528 \t 34 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000026 / 1050\n",
      "Frames to be processed: 1024  | To do: 97.52 % | Done: 2.48 %\n",
      "\n",
      "2022-04-20 13:10:41.072708\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000026.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 26.3ms pre-process, 180.0ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.926 \tBbox: [ 369 \t 734 \t 669 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9165 \tBbox: [ 541 \t 159 \t 642 \t 409 ]\n",
      "3 \tObject: person \tConfidence = 0.8973 \tBbox: [ 473 \t 479 \t 626 \t 761 ]\n",
      "4 \tObject: person \tConfidence = 0.8829 \tBbox: [ 428 \t 149 \t 521 \t 395 ]\n",
      "5 \tObject: person \tConfidence = 0.7968 \tBbox: [ 433 \t 0 \t 482 \t 137 ]\n",
      "6 \tObject: person \tConfidence = 0.6199 \tBbox: [ 558 \t 33 \t 639 \t 195 ]\n",
      "7 \tObject: person \tConfidence = 0.6137 \tBbox: [ 465 \t 0 \t 505 \t 105 ]\n",
      "8 \tObject: person \tConfidence = 0.6098 \tBbox: [ 551 \t 5 \t 601 \t 153 ]\n",
      "9 \tObject: person \tConfidence = 0.5802 \tBbox: [ 507 \t 0 \t 528 \t 34 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000027 / 1050\n",
      "Frames to be processed: 1023  | To do: 97.43 % | Done: 2.57 %\n",
      "\n",
      "2022-04-20 13:10:41.551612\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000027.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 27.8ms pre-process, 181.8ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9263 \tBbox: [ 369 \t 733 \t 669 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9019 \tBbox: [ 543 \t 160 \t 645 \t 426 ]\n",
      "3 \tObject: person \tConfidence = 0.8963 \tBbox: [ 473 \t 479 \t 626 \t 760 ]\n",
      "4 \tObject: person \tConfidence = 0.8832 \tBbox: [ 428 \t 148 \t 521 \t 395 ]\n",
      "5 \tObject: person \tConfidence = 0.7894 \tBbox: [ 433 \t 0 \t 482 \t 137 ]\n",
      "6 \tObject: person \tConfidence = 0.6217 \tBbox: [ 465 \t 0 \t 505 \t 105 ]\n",
      "7 \tObject: person \tConfidence = 0.6111 \tBbox: [ 558 \t 32 \t 640 \t 187 ]\n",
      "8 \tObject: person \tConfidence = 0.5982 \tBbox: [ 551 \t 5 \t 601 \t 153 ]\n",
      "9 \tObject: person \tConfidence = 0.5834 \tBbox: [ 507 \t 0 \t 528 \t 33 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000028 / 1050\n",
      "Frames to be processed: 1022  | To do: 97.33 % | Done: 2.67 %\n",
      "\n",
      "2022-04-20 13:10:42.011752\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000028.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 31.8ms pre-process, 181.9ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9261 \tBbox: [ 369 \t 733 \t 669 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.903 \tBbox: [ 474 \t 479 \t 627 \t 761 ]\n",
      "3 \tObject: person \tConfidence = 0.8991 \tBbox: [ 545 \t 169 \t 650 \t 445 ]\n",
      "4 \tObject: person \tConfidence = 0.879 \tBbox: [ 429 \t 148 \t 522 \t 395 ]\n",
      "5 \tObject: person \tConfidence = 0.7878 \tBbox: [ 433 \t 0 \t 482 \t 137 ]\n",
      "6 \tObject: person \tConfidence = 0.7416 \tBbox: [ 559 \t 31 \t 640 \t 178 ]\n",
      "7 \tObject: person \tConfidence = 0.6749 \tBbox: [ 465 \t 0 \t 504 \t 105 ]\n",
      "8 \tObject: person \tConfidence = 0.6394 \tBbox: [ 551 \t 3 \t 600 \t 171 ]\n",
      "9 \tObject: person \tConfidence = 0.5715 \tBbox: [ 509 \t 0 \t 528 \t 30 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000029 / 1050\n",
      "Frames to be processed: 1021  | To do: 97.24 % | Done: 2.76 %\n",
      "\n",
      "2022-04-20 13:10:42.469936\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000029.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 24.8ms pre-process, 170.9ms inference, 3.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.928 \tBbox: [ 369 \t 732 \t 669 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9 \tBbox: [ 473 \t 479 \t 626 \t 760 ]\n",
      "3 \tObject: person \tConfidence = 0.8906 \tBbox: [ 546 \t 175 \t 652 \t 450 ]\n",
      "4 \tObject: person \tConfidence = 0.884 \tBbox: [ 428 \t 148 \t 522 \t 394 ]\n",
      "5 \tObject: person \tConfidence = 0.7766 \tBbox: [ 433 \t 0 \t 482 \t 136 ]\n",
      "6 \tObject: person \tConfidence = 0.6775 \tBbox: [ 559 \t 30 \t 640 \t 178 ]\n",
      "7 \tObject: person \tConfidence = 0.6696 \tBbox: [ 464 \t 0 \t 505 \t 105 ]\n",
      "8 \tObject: person \tConfidence = 0.6229 \tBbox: [ 551 \t 4 \t 600 \t 149 ]\n",
      "9 \tObject: person \tConfidence = 0.6005 \tBbox: [ 509 \t 0 \t 529 \t 29 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000030 / 1050\n",
      "Frames to be processed: 1020  | To do: 97.14 % | Done: 2.86 %\n",
      "\n",
      "2022-04-20 13:10:43.153126\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000030.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 26.1ms pre-process, 178.0ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9225 \tBbox: [ 369 \t 732 \t 668 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8976 \tBbox: [ 473 \t 479 \t 626 \t 760 ]\n",
      "3 \tObject: person \tConfidence = 0.8896 \tBbox: [ 427 \t 148 \t 522 \t 394 ]\n",
      "4 \tObject: person \tConfidence = 0.8578 \tBbox: [ 544 \t 180 \t 655 \t 457 ]\n",
      "5 \tObject: person \tConfidence = 0.7801 \tBbox: [ 433 \t 0 \t 482 \t 135 ]\n",
      "6 \tObject: person \tConfidence = 0.6735 \tBbox: [ 465 \t 0 \t 505 \t 105 ]\n",
      "7 \tObject: person \tConfidence = 0.638 \tBbox: [ 551 \t 4 \t 601 \t 153 ]\n",
      "8 \tObject: person \tConfidence = 0.613 \tBbox: [ 559 \t 31 \t 640 \t 186 ]\n",
      "9 \tObject: person \tConfidence = 0.5955 \tBbox: [ 510 \t 0 \t 529 \t 29 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000031 / 1050\n",
      "Frames to be processed: 1019  | To do: 97.05 % | Done: 2.95 %\n",
      "\n",
      "2022-04-20 13:10:43.761270\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000031.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 23.9ms pre-process, 181.3ms inference, 10.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9254 \tBbox: [ 369 \t 732 \t 667 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8849 \tBbox: [ 427 \t 148 \t 522 \t 396 ]\n",
      "3 \tObject: person \tConfidence = 0.871 \tBbox: [ 472 \t 479 \t 626 \t 761 ]\n",
      "4 \tObject: person \tConfidence = 0.8588 \tBbox: [ 543 \t 189 \t 658 \t 470 ]\n",
      "5 \tObject: person \tConfidence = 0.8054 \tBbox: [ 433 \t 0 \t 482 \t 135 ]\n",
      "6 \tObject: person \tConfidence = 0.6845 \tBbox: [ 465 \t 0 \t 505 \t 105 ]\n",
      "7 \tObject: person \tConfidence = 0.6489 \tBbox: [ 551 \t 4 \t 601 \t 176 ]\n",
      "8 \tObject: person \tConfidence = 0.6207 \tBbox: [ 561 \t 31 \t 640 \t 193 ]\n",
      "9 \tObject: person \tConfidence = 0.6051 \tBbox: [ 511 \t 0 \t 529 \t 29 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000032 / 1050\n",
      "Frames to be processed: 1018  | To do: 96.95 % | Done: 3.05 %\n",
      "\n",
      "2022-04-20 13:10:44.341212\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000032.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 25.9ms pre-process, 181.4ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9251 \tBbox: [ 369 \t 731 \t 667 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8979 \tBbox: [ 549 \t 193 \t 658 \t 476 ]\n",
      "3 \tObject: person \tConfidence = 0.8881 \tBbox: [ 473 \t 478 \t 626 \t 759 ]\n",
      "4 \tObject: person \tConfidence = 0.8865 \tBbox: [ 428 \t 148 \t 522 \t 396 ]\n",
      "5 \tObject: person \tConfidence = 0.7874 \tBbox: [ 433 \t 0 \t 482 \t 135 ]\n",
      "6 \tObject: person \tConfidence = 0.7027 \tBbox: [ 551 \t 4 \t 601 \t 177 ]\n",
      "7 \tObject: person \tConfidence = 0.6719 \tBbox: [ 464 \t 0 \t 506 \t 105 ]\n",
      "8 \tObject: person \tConfidence = 0.6328 \tBbox: [ 561 \t 29 \t 642 \t 228 ]\n",
      "9 \tObject: person \tConfidence = 0.6127 \tBbox: [ 512 \t 0 \t 530 \t 29 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000033 / 1050\n",
      "Frames to be processed: 1017  | To do: 96.86 % | Done: 3.14 %\n",
      "\n",
      "2022-04-20 13:10:44.763749\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000033.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 29.1ms pre-process, 175.2ms inference, 11.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9234 \tBbox: [ 369 \t 730 \t 667 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8875 \tBbox: [ 473 \t 478 \t 626 \t 759 ]\n",
      "3 \tObject: person \tConfidence = 0.8838 \tBbox: [ 551 \t 198 \t 661 \t 479 ]\n",
      "4 \tObject: person \tConfidence = 0.8833 \tBbox: [ 428 \t 148 \t 522 \t 395 ]\n",
      "5 \tObject: person \tConfidence = 0.8205 \tBbox: [ 562 \t 30 \t 641 \t 243 ]\n",
      "6 \tObject: person \tConfidence = 0.7916 \tBbox: [ 433 \t 0 \t 482 \t 135 ]\n",
      "7 \tObject: person \tConfidence = 0.6919 \tBbox: [ 551 \t 3 \t 601 \t 179 ]\n",
      "8 \tObject: person \tConfidence = 0.663 \tBbox: [ 465 \t 0 \t 506 \t 105 ]\n",
      "9 \tObject: person \tConfidence = 0.5941 \tBbox: [ 512 \t 0 \t 530 \t 28 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000034 / 1050\n",
      "Frames to be processed: 1016  | To do: 96.76 % | Done: 3.24 %\n",
      "\n",
      "2022-04-20 13:10:45.226335\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000034.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 27.3ms pre-process, 178.2ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9233 \tBbox: [ 370 \t 731 \t 667 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8984 \tBbox: [ 473 \t 477 \t 625 \t 759 ]\n",
      "3 \tObject: person \tConfidence = 0.8959 \tBbox: [ 558 \t 202 \t 664 \t 478 ]\n",
      "4 \tObject: person \tConfidence = 0.8822 \tBbox: [ 427 \t 148 \t 522 \t 394 ]\n",
      "5 \tObject: person \tConfidence = 0.8253 \tBbox: [ 562 \t 29 \t 641 \t 244 ]\n",
      "6 \tObject: person \tConfidence = 0.7941 \tBbox: [ 433 \t 0 \t 482 \t 135 ]\n",
      "7 \tObject: person \tConfidence = 0.7168 \tBbox: [ 551 \t 3 \t 600 \t 179 ]\n",
      "8 \tObject: person \tConfidence = 0.6939 \tBbox: [ 464 \t 0 \t 507 \t 105 ]\n",
      "9 \tObject: person \tConfidence = 0.5949 \tBbox: [ 513 \t 0 \t 530 \t 28 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000035 / 1050\n",
      "Frames to be processed: 1015  | To do: 96.67 % | Done: 3.33 %\n",
      "\n",
      "2022-04-20 13:10:45.655249\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000035.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 28.9ms pre-process, 168.9ms inference, 3.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9227 \tBbox: [ 370 \t 730 \t 668 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9048 \tBbox: [ 474 \t 477 \t 625 \t 758 ]\n",
      "3 \tObject: person \tConfidence = 0.9004 \tBbox: [ 558 \t 203 \t 667 \t 478 ]\n",
      "4 \tObject: person \tConfidence = 0.8852 \tBbox: [ 427 \t 148 \t 522 \t 394 ]\n",
      "5 \tObject: person \tConfidence = 0.8233 \tBbox: [ 562 \t 29 \t 641 \t 245 ]\n",
      "6 \tObject: person \tConfidence = 0.8075 \tBbox: [ 433 \t 0 \t 483 \t 135 ]\n",
      "7 \tObject: person \tConfidence = 0.7357 \tBbox: [ 551 \t 3 \t 601 \t 179 ]\n",
      "8 \tObject: person \tConfidence = 0.6921 \tBbox: [ 465 \t 0 \t 507 \t 105 ]\n",
      "9 \tObject: person \tConfidence = 0.6076 \tBbox: [ 513 \t 0 \t 530 \t 28 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000036 / 1050\n",
      "Frames to be processed: 1014  | To do: 96.57 % | Done: 3.43 %\n",
      "\n",
      "2022-04-20 13:10:46.076230\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000036.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 37.9ms pre-process, 173.9ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.926 \tBbox: [ 370 \t 730 \t 668 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.905 \tBbox: [ 474 \t 477 \t 625 \t 757 ]\n",
      "3 \tObject: person \tConfidence = 0.903 \tBbox: [ 558 \t 203 \t 670 \t 479 ]\n",
      "4 \tObject: person \tConfidence = 0.8839 \tBbox: [ 427 \t 148 \t 522 \t 393 ]\n",
      "5 \tObject: person \tConfidence = 0.8198 \tBbox: [ 563 \t 29 \t 642 \t 243 ]\n",
      "6 \tObject: person \tConfidence = 0.8112 \tBbox: [ 433 \t 0 \t 482 \t 136 ]\n",
      "7 \tObject: person \tConfidence = 0.743 \tBbox: [ 551 \t 4 \t 601 \t 179 ]\n",
      "8 \tObject: person \tConfidence = 0.6886 \tBbox: [ 465 \t 0 \t 507 \t 105 ]\n",
      "9 \tObject: person \tConfidence = 0.594 \tBbox: [ 513 \t 0 \t 529 \t 28 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000037 / 1050\n",
      "Frames to be processed: 1013  | To do: 96.48 % | Done: 3.52 %\n",
      "\n",
      "2022-04-20 13:10:46.520176\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000037.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 31.5ms pre-process, 173.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9248 \tBbox: [ 370 \t 730 \t 668 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9042 \tBbox: [ 474 \t 477 \t 625 \t 757 ]\n",
      "3 \tObject: person \tConfidence = 0.9037 \tBbox: [ 560 \t 204 \t 673 \t 480 ]\n",
      "4 \tObject: person \tConfidence = 0.881 \tBbox: [ 428 \t 148 \t 523 \t 392 ]\n",
      "5 \tObject: person \tConfidence = 0.8243 \tBbox: [ 433 \t 0 \t 481 \t 136 ]\n",
      "6 \tObject: person \tConfidence = 0.8165 \tBbox: [ 564 \t 29 \t 642 \t 242 ]\n",
      "7 \tObject: person \tConfidence = 0.7285 \tBbox: [ 551 \t 3 \t 601 \t 179 ]\n",
      "8 \tObject: person \tConfidence = 0.7021 \tBbox: [ 465 \t 0 \t 507 \t 104 ]\n",
      "9 \tObject: person \tConfidence = 0.5899 \tBbox: [ 513 \t 0 \t 529 \t 28 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000038 / 1050\n",
      "Frames to be processed: 1012  | To do: 96.38 % | Done: 3.62 %\n",
      "\n",
      "2022-04-20 13:10:46.936879\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000038.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 30.9ms pre-process, 177.7ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9252 \tBbox: [ 370 \t 729 \t 668 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9093 \tBbox: [ 563 \t 211 \t 679 \t 504 ]\n",
      "3 \tObject: person \tConfidence = 0.8965 \tBbox: [ 473 \t 477 \t 626 \t 758 ]\n",
      "4 \tObject: person \tConfidence = 0.8775 \tBbox: [ 433 \t 148 \t 523 \t 394 ]\n",
      "5 \tObject: person \tConfidence = 0.8265 \tBbox: [ 563 \t 27 \t 642 \t 249 ]\n",
      "6 \tObject: person \tConfidence = 0.8203 \tBbox: [ 433 \t 0 \t 482 \t 136 ]\n",
      "7 \tObject: person \tConfidence = 0.7427 \tBbox: [ 551 \t 3 \t 601 \t 179 ]\n",
      "8 \tObject: person \tConfidence = 0.7027 \tBbox: [ 465 \t 0 \t 506 \t 105 ]\n",
      "9 \tObject: person \tConfidence = 0.6196 \tBbox: [ 513 \t 0 \t 529 \t 28 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000039 / 1050\n",
      "Frames to be processed: 1011  | To do: 96.29 % | Done: 3.71 %\n",
      "\n",
      "2022-04-20 13:10:47.419745\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000039.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 30.7ms pre-process, 175.0ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9249 \tBbox: [ 370 \t 729 \t 668 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9047 \tBbox: [ 563 \t 217 \t 680 \t 519 ]\n",
      "3 \tObject: person \tConfidence = 0.8984 \tBbox: [ 473 \t 476 \t 627 \t 757 ]\n",
      "4 \tObject: person \tConfidence = 0.866 \tBbox: [ 438 \t 148 \t 523 \t 393 ]\n",
      "5 \tObject: person \tConfidence = 0.8265 \tBbox: [ 562 \t 27 \t 642 \t 252 ]\n",
      "6 \tObject: person \tConfidence = 0.8133 \tBbox: [ 432 \t 0 \t 482 \t 136 ]\n",
      "7 \tObject: person \tConfidence = 0.7305 \tBbox: [ 551 \t 3 \t 601 \t 179 ]\n",
      "8 \tObject: person \tConfidence = 0.7002 \tBbox: [ 465 \t 0 \t 506 \t 104 ]\n",
      "9 \tObject: person \tConfidence = 0.6032 \tBbox: [ 513 \t 0 \t 530 \t 28 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000040 / 1050\n",
      "Frames to be processed: 1010  | To do: 96.19 % | Done: 3.81 %\n",
      "\n",
      "2022-04-20 13:10:47.880729\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000040.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 28.2ms pre-process, 171.0ms inference, 10.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9258 \tBbox: [ 370 \t 729 \t 669 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9011 \tBbox: [ 473 \t 477 \t 625 \t 757 ]\n",
      "3 \tObject: person \tConfidence = 0.8856 \tBbox: [ 563 \t 222 \t 681 \t 526 ]\n",
      "4 \tObject: person \tConfidence = 0.8533 \tBbox: [ 442 \t 149 \t 524 \t 394 ]\n",
      "5 \tObject: person \tConfidence = 0.8421 \tBbox: [ 563 \t 27 \t 642 \t 256 ]\n",
      "6 \tObject: person \tConfidence = 0.811 \tBbox: [ 432 \t 0 \t 481 \t 135 ]\n",
      "7 \tObject: person \tConfidence = 0.7566 \tBbox: [ 551 \t 3 \t 602 \t 179 ]\n",
      "8 \tObject: person \tConfidence = 0.703 \tBbox: [ 465 \t 0 \t 507 \t 105 ]\n",
      "9 \tObject: person \tConfidence = 0.5835 \tBbox: [ 513 \t 0 \t 530 \t 28 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000041 / 1050\n",
      "Frames to be processed: 1009  | To do: 96.1 % | Done: 3.9 %\n",
      "\n",
      "2022-04-20 13:10:48.299632\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000041.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 37.1ms pre-process, 176.7ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9237 \tBbox: [ 371 \t 729 \t 668 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8968 \tBbox: [ 473 \t 477 \t 626 \t 757 ]\n",
      "3 \tObject: person \tConfidence = 0.8754 \tBbox: [ 565 \t 230 \t 683 \t 537 ]\n",
      "4 \tObject: person \tConfidence = 0.8548 \tBbox: [ 564 \t 27 \t 642 \t 259 ]\n",
      "5 \tObject: person \tConfidence = 0.8507 \tBbox: [ 443 \t 148 \t 524 \t 395 ]\n",
      "6 \tObject: person \tConfidence = 0.8149 \tBbox: [ 432 \t 0 \t 480 \t 136 ]\n",
      "7 \tObject: person \tConfidence = 0.7897 \tBbox: [ 552 \t 4 \t 602 \t 179 ]\n",
      "8 \tObject: person \tConfidence = 0.7099 \tBbox: [ 466 \t 0 \t 505 \t 105 ]\n",
      "9 \tObject: person \tConfidence = 0.599 \tBbox: [ 514 \t 0 \t 530 \t 28 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000042 / 1050\n",
      "Frames to be processed: 1008  | To do: 96.0 % | Done: 4.0 %\n",
      "\n",
      "2022-04-20 13:10:48.743460\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000042.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 25.2ms pre-process, 180.1ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9253 \tBbox: [ 371 \t 729 \t 668 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9005 \tBbox: [ 473 \t 477 \t 627 \t 757 ]\n",
      "3 \tObject: person \tConfidence = 0.8902 \tBbox: [ 567 \t 238 \t 686 \t 545 ]\n",
      "4 \tObject: person \tConfidence = 0.8615 \tBbox: [ 564 \t 26 \t 642 \t 259 ]\n",
      "5 \tObject: person \tConfidence = 0.8411 \tBbox: [ 443 \t 148 \t 524 \t 396 ]\n",
      "6 \tObject: person \tConfidence = 0.8197 \tBbox: [ 432 \t 0 \t 480 \t 136 ]\n",
      "7 \tObject: person \tConfidence = 0.7908 \tBbox: [ 552 \t 4 \t 602 \t 179 ]\n",
      "8 \tObject: person \tConfidence = 0.7238 \tBbox: [ 466 \t 0 \t 506 \t 105 ]\n",
      "9 \tObject: person \tConfidence = 0.5412 \tBbox: [ 515 \t 0 \t 530 \t 27 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000043 / 1050\n",
      "Frames to be processed: 1007  | To do: 95.9 % | Done: 4.1 %\n",
      "\n",
      "2022-04-20 13:10:49.174873\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000043.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 27.0ms pre-process, 171.8ms inference, 4.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9251 \tBbox: [ 370 \t 729 \t 668 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9066 \tBbox: [ 474 \t 477 \t 623 \t 757 ]\n",
      "3 \tObject: person \tConfidence = 0.8836 \tBbox: [ 567 \t 250 \t 694 \t 566 ]\n",
      "4 \tObject: person \tConfidence = 0.8691 \tBbox: [ 564 \t 26 \t 643 \t 260 ]\n",
      "5 \tObject: person \tConfidence = 0.8274 \tBbox: [ 443 \t 148 \t 525 \t 394 ]\n",
      "6 \tObject: person \tConfidence = 0.8269 \tBbox: [ 432 \t 0 \t 482 \t 136 ]\n",
      "7 \tObject: person \tConfidence = 0.7852 \tBbox: [ 551 \t 3 \t 602 \t 178 ]\n",
      "8 \tObject: person \tConfidence = 0.7031 \tBbox: [ 466 \t 0 \t 505 \t 105 ]\n",
      "9 \tObject: person \tConfidence = 0.4383 \tBbox: [ 516 \t 0 \t 530 \t 20 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000044 / 1050\n",
      "Frames to be processed: 1006  | To do: 95.81 % | Done: 4.19 %\n",
      "\n",
      "2022-04-20 13:10:49.587683\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000044.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 35.8ms pre-process, 175.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9261 \tBbox: [ 371 \t 729 \t 668 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9012 \tBbox: [ 575 \t 254 \t 700 \t 569 ]\n",
      "3 \tObject: person \tConfidence = 0.9009 \tBbox: [ 473 \t 477 \t 622 \t 758 ]\n",
      "4 \tObject: person \tConfidence = 0.8692 \tBbox: [ 565 \t 26 \t 643 \t 259 ]\n",
      "5 \tObject: person \tConfidence = 0.8257 \tBbox: [ 432 \t 0 \t 481 \t 135 ]\n",
      "6 \tObject: person \tConfidence = 0.8217 \tBbox: [ 444 \t 148 \t 526 \t 394 ]\n",
      "7 \tObject: person \tConfidence = 0.8041 \tBbox: [ 551 \t 3 \t 603 \t 178 ]\n",
      "8 \tObject: person \tConfidence = 0.7256 \tBbox: [ 466 \t 0 \t 505 \t 105 ]\n",
      "9 \tObject: person \tConfidence = 0.4378 \tBbox: [ 516 \t 0 \t 530 \t 20 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000045 / 1050\n",
      "Frames to be processed: 1005  | To do: 95.71 % | Done: 4.29 %\n",
      "\n",
      "2022-04-20 13:10:50.045829\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000045.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 34.4ms pre-process, 164.4ms inference, 3.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9244 \tBbox: [ 371 \t 729 \t 668 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9011 \tBbox: [ 473 \t 477 \t 623 \t 758 ]\n",
      "3 \tObject: person \tConfidence = 0.8957 \tBbox: [ 571 \t 257 \t 704 \t 571 ]\n",
      "4 \tObject: person \tConfidence = 0.8726 \tBbox: [ 564 \t 25 \t 643 \t 259 ]\n",
      "5 \tObject: person \tConfidence = 0.8386 \tBbox: [ 432 \t 0 \t 481 \t 135 ]\n",
      "6 \tObject: person \tConfidence = 0.8285 \tBbox: [ 445 \t 148 \t 525 \t 392 ]\n",
      "7 \tObject: person \tConfidence = 0.7994 \tBbox: [ 551 \t 3 \t 603 \t 178 ]\n",
      "8 \tObject: person \tConfidence = 0.706 \tBbox: [ 466 \t 0 \t 505 \t 105 ]\n",
      "9 \tObject: person \tConfidence = 0.4701 \tBbox: [ 515 \t 0 \t 530 \t 20 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000046 / 1050\n",
      "Frames to be processed: 1004  | To do: 95.62 % | Done: 4.38 %\n",
      "\n",
      "2022-04-20 13:10:50.501881\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000046.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 36.0ms pre-process, 174.4ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9251 \tBbox: [ 371 \t 728 \t 669 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9063 \tBbox: [ 475 \t 478 \t 623 \t 758 ]\n",
      "3 \tObject: person \tConfidence = 0.8962 \tBbox: [ 569 \t 259 \t 708 \t 571 ]\n",
      "4 \tObject: person \tConfidence = 0.8755 \tBbox: [ 566 \t 25 \t 643 \t 259 ]\n",
      "5 \tObject: person \tConfidence = 0.8422 \tBbox: [ 432 \t 0 \t 481 \t 136 ]\n",
      "6 \tObject: person \tConfidence = 0.8345 \tBbox: [ 446 \t 148 \t 525 \t 392 ]\n",
      "7 \tObject: person \tConfidence = 0.81 \tBbox: [ 552 \t 2 \t 603 \t 178 ]\n",
      "8 \tObject: person \tConfidence = 0.7081 \tBbox: [ 467 \t 0 \t 505 \t 104 ]\n",
      "9 \tObject: person \tConfidence = 0.4466 \tBbox: [ 516 \t 0 \t 530 \t 19 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000047 / 1050\n",
      "Frames to be processed: 1003  | To do: 95.52 % | Done: 4.48 %\n",
      "\n",
      "2022-04-20 13:10:50.999139\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000047.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 27.4ms pre-process, 180.8ms inference, 12.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9197 \tBbox: [ 370 \t 728 \t 668 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9056 \tBbox: [ 573 \t 261 \t 710 \t 571 ]\n",
      "3 \tObject: person \tConfidence = 0.9052 \tBbox: [ 475 \t 478 \t 623 \t 758 ]\n",
      "4 \tObject: person \tConfidence = 0.876 \tBbox: [ 565 \t 25 \t 643 \t 259 ]\n",
      "5 \tObject: person \tConfidence = 0.8449 \tBbox: [ 432 \t 0 \t 481 \t 136 ]\n",
      "6 \tObject: person \tConfidence = 0.8366 \tBbox: [ 446 \t 148 \t 525 \t 392 ]\n",
      "7 \tObject: person \tConfidence = 0.8075 \tBbox: [ 552 \t 2 \t 603 \t 177 ]\n",
      "8 \tObject: person \tConfidence = 0.7082 \tBbox: [ 467 \t 0 \t 505 \t 104 ]\n",
      "9 \tObject: person \tConfidence = 0.4911 \tBbox: [ 516 \t 0 \t 531 \t 20 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000048 / 1050\n",
      "Frames to be processed: 1002  | To do: 95.43 % | Done: 4.57 %\n",
      "\n",
      "2022-04-20 13:10:51.440715\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000048.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 36.1ms pre-process, 180.5ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9189 \tBbox: [ 371 \t 729 \t 668 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9031 \tBbox: [ 475 \t 478 \t 623 \t 758 ]\n",
      "3 \tObject: person \tConfidence = 0.8947 \tBbox: [ 578 \t 264 \t 713 \t 572 ]\n",
      "4 \tObject: person \tConfidence = 0.8741 \tBbox: [ 565 \t 25 \t 644 \t 259 ]\n",
      "5 \tObject: person \tConfidence = 0.8533 \tBbox: [ 432 \t 0 \t 480 \t 136 ]\n",
      "6 \tObject: person \tConfidence = 0.8366 \tBbox: [ 447 \t 147 \t 525 \t 392 ]\n",
      "7 \tObject: person \tConfidence = 0.7945 \tBbox: [ 552 \t 2 \t 604 \t 177 ]\n",
      "8 \tObject: person \tConfidence = 0.705 \tBbox: [ 467 \t 0 \t 506 \t 104 ]\n",
      "9 \tObject: person \tConfidence = 0.5284 \tBbox: [ 516 \t 0 \t 531 \t 21 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000049 / 1050\n",
      "Frames to be processed: 1001  | To do: 95.33 % | Done: 4.67 %\n",
      "\n",
      "2022-04-20 13:10:51.879666\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000049.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 32.1ms pre-process, 170.1ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9154 \tBbox: [ 371 \t 729 \t 668 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9014 \tBbox: [ 474 \t 478 \t 625 \t 758 ]\n",
      "3 \tObject: person \tConfidence = 0.8953 \tBbox: [ 583 \t 272 \t 723 \t 574 ]\n",
      "4 \tObject: person \tConfidence = 0.8692 \tBbox: [ 565 \t 25 \t 644 \t 258 ]\n",
      "5 \tObject: person \tConfidence = 0.8476 \tBbox: [ 432 \t 0 \t 481 \t 137 ]\n",
      "6 \tObject: person \tConfidence = 0.8451 \tBbox: [ 446 \t 147 \t 525 \t 391 ]\n",
      "7 \tObject: person \tConfidence = 0.7977 \tBbox: [ 552 \t 2 \t 604 \t 177 ]\n",
      "8 \tObject: person \tConfidence = 0.7103 \tBbox: [ 467 \t 0 \t 505 \t 104 ]\n",
      "9 \tObject: person \tConfidence = 0.4872 \tBbox: [ 518 \t 0 \t 532 \t 20 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000050 / 1050\n",
      "Frames to be processed: 1000  | To do: 95.24 % | Done: 4.76 %\n",
      "\n",
      "2022-04-20 13:10:52.332612\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000050.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 27.0ms pre-process, 174.6ms inference, 2.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9187 \tBbox: [ 371 \t 729 \t 670 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8995 \tBbox: [ 476 \t 477 \t 626 \t 757 ]\n",
      "3 \tObject: person \tConfidence = 0.8909 \tBbox: [ 584 \t 279 \t 730 \t 574 ]\n",
      "4 \tObject: person \tConfidence = 0.8702 \tBbox: [ 565 \t 24 \t 644 \t 258 ]\n",
      "5 \tObject: person \tConfidence = 0.852 \tBbox: [ 432 \t 0 \t 481 \t 137 ]\n",
      "6 \tObject: person \tConfidence = 0.8486 \tBbox: [ 446 \t 147 \t 524 \t 391 ]\n",
      "7 \tObject: person \tConfidence = 0.801 \tBbox: [ 553 \t 2 \t 604 \t 177 ]\n",
      "8 \tObject: person \tConfidence = 0.7272 \tBbox: [ 467 \t 0 \t 507 \t 104 ]\n",
      "9 \tObject: person \tConfidence = 0.4209 \tBbox: [ 517 \t 0 \t 532 \t 19 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000051 / 1050\n",
      "Frames to be processed: 999  | To do: 95.14 % | Done: 4.86 %\n",
      "\n",
      "2022-04-20 13:10:52.793252\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000051.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 31.0ms pre-process, 168.2ms inference, 3.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9163 \tBbox: [ 371 \t 729 \t 669 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9021 \tBbox: [ 476 \t 477 \t 627 \t 758 ]\n",
      "3 \tObject: person \tConfidence = 0.8975 \tBbox: [ 585 \t 286 \t 736 \t 629 ]\n",
      "4 \tObject: person \tConfidence = 0.8674 \tBbox: [ 564 \t 25 \t 644 \t 257 ]\n",
      "5 \tObject: person \tConfidence = 0.8559 \tBbox: [ 432 \t 0 \t 481 \t 137 ]\n",
      "6 \tObject: person \tConfidence = 0.8486 \tBbox: [ 445 \t 146 \t 524 \t 392 ]\n",
      "7 \tObject: person \tConfidence = 0.7877 \tBbox: [ 553 \t 2 \t 604 \t 177 ]\n",
      "8 \tObject: person \tConfidence = 0.7343 \tBbox: [ 467 \t 0 \t 507 \t 104 ]\n",
      "9 \tObject: person \tConfidence = 0.4466 \tBbox: [ 518 \t 0 \t 533 \t 20 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000052 / 1050\n",
      "Frames to be processed: 998  | To do: 95.05 % | Done: 4.95 %\n",
      "\n",
      "2022-04-20 13:10:53.259546\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000052.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 28.3ms pre-process, 173.3ms inference, 4.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9183 \tBbox: [ 371 \t 729 \t 670 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.909 \tBbox: [ 584 \t 294 \t 742 \t 638 ]\n",
      "3 \tObject: person \tConfidence = 0.8929 \tBbox: [ 475 \t 477 \t 628 \t 758 ]\n",
      "4 \tObject: person \tConfidence = 0.8684 \tBbox: [ 564 \t 24 \t 644 \t 257 ]\n",
      "5 \tObject: person \tConfidence = 0.8607 \tBbox: [ 432 \t 0 \t 481 \t 137 ]\n",
      "6 \tObject: person \tConfidence = 0.8456 \tBbox: [ 446 \t 146 \t 524 \t 392 ]\n",
      "7 \tObject: person \tConfidence = 0.7841 \tBbox: [ 554 \t 3 \t 604 \t 177 ]\n",
      "8 \tObject: person \tConfidence = 0.7354 \tBbox: [ 467 \t 0 \t 507 \t 104 ]\n",
      "9 \tObject: person \tConfidence = 0.4137 \tBbox: [ 518 \t 0 \t 533 \t 20 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000053 / 1050\n",
      "Frames to be processed: 997  | To do: 94.95 % | Done: 5.05 %\n",
      "\n",
      "2022-04-20 13:10:53.691801\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000053.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 30.0ms pre-process, 180.2ms inference, 6.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9209 \tBbox: [ 372 \t 729 \t 671 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9016 \tBbox: [ 589 \t 302 \t 746 \t 661 ]\n",
      "3 \tObject: person \tConfidence = 0.8969 \tBbox: [ 476 \t 477 \t 628 \t 758 ]\n",
      "4 \tObject: person \tConfidence = 0.8681 \tBbox: [ 565 \t 25 \t 645 \t 258 ]\n",
      "5 \tObject: person \tConfidence = 0.8583 \tBbox: [ 431 \t 0 \t 480 \t 137 ]\n",
      "6 \tObject: person \tConfidence = 0.8254 \tBbox: [ 445 \t 144 \t 525 \t 393 ]\n",
      "7 \tObject: person \tConfidence = 0.801 \tBbox: [ 553 \t 2 \t 604 \t 177 ]\n",
      "8 \tObject: person \tConfidence = 0.7325 \tBbox: [ 467 \t 0 \t 508 \t 104 ]\n",
      "9 \tObject: person \tConfidence = 0.4428 \tBbox: [ 518 \t 0 \t 533 \t 21 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000054 / 1050\n",
      "Frames to be processed: 996  | To do: 94.86 % | Done: 5.14 %\n",
      "\n",
      "2022-04-20 13:10:54.144395\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000054.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 28.3ms pre-process, 173.0ms inference, 13.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9191 \tBbox: [ 372 \t 729 \t 671 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9107 \tBbox: [ 592 \t 320 \t 752 \t 683 ]\n",
      "3 \tObject: person \tConfidence = 0.8893 \tBbox: [ 475 \t 475 \t 630 \t 759 ]\n",
      "4 \tObject: person \tConfidence = 0.8688 \tBbox: [ 565 \t 25 \t 645 \t 258 ]\n",
      "5 \tObject: person \tConfidence = 0.8547 \tBbox: [ 431 \t 0 \t 480 \t 137 ]\n",
      "6 \tObject: person \tConfidence = 0.8378 \tBbox: [ 446 \t 144 \t 525 \t 390 ]\n",
      "7 \tObject: person \tConfidence = 0.7989 \tBbox: [ 554 \t 3 \t 605 \t 177 ]\n",
      "8 \tObject: person \tConfidence = 0.7466 \tBbox: [ 467 \t 0 \t 506 \t 104 ]\n",
      "9 \tObject: person \tConfidence = 0.4763 \tBbox: [ 519 \t 0 \t 533 \t 21 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000055 / 1050\n",
      "Frames to be processed: 995  | To do: 94.76 % | Done: 5.24 %\n",
      "\n",
      "2022-04-20 13:10:54.589726\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000055.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 26.1ms pre-process, 176.6ms inference, 2.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9182 \tBbox: [ 373 \t 729 \t 671 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9057 \tBbox: [ 594 \t 325 \t 755 \t 690 ]\n",
      "3 \tObject: person \tConfidence = 0.8874 \tBbox: [ 474 \t 476 \t 631 \t 761 ]\n",
      "4 \tObject: person \tConfidence = 0.8665 \tBbox: [ 565 \t 25 \t 645 \t 257 ]\n",
      "5 \tObject: person \tConfidence = 0.8592 \tBbox: [ 431 \t 0 \t 480 \t 137 ]\n",
      "6 \tObject: person \tConfidence = 0.8359 \tBbox: [ 446 \t 141 \t 525 \t 392 ]\n",
      "7 \tObject: person \tConfidence = 0.7784 \tBbox: [ 554 \t 3 \t 605 \t 177 ]\n",
      "8 \tObject: person \tConfidence = 0.7497 \tBbox: [ 467 \t 0 \t 506 \t 104 ]\n",
      "9 \tObject: person \tConfidence = 0.4718 \tBbox: [ 519 \t 0 \t 532 \t 20 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000056 / 1050\n",
      "Frames to be processed: 994  | To do: 94.67 % | Done: 5.33 %\n",
      "\n",
      "2022-04-20 13:10:55.030774\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000056.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 26.2ms pre-process, 180.1ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9168 \tBbox: [ 372 \t 729 \t 670 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9103 \tBbox: [ 596 \t 331 \t 759 \t 695 ]\n",
      "3 \tObject: person \tConfidence = 0.8877 \tBbox: [ 475 \t 477 \t 628 \t 759 ]\n",
      "4 \tObject: person \tConfidence = 0.8677 \tBbox: [ 565 \t 25 \t 645 \t 257 ]\n",
      "5 \tObject: person \tConfidence = 0.8508 \tBbox: [ 431 \t 0 \t 480 \t 137 ]\n",
      "6 \tObject: person \tConfidence = 0.8456 \tBbox: [ 447 \t 142 \t 525 \t 391 ]\n",
      "7 \tObject: person \tConfidence = 0.7616 \tBbox: [ 467 \t 0 \t 506 \t 104 ]\n",
      "8 \tObject: person \tConfidence = 0.7504 \tBbox: [ 555 \t 3 \t 605 \t 177 ]\n",
      "9 \tObject: person \tConfidence = 0.4251 \tBbox: [ 519 \t 0 \t 532 \t 19 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000057 / 1050\n",
      "Frames to be processed: 993  | To do: 94.57 % | Done: 5.43 %\n",
      "\n",
      "2022-04-20 13:10:55.443813\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000057.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 28.2ms pre-process, 171.4ms inference, 4.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9166 \tBbox: [ 373 \t 730 \t 669 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9153 \tBbox: [ 596 \t 336 \t 760 \t 695 ]\n",
      "3 \tObject: person \tConfidence = 0.8958 \tBbox: [ 475 \t 477 \t 629 \t 759 ]\n",
      "4 \tObject: person \tConfidence = 0.8686 \tBbox: [ 565 \t 25 \t 645 \t 257 ]\n",
      "5 \tObject: person \tConfidence = 0.8472 \tBbox: [ 431 \t 0 \t 480 \t 137 ]\n",
      "6 \tObject: person \tConfidence = 0.847 \tBbox: [ 445 \t 140 \t 525 \t 392 ]\n",
      "7 \tObject: person \tConfidence = 0.7741 \tBbox: [ 554 \t 3 \t 605 \t 177 ]\n",
      "8 \tObject: person \tConfidence = 0.7535 \tBbox: [ 467 \t 0 \t 506 \t 104 ]\n",
      "9 \tObject: person \tConfidence = 0.3893 \tBbox: [ 520 \t 0 \t 533 \t 20 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000058 / 1050\n",
      "Frames to be processed: 992  | To do: 94.48 % | Done: 5.52 %\n",
      "\n",
      "2022-04-20 13:10:55.922379\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000058.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 31.5ms pre-process, 175.5ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.918 \tBbox: [ 596 \t 339 \t 762 \t 695 ]\n",
      "2 \tObject: person \tConfidence = 0.9167 \tBbox: [ 373 \t 730 \t 670 \t 1079 ]\n",
      "3 \tObject: person \tConfidence = 0.8977 \tBbox: [ 476 \t 477 \t 629 \t 759 ]\n",
      "4 \tObject: person \tConfidence = 0.87 \tBbox: [ 566 \t 25 \t 646 \t 257 ]\n",
      "5 \tObject: person \tConfidence = 0.8581 \tBbox: [ 446 \t 139 \t 525 \t 391 ]\n",
      "6 \tObject: person \tConfidence = 0.8345 \tBbox: [ 431 \t 0 \t 480 \t 137 ]\n",
      "7 \tObject: person \tConfidence = 0.7873 \tBbox: [ 555 \t 3 \t 605 \t 177 ]\n",
      "8 \tObject: person \tConfidence = 0.7466 \tBbox: [ 467 \t 0 \t 507 \t 104 ]\n",
      "9 \tObject: person \tConfidence = 0.3228 \tBbox: [ 521 \t 0 \t 533 \t 15 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000059 / 1050\n",
      "Frames to be processed: 991  | To do: 94.38 % | Done: 5.62 %\n",
      "\n",
      "2022-04-20 13:10:56.395216\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000059.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 23.8ms pre-process, 179.1ms inference, 3.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9185 \tBbox: [ 373 \t 730 \t 672 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9184 \tBbox: [ 598 \t 347 \t 764 \t 696 ]\n",
      "3 \tObject: person \tConfidence = 0.894 \tBbox: [ 476 \t 476 \t 629 \t 761 ]\n",
      "4 \tObject: person \tConfidence = 0.8697 \tBbox: [ 566 \t 25 \t 645 \t 257 ]\n",
      "5 \tObject: person \tConfidence = 0.8507 \tBbox: [ 446 \t 139 \t 526 \t 393 ]\n",
      "6 \tObject: person \tConfidence = 0.8239 \tBbox: [ 431 \t 0 \t 481 \t 137 ]\n",
      "7 \tObject: person \tConfidence = 0.7885 \tBbox: [ 555 \t 3 \t 605 \t 177 ]\n",
      "8 \tObject: person \tConfidence = 0.7303 \tBbox: [ 467 \t 0 \t 506 \t 104 ]\n",
      "9 \tObject: person \tConfidence = 0.3663 \tBbox: [ 519 \t 0 \t 533 \t 15 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000060 / 1050\n",
      "Frames to be processed: 990  | To do: 94.29 % | Done: 5.71 %\n",
      "\n",
      "2022-04-20 13:10:56.806486\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000060.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 24.8ms pre-process, 170.5ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9159 \tBbox: [ 599 \t 356 \t 765 \t 696 ]\n",
      "2 \tObject: person \tConfidence = 0.9119 \tBbox: [ 374 \t 730 \t 669 \t 1079 ]\n",
      "3 \tObject: person \tConfidence = 0.895 \tBbox: [ 475 \t 477 \t 629 \t 760 ]\n",
      "4 \tObject: person \tConfidence = 0.8595 \tBbox: [ 566 \t 25 \t 646 \t 257 ]\n",
      "5 \tObject: person \tConfidence = 0.8403 \tBbox: [ 447 \t 138 \t 526 \t 394 ]\n",
      "6 \tObject: person \tConfidence = 0.8374 \tBbox: [ 431 \t 0 \t 481 \t 137 ]\n",
      "7 \tObject: person \tConfidence = 0.7371 \tBbox: [ 555 \t 2 \t 605 \t 177 ]\n",
      "8 \tObject: person \tConfidence = 0.7242 \tBbox: [ 467 \t 0 \t 506 \t 104 ]\n",
      "9 \tObject: person \tConfidence = 0.3329 \tBbox: [ 519 \t 0 \t 533 \t 15 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000061 / 1050\n",
      "Frames to be processed: 989  | To do: 94.19 % | Done: 5.81 %\n",
      "\n",
      "2022-04-20 13:10:57.245084\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000061.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons\n",
      "Speed: 26.4ms pre-process, 177.7ms inference, 12.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9131 \tBbox: [ 373 \t 730 \t 668 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9113 \tBbox: [ 602 \t 361 \t 763 \t 716 ]\n",
      "3 \tObject: person \tConfidence = 0.8968 \tBbox: [ 475 \t 476 \t 630 \t 760 ]\n",
      "4 \tObject: person \tConfidence = 0.8637 \tBbox: [ 566 \t 25 \t 646 \t 257 ]\n",
      "5 \tObject: person \tConfidence = 0.8397 \tBbox: [ 446 \t 138 \t 526 \t 394 ]\n",
      "6 \tObject: person \tConfidence = 0.8349 \tBbox: [ 431 \t 0 \t 481 \t 136 ]\n",
      "7 \tObject: person \tConfidence = 0.7624 \tBbox: [ 467 \t 0 \t 507 \t 105 ]\n",
      "8 \tObject: person \tConfidence = 0.7564 \tBbox: [ 555 \t 2 \t 605 \t 177 ]\n",
      "9 \tObject: person \tConfidence = 0.3004 \tBbox: [ 519 \t 0 \t 534 \t 16 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000062 / 1050\n",
      "Frames to be processed: 988  | To do: 94.1 % | Done: 5.9 %\n",
      "\n",
      "2022-04-20 13:10:57.668592\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000062.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 29.2ms pre-process, 171.4ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9127 \tBbox: [ 374 \t 730 \t 667 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9068 \tBbox: [ 604 \t 369 \t 761 \t 750 ]\n",
      "3 \tObject: person \tConfidence = 0.8937 \tBbox: [ 475 \t 477 \t 629 \t 759 ]\n",
      "4 \tObject: person \tConfidence = 0.86 \tBbox: [ 566 \t 25 \t 646 \t 257 ]\n",
      "5 \tObject: person \tConfidence = 0.853 \tBbox: [ 431 \t 0 \t 480 \t 136 ]\n",
      "6 \tObject: person \tConfidence = 0.8088 \tBbox: [ 447 \t 138 \t 526 \t 395 ]\n",
      "7 \tObject: person \tConfidence = 0.7638 \tBbox: [ 467 \t 0 \t 506 \t 104 ]\n",
      "8 \tObject: person \tConfidence = 0.7584 \tBbox: [ 555 \t 3 \t 605 \t 177 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000063 / 1050\n",
      "Frames to be processed: 987  | To do: 94.0 % | Done: 6.0 %\n",
      "\n",
      "2022-04-20 13:10:58.079968\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000063.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 35.2ms pre-process, 175.3ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9121 \tBbox: [ 374 \t 730 \t 667 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9024 \tBbox: [ 607 \t 381 \t 761 \t 787 ]\n",
      "3 \tObject: person \tConfidence = 0.8951 \tBbox: [ 475 \t 476 \t 630 \t 760 ]\n",
      "4 \tObject: person \tConfidence = 0.8705 \tBbox: [ 431 \t 0 \t 481 \t 136 ]\n",
      "5 \tObject: person \tConfidence = 0.8589 \tBbox: [ 567 \t 25 \t 646 \t 257 ]\n",
      "6 \tObject: person \tConfidence = 0.8027 \tBbox: [ 446 \t 137 \t 527 \t 394 ]\n",
      "7 \tObject: person \tConfidence = 0.7559 \tBbox: [ 467 \t 0 \t 507 \t 104 ]\n",
      "8 \tObject: person \tConfidence = 0.7038 \tBbox: [ 556 \t 2 \t 605 \t 177 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000064 / 1050\n",
      "Frames to be processed: 986  | To do: 93.9 % | Done: 6.1 %\n",
      "\n",
      "2022-04-20 13:10:58.531528\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000064.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 36.0ms pre-process, 169.2ms inference, 3.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9145 \tBbox: [ 616 \t 403 \t 760 \t 817 ]\n",
      "2 \tObject: person \tConfidence = 0.9112 \tBbox: [ 374 \t 730 \t 668 \t 1079 ]\n",
      "3 \tObject: person \tConfidence = 0.901 \tBbox: [ 475 \t 476 \t 629 \t 759 ]\n",
      "4 \tObject: person \tConfidence = 0.8576 \tBbox: [ 431 \t 0 \t 481 \t 137 ]\n",
      "5 \tObject: person \tConfidence = 0.8572 \tBbox: [ 567 \t 25 \t 646 \t 257 ]\n",
      "6 \tObject: person \tConfidence = 0.8148 \tBbox: [ 449 \t 137 \t 526 \t 395 ]\n",
      "7 \tObject: person \tConfidence = 0.7303 \tBbox: [ 556 \t 3 \t 606 \t 178 ]\n",
      "8 \tObject: person \tConfidence = 0.7281 \tBbox: [ 467 \t 0 \t 507 \t 104 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000065 / 1050\n",
      "Frames to be processed: 985  | To do: 93.81 % | Done: 6.19 %\n",
      "\n",
      "2022-04-20 13:10:58.960437\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000065.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 25.9ms pre-process, 174.7ms inference, 3.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9156 \tBbox: [ 618 \t 418 \t 761 \t 832 ]\n",
      "2 \tObject: person \tConfidence = 0.9127 \tBbox: [ 374 \t 730 \t 668 \t 1079 ]\n",
      "3 \tObject: person \tConfidence = 0.9035 \tBbox: [ 476 \t 476 \t 629 \t 759 ]\n",
      "4 \tObject: person \tConfidence = 0.8625 \tBbox: [ 566 \t 25 \t 646 \t 258 ]\n",
      "5 \tObject: person \tConfidence = 0.8541 \tBbox: [ 431 \t 0 \t 482 \t 137 ]\n",
      "6 \tObject: person \tConfidence = 0.8141 \tBbox: [ 450 \t 137 \t 527 \t 395 ]\n",
      "7 \tObject: person \tConfidence = 0.7193 \tBbox: [ 467 \t 0 \t 509 \t 104 ]\n",
      "8 \tObject: person \tConfidence = 0.7079 \tBbox: [ 556 \t 3 \t 606 \t 178 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000066 / 1050\n",
      "Frames to be processed: 984  | To do: 93.71 % | Done: 6.29 %\n",
      "\n",
      "2022-04-20 13:10:59.415395\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000066.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 25.2ms pre-process, 174.7ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9147 \tBbox: [ 373 \t 730 \t 669 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9147 \tBbox: [ 621 \t 431 \t 764 \t 849 ]\n",
      "3 \tObject: person \tConfidence = 0.9018 \tBbox: [ 476 \t 476 \t 629 \t 760 ]\n",
      "4 \tObject: person \tConfidence = 0.8651 \tBbox: [ 567 \t 25 \t 646 \t 258 ]\n",
      "5 \tObject: person \tConfidence = 0.8562 \tBbox: [ 432 \t 0 \t 482 \t 137 ]\n",
      "6 \tObject: person \tConfidence = 0.8021 \tBbox: [ 450 \t 137 \t 527 \t 394 ]\n",
      "7 \tObject: person \tConfidence = 0.7619 \tBbox: [ 556 \t 3 \t 607 \t 178 ]\n",
      "8 \tObject: person \tConfidence = 0.7134 \tBbox: [ 467 \t 0 \t 509 \t 104 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000067 / 1050\n",
      "Frames to be processed: 983  | To do: 93.62 % | Done: 6.38 %\n",
      "\n",
      "2022-04-20 13:10:59.957841\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000067.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 29.4ms pre-process, 171.1ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9155 \tBbox: [ 618 \t 440 \t 766 \t 861 ]\n",
      "2 \tObject: person \tConfidence = 0.9147 \tBbox: [ 373 \t 731 \t 669 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8993 \tBbox: [ 476 \t 476 \t 627 \t 759 ]\n",
      "4 \tObject: person \tConfidence = 0.8626 \tBbox: [ 568 \t 26 \t 647 \t 256 ]\n",
      "5 \tObject: person \tConfidence = 0.849 \tBbox: [ 432 \t 0 \t 482 \t 137 ]\n",
      "6 \tObject: person \tConfidence = 0.8068 \tBbox: [ 450 \t 136 \t 527 \t 395 ]\n",
      "7 \tObject: person \tConfidence = 0.7738 \tBbox: [ 556 \t 3 \t 607 \t 178 ]\n",
      "8 \tObject: person \tConfidence = 0.7067 \tBbox: [ 468 \t 0 \t 510 \t 104 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000068 / 1050\n",
      "Frames to be processed: 982  | To do: 93.52 % | Done: 6.48 %\n",
      "\n",
      "2022-04-20 13:11:00.390969\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000068.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 29.7ms pre-process, 172.9ms inference, 15.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9132 \tBbox: [ 374 \t 731 \t 668 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9068 \tBbox: [ 617 \t 449 \t 765 \t 867 ]\n",
      "3 \tObject: person \tConfidence = 0.8997 \tBbox: [ 477 \t 475 \t 627 \t 759 ]\n",
      "4 \tObject: person \tConfidence = 0.8616 \tBbox: [ 568 \t 26 \t 647 \t 256 ]\n",
      "5 \tObject: person \tConfidence = 0.8454 \tBbox: [ 432 \t 0 \t 482 \t 137 ]\n",
      "6 \tObject: person \tConfidence = 0.8085 \tBbox: [ 451 \t 136 \t 527 \t 395 ]\n",
      "7 \tObject: person \tConfidence = 0.7856 \tBbox: [ 556 \t 3 \t 607 \t 178 ]\n",
      "8 \tObject: person \tConfidence = 0.7227 \tBbox: [ 468 \t 0 \t 509 \t 104 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000069 / 1050\n",
      "Frames to be processed: 981  | To do: 93.43 % | Done: 6.57 %\n",
      "\n",
      "2022-04-20 13:11:00.821674\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000069.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 26.8ms pre-process, 176.7ms inference, 2.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9129 \tBbox: [ 374 \t 730 \t 668 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9007 \tBbox: [ 476 \t 475 \t 628 \t 761 ]\n",
      "3 \tObject: person \tConfidence = 0.8857 \tBbox: [ 618 \t 463 \t 765 \t 868 ]\n",
      "4 \tObject: person \tConfidence = 0.8653 \tBbox: [ 569 \t 26 \t 647 \t 256 ]\n",
      "5 \tObject: person \tConfidence = 0.8548 \tBbox: [ 432 \t 0 \t 481 \t 137 ]\n",
      "6 \tObject: person \tConfidence = 0.8227 \tBbox: [ 453 \t 135 \t 528 \t 395 ]\n",
      "7 \tObject: person \tConfidence = 0.7868 \tBbox: [ 557 \t 2 \t 607 \t 178 ]\n",
      "8 \tObject: person \tConfidence = 0.7282 \tBbox: [ 468 \t 0 \t 509 \t 104 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000070 / 1050\n",
      "Frames to be processed: 980  | To do: 93.33 % | Done: 6.67 %\n",
      "\n",
      "2022-04-20 13:11:01.297064\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000070.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 31.3ms pre-process, 180.4ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9152 \tBbox: [ 373 \t 731 \t 668 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9039 \tBbox: [ 476 \t 475 \t 629 \t 760 ]\n",
      "3 \tObject: person \tConfidence = 0.9024 \tBbox: [ 620 \t 469 \t 766 \t 868 ]\n",
      "4 \tObject: person \tConfidence = 0.8716 \tBbox: [ 569 \t 26 \t 647 \t 256 ]\n",
      "5 \tObject: person \tConfidence = 0.835 \tBbox: [ 432 \t 0 \t 482 \t 137 ]\n",
      "6 \tObject: person \tConfidence = 0.8336 \tBbox: [ 453 \t 134 \t 529 \t 395 ]\n",
      "7 \tObject: person \tConfidence = 0.803 \tBbox: [ 557 \t 2 \t 608 \t 178 ]\n",
      "8 \tObject: person \tConfidence = 0.6913 \tBbox: [ 468 \t 0 \t 509 \t 104 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000071 / 1050\n",
      "Frames to be processed: 979  | To do: 93.24 % | Done: 6.76 %\n",
      "\n",
      "2022-04-20 13:11:01.754029\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000071.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 27.4ms pre-process, 173.5ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9129 \tBbox: [ 374 \t 731 \t 667 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9004 \tBbox: [ 476 \t 475 \t 630 \t 760 ]\n",
      "3 \tObject: person \tConfidence = 0.8778 \tBbox: [ 628 \t 475 \t 765 \t 870 ]\n",
      "4 \tObject: person \tConfidence = 0.8714 \tBbox: [ 570 \t 26 \t 647 \t 256 ]\n",
      "5 \tObject: person \tConfidence = 0.8561 \tBbox: [ 454 \t 134 \t 529 \t 393 ]\n",
      "6 \tObject: person \tConfidence = 0.8438 \tBbox: [ 433 \t 0 \t 482 \t 137 ]\n",
      "7 \tObject: person \tConfidence = 0.8049 \tBbox: [ 557 \t 2 \t 608 \t 178 ]\n",
      "8 \tObject: person \tConfidence = 0.6361 \tBbox: [ 468 \t 0 \t 510 \t 103 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000072 / 1050\n",
      "Frames to be processed: 978  | To do: 93.14 % | Done: 6.86 %\n",
      "\n",
      "2022-04-20 13:11:02.198361\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000072.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 28.8ms pre-process, 176.1ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9109 \tBbox: [ 374 \t 731 \t 666 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9008 \tBbox: [ 476 \t 474 \t 630 \t 760 ]\n",
      "3 \tObject: person \tConfidence = 0.8874 \tBbox: [ 627 \t 481 \t 766 \t 868 ]\n",
      "4 \tObject: person \tConfidence = 0.8634 \tBbox: [ 570 \t 25 \t 647 \t 256 ]\n",
      "5 \tObject: person \tConfidence = 0.8537 \tBbox: [ 454 \t 134 \t 530 \t 392 ]\n",
      "6 \tObject: person \tConfidence = 0.8318 \tBbox: [ 433 \t 0 \t 481 \t 137 ]\n",
      "7 \tObject: person \tConfidence = 0.7875 \tBbox: [ 557 \t 2 \t 607 \t 177 ]\n",
      "8 \tObject: person \tConfidence = 0.6181 \tBbox: [ 468 \t 0 \t 510 \t 103 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000073 / 1050\n",
      "Frames to be processed: 977  | To do: 93.05 % | Done: 6.95 %\n",
      "\n",
      "2022-04-20 13:11:02.679589\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000073.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 27.3ms pre-process, 179.3ms inference, 4.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9144 \tBbox: [ 373 \t 731 \t 669 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9003 \tBbox: [ 476 \t 474 \t 630 \t 759 ]\n",
      "3 \tObject: person \tConfidence = 0.8637 \tBbox: [ 454 \t 134 \t 530 \t 392 ]\n",
      "4 \tObject: person \tConfidence = 0.8615 \tBbox: [ 570 \t 25 \t 646 \t 256 ]\n",
      "5 \tObject: person \tConfidence = 0.8516 \tBbox: [ 628 \t 493 \t 766 \t 893 ]\n",
      "6 \tObject: person \tConfidence = 0.8364 \tBbox: [ 433 \t 0 \t 481 \t 137 ]\n",
      "7 \tObject: person \tConfidence = 0.7986 \tBbox: [ 557 \t 2 \t 608 \t 177 ]\n",
      "8 \tObject: person \tConfidence = 0.6603 \tBbox: [ 468 \t 0 \t 511 \t 103 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000074 / 1050\n",
      "Frames to be processed: 976  | To do: 92.95 % | Done: 7.05 %\n",
      "\n",
      "2022-04-20 13:11:03.173018\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000074.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 29.2ms pre-process, 180.7ms inference, 3.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9264 \tBbox: [ 374 \t 731 \t 668 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8925 \tBbox: [ 476 \t 474 \t 630 \t 759 ]\n",
      "3 \tObject: person \tConfidence = 0.8689 \tBbox: [ 628 \t 520 \t 766 \t 1002 ]\n",
      "4 \tObject: person \tConfidence = 0.8644 \tBbox: [ 455 \t 133 \t 531 \t 392 ]\n",
      "5 \tObject: person \tConfidence = 0.8592 \tBbox: [ 570 \t 25 \t 647 \t 254 ]\n",
      "6 \tObject: person \tConfidence = 0.853 \tBbox: [ 433 \t 0 \t 479 \t 135 ]\n",
      "7 \tObject: person \tConfidence = 0.7818 \tBbox: [ 557 \t 2 \t 608 \t 177 ]\n",
      "8 \tObject: person \tConfidence = 0.6702 \tBbox: [ 468 \t 0 \t 511 \t 103 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000075 / 1050\n",
      "Frames to be processed: 975  | To do: 92.86 % | Done: 7.14 %\n",
      "\n",
      "2022-04-20 13:11:03.669017\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000075.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 27.9ms pre-process, 175.7ms inference, 4.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.925 \tBbox: [ 374 \t 731 \t 669 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.89 \tBbox: [ 476 \t 473 \t 629 \t 760 ]\n",
      "3 \tObject: person \tConfidence = 0.8807 \tBbox: [ 631 \t 540 \t 766 \t 1036 ]\n",
      "4 \tObject: person \tConfidence = 0.8683 \tBbox: [ 454 \t 133 \t 531 \t 391 ]\n",
      "5 \tObject: person \tConfidence = 0.8608 \tBbox: [ 433 \t 0 \t 479 \t 135 ]\n",
      "6 \tObject: person \tConfidence = 0.8603 \tBbox: [ 570 \t 25 \t 647 \t 254 ]\n",
      "7 \tObject: person \tConfidence = 0.7763 \tBbox: [ 557 \t 2 \t 608 \t 177 ]\n",
      "8 \tObject: person \tConfidence = 0.682 \tBbox: [ 468 \t 0 \t 511 \t 102 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000076 / 1050\n",
      "Frames to be processed: 974  | To do: 92.76 % | Done: 7.24 %\n",
      "\n",
      "2022-04-20 13:11:04.069324\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000076.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 27.7ms pre-process, 169.6ms inference, 3.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9214 \tBbox: [ 374 \t 731 \t 671 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8876 \tBbox: [ 476 \t 473 \t 628 \t 762 ]\n",
      "3 \tObject: person \tConfidence = 0.8661 \tBbox: [ 570 \t 25 \t 647 \t 256 ]\n",
      "4 \tObject: person \tConfidence = 0.8654 \tBbox: [ 454 \t 133 \t 532 \t 391 ]\n",
      "5 \tObject: person \tConfidence = 0.8553 \tBbox: [ 433 \t 0 \t 480 \t 136 ]\n",
      "6 \tObject: person \tConfidence = 0.843 \tBbox: [ 633 \t 557 \t 766 \t 1071 ]\n",
      "7 \tObject: person \tConfidence = 0.7826 \tBbox: [ 558 \t 1 \t 608 \t 177 ]\n",
      "8 \tObject: person \tConfidence = 0.6716 \tBbox: [ 469 \t 0 \t 511 \t 102 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000077 / 1050\n",
      "Frames to be processed: 973  | To do: 92.67 % | Done: 7.33 %\n",
      "\n",
      "2022-04-20 13:11:04.500344\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000077.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 36.7ms pre-process, 177.9ms inference, 10.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9193 \tBbox: [ 375 \t 731 \t 668 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8867 \tBbox: [ 474 \t 474 \t 629 \t 762 ]\n",
      "3 \tObject: person \tConfidence = 0.8628 \tBbox: [ 570 \t 26 \t 647 \t 255 ]\n",
      "4 \tObject: person \tConfidence = 0.859 \tBbox: [ 433 \t 0 \t 480 \t 135 ]\n",
      "5 \tObject: person \tConfidence = 0.8568 \tBbox: [ 453 \t 133 \t 532 \t 391 ]\n",
      "6 \tObject: person \tConfidence = 0.8555 \tBbox: [ 633 \t 573 \t 765 \t 1078 ]\n",
      "7 \tObject: person \tConfidence = 0.7844 \tBbox: [ 557 \t 1 \t 608 \t 177 ]\n",
      "8 \tObject: person \tConfidence = 0.6964 \tBbox: [ 469 \t 0 \t 511 \t 102 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000078 / 1050\n",
      "Frames to be processed: 972  | To do: 92.57 % | Done: 7.43 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:11:04.938576\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000078.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 25.5ms pre-process, 169.6ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9167 \tBbox: [ 375 \t 730 \t 667 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8856 \tBbox: [ 474 \t 474 \t 629 \t 762 ]\n",
      "3 \tObject: person \tConfidence = 0.8707 \tBbox: [ 648 \t 588 \t 765 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.8615 \tBbox: [ 570 \t 26 \t 648 \t 255 ]\n",
      "5 \tObject: person \tConfidence = 0.8551 \tBbox: [ 433 \t 0 \t 481 \t 136 ]\n",
      "6 \tObject: person \tConfidence = 0.8507 \tBbox: [ 450 \t 133 \t 533 \t 391 ]\n",
      "7 \tObject: person \tConfidence = 0.778 \tBbox: [ 558 \t 1 \t 608 \t 177 ]\n",
      "8 \tObject: person \tConfidence = 0.6828 \tBbox: [ 471 \t 0 \t 512 \t 100 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000079 / 1050\n",
      "Frames to be processed: 971  | To do: 92.48 % | Done: 7.52 %\n",
      "\n",
      "2022-04-20 13:11:05.381758\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000079.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 28.8ms pre-process, 173.8ms inference, 3.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9215 \tBbox: [ 375 \t 730 \t 668 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8883 \tBbox: [ 474 \t 474 \t 630 \t 760 ]\n",
      "3 \tObject: person \tConfidence = 0.879 \tBbox: [ 651 \t 617 \t 765 \t 1080 ]\n",
      "4 \tObject: person \tConfidence = 0.8774 \tBbox: [ 454 \t 133 \t 532 \t 392 ]\n",
      "5 \tObject: person \tConfidence = 0.8631 \tBbox: [ 570 \t 25 \t 648 \t 255 ]\n",
      "6 \tObject: person \tConfidence = 0.8568 \tBbox: [ 433 \t 0 \t 480 \t 135 ]\n",
      "7 \tObject: person \tConfidence = 0.773 \tBbox: [ 558 \t 1 \t 608 \t 177 ]\n",
      "8 \tObject: person \tConfidence = 0.6504 \tBbox: [ 473 \t 0 \t 513 \t 99 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000080 / 1050\n",
      "Frames to be processed: 970  | To do: 92.38 % | Done: 7.62 %\n",
      "\n",
      "2022-04-20 13:11:05.808656\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000080.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 30.9ms pre-process, 175.8ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9214 \tBbox: [ 375 \t 730 \t 668 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.89 \tBbox: [ 476 \t 474 \t 630 \t 760 ]\n",
      "3 \tObject: person \tConfidence = 0.8678 \tBbox: [ 452 \t 133 \t 533 \t 392 ]\n",
      "4 \tObject: person \tConfidence = 0.861 \tBbox: [ 570 \t 25 \t 647 \t 255 ]\n",
      "5 \tObject: person \tConfidence = 0.8581 \tBbox: [ 653 \t 631 \t 765 \t 1078 ]\n",
      "6 \tObject: person \tConfidence = 0.8522 \tBbox: [ 433 \t 0 \t 481 \t 136 ]\n",
      "7 \tObject: person \tConfidence = 0.7706 \tBbox: [ 558 \t 1 \t 608 \t 176 ]\n",
      "8 \tObject: person \tConfidence = 0.6457 \tBbox: [ 473 \t 0 \t 513 \t 99 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000081 / 1050\n",
      "Frames to be processed: 969  | To do: 92.29 % | Done: 7.71 %\n",
      "\n",
      "2022-04-20 13:11:06.255773\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000081.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 29.4ms pre-process, 180.2ms inference, 4.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9211 \tBbox: [ 375 \t 730 \t 669 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8834 \tBbox: [ 475 \t 474 \t 630 \t 762 ]\n",
      "3 \tObject: person \tConfidence = 0.8746 \tBbox: [ 453 \t 133 \t 533 \t 392 ]\n",
      "4 \tObject: person \tConfidence = 0.8688 \tBbox: [ 570 \t 25 \t 647 \t 255 ]\n",
      "5 \tObject: person \tConfidence = 0.8559 \tBbox: [ 433 \t 0 \t 482 \t 136 ]\n",
      "6 \tObject: person \tConfidence = 0.8054 \tBbox: [ 656 \t 641 \t 766 \t 1078 ]\n",
      "7 \tObject: person \tConfidence = 0.7736 \tBbox: [ 558 \t 1 \t 608 \t 176 ]\n",
      "8 \tObject: person \tConfidence = 0.6539 \tBbox: [ 474 \t 0 \t 513 \t 97 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000082 / 1050\n",
      "Frames to be processed: 968  | To do: 92.19 % | Done: 7.81 %\n",
      "\n",
      "2022-04-20 13:11:06.720816\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000082.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 30.3ms pre-process, 183.1ms inference, 6.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9205 \tBbox: [ 375 \t 730 \t 669 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8834 \tBbox: [ 475 \t 474 \t 629 \t 763 ]\n",
      "3 \tObject: person \tConfidence = 0.8815 \tBbox: [ 453 \t 133 \t 533 \t 392 ]\n",
      "4 \tObject: person \tConfidence = 0.8667 \tBbox: [ 570 \t 25 \t 647 \t 255 ]\n",
      "5 \tObject: person \tConfidence = 0.8542 \tBbox: [ 433 \t 0 \t 483 \t 136 ]\n",
      "6 \tObject: person \tConfidence = 0.8359 \tBbox: [ 657 \t 661 \t 765 \t 1078 ]\n",
      "7 \tObject: person \tConfidence = 0.7499 \tBbox: [ 558 \t 1 \t 608 \t 176 ]\n",
      "8 \tObject: person \tConfidence = 0.6353 \tBbox: [ 476 \t 0 \t 513 \t 95 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000083 / 1050\n",
      "Frames to be processed: 967  | To do: 92.1 % | Done: 7.9 %\n",
      "\n",
      "2022-04-20 13:11:07.291815\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000083.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 34.3ms pre-process, 181.8ms inference, 7.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9202 \tBbox: [ 375 \t 730 \t 669 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8839 \tBbox: [ 475 \t 474 \t 629 \t 762 ]\n",
      "3 \tObject: person \tConfidence = 0.8826 \tBbox: [ 454 \t 134 \t 533 \t 392 ]\n",
      "4 \tObject: person \tConfidence = 0.8678 \tBbox: [ 570 \t 26 \t 647 \t 255 ]\n",
      "5 \tObject: person \tConfidence = 0.8541 \tBbox: [ 433 \t 0 \t 483 \t 135 ]\n",
      "6 \tObject: person \tConfidence = 0.8012 \tBbox: [ 663 \t 681 \t 766 \t 1078 ]\n",
      "7 \tObject: person \tConfidence = 0.7621 \tBbox: [ 559 \t 1 \t 608 \t 176 ]\n",
      "8 \tObject: person \tConfidence = 0.6094 \tBbox: [ 476 \t 0 \t 513 \t 94 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000084 / 1050\n",
      "Frames to be processed: 966  | To do: 92.0 % | Done: 8.0 %\n",
      "\n",
      "2022-04-20 13:11:07.898439\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000084.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 29.4ms pre-process, 181.8ms inference, 6.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.921 \tBbox: [ 375 \t 729 \t 668 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8906 \tBbox: [ 475 \t 475 \t 630 \t 760 ]\n",
      "3 \tObject: person \tConfidence = 0.8709 \tBbox: [ 570 \t 26 \t 647 \t 255 ]\n",
      "4 \tObject: person \tConfidence = 0.8651 \tBbox: [ 452 \t 134 \t 534 \t 392 ]\n",
      "5 \tObject: person \tConfidence = 0.8535 \tBbox: [ 433 \t 0 \t 482 \t 135 ]\n",
      "6 \tObject: person \tConfidence = 0.7602 \tBbox: [ 559 \t 1 \t 608 \t 176 ]\n",
      "7 \tObject: person \tConfidence = 0.6727 \tBbox: [ 667 \t 731 \t 766 \t 1077 ]\n",
      "8 \tObject: person \tConfidence = 0.6392 \tBbox: [ 476 \t 1 \t 513 \t 97 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000085 / 1050\n",
      "Frames to be processed: 965  | To do: 91.9 % | Done: 8.1 %\n",
      "\n",
      "2022-04-20 13:11:08.375559\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000085.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 33.4ms pre-process, 180.2ms inference, 4.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.92 \tBbox: [ 375 \t 729 \t 668 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8969 \tBbox: [ 477 \t 474 \t 630 \t 760 ]\n",
      "3 \tObject: person \tConfidence = 0.8737 \tBbox: [ 571 \t 25 \t 647 \t 255 ]\n",
      "4 \tObject: person \tConfidence = 0.8725 \tBbox: [ 453 \t 134 \t 533 \t 393 ]\n",
      "5 \tObject: person \tConfidence = 0.8463 \tBbox: [ 434 \t 0 \t 483 \t 135 ]\n",
      "6 \tObject: person \tConfidence = 0.7503 \tBbox: [ 559 \t 1 \t 608 \t 176 ]\n",
      "7 \tObject: person \tConfidence = 0.6558 \tBbox: [ 476 \t 1 \t 513 \t 99 ]\n",
      "8 \tObject: person \tConfidence = 0.5614 \tBbox: [ 667 \t 755 \t 765 \t 1078 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000086 / 1050\n",
      "Frames to be processed: 964  | To do: 91.81 % | Done: 8.19 %\n",
      "\n",
      "2022-04-20 13:11:08.811304\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000086.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 36.5ms pre-process, 171.6ms inference, 2.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9192 \tBbox: [ 375 \t 729 \t 667 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8978 \tBbox: [ 477 \t 475 \t 630 \t 761 ]\n",
      "3 \tObject: person \tConfidence = 0.8768 \tBbox: [ 454 \t 134 \t 533 \t 393 ]\n",
      "4 \tObject: person \tConfidence = 0.8683 \tBbox: [ 571 \t 25 \t 647 \t 257 ]\n",
      "5 \tObject: person \tConfidence = 0.8502 \tBbox: [ 434 \t 0 \t 483 \t 135 ]\n",
      "6 \tObject: person \tConfidence = 0.7326 \tBbox: [ 559 \t 1 \t 609 \t 176 ]\n",
      "7 \tObject: person \tConfidence = 0.6822 \tBbox: [ 476 \t 1 \t 513 \t 100 ]\n",
      "8 \tObject: person \tConfidence = 0.5212 \tBbox: [ 666 \t 771 \t 766 \t 1077 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000087 / 1050\n",
      "Frames to be processed: 963  | To do: 91.71 % | Done: 8.29 %\n",
      "\n",
      "2022-04-20 13:11:09.345762\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000087.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 29.5ms pre-process, 174.0ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9305 \tBbox: [ 376 \t 729 \t 670 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9017 \tBbox: [ 478 \t 475 \t 630 \t 761 ]\n",
      "3 \tObject: person \tConfidence = 0.8759 \tBbox: [ 453 \t 134 \t 533 \t 393 ]\n",
      "4 \tObject: person \tConfidence = 0.8735 \tBbox: [ 571 \t 25 \t 647 \t 256 ]\n",
      "5 \tObject: person \tConfidence = 0.8527 \tBbox: [ 434 \t 0 \t 482 \t 135 ]\n",
      "6 \tObject: person \tConfidence = 0.7458 \tBbox: [ 560 \t 1 \t 609 \t 176 ]\n",
      "7 \tObject: person \tConfidence = 0.6911 \tBbox: [ 476 \t 1 \t 513 \t 101 ]\n",
      "8 \tObject: person \tConfidence = 0.4316 \tBbox: [ 664 \t 842 \t 766 \t 1078 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000088 / 1050\n",
      "Frames to be processed: 962  | To do: 91.62 % | Done: 8.38 %\n",
      "\n",
      "2022-04-20 13:11:09.779998\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000088.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 32.0ms pre-process, 177.6ms inference, 6.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9217 \tBbox: [ 375 \t 729 \t 667 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9074 \tBbox: [ 478 \t 475 \t 631 \t 758 ]\n",
      "3 \tObject: person \tConfidence = 0.8761 \tBbox: [ 453 \t 133 \t 532 \t 393 ]\n",
      "4 \tObject: person \tConfidence = 0.8749 \tBbox: [ 571 \t 25 \t 647 \t 256 ]\n",
      "5 \tObject: person \tConfidence = 0.8505 \tBbox: [ 434 \t 0 \t 482 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.737 \tBbox: [ 559 \t 1 \t 609 \t 176 ]\n",
      "7 \tObject: person \tConfidence = 0.6769 \tBbox: [ 476 \t 1 \t 514 \t 100 ]\n",
      "8 \tObject: person \tConfidence = 0.4112 \tBbox: [ 660 \t 865 \t 765 \t 1078 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000089 / 1050\n",
      "Frames to be processed: 961  | To do: 91.52 % | Done: 8.48 %\n",
      "\n",
      "2022-04-20 13:11:10.254003\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000089.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 28.0ms pre-process, 177.9ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9229 \tBbox: [ 375 \t 729 \t 667 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9023 \tBbox: [ 478 \t 473 \t 630 \t 761 ]\n",
      "3 \tObject: person \tConfidence = 0.8733 \tBbox: [ 571 \t 25 \t 647 \t 256 ]\n",
      "4 \tObject: person \tConfidence = 0.8647 \tBbox: [ 452 \t 133 \t 531 \t 393 ]\n",
      "5 \tObject: person \tConfidence = 0.8472 \tBbox: [ 434 \t 0 \t 482 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.7331 \tBbox: [ 560 \t 1 \t 609 \t 176 ]\n",
      "7 \tObject: person \tConfidence = 0.6703 \tBbox: [ 476 \t 1 \t 514 \t 100 ]\n",
      "8 \tObject: person \tConfidence = 0.3962 \tBbox: [ 664 \t 928 \t 765 \t 1079 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000090 / 1050\n",
      "Frames to be processed: 960  | To do: 91.43 % | Done: 8.57 %\n",
      "\n",
      "2022-04-20 13:11:10.685313\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000090.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 26.6ms pre-process, 170.0ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9177 \tBbox: [ 375 \t 729 \t 664 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9056 \tBbox: [ 478 \t 473 \t 630 \t 759 ]\n",
      "3 \tObject: person \tConfidence = 0.8746 \tBbox: [ 572 \t 25 \t 647 \t 256 ]\n",
      "4 \tObject: person \tConfidence = 0.8664 \tBbox: [ 453 \t 133 \t 531 \t 392 ]\n",
      "5 \tObject: person \tConfidence = 0.8503 \tBbox: [ 434 \t 0 \t 482 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.7394 \tBbox: [ 560 \t 1 \t 609 \t 175 ]\n",
      "7 \tObject: person \tConfidence = 0.6746 \tBbox: [ 476 \t 1 \t 514 \t 100 ]\n",
      "8 \tObject: person \tConfidence = 0.3095 \tBbox: [ 672 \t 956 \t 765 \t 1079 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000091 / 1050\n",
      "Frames to be processed: 959  | To do: 91.33 % | Done: 8.67 %\n",
      "\n",
      "2022-04-20 13:11:11.119698\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000091.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 34.3ms pre-process, 175.0ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9213 \tBbox: [ 375 \t 728 \t 665 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9076 \tBbox: [ 478 \t 473 \t 630 \t 758 ]\n",
      "3 \tObject: person \tConfidence = 0.8741 \tBbox: [ 572 \t 25 \t 647 \t 255 ]\n",
      "4 \tObject: person \tConfidence = 0.8659 \tBbox: [ 453 \t 133 \t 529 \t 392 ]\n",
      "5 \tObject: person \tConfidence = 0.842 \tBbox: [ 434 \t 0 \t 483 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.7559 \tBbox: [ 560 \t 1 \t 609 \t 175 ]\n",
      "7 \tObject: person \tConfidence = 0.6748 \tBbox: [ 476 \t 0 \t 514 \t 101 ]\n",
      "8 \tObject: person \tConfidence = 0.3543 \tBbox: [ 684 \t 983 \t 765 \t 1079 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000092 / 1050\n",
      "Frames to be processed: 958  | To do: 91.24 % | Done: 8.76 %\n",
      "\n",
      "2022-04-20 13:11:11.528603\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000092.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 28.8ms pre-process, 175.8ms inference, 11.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9168 \tBbox: [ 376 \t 728 \t 663 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9076 \tBbox: [ 478 \t 473 \t 631 \t 758 ]\n",
      "3 \tObject: person \tConfidence = 0.8754 \tBbox: [ 572 \t 25 \t 647 \t 256 ]\n",
      "4 \tObject: person \tConfidence = 0.8624 \tBbox: [ 453 \t 133 \t 529 \t 392 ]\n",
      "5 \tObject: person \tConfidence = 0.8353 \tBbox: [ 434 \t 0 \t 483 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.7664 \tBbox: [ 560 \t 1 \t 609 \t 175 ]\n",
      "7 \tObject: person \tConfidence = 0.6782 \tBbox: [ 476 \t 0 \t 514 \t 101 ]\n",
      "8 \tObject: person \tConfidence = 0.5863 \tBbox: [ 694 \t 1008 \t 765 \t 1079 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000093 / 1050\n",
      "Frames to be processed: 957  | To do: 91.14 % | Done: 8.86 %\n",
      "\n",
      "2022-04-20 13:11:12.014414\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000093.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 27.8ms pre-process, 179.4ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.914 \tBbox: [ 376 \t 728 \t 666 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9053 \tBbox: [ 478 \t 473 \t 630 \t 757 ]\n",
      "3 \tObject: person \tConfidence = 0.8777 \tBbox: [ 572 \t 24 \t 647 \t 255 ]\n",
      "4 \tObject: person \tConfidence = 0.8531 \tBbox: [ 452 \t 133 \t 529 \t 391 ]\n",
      "5 \tObject: person \tConfidence = 0.8403 \tBbox: [ 434 \t 0 \t 484 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.7506 \tBbox: [ 560 \t 1 \t 609 \t 175 ]\n",
      "7 \tObject: person \tConfidence = 0.6907 \tBbox: [ 476 \t 0 \t 514 \t 101 ]\n",
      "8 \tObject: person \tConfidence = 0.3384 \tBbox: [ 707 \t 1027 \t 765 \t 1079 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000094 / 1050\n",
      "Frames to be processed: 956  | To do: 91.05 % | Done: 8.95 %\n",
      "\n",
      "2022-04-20 13:11:12.443653\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000094.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons\n",
      "Speed: 33.1ms pre-process, 185.9ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 7 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9152 \tBbox: [ 376 \t 728 \t 665 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.904 \tBbox: [ 477 \t 473 \t 631 \t 757 ]\n",
      "3 \tObject: person \tConfidence = 0.8791 \tBbox: [ 572 \t 24 \t 647 \t 256 ]\n",
      "4 \tObject: person \tConfidence = 0.8521 \tBbox: [ 451 \t 133 \t 529 \t 391 ]\n",
      "5 \tObject: person \tConfidence = 0.8383 \tBbox: [ 435 \t 0 \t 484 \t 135 ]\n",
      "6 \tObject: person \tConfidence = 0.7587 \tBbox: [ 560 \t 1 \t 609 \t 175 ]\n",
      "7 \tObject: person \tConfidence = 0.7001 \tBbox: [ 476 \t 0 \t 514 \t 101 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000095 / 1050\n",
      "Frames to be processed: 955  | To do: 90.95 % | Done: 9.05 %\n",
      "\n",
      "2022-04-20 13:11:12.861685\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000095.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons\n",
      "Speed: 26.6ms pre-process, 171.7ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 7 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9154 \tBbox: [ 376 \t 728 \t 665 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9035 \tBbox: [ 478 \t 472 \t 631 \t 756 ]\n",
      "3 \tObject: person \tConfidence = 0.8773 \tBbox: [ 572 \t 24 \t 647 \t 256 ]\n",
      "4 \tObject: person \tConfidence = 0.8514 \tBbox: [ 452 \t 133 \t 529 \t 391 ]\n",
      "5 \tObject: person \tConfidence = 0.8356 \tBbox: [ 435 \t 0 \t 485 \t 135 ]\n",
      "6 \tObject: person \tConfidence = 0.7259 \tBbox: [ 560 \t 1 \t 609 \t 175 ]\n",
      "7 \tObject: person \tConfidence = 0.6874 \tBbox: [ 477 \t 0 \t 514 \t 101 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000096 / 1050\n",
      "Frames to be processed: 954  | To do: 90.86 % | Done: 9.14 %\n",
      "\n",
      "2022-04-20 13:11:13.329667\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000096.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons\n",
      "Speed: 28.2ms pre-process, 175.4ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 7 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9166 \tBbox: [ 376 \t 727 \t 663 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8998 \tBbox: [ 477 \t 472 \t 631 \t 756 ]\n",
      "3 \tObject: person \tConfidence = 0.8755 \tBbox: [ 571 \t 24 \t 647 \t 256 ]\n",
      "4 \tObject: person \tConfidence = 0.8495 \tBbox: [ 452 \t 133 \t 529 \t 391 ]\n",
      "5 \tObject: person \tConfidence = 0.8324 \tBbox: [ 435 \t 0 \t 485 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.7222 \tBbox: [ 560 \t 1 \t 609 \t 175 ]\n",
      "7 \tObject: person \tConfidence = 0.6672 \tBbox: [ 478 \t 0 \t 514 \t 101 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000097 / 1050\n",
      "Frames to be processed: 953  | To do: 90.76 % | Done: 9.24 %\n",
      "\n",
      "2022-04-20 13:11:13.764876\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000097.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons\n",
      "Speed: 24.3ms pre-process, 177.3ms inference, 5.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 7 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9159 \tBbox: [ 377 \t 727 \t 664 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8941 \tBbox: [ 476 \t 473 \t 631 \t 757 ]\n",
      "3 \tObject: person \tConfidence = 0.8674 \tBbox: [ 570 \t 24 \t 647 \t 256 ]\n",
      "4 \tObject: person \tConfidence = 0.8481 \tBbox: [ 452 \t 134 \t 529 \t 391 ]\n",
      "5 \tObject: person \tConfidence = 0.8436 \tBbox: [ 435 \t 0 \t 485 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.6819 \tBbox: [ 560 \t 1 \t 609 \t 175 ]\n",
      "7 \tObject: person \tConfidence = 0.6629 \tBbox: [ 478 \t 0 \t 514 \t 101 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000098 / 1050\n",
      "Frames to be processed: 952  | To do: 90.67 % | Done: 9.33 %\n",
      "\n",
      "2022-04-20 13:11:14.197817\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000098.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons\n",
      "Speed: 27.3ms pre-process, 180.5ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 7 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9178 \tBbox: [ 377 \t 727 \t 663 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8905 \tBbox: [ 475 \t 473 \t 632 \t 757 ]\n",
      "3 \tObject: person \tConfidence = 0.8649 \tBbox: [ 569 \t 24 \t 646 \t 256 ]\n",
      "4 \tObject: person \tConfidence = 0.8647 \tBbox: [ 453 \t 134 \t 529 \t 391 ]\n",
      "5 \tObject: person \tConfidence = 0.8391 \tBbox: [ 435 \t 0 \t 485 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.6512 \tBbox: [ 561 \t 1 \t 609 \t 176 ]\n",
      "7 \tObject: person \tConfidence = 0.6304 \tBbox: [ 479 \t 0 \t 514 \t 100 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000099 / 1050\n",
      "Frames to be processed: 951  | To do: 90.57 % | Done: 9.43 %\n",
      "\n",
      "2022-04-20 13:11:14.621707\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000099.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons\n",
      "Speed: 26.8ms pre-process, 179.5ms inference, 12.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 7 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9211 \tBbox: [ 377 \t 726 \t 667 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8773 \tBbox: [ 474 \t 473 \t 632 \t 758 ]\n",
      "3 \tObject: person \tConfidence = 0.8694 \tBbox: [ 454 \t 133 \t 529 \t 391 ]\n",
      "4 \tObject: person \tConfidence = 0.8659 \tBbox: [ 570 \t 24 \t 647 \t 256 ]\n",
      "5 \tObject: person \tConfidence = 0.8338 \tBbox: [ 436 \t 0 \t 485 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.674 \tBbox: [ 561 \t 1 \t 609 \t 176 ]\n",
      "7 \tObject: person \tConfidence = 0.6612 \tBbox: [ 477 \t 0 \t 514 \t 101 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000100 / 1050\n",
      "Frames to be processed: 950  | To do: 90.48 % | Done: 9.52 %\n",
      "\n",
      "2022-04-20 13:11:15.045369\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000100.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons\n",
      "Speed: 29.0ms pre-process, 169.5ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 7 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.924 \tBbox: [ 377 \t 725 \t 668 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8909 \tBbox: [ 477 \t 474 \t 632 \t 756 ]\n",
      "3 \tObject: person \tConfidence = 0.8657 \tBbox: [ 454 \t 133 \t 529 \t 391 ]\n",
      "4 \tObject: person \tConfidence = 0.8596 \tBbox: [ 570 \t 24 \t 647 \t 256 ]\n",
      "5 \tObject: person \tConfidence = 0.8231 \tBbox: [ 436 \t 1 \t 485 \t 133 ]\n",
      "6 \tObject: person \tConfidence = 0.6445 \tBbox: [ 561 \t 2 \t 609 \t 175 ]\n",
      "7 \tObject: person \tConfidence = 0.6091 \tBbox: [ 478 \t 0 \t 514 \t 101 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000101 / 1050\n",
      "Frames to be processed: 949  | To do: 90.38 % | Done: 9.62 %\n",
      "\n",
      "2022-04-20 13:11:15.525982\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000101.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons\n",
      "Speed: 27.1ms pre-process, 175.7ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 7 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9214 \tBbox: [ 377 \t 724 \t 667 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8859 \tBbox: [ 476 \t 473 \t 632 \t 756 ]\n",
      "3 \tObject: person \tConfidence = 0.8629 \tBbox: [ 454 \t 133 \t 529 \t 391 ]\n",
      "4 \tObject: person \tConfidence = 0.8544 \tBbox: [ 571 \t 24 \t 646 \t 257 ]\n",
      "5 \tObject: person \tConfidence = 0.8382 \tBbox: [ 436 \t 0 \t 485 \t 135 ]\n",
      "6 \tObject: person \tConfidence = 0.6698 \tBbox: [ 561 \t 2 \t 609 \t 176 ]\n",
      "7 \tObject: person \tConfidence = 0.6406 \tBbox: [ 477 \t 0 \t 514 \t 101 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000102 / 1050\n",
      "Frames to be processed: 948  | To do: 90.29 % | Done: 9.71 %\n",
      "\n",
      "2022-04-20 13:11:15.941290\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000102.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 59.5ms pre-process, 177.6ms inference, 3.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.919 \tBbox: [ 377 \t 723 \t 663 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8878 \tBbox: [ 476 \t 473 \t 633 \t 755 ]\n",
      "3 \tObject: person \tConfidence = 0.8596 \tBbox: [ 453 \t 134 \t 529 \t 391 ]\n",
      "4 \tObject: person \tConfidence = 0.8526 \tBbox: [ 572 \t 23 \t 646 \t 256 ]\n",
      "5 \tObject: person \tConfidence = 0.826 \tBbox: [ 436 \t 1 \t 485 \t 133 ]\n",
      "6 \tObject: person \tConfidence = 0.7162 \tBbox: [ 561 \t 2 \t 609 \t 176 ]\n",
      "7 \tObject: person \tConfidence = 0.6152 \tBbox: [ 477 \t 0 \t 515 \t 101 ]\n",
      "8 \tObject: person \tConfidence = 0.3778 \tBbox: [ 651 \t 3 \t 668 \t 86 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000103 / 1050\n",
      "Frames to be processed: 947  | To do: 90.19 % | Done: 9.81 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 23.7ms pre-process, 169.0ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:11:16.448885\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000103.jpg ------------------------------ \n",
      "\n",
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9186 \tBbox: [ 377 \t 723 \t 664 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8869 \tBbox: [ 476 \t 474 \t 634 \t 756 ]\n",
      "3 \tObject: person \tConfidence = 0.8576 \tBbox: [ 453 \t 134 \t 529 \t 391 ]\n",
      "4 \tObject: person \tConfidence = 0.8509 \tBbox: [ 571 \t 22 \t 646 \t 257 ]\n",
      "5 \tObject: person \tConfidence = 0.8312 \tBbox: [ 436 \t 1 \t 486 \t 133 ]\n",
      "6 \tObject: person \tConfidence = 0.7053 \tBbox: [ 561 \t 2 \t 608 \t 177 ]\n",
      "7 \tObject: person \tConfidence = 0.6114 \tBbox: [ 477 \t 0 \t 515 \t 101 ]\n",
      "8 \tObject: person \tConfidence = 0.357 \tBbox: [ 650 \t 2 \t 668 \t 87 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000104 / 1050\n",
      "Frames to be processed: 946  | To do: 90.1 % | Done: 9.9 %\n",
      "\n",
      "2022-04-20 13:11:16.992695\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000104.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 24.3ms pre-process, 174.3ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9251 \tBbox: [ 377 \t 722 \t 669 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8904 \tBbox: [ 477 \t 474 \t 634 \t 754 ]\n",
      "3 \tObject: person \tConfidence = 0.8591 \tBbox: [ 453 \t 134 \t 529 \t 391 ]\n",
      "4 \tObject: person \tConfidence = 0.8453 \tBbox: [ 572 \t 22 \t 645 \t 256 ]\n",
      "5 \tObject: person \tConfidence = 0.8183 \tBbox: [ 436 \t 1 \t 486 \t 133 ]\n",
      "6 \tObject: person \tConfidence = 0.6846 \tBbox: [ 561 \t 3 \t 608 \t 177 ]\n",
      "7 \tObject: person \tConfidence = 0.6118 \tBbox: [ 477 \t 0 \t 515 \t 102 ]\n",
      "8 \tObject: person \tConfidence = 0.513 \tBbox: [ 647 \t 2 \t 667 \t 87 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000105 / 1050\n",
      "Frames to be processed: 945  | To do: 90.0 % | Done: 10.0 %\n",
      "\n",
      "2022-04-20 13:11:17.427501\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000105.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 34.1ms pre-process, 168.8ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9239 \tBbox: [ 377 \t 722 \t 668 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8833 \tBbox: [ 476 \t 474 \t 634 \t 754 ]\n",
      "3 \tObject: person \tConfidence = 0.8585 \tBbox: [ 453 \t 134 \t 529 \t 392 ]\n",
      "4 \tObject: person \tConfidence = 0.8527 \tBbox: [ 570 \t 21 \t 645 \t 257 ]\n",
      "5 \tObject: person \tConfidence = 0.82 \tBbox: [ 437 \t 1 \t 487 \t 133 ]\n",
      "6 \tObject: person \tConfidence = 0.6781 \tBbox: [ 560 \t 3 \t 608 \t 177 ]\n",
      "7 \tObject: person \tConfidence = 0.5844 \tBbox: [ 478 \t 0 \t 515 \t 101 ]\n",
      "8 \tObject: person \tConfidence = 0.5544 \tBbox: [ 646 \t 1 \t 668 \t 88 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000106 / 1050\n",
      "Frames to be processed: 944  | To do: 89.9 % | Done: 10.1 %\n",
      "\n",
      "2022-04-20 13:11:17.836083\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000106.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 27.9ms pre-process, 174.6ms inference, 6.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9229 \tBbox: [ 377 \t 722 \t 668 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8818 \tBbox: [ 476 \t 474 \t 634 \t 753 ]\n",
      "3 \tObject: person \tConfidence = 0.8577 \tBbox: [ 453 \t 134 \t 529 \t 392 ]\n",
      "4 \tObject: person \tConfidence = 0.847 \tBbox: [ 571 \t 21 \t 645 \t 257 ]\n",
      "5 \tObject: person \tConfidence = 0.8041 \tBbox: [ 438 \t 1 \t 488 \t 133 ]\n",
      "6 \tObject: person \tConfidence = 0.7188 \tBbox: [ 561 \t 3 \t 607 \t 177 ]\n",
      "7 \tObject: person \tConfidence = 0.6074 \tBbox: [ 645 \t 0 \t 668 \t 88 ]\n",
      "8 \tObject: person \tConfidence = 0.5652 \tBbox: [ 479 \t 0 \t 515 \t 100 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000107 / 1050\n",
      "Frames to be processed: 943  | To do: 89.81 % | Done: 10.19 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 26.5ms pre-process, 167.5ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:11:18.273943\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000107.jpg ------------------------------ \n",
      "\n",
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9259 \tBbox: [ 377 \t 722 \t 670 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.873 \tBbox: [ 475 \t 474 \t 635 \t 754 ]\n",
      "3 \tObject: person \tConfidence = 0.8562 \tBbox: [ 570 \t 20 \t 645 \t 257 ]\n",
      "4 \tObject: person \tConfidence = 0.8397 \tBbox: [ 448 \t 134 \t 530 \t 391 ]\n",
      "5 \tObject: person \tConfidence = 0.8249 \tBbox: [ 438 \t 1 \t 488 \t 133 ]\n",
      "6 \tObject: person \tConfidence = 0.7405 \tBbox: [ 560 \t 3 \t 607 \t 176 ]\n",
      "7 \tObject: person \tConfidence = 0.5474 \tBbox: [ 643 \t 0 \t 668 \t 89 ]\n",
      "8 \tObject: person \tConfidence = 0.5369 \tBbox: [ 478 \t 0 \t 515 \t 100 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000108 / 1050\n",
      "Frames to be processed: 942  | To do: 89.71 % | Done: 10.29 %\n",
      "\n",
      "2022-04-20 13:11:18.673825\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000108.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 26.9ms pre-process, 174.9ms inference, 13.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9256 \tBbox: [ 376 \t 722 \t 669 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8797 \tBbox: [ 476 \t 474 \t 635 \t 753 ]\n",
      "3 \tObject: person \tConfidence = 0.8626 \tBbox: [ 571 \t 20 \t 645 \t 256 ]\n",
      "4 \tObject: person \tConfidence = 0.8478 \tBbox: [ 450 \t 134 \t 529 \t 391 ]\n",
      "5 \tObject: person \tConfidence = 0.816 \tBbox: [ 437 \t 1 \t 487 \t 133 ]\n",
      "6 \tObject: person \tConfidence = 0.7661 \tBbox: [ 560 \t 3 \t 607 \t 176 ]\n",
      "7 \tObject: person \tConfidence = 0.5618 \tBbox: [ 478 \t 0 \t 515 \t 101 ]\n",
      "8 \tObject: person \tConfidence = 0.5567 \tBbox: [ 643 \t 0 \t 668 \t 93 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000109 / 1050\n",
      "Frames to be processed: 941  | To do: 89.62 % | Done: 10.38 %\n",
      "\n",
      "2022-04-20 13:11:19.114301\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000109.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons\n",
      "Speed: 29.0ms pre-process, 172.7ms inference, 3.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9265 \tBbox: [ 377 \t 722 \t 670 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8963 \tBbox: [ 478 \t 474 \t 635 \t 752 ]\n",
      "3 \tObject: person \tConfidence = 0.8524 \tBbox: [ 570 \t 20 \t 645 \t 257 ]\n",
      "4 \tObject: person \tConfidence = 0.8507 \tBbox: [ 446 \t 134 \t 530 \t 391 ]\n",
      "5 \tObject: person \tConfidence = 0.7965 \tBbox: [ 438 \t 1 \t 486 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.6984 \tBbox: [ 561 \t 3 \t 607 \t 175 ]\n",
      "7 \tObject: person \tConfidence = 0.5993 \tBbox: [ 641 \t 0 \t 668 \t 135 ]\n",
      "8 \tObject: person \tConfidence = 0.5981 \tBbox: [ 478 \t 0 \t 515 \t 101 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000110 / 1050\n",
      "Frames to be processed: 940  | To do: 89.52 % | Done: 10.48 %\n",
      "\n",
      "2022-04-20 13:11:19.516231\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000110.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 49.3ms pre-process, 177.7ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9271 \tBbox: [ 377 \t 722 \t 671 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9016 \tBbox: [ 479 \t 473 \t 635 \t 750 ]\n",
      "3 \tObject: person \tConfidence = 0.8523 \tBbox: [ 437 \t 133 \t 531 \t 392 ]\n",
      "4 \tObject: person \tConfidence = 0.8419 \tBbox: [ 570 \t 20 \t 645 \t 256 ]\n",
      "5 \tObject: person \tConfidence = 0.7964 \tBbox: [ 438 \t 1 \t 486 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.7166 \tBbox: [ 561 \t 1 \t 606 \t 174 ]\n",
      "7 \tObject: person \tConfidence = 0.6303 \tBbox: [ 640 \t 0 \t 668 \t 136 ]\n",
      "8 \tObject: person \tConfidence = 0.6214 \tBbox: [ 477 \t 0 \t 515 \t 101 ]\n",
      "9 \tObject: train \tConfidence = 0.4171 \tBbox: [ 294 \t 0 \t 433 \t 47 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000111 / 1050\n",
      "Frames to be processed: 939  | To do: 89.43 % | Done: 10.57 %\n",
      "\n",
      "2022-04-20 13:11:19.964250\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000111.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 36.1ms pre-process, 170.1ms inference, 4.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9292 \tBbox: [ 377 \t 722 \t 672 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9022 \tBbox: [ 480 \t 474 \t 635 \t 751 ]\n",
      "3 \tObject: person \tConfidence = 0.848 \tBbox: [ 440 \t 134 \t 532 \t 391 ]\n",
      "4 \tObject: person \tConfidence = 0.8456 \tBbox: [ 570 \t 19 \t 644 \t 256 ]\n",
      "5 \tObject: person \tConfidence = 0.7962 \tBbox: [ 439 \t 1 \t 486 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.7161 \tBbox: [ 561 \t 1 \t 606 \t 173 ]\n",
      "7 \tObject: person \tConfidence = 0.6356 \tBbox: [ 639 \t 0 \t 669 \t 136 ]\n",
      "8 \tObject: person \tConfidence = 0.6203 \tBbox: [ 478 \t 0 \t 515 \t 101 ]\n",
      "9 \tObject: train \tConfidence = 0.5176 \tBbox: [ 290 \t 0 \t 433 \t 48 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000112 / 1050\n",
      "Frames to be processed: 938  | To do: 89.33 % | Done: 10.67 %\n",
      "\n",
      "2022-04-20 13:11:20.374840\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000112.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 25.8ms pre-process, 175.6ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9279 \tBbox: [ 377 \t 722 \t 672 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9029 \tBbox: [ 480 \t 473 \t 635 \t 751 ]\n",
      "3 \tObject: person \tConfidence = 0.8529 \tBbox: [ 569 \t 19 \t 644 \t 256 ]\n",
      "4 \tObject: person \tConfidence = 0.8489 \tBbox: [ 447 \t 134 \t 532 \t 391 ]\n",
      "5 \tObject: person \tConfidence = 0.8026 \tBbox: [ 439 \t 1 \t 485 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.68 \tBbox: [ 561 \t 1 \t 606 \t 172 ]\n",
      "7 \tObject: person \tConfidence = 0.622 \tBbox: [ 477 \t 0 \t 515 \t 102 ]\n",
      "8 \tObject: person \tConfidence = 0.6167 \tBbox: [ 639 \t 0 \t 669 \t 136 ]\n",
      "9 \tObject: train \tConfidence = 0.4817 \tBbox: [ 288 \t 0 \t 434 \t 50 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000113 / 1050\n",
      "Frames to be processed: 937  | To do: 89.24 % | Done: 10.76 %\n",
      "\n",
      "2022-04-20 13:11:20.798373\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000113.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 27.6ms pre-process, 165.6ms inference, 12.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9296 \tBbox: [ 377 \t 722 \t 672 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8948 \tBbox: [ 479 \t 473 \t 634 \t 752 ]\n",
      "3 \tObject: person \tConfidence = 0.8537 \tBbox: [ 569 \t 19 \t 643 \t 254 ]\n",
      "4 \tObject: person \tConfidence = 0.8529 \tBbox: [ 439 \t 134 \t 533 \t 391 ]\n",
      "5 \tObject: person \tConfidence = 0.8093 \tBbox: [ 439 \t 1 \t 485 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.6551 \tBbox: [ 561 \t 1 \t 606 \t 171 ]\n",
      "7 \tObject: person \tConfidence = 0.6124 \tBbox: [ 478 \t 0 \t 515 \t 102 ]\n",
      "8 \tObject: person \tConfidence = 0.5742 \tBbox: [ 638 \t 0 \t 669 \t 136 ]\n",
      "9 \tObject: train \tConfidence = 0.5659 \tBbox: [ 290 \t 0 \t 433 \t 48 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000114 / 1050\n",
      "Frames to be processed: 936  | To do: 89.14 % | Done: 10.86 %\n",
      "\n",
      "2022-04-20 13:11:21.247086\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000114.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 29.1ms pre-process, 174.7ms inference, 3.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9243 \tBbox: [ 377 \t 722 \t 671 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8965 \tBbox: [ 479 \t 473 \t 634 \t 751 ]\n",
      "3 \tObject: person \tConfidence = 0.8575 \tBbox: [ 568 \t 19 \t 643 \t 254 ]\n",
      "4 \tObject: person \tConfidence = 0.8544 \tBbox: [ 441 \t 134 \t 533 \t 391 ]\n",
      "5 \tObject: person \tConfidence = 0.8154 \tBbox: [ 439 \t 1 \t 484 \t 133 ]\n",
      "6 \tObject: person \tConfidence = 0.6554 \tBbox: [ 561 \t 1 \t 606 \t 172 ]\n",
      "7 \tObject: person \tConfidence = 0.6144 \tBbox: [ 635 \t 0 \t 669 \t 131 ]\n",
      "8 \tObject: person \tConfidence = 0.6098 \tBbox: [ 478 \t 0 \t 516 \t 102 ]\n",
      "9 \tObject: train \tConfidence = 0.6058 \tBbox: [ 288 \t 0 \t 435 \t 55 ]\n",
      "10 \tObject: person \tConfidence = 0.3564 \tBbox: [ 711 \t 479 \t 765 \t 673 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000115 / 1050\n",
      "Frames to be processed: 935  | To do: 89.05 % | Done: 10.95 %\n",
      "\n",
      "2022-04-20 13:11:21.710024\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000115.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 24.5ms pre-process, 169.3ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9205 \tBbox: [ 377 \t 721 \t 670 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8952 \tBbox: [ 479 \t 473 \t 634 \t 752 ]\n",
      "3 \tObject: person \tConfidence = 0.8697 \tBbox: [ 434 \t 133 \t 533 \t 391 ]\n",
      "4 \tObject: person \tConfidence = 0.8614 \tBbox: [ 569 \t 19 \t 643 \t 255 ]\n",
      "5 \tObject: person \tConfidence = 0.8134 \tBbox: [ 439 \t 1 \t 485 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.6876 \tBbox: [ 633 \t 0 \t 669 \t 130 ]\n",
      "7 \tObject: person \tConfidence = 0.6707 \tBbox: [ 561 \t 1 \t 606 \t 172 ]\n",
      "8 \tObject: train \tConfidence = 0.6282 \tBbox: [ 285 \t 0 \t 435 \t 60 ]\n",
      "9 \tObject: person \tConfidence = 0.6057 \tBbox: [ 478 \t 0 \t 516 \t 101 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000116 / 1050\n",
      "Frames to be processed: 934  | To do: 88.95 % | Done: 11.05 %\n",
      "\n",
      "2022-04-20 13:11:22.183407\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000116.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 24.5ms pre-process, 175.2ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9222 \tBbox: [ 377 \t 721 \t 671 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8912 \tBbox: [ 479 \t 473 \t 634 \t 753 ]\n",
      "3 \tObject: person \tConfidence = 0.8782 \tBbox: [ 433 \t 133 \t 533 \t 390 ]\n",
      "4 \tObject: person \tConfidence = 0.8573 \tBbox: [ 569 \t 18 \t 642 \t 256 ]\n",
      "5 \tObject: person \tConfidence = 0.8289 \tBbox: [ 439 \t 0 \t 485 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.6781 \tBbox: [ 561 \t 1 \t 606 \t 174 ]\n",
      "7 \tObject: train \tConfidence = 0.6394 \tBbox: [ 281 \t 0 \t 435 \t 65 ]\n",
      "8 \tObject: person \tConfidence = 0.6095 \tBbox: [ 479 \t 0 \t 516 \t 101 ]\n",
      "9 \tObject: person \tConfidence = 0.5998 \tBbox: [ 633 \t 0 \t 669 \t 131 ]\n",
      "10 \tObject: person \tConfidence = 0.3508 \tBbox: [ 699 \t 398 \t 765 \t 659 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000117 / 1050\n",
      "Frames to be processed: 933  | To do: 88.86 % | Done: 11.14 %\n",
      "\n",
      "2022-04-20 13:11:22.669517\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000117.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 36.7ms pre-process, 175.2ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9235 \tBbox: [ 377 \t 721 \t 671 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8926 \tBbox: [ 479 \t 473 \t 634 \t 752 ]\n",
      "3 \tObject: person \tConfidence = 0.8799 \tBbox: [ 433 \t 133 \t 533 \t 391 ]\n",
      "4 \tObject: person \tConfidence = 0.8574 \tBbox: [ 569 \t 18 \t 642 \t 255 ]\n",
      "5 \tObject: person \tConfidence = 0.8231 \tBbox: [ 439 \t 0 \t 485 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.6593 \tBbox: [ 561 \t 1 \t 606 \t 173 ]\n",
      "7 \tObject: train \tConfidence = 0.6413 \tBbox: [ 276 \t 0 \t 434 \t 68 ]\n",
      "8 \tObject: person \tConfidence = 0.6313 \tBbox: [ 632 \t 0 \t 669 \t 136 ]\n",
      "9 \tObject: person \tConfidence = 0.6232 \tBbox: [ 478 \t 0 \t 516 \t 101 ]\n",
      "10 \tObject: person \tConfidence = 0.4483 \tBbox: [ 695 \t 424 \t 764 \t 654 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000118 / 1050\n",
      "Frames to be processed: 932  | To do: 88.76 % | Done: 11.24 %\n",
      "\n",
      "2022-04-20 13:11:23.118024\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000118.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 25.1ms pre-process, 177.1ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9216 \tBbox: [ 377 \t 721 \t 671 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8942 \tBbox: [ 479 \t 473 \t 634 \t 752 ]\n",
      "3 \tObject: person \tConfidence = 0.88 \tBbox: [ 433 \t 133 \t 533 \t 391 ]\n",
      "4 \tObject: person \tConfidence = 0.8536 \tBbox: [ 569 \t 19 \t 642 \t 254 ]\n",
      "5 \tObject: person \tConfidence = 0.8281 \tBbox: [ 439 \t 0 \t 486 \t 134 ]\n",
      "6 \tObject: train \tConfidence = 0.6539 \tBbox: [ 242 \t 0 \t 435 \t 69 ]\n",
      "7 \tObject: person \tConfidence = 0.6462 \tBbox: [ 561 \t 1 \t 607 \t 173 ]\n",
      "8 \tObject: person \tConfidence = 0.6134 \tBbox: [ 478 \t 0 \t 516 \t 101 ]\n",
      "9 \tObject: person \tConfidence = 0.5715 \tBbox: [ 631 \t 0 \t 670 \t 139 ]\n",
      "10 \tObject: person \tConfidence = 0.4468 \tBbox: [ 692 \t 406 \t 765 \t 653 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000119 / 1050\n",
      "Frames to be processed: 931  | To do: 88.67 % | Done: 11.33 %\n",
      "\n",
      "2022-04-20 13:11:23.587720\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000119.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 25.7ms pre-process, 172.8ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9218 \tBbox: [ 377 \t 721 \t 671 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8974 \tBbox: [ 480 \t 473 \t 634 \t 751 ]\n",
      "3 \tObject: person \tConfidence = 0.8653 \tBbox: [ 435 \t 132 \t 533 \t 390 ]\n",
      "4 \tObject: person \tConfidence = 0.8262 \tBbox: [ 568 \t 21 \t 639 \t 250 ]\n",
      "5 \tObject: person \tConfidence = 0.8207 \tBbox: [ 439 \t 0 \t 485 \t 134 ]\n",
      "6 \tObject: train \tConfidence = 0.7354 \tBbox: [ 234 \t 0 \t 435 \t 78 ]\n",
      "7 \tObject: person \tConfidence = 0.643 \tBbox: [ 478 \t 0 \t 516 \t 101 ]\n",
      "8 \tObject: person \tConfidence = 0.5266 \tBbox: [ 561 \t 1 \t 608 \t 172 ]\n",
      "9 \tObject: person \tConfidence = 0.5218 \tBbox: [ 688 \t 353 \t 766 \t 658 ]\n",
      "10 \tObject: person \tConfidence = 0.4307 \tBbox: [ 630 \t 0 \t 670 \t 133 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000120 / 1050\n",
      "Frames to be processed: 930  | To do: 88.57 % | Done: 11.43 %\n",
      "\n",
      "2022-04-20 13:11:24.051803\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000120.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 29.3ms pre-process, 167.2ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9196 \tBbox: [ 377 \t 721 \t 669 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.898 \tBbox: [ 481 \t 473 \t 635 \t 751 ]\n",
      "3 \tObject: person \tConfidence = 0.8692 \tBbox: [ 434 \t 133 \t 533 \t 390 ]\n",
      "4 \tObject: person \tConfidence = 0.8277 \tBbox: [ 439 \t 0 \t 484 \t 134 ]\n",
      "5 \tObject: person \tConfidence = 0.813 \tBbox: [ 566 \t 20 \t 638 \t 252 ]\n",
      "6 \tObject: train \tConfidence = 0.715 \tBbox: [ 232 \t 0 \t 435 \t 77 ]\n",
      "7 \tObject: person \tConfidence = 0.6237 \tBbox: [ 478 \t 0 \t 516 \t 101 ]\n",
      "8 \tObject: person \tConfidence = 0.6111 \tBbox: [ 685 \t 349 \t 766 \t 663 ]\n",
      "9 \tObject: person \tConfidence = 0.5234 \tBbox: [ 629 \t 0 \t 669 \t 134 ]\n",
      "10 \tObject: person \tConfidence = 0.4642 \tBbox: [ 561 \t 4 \t 613 \t 174 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000121 / 1050\n",
      "Frames to be processed: 929  | To do: 88.48 % | Done: 11.52 %\n",
      "\n",
      "2022-04-20 13:11:24.557851\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000121.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 37.1ms pre-process, 175.1ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.919 \tBbox: [ 376 \t 721 \t 669 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8965 \tBbox: [ 481 \t 473 \t 635 \t 751 ]\n",
      "3 \tObject: person \tConfidence = 0.8762 \tBbox: [ 433 \t 133 \t 533 \t 390 ]\n",
      "4 \tObject: person \tConfidence = 0.8266 \tBbox: [ 439 \t 0 \t 484 \t 134 ]\n",
      "5 \tObject: person \tConfidence = 0.8017 \tBbox: [ 564 \t 21 \t 637 \t 250 ]\n",
      "6 \tObject: train \tConfidence = 0.7044 \tBbox: [ 247 \t 0 \t 435 \t 79 ]\n",
      "7 \tObject: person \tConfidence = 0.6298 \tBbox: [ 478 \t 0 \t 515 \t 101 ]\n",
      "8 \tObject: person \tConfidence = 0.6286 \tBbox: [ 684 \t 332 \t 765 \t 666 ]\n",
      "9 \tObject: person \tConfidence = 0.5835 \tBbox: [ 628 \t 0 \t 669 \t 134 ]\n",
      "10 \tObject: person \tConfidence = 0.457 \tBbox: [ 561 \t 5 \t 614 \t 175 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000122 / 1050\n",
      "Frames to be processed: 928  | To do: 88.38 % | Done: 11.62 %\n",
      "\n",
      "2022-04-20 13:11:25.050138\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000122.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 34.8ms pre-process, 178.0ms inference, 3.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9196 \tBbox: [ 377 \t 721 \t 669 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8925 \tBbox: [ 480 \t 473 \t 635 \t 752 ]\n",
      "3 \tObject: person \tConfidence = 0.8822 \tBbox: [ 433 \t 133 \t 533 \t 389 ]\n",
      "4 \tObject: person \tConfidence = 0.8278 \tBbox: [ 439 \t 0 \t 485 \t 134 ]\n",
      "5 \tObject: person \tConfidence = 0.7981 \tBbox: [ 563 \t 24 \t 637 \t 250 ]\n",
      "6 \tObject: person \tConfidence = 0.7613 \tBbox: [ 681 \t 324 \t 765 \t 666 ]\n",
      "7 \tObject: train \tConfidence = 0.7145 \tBbox: [ 242 \t 0 \t 435 \t 82 ]\n",
      "8 \tObject: person \tConfidence = 0.6905 \tBbox: [ 627 \t 0 \t 670 \t 132 ]\n",
      "9 \tObject: person \tConfidence = 0.6511 \tBbox: [ 478 \t 0 \t 516 \t 101 ]\n",
      "10 \tObject: person \tConfidence = 0.5536 \tBbox: [ 561 \t 10 \t 615 \t 176 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000123 / 1050\n",
      "Frames to be processed: 927  | To do: 88.29 % | Done: 11.71 %\n",
      "\n",
      "2022-04-20 13:11:25.566463\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000123.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 45.1ms pre-process, 181.1ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9216 \tBbox: [ 377 \t 721 \t 670 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8925 \tBbox: [ 480 \t 473 \t 635 \t 752 ]\n",
      "3 \tObject: person \tConfidence = 0.8819 \tBbox: [ 433 \t 133 \t 533 \t 389 ]\n",
      "4 \tObject: person \tConfidence = 0.8407 \tBbox: [ 562 \t 18 \t 638 \t 250 ]\n",
      "5 \tObject: person \tConfidence = 0.8187 \tBbox: [ 440 \t 0 \t 485 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.8141 \tBbox: [ 678 \t 323 \t 765 \t 660 ]\n",
      "7 \tObject: train \tConfidence = 0.718 \tBbox: [ 237 \t 1 \t 436 \t 90 ]\n",
      "8 \tObject: person \tConfidence = 0.6888 \tBbox: [ 624 \t 0 \t 670 \t 135 ]\n",
      "9 \tObject: person \tConfidence = 0.6193 \tBbox: [ 477 \t 0 \t 516 \t 101 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000124 / 1050\n",
      "Frames to be processed: 926  | To do: 88.19 % | Done: 11.81 %\n",
      "\n",
      "2022-04-20 13:11:26.038838\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000124.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 37.5ms pre-process, 181.0ms inference, 4.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9219 \tBbox: [ 377 \t 721 \t 670 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8906 \tBbox: [ 480 \t 473 \t 635 \t 751 ]\n",
      "3 \tObject: person \tConfidence = 0.8846 \tBbox: [ 433 \t 133 \t 532 \t 389 ]\n",
      "4 \tObject: person \tConfidence = 0.8496 \tBbox: [ 671 \t 317 \t 765 \t 671 ]\n",
      "5 \tObject: person \tConfidence = 0.8153 \tBbox: [ 440 \t 0 \t 485 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.7864 \tBbox: [ 563 \t 20 \t 647 \t 249 ]\n",
      "7 \tObject: person \tConfidence = 0.7353 \tBbox: [ 623 \t 0 \t 671 \t 132 ]\n",
      "8 \tObject: train \tConfidence = 0.7145 \tBbox: [ 235 \t 0 \t 435 \t 96 ]\n",
      "9 \tObject: person \tConfidence = 0.5857 \tBbox: [ 478 \t 0 \t 517 \t 101 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000125 / 1050\n",
      "Frames to be processed: 925  | To do: 88.1 % | Done: 11.9 %\n",
      "\n",
      "2022-04-20 13:11:26.563172\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000125.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 34.2ms pre-process, 177.5ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9227 \tBbox: [ 377 \t 721 \t 672 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8896 \tBbox: [ 480 \t 473 \t 635 \t 752 ]\n",
      "3 \tObject: person \tConfidence = 0.8639 \tBbox: [ 435 \t 133 \t 532 \t 390 ]\n",
      "4 \tObject: person \tConfidence = 0.837 \tBbox: [ 668 \t 317 \t 766 \t 657 ]\n",
      "5 \tObject: person \tConfidence = 0.8128 \tBbox: [ 440 \t 0 \t 485 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.7945 \tBbox: [ 563 \t 21 \t 638 \t 249 ]\n",
      "7 \tObject: person \tConfidence = 0.7143 \tBbox: [ 618 \t 0 \t 670 \t 133 ]\n",
      "8 \tObject: train \tConfidence = 0.6852 \tBbox: [ 231 \t 0 \t 435 \t 97 ]\n",
      "9 \tObject: person \tConfidence = 0.5858 \tBbox: [ 478 \t 0 \t 517 \t 101 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000126 / 1050\n",
      "Frames to be processed: 924  | To do: 88.0 % | Done: 12.0 %\n",
      "\n",
      "2022-04-20 13:11:27.058567\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000126.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 39.9ms pre-process, 178.9ms inference, 4.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9254 \tBbox: [ 377 \t 721 \t 672 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8875 \tBbox: [ 480 \t 473 \t 635 \t 752 ]\n",
      "3 \tObject: person \tConfidence = 0.8709 \tBbox: [ 434 \t 132 \t 532 \t 390 ]\n",
      "4 \tObject: person \tConfidence = 0.8564 \tBbox: [ 663 \t 319 \t 765 \t 652 ]\n",
      "5 \tObject: person \tConfidence = 0.828 \tBbox: [ 563 \t 21 \t 635 \t 249 ]\n",
      "6 \tObject: person \tConfidence = 0.8171 \tBbox: [ 440 \t 0 \t 485 \t 134 ]\n",
      "7 \tObject: person \tConfidence = 0.7869 \tBbox: [ 618 \t 0 \t 670 \t 132 ]\n",
      "8 \tObject: person \tConfidence = 0.596 \tBbox: [ 478 \t 0 \t 517 \t 101 ]\n",
      "9 \tObject: train \tConfidence = 0.5865 \tBbox: [ 225 \t 0 \t 435 \t 100 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000127 / 1050\n",
      "Frames to be processed: 923  | To do: 87.9 % | Done: 12.1 %\n",
      "\n",
      "2022-04-20 13:11:27.537676\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000127.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 24.9ms pre-process, 177.6ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9255 \tBbox: [ 377 \t 722 \t 673 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8899 \tBbox: [ 480 \t 473 \t 635 \t 751 ]\n",
      "3 \tObject: person \tConfidence = 0.8781 \tBbox: [ 433 \t 132 \t 532 \t 390 ]\n",
      "4 \tObject: person \tConfidence = 0.8259 \tBbox: [ 617 \t 0 \t 670 \t 128 ]\n",
      "5 \tObject: person \tConfidence = 0.8181 \tBbox: [ 440 \t 0 \t 485 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.813 \tBbox: [ 654 \t 317 \t 765 \t 653 ]\n",
      "7 \tObject: person \tConfidence = 0.8104 \tBbox: [ 563 \t 20 \t 634 \t 249 ]\n",
      "8 \tObject: train \tConfidence = 0.6534 \tBbox: [ 220 \t 1 \t 434 \t 114 ]\n",
      "9 \tObject: person \tConfidence = 0.6037 \tBbox: [ 479 \t 0 \t 517 \t 100 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000128 / 1050\n",
      "Frames to be processed: 922  | To do: 87.81 % | Done: 12.19 %\n",
      "\n",
      "2022-04-20 13:11:28.040572\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000128.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 29.3ms pre-process, 180.0ms inference, 4.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9281 \tBbox: [ 378 \t 722 \t 674 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8943 \tBbox: [ 636 \t 315 \t 766 \t 653 ]\n",
      "3 \tObject: person \tConfidence = 0.8899 \tBbox: [ 481 \t 473 \t 635 \t 751 ]\n",
      "4 \tObject: person \tConfidence = 0.8658 \tBbox: [ 434 \t 133 \t 532 \t 390 ]\n",
      "5 \tObject: person \tConfidence = 0.8139 \tBbox: [ 440 \t 0 \t 485 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.8016 \tBbox: [ 616 \t 0 \t 668 \t 129 ]\n",
      "7 \tObject: person \tConfidence = 0.7833 \tBbox: [ 564 \t 21 \t 635 \t 248 ]\n",
      "8 \tObject: train \tConfidence = 0.7352 \tBbox: [ 215 \t 0 \t 435 \t 115 ]\n",
      "9 \tObject: person \tConfidence = 0.615 \tBbox: [ 479 \t 0 \t 518 \t 100 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000129 / 1050\n",
      "Frames to be processed: 921  | To do: 87.71 % | Done: 12.29 %\n",
      "\n",
      "2022-04-20 13:11:28.472710\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000129.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 29.7ms pre-process, 182.2ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9285 \tBbox: [ 377 \t 722 \t 674 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8954 \tBbox: [ 624 \t 312 \t 764 \t 653 ]\n",
      "3 \tObject: person \tConfidence = 0.8653 \tBbox: [ 481 \t 474 \t 635 \t 752 ]\n",
      "4 \tObject: person \tConfidence = 0.855 \tBbox: [ 436 \t 133 \t 532 \t 390 ]\n",
      "5 \tObject: person \tConfidence = 0.8064 \tBbox: [ 440 \t 0 \t 486 \t 134 ]\n",
      "6 \tObject: train \tConfidence = 0.7881 \tBbox: [ 203 \t 0 \t 437 \t 123 ]\n",
      "7 \tObject: person \tConfidence = 0.7826 \tBbox: [ 615 \t 0 \t 663 \t 121 ]\n",
      "8 \tObject: person \tConfidence = 0.7427 \tBbox: [ 563 \t 21 \t 640 \t 249 ]\n",
      "9 \tObject: person \tConfidence = 0.6029 \tBbox: [ 479 \t 0 \t 517 \t 100 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000130 / 1050\n",
      "Frames to be processed: 920  | To do: 87.62 % | Done: 12.38 %\n",
      "\n",
      "2022-04-20 13:11:28.926813\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000130.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 23.9ms pre-process, 175.1ms inference, 11.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9284 \tBbox: [ 378 \t 722 \t 674 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9138 \tBbox: [ 622 \t 311 \t 765 \t 654 ]\n",
      "3 \tObject: person \tConfidence = 0.8804 \tBbox: [ 481 \t 474 \t 635 \t 752 ]\n",
      "4 \tObject: person \tConfidence = 0.8539 \tBbox: [ 438 \t 133 \t 532 \t 390 ]\n",
      "5 \tObject: person \tConfidence = 0.8305 \tBbox: [ 614 \t 0 \t 663 \t 118 ]\n",
      "6 \tObject: person \tConfidence = 0.8002 \tBbox: [ 440 \t 0 \t 486 \t 134 ]\n",
      "7 \tObject: train \tConfidence = 0.7997 \tBbox: [ 195 \t 1 \t 437 \t 130 ]\n",
      "8 \tObject: person \tConfidence = 0.7924 \tBbox: [ 563 \t 22 \t 638 \t 249 ]\n",
      "9 \tObject: person \tConfidence = 0.6052 \tBbox: [ 479 \t 0 \t 517 \t 100 ]\n",
      "10 \tObject: person \tConfidence = 0.3033 \tBbox: [ 571 \t 0 \t 611 \t 49 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000131 / 1050\n",
      "Frames to be processed: 919  | To do: 87.52 % | Done: 12.48 %\n",
      "\n",
      "2022-04-20 13:11:29.423720\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000131.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 23.8ms pre-process, 179.5ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9279 \tBbox: [ 377 \t 722 \t 674 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9172 \tBbox: [ 622 \t 311 \t 765 \t 654 ]\n",
      "3 \tObject: person \tConfidence = 0.8801 \tBbox: [ 481 \t 474 \t 634 \t 752 ]\n",
      "4 \tObject: person \tConfidence = 0.8516 \tBbox: [ 439 \t 133 \t 532 \t 390 ]\n",
      "5 \tObject: person \tConfidence = 0.8228 \tBbox: [ 563 \t 21 \t 633 \t 249 ]\n",
      "6 \tObject: train \tConfidence = 0.8169 \tBbox: [ 184 \t 0 \t 438 \t 137 ]\n",
      "7 \tObject: person \tConfidence = 0.8138 \tBbox: [ 612 \t 0 \t 659 \t 117 ]\n",
      "8 \tObject: person \tConfidence = 0.8017 \tBbox: [ 440 \t 0 \t 485 \t 134 ]\n",
      "9 \tObject: person \tConfidence = 0.6488 \tBbox: [ 479 \t 0 \t 518 \t 100 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000132 / 1050\n",
      "Frames to be processed: 918  | To do: 87.43 % | Done: 12.57 %\n",
      "\n",
      "2022-04-20 13:11:29.950913\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000132.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 38.3ms pre-process, 178.7ms inference, 10.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9278 \tBbox: [ 377 \t 722 \t 674 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9151 \tBbox: [ 622 \t 309 \t 765 \t 654 ]\n",
      "3 \tObject: person \tConfidence = 0.8906 \tBbox: [ 481 \t 474 \t 633 \t 752 ]\n",
      "4 \tObject: person \tConfidence = 0.8442 \tBbox: [ 445 \t 133 \t 532 \t 390 ]\n",
      "5 \tObject: person \tConfidence = 0.8423 \tBbox: [ 563 \t 22 \t 631 \t 249 ]\n",
      "6 \tObject: train \tConfidence = 0.8345 \tBbox: [ 179 \t 0 \t 437 \t 143 ]\n",
      "7 \tObject: person \tConfidence = 0.8317 \tBbox: [ 610 \t 0 \t 660 \t 114 ]\n",
      "8 \tObject: person \tConfidence = 0.8011 \tBbox: [ 440 \t 0 \t 486 \t 134 ]\n",
      "9 \tObject: person \tConfidence = 0.65 \tBbox: [ 480 \t 0 \t 517 \t 100 ]\n",
      "10 \tObject: person \tConfidence = 0.356 \tBbox: [ 570 \t 1 \t 608 \t 56 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000133 / 1050\n",
      "Frames to be processed: 917  | To do: 87.33 % | Done: 12.67 %\n",
      "\n",
      "2022-04-20 13:11:30.498613\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000133.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 29.9ms pre-process, 174.8ms inference, 4.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9258 \tBbox: [ 377 \t 722 \t 673 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.906 \tBbox: [ 622 \t 307 \t 763 \t 653 ]\n",
      "3 \tObject: person \tConfidence = 0.8914 \tBbox: [ 481 \t 475 \t 633 \t 753 ]\n",
      "4 \tObject: person \tConfidence = 0.8583 \tBbox: [ 452 \t 133 \t 532 \t 390 ]\n",
      "5 \tObject: train \tConfidence = 0.843 \tBbox: [ 172 \t 0 \t 437 \t 149 ]\n",
      "6 \tObject: person \tConfidence = 0.8168 \tBbox: [ 563 \t 21 \t 631 \t 249 ]\n",
      "7 \tObject: person \tConfidence = 0.8123 \tBbox: [ 440 \t 0 \t 486 \t 134 ]\n",
      "8 \tObject: person \tConfidence = 0.787 \tBbox: [ 609 \t 0 \t 659 \t 114 ]\n",
      "9 \tObject: person \tConfidence = 0.6485 \tBbox: [ 480 \t 0 \t 517 \t 100 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000134 / 1050\n",
      "Frames to be processed: 916  | To do: 87.24 % | Done: 12.76 %\n",
      "\n",
      "2022-04-20 13:11:30.928390\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000134.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 27.8ms pre-process, 180.8ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9229 \tBbox: [ 377 \t 722 \t 673 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8986 \tBbox: [ 622 \t 303 \t 755 \t 645 ]\n",
      "3 \tObject: person \tConfidence = 0.8943 \tBbox: [ 482 \t 475 \t 632 \t 753 ]\n",
      "4 \tObject: train \tConfidence = 0.8552 \tBbox: [ 164 \t 0 \t 437 \t 172 ]\n",
      "5 \tObject: person \tConfidence = 0.8459 \tBbox: [ 440 \t 133 \t 532 \t 391 ]\n",
      "6 \tObject: person \tConfidence = 0.8107 \tBbox: [ 440 \t 0 \t 486 \t 134 ]\n",
      "7 \tObject: person \tConfidence = 0.7624 \tBbox: [ 563 \t 17 \t 630 \t 247 ]\n",
      "8 \tObject: person \tConfidence = 0.7039 \tBbox: [ 606 \t 0 \t 656 \t 117 ]\n",
      "9 \tObject: person \tConfidence = 0.6396 \tBbox: [ 479 \t 0 \t 518 \t 100 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000135 / 1050\n",
      "Frames to be processed: 915  | To do: 87.14 % | Done: 12.86 %\n",
      "\n",
      "2022-04-20 13:11:31.363147\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000135.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 28.5ms pre-process, 180.4ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.924 \tBbox: [ 377 \t 722 \t 673 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8948 \tBbox: [ 620 \t 300 \t 745 \t 637 ]\n",
      "3 \tObject: person \tConfidence = 0.8914 \tBbox: [ 482 \t 475 \t 632 \t 754 ]\n",
      "4 \tObject: train \tConfidence = 0.858 \tBbox: [ 158 \t 0 \t 437 \t 171 ]\n",
      "5 \tObject: person \tConfidence = 0.8489 \tBbox: [ 450 \t 133 \t 532 \t 390 ]\n",
      "6 \tObject: person \tConfidence = 0.8202 \tBbox: [ 440 \t 0 \t 486 \t 134 ]\n",
      "7 \tObject: person \tConfidence = 0.7612 \tBbox: [ 563 \t 19 \t 628 \t 248 ]\n",
      "8 \tObject: person \tConfidence = 0.6657 \tBbox: [ 605 \t 0 \t 654 \t 118 ]\n",
      "9 \tObject: person \tConfidence = 0.6428 \tBbox: [ 479 \t 0 \t 518 \t 100 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000136 / 1050\n",
      "Frames to be processed: 914  | To do: 87.05 % | Done: 12.95 %\n",
      "\n",
      "2022-04-20 13:11:31.833933\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000136.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 30.2ms pre-process, 172.1ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9242 \tBbox: [ 377 \t 723 \t 673 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8958 \tBbox: [ 482 \t 474 \t 633 \t 755 ]\n",
      "3 \tObject: person \tConfidence = 0.8812 \tBbox: [ 616 \t 298 \t 741 \t 627 ]\n",
      "4 \tObject: train \tConfidence = 0.8635 \tBbox: [ 154 \t 0 \t 437 \t 183 ]\n",
      "5 \tObject: person \tConfidence = 0.8468 \tBbox: [ 450 \t 133 \t 532 \t 390 ]\n",
      "6 \tObject: person \tConfidence = 0.8242 \tBbox: [ 440 \t 0 \t 486 \t 134 ]\n",
      "7 \tObject: person \tConfidence = 0.7579 \tBbox: [ 562 \t 20 \t 631 \t 248 ]\n",
      "8 \tObject: person \tConfidence = 0.646 \tBbox: [ 479 \t 0 \t 518 \t 100 ]\n",
      "9 \tObject: person \tConfidence = 0.4702 \tBbox: [ 605 \t 0 \t 652 \t 119 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000137 / 1050\n",
      "Frames to be processed: 913  | To do: 86.95 % | Done: 13.05 %\n",
      "\n",
      "2022-04-20 13:11:32.257568\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000137.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 28.5ms pre-process, 180.1ms inference, 4.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9195 \tBbox: [ 377 \t 723 \t 672 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8953 \tBbox: [ 483 \t 474 \t 633 \t 753 ]\n",
      "3 \tObject: person \tConfidence = 0.8792 \tBbox: [ 613 \t 296 \t 736 \t 616 ]\n",
      "4 \tObject: train \tConfidence = 0.8589 \tBbox: [ 143 \t 0 \t 436 \t 193 ]\n",
      "5 \tObject: person \tConfidence = 0.8475 \tBbox: [ 451 \t 133 \t 532 \t 390 ]\n",
      "6 \tObject: person \tConfidence = 0.8185 \tBbox: [ 440 \t 0 \t 486 \t 133 ]\n",
      "7 \tObject: person \tConfidence = 0.7082 \tBbox: [ 562 \t 19 \t 632 \t 249 ]\n",
      "8 \tObject: person \tConfidence = 0.6504 \tBbox: [ 479 \t 0 \t 518 \t 100 ]\n",
      "9 \tObject: person \tConfidence = 0.5381 \tBbox: [ 605 \t 0 \t 652 \t 119 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000138 / 1050\n",
      "Frames to be processed: 912  | To do: 86.86 % | Done: 13.14 %\n",
      "\n",
      "2022-04-20 13:11:32.746668\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000138.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 26.8ms pre-process, 176.5ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9182 \tBbox: [ 377 \t 723 \t 672 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.898 \tBbox: [ 483 \t 474 \t 632 \t 753 ]\n",
      "3 \tObject: person \tConfidence = 0.8906 \tBbox: [ 609 \t 295 \t 732 \t 608 ]\n",
      "4 \tObject: train \tConfidence = 0.849 \tBbox: [ 137 \t 0 \t 436 \t 199 ]\n",
      "5 \tObject: person \tConfidence = 0.8487 \tBbox: [ 451 \t 133 \t 533 \t 390 ]\n",
      "6 \tObject: person \tConfidence = 0.8053 \tBbox: [ 440 \t 1 \t 486 \t 134 ]\n",
      "7 \tObject: person \tConfidence = 0.7776 \tBbox: [ 562 \t 16 \t 629 \t 248 ]\n",
      "8 \tObject: person \tConfidence = 0.6382 \tBbox: [ 480 \t 0 \t 518 \t 100 ]\n",
      "9 \tObject: person \tConfidence = 0.5981 \tBbox: [ 604 \t 0 \t 651 \t 118 ]\n",
      "10 \tObject: person \tConfidence = 0.3202 \tBbox: [ 627 \t 373 \t 744 \t 517 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000139 / 1050\n",
      "Frames to be processed: 911  | To do: 86.76 % | Done: 13.24 %\n",
      "\n",
      "2022-04-20 13:11:33.184284\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000139.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 28.4ms pre-process, 171.9ms inference, 4.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9197 \tBbox: [ 377 \t 723 \t 672 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8964 \tBbox: [ 483 \t 475 \t 633 \t 753 ]\n",
      "3 \tObject: person \tConfidence = 0.8672 \tBbox: [ 454 \t 133 \t 532 \t 390 ]\n",
      "4 \tObject: person \tConfidence = 0.8663 \tBbox: [ 601 \t 291 \t 724 \t 607 ]\n",
      "5 \tObject: person \tConfidence = 0.8128 \tBbox: [ 440 \t 0 \t 487 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.8076 \tBbox: [ 561 \t 9 \t 629 \t 249 ]\n",
      "7 \tObject: train \tConfidence = 0.7711 \tBbox: [ 119 \t 0 \t 436 \t 207 ]\n",
      "8 \tObject: person \tConfidence = 0.6548 \tBbox: [ 479 \t 0 \t 518 \t 100 ]\n",
      "9 \tObject: person \tConfidence = 0.4812 \tBbox: [ 601 \t 0 \t 650 \t 119 ]\n",
      "10 \tObject: person \tConfidence = 0.3536 \tBbox: [ 269 \t 0 \t 309 \t 35 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000140 / 1050\n",
      "Frames to be processed: 910  | To do: 86.67 % | Done: 13.33 %\n",
      "\n",
      "2022-04-20 13:11:33.670575\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000140.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 24.6ms pre-process, 176.4ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9174 \tBbox: [ 377 \t 723 \t 671 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8964 \tBbox: [ 483 \t 473 \t 634 \t 755 ]\n",
      "3 \tObject: person \tConfidence = 0.8768 \tBbox: [ 597 \t 289 \t 721 \t 607 ]\n",
      "4 \tObject: person \tConfidence = 0.8653 \tBbox: [ 454 \t 133 \t 533 \t 390 ]\n",
      "5 \tObject: person \tConfidence = 0.8269 \tBbox: [ 561 \t 6 \t 628 \t 249 ]\n",
      "6 \tObject: person \tConfidence = 0.8102 \tBbox: [ 441 \t 0 \t 486 \t 134 ]\n",
      "7 \tObject: train \tConfidence = 0.7103 \tBbox: [ 110 \t 0 \t 435 \t 223 ]\n",
      "8 \tObject: person \tConfidence = 0.6249 \tBbox: [ 479 \t 0 \t 518 \t 100 ]\n",
      "9 \tObject: person \tConfidence = 0.4863 \tBbox: [ 604 \t 0 \t 649 \t 119 ]\n",
      "10 \tObject: person \tConfidence = 0.4316 \tBbox: [ 264 \t 0 \t 305 \t 42 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000141 / 1050\n",
      "Frames to be processed: 909  | To do: 86.57 % | Done: 13.43 %\n",
      "\n",
      "2022-04-20 13:11:34.113652\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000141.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 34.2ms pre-process, 184.6ms inference, 16.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9174 \tBbox: [ 377 \t 723 \t 672 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8971 \tBbox: [ 484 \t 475 \t 635 \t 754 ]\n",
      "3 \tObject: person \tConfidence = 0.8737 \tBbox: [ 592 \t 287 \t 717 \t 607 ]\n",
      "4 \tObject: person \tConfidence = 0.8597 \tBbox: [ 453 \t 133 \t 533 \t 390 ]\n",
      "5 \tObject: person \tConfidence = 0.8289 \tBbox: [ 561 \t 7 \t 629 \t 249 ]\n",
      "6 \tObject: person \tConfidence = 0.8214 \tBbox: [ 440 \t 1 \t 487 \t 134 ]\n",
      "7 \tObject: train \tConfidence = 0.8214 \tBbox: [ 99 \t 0 \t 438 \t 228 ]\n",
      "8 \tObject: person \tConfidence = 0.6395 \tBbox: [ 479 \t 0 \t 518 \t 100 ]\n",
      "9 \tObject: person \tConfidence = 0.4899 \tBbox: [ 600 \t 0 \t 646 \t 119 ]\n",
      "10 \tObject: person \tConfidence = 0.3263 \tBbox: [ 257 \t 8 \t 300 \t 48 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000142 / 1050\n",
      "Frames to be processed: 908  | To do: 86.48 % | Done: 13.52 %\n",
      "\n",
      "2022-04-20 13:11:34.640466\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000142.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 24.8ms pre-process, 175.0ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9165 \tBbox: [ 377 \t 724 \t 671 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8915 \tBbox: [ 483 \t 474 \t 636 \t 755 ]\n",
      "3 \tObject: train \tConfidence = 0.8603 \tBbox: [ 90 \t 0 \t 439 \t 239 ]\n",
      "4 \tObject: person \tConfidence = 0.8568 \tBbox: [ 588 \t 286 \t 711 \t 607 ]\n",
      "5 \tObject: person \tConfidence = 0.8485 \tBbox: [ 438 \t 132 \t 534 \t 390 ]\n",
      "6 \tObject: person \tConfidence = 0.8189 \tBbox: [ 561 \t 10 \t 629 \t 249 ]\n",
      "7 \tObject: person \tConfidence = 0.8104 \tBbox: [ 441 \t 1 \t 487 \t 134 ]\n",
      "8 \tObject: person \tConfidence = 0.6215 \tBbox: [ 479 \t 0 \t 518 \t 100 ]\n",
      "9 \tObject: person \tConfidence = 0.4858 \tBbox: [ 585 \t 0 \t 647 \t 119 ]\n",
      "10 \tObject: person \tConfidence = 0.304 \tBbox: [ 252 \t 13 \t 286 \t 51 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000143 / 1050\n",
      "Frames to be processed: 907  | To do: 86.38 % | Done: 13.62 %\n",
      "\n",
      "2022-04-20 13:11:35.117801\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000143.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 24.2ms pre-process, 181.3ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9179 \tBbox: [ 377 \t 724 \t 671 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8937 \tBbox: [ 482 \t 473 \t 636 \t 756 ]\n",
      "3 \tObject: train \tConfidence = 0.8739 \tBbox: [ 74 \t 0 \t 440 \t 249 ]\n",
      "4 \tObject: person \tConfidence = 0.8667 \tBbox: [ 584 \t 284 \t 709 \t 607 ]\n",
      "5 \tObject: person \tConfidence = 0.8541 \tBbox: [ 451 \t 133 \t 534 \t 390 ]\n",
      "6 \tObject: person \tConfidence = 0.8252 \tBbox: [ 561 \t 12 \t 628 \t 249 ]\n",
      "7 \tObject: person \tConfidence = 0.817 \tBbox: [ 441 \t 0 \t 486 \t 133 ]\n",
      "8 \tObject: person \tConfidence = 0.5876 \tBbox: [ 479 \t 0 \t 518 \t 100 ]\n",
      "9 \tObject: person \tConfidence = 0.5478 \tBbox: [ 586 \t 0 \t 648 \t 119 ]\n",
      "10 \tObject: person \tConfidence = 0.3286 \tBbox: [ 249 \t 17 \t 285 \t 58 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000144 / 1050\n",
      "Frames to be processed: 906  | To do: 86.29 % | Done: 13.71 %\n",
      "\n",
      "2022-04-20 13:11:35.541585\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000144.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 25.3ms pre-process, 172.4ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9203 \tBbox: [ 377 \t 724 \t 673 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8941 \tBbox: [ 482 \t 473 \t 636 \t 756 ]\n",
      "3 \tObject: train \tConfidence = 0.8821 \tBbox: [ 57 \t 1 \t 442 \t 268 ]\n",
      "4 \tObject: person \tConfidence = 0.8646 \tBbox: [ 578 \t 282 \t 706 \t 607 ]\n",
      "5 \tObject: person \tConfidence = 0.8531 \tBbox: [ 450 \t 133 \t 535 \t 390 ]\n",
      "6 \tObject: person \tConfidence = 0.8172 \tBbox: [ 560 \t 10 \t 629 \t 249 ]\n",
      "7 \tObject: person \tConfidence = 0.8077 \tBbox: [ 441 \t 0 \t 486 \t 133 ]\n",
      "8 \tObject: person \tConfidence = 0.6273 \tBbox: [ 480 \t 0 \t 520 \t 100 ]\n",
      "9 \tObject: person \tConfidence = 0.497 \tBbox: [ 235 \t 28 \t 273 \t 71 ]\n",
      "10 \tObject: person \tConfidence = 0.4564 \tBbox: [ 582 \t 0 \t 647 \t 118 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000145 / 1050\n",
      "Frames to be processed: 905  | To do: 86.19 % | Done: 13.81 %\n",
      "\n",
      "2022-04-20 13:11:35.984162\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000145.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 24.5ms pre-process, 175.5ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9189 \tBbox: [ 377 \t 724 \t 673 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8941 \tBbox: [ 481 \t 473 \t 636 \t 756 ]\n",
      "3 \tObject: train \tConfidence = 0.8659 \tBbox: [ 45 \t 1 \t 441 \t 283 ]\n",
      "4 \tObject: person \tConfidence = 0.8638 \tBbox: [ 453 \t 133 \t 535 \t 390 ]\n",
      "5 \tObject: person \tConfidence = 0.8561 \tBbox: [ 578 \t 281 \t 701 \t 607 ]\n",
      "6 \tObject: person \tConfidence = 0.8181 \tBbox: [ 559 \t 13 \t 631 \t 249 ]\n",
      "7 \tObject: person \tConfidence = 0.7917 \tBbox: [ 441 \t 0 \t 485 \t 133 ]\n",
      "8 \tObject: person \tConfidence = 0.6682 \tBbox: [ 480 \t 0 \t 519 \t 101 ]\n",
      "9 \tObject: person \tConfidence = 0.6483 \tBbox: [ 226 \t 33 \t 270 \t 79 ]\n",
      "10 \tObject: person \tConfidence = 0.3465 \tBbox: [ 574 \t 0 \t 646 \t 94 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000146 / 1050\n",
      "Frames to be processed: 904  | To do: 86.1 % | Done: 13.9 %\n",
      "\n",
      "2022-04-20 13:11:36.531694\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000146.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 49.8ms pre-process, 179.3ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9194 \tBbox: [ 377 \t 724 \t 673 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8972 \tBbox: [ 483 \t 473 \t 635 \t 754 ]\n",
      "3 \tObject: train \tConfidence = 0.8772 \tBbox: [ 26 \t 1 \t 443 \t 300 ]\n",
      "4 \tObject: person \tConfidence = 0.8595 \tBbox: [ 578 \t 281 \t 698 \t 607 ]\n",
      "5 \tObject: person \tConfidence = 0.8555 \tBbox: [ 452 \t 132 \t 535 \t 390 ]\n",
      "6 \tObject: person \tConfidence = 0.8338 \tBbox: [ 559 \t 13 \t 629 \t 249 ]\n",
      "7 \tObject: person \tConfidence = 0.8074 \tBbox: [ 441 \t 0 \t 485 \t 133 ]\n",
      "8 \tObject: person \tConfidence = 0.6846 \tBbox: [ 480 \t 0 \t 520 \t 101 ]\n",
      "9 \tObject: person \tConfidence = 0.5254 \tBbox: [ 220 \t 39 \t 263 \t 87 ]\n",
      "10 \tObject: person \tConfidence = 0.34 \tBbox: [ 573 \t 0 \t 647 \t 72 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000147 / 1050\n",
      "Frames to be processed: 903  | To do: 86.0 % | Done: 14.0 %\n",
      "\n",
      "2022-04-20 13:11:37.000615\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000147.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 38.4ms pre-process, 180.7ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9222 \tBbox: [ 377 \t 723 \t 674 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8953 \tBbox: [ 483 \t 474 \t 635 \t 754 ]\n",
      "3 \tObject: train \tConfidence = 0.8692 \tBbox: [ 16 \t 1 \t 443 \t 315 ]\n",
      "4 \tObject: person \tConfidence = 0.8577 \tBbox: [ 453 \t 132 \t 535 \t 390 ]\n",
      "5 \tObject: person \tConfidence = 0.8529 \tBbox: [ 579 \t 280 \t 695 \t 607 ]\n",
      "6 \tObject: person \tConfidence = 0.8282 \tBbox: [ 558 \t 17 \t 629 \t 249 ]\n",
      "7 \tObject: person \tConfidence = 0.8114 \tBbox: [ 441 \t 0 \t 486 \t 133 ]\n",
      "8 \tObject: person \tConfidence = 0.6977 \tBbox: [ 480 \t 0 \t 520 \t 101 ]\n",
      "9 \tObject: person \tConfidence = 0.497 \tBbox: [ 211 \t 47 \t 258 \t 95 ]\n",
      "10 \tObject: person \tConfidence = 0.3426 \tBbox: [ 572 \t 0 \t 646 \t 69 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000148 / 1050\n",
      "Frames to be processed: 902  | To do: 85.9 % | Done: 14.1 %\n",
      "\n",
      "2022-04-20 13:11:37.508147\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000148.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 30.6ms pre-process, 182.3ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9205 \tBbox: [ 377 \t 723 \t 673 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8941 \tBbox: [ 482 \t 473 \t 635 \t 754 ]\n",
      "3 \tObject: train \tConfidence = 0.872 \tBbox: [ 7 \t 1 \t 446 \t 323 ]\n",
      "4 \tObject: person \tConfidence = 0.8542 \tBbox: [ 578 \t 278 \t 693 \t 606 ]\n",
      "5 \tObject: person \tConfidence = 0.8538 \tBbox: [ 454 \t 132 \t 536 \t 390 ]\n",
      "6 \tObject: person \tConfidence = 0.837 \tBbox: [ 558 \t 18 \t 629 \t 249 ]\n",
      "7 \tObject: person \tConfidence = 0.8165 \tBbox: [ 441 \t 0 \t 486 \t 133 ]\n",
      "8 \tObject: person \tConfidence = 0.7159 \tBbox: [ 480 \t 0 \t 521 \t 101 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000149 / 1050\n",
      "Frames to be processed: 901  | To do: 85.81 % | Done: 14.19 %\n",
      "\n",
      "2022-04-20 13:11:38.050114\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000149.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 27.8ms pre-process, 183.2ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9228 \tBbox: [ 377 \t 723 \t 673 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8952 \tBbox: [ 482 \t 473 \t 635 \t 754 ]\n",
      "3 \tObject: train \tConfidence = 0.8853 \tBbox: [ 0 \t 1 \t 444 \t 350 ]\n",
      "4 \tObject: person \tConfidence = 0.8634 \tBbox: [ 574 \t 275 \t 685 \t 606 ]\n",
      "5 \tObject: person \tConfidence = 0.8583 \tBbox: [ 557 \t 20 \t 628 \t 249 ]\n",
      "6 \tObject: person \tConfidence = 0.8539 \tBbox: [ 454 \t 133 \t 536 \t 390 ]\n",
      "7 \tObject: person \tConfidence = 0.8037 \tBbox: [ 441 \t 0 \t 486 \t 133 ]\n",
      "8 \tObject: person \tConfidence = 0.7221 \tBbox: [ 480 \t 0 \t 521 \t 101 ]\n",
      "9 \tObject: person \tConfidence = 0.3041 \tBbox: [ 463 \t 210 \t 532 \t 343 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000150 / 1050\n",
      "Frames to be processed: 900  | To do: 85.71 % | Done: 14.29 %\n",
      "\n",
      "2022-04-20 13:11:38.490891\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000150.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 30.9ms pre-process, 186.0ms inference, 4.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9225 \tBbox: [ 377 \t 723 \t 673 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8956 \tBbox: [ 482 \t 473 \t 635 \t 754 ]\n",
      "3 \tObject: train \tConfidence = 0.8872 \tBbox: [ 1 \t 1 \t 443 \t 366 ]\n",
      "4 \tObject: person \tConfidence = 0.8631 \tBbox: [ 557 \t 19 \t 628 \t 249 ]\n",
      "5 \tObject: person \tConfidence = 0.8564 \tBbox: [ 572 \t 273 \t 684 \t 605 ]\n",
      "6 \tObject: person \tConfidence = 0.8441 \tBbox: [ 450 \t 133 \t 537 \t 391 ]\n",
      "7 \tObject: person \tConfidence = 0.8194 \tBbox: [ 441 \t 0 \t 486 \t 133 ]\n",
      "8 \tObject: person \tConfidence = 0.7248 \tBbox: [ 480 \t 0 \t 521 \t 101 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000151 / 1050\n",
      "Frames to be processed: 899  | To do: 85.62 % | Done: 14.38 %\n",
      "\n",
      "2022-04-20 13:11:39.088626\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000151.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 32.7ms pre-process, 173.0ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9222 \tBbox: [ 377 \t 723 \t 673 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8898 \tBbox: [ 482 \t 474 \t 640 \t 754 ]\n",
      "3 \tObject: train \tConfidence = 0.8872 \tBbox: [ 1 \t 0 \t 441 \t 394 ]\n",
      "4 \tObject: person \tConfidence = 0.8618 \tBbox: [ 557 \t 19 \t 628 \t 249 ]\n",
      "5 \tObject: person \tConfidence = 0.8494 \tBbox: [ 570 \t 271 \t 683 \t 605 ]\n",
      "6 \tObject: person \tConfidence = 0.8429 \tBbox: [ 446 \t 133 \t 537 \t 391 ]\n",
      "7 \tObject: person \tConfidence = 0.8166 \tBbox: [ 441 \t 0 \t 485 \t 132 ]\n",
      "8 \tObject: person \tConfidence = 0.7179 \tBbox: [ 480 \t 0 \t 520 \t 101 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000152 / 1050\n",
      "Frames to be processed: 898  | To do: 85.52 % | Done: 14.48 %\n",
      "\n",
      "2022-04-20 13:11:39.558676\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000152.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 29.1ms pre-process, 174.4ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.922 \tBbox: [ 377 \t 723 \t 672 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.8858 \tBbox: [ 1 \t 0 \t 442 \t 404 ]\n",
      "3 \tObject: person \tConfidence = 0.884 \tBbox: [ 482 \t 474 \t 639 \t 754 ]\n",
      "4 \tObject: person \tConfidence = 0.8619 \tBbox: [ 556 \t 19 \t 627 \t 249 ]\n",
      "5 \tObject: person \tConfidence = 0.8533 \tBbox: [ 569 \t 269 \t 681 \t 604 ]\n",
      "6 \tObject: person \tConfidence = 0.8447 \tBbox: [ 448 \t 132 \t 537 \t 391 ]\n",
      "7 \tObject: person \tConfidence = 0.8125 \tBbox: [ 441 \t 0 \t 486 \t 133 ]\n",
      "8 \tObject: person \tConfidence = 0.7166 \tBbox: [ 480 \t 0 \t 520 \t 101 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000153 / 1050\n",
      "Frames to be processed: 897  | To do: 85.43 % | Done: 14.57 %\n",
      "\n",
      "2022-04-20 13:11:40.001987\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000153.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 29.2ms pre-process, 180.7ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9245 \tBbox: [ 377 \t 722 \t 673 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8837 \tBbox: [ 482 \t 474 \t 638 \t 754 ]\n",
      "3 \tObject: train \tConfidence = 0.8662 \tBbox: [ 1 \t 2 \t 442 \t 428 ]\n",
      "4 \tObject: person \tConfidence = 0.8576 \tBbox: [ 568 \t 267 \t 679 \t 602 ]\n",
      "5 \tObject: person \tConfidence = 0.8487 \tBbox: [ 556 \t 13 \t 627 \t 249 ]\n",
      "6 \tObject: person \tConfidence = 0.8399 \tBbox: [ 442 \t 132 \t 537 \t 391 ]\n",
      "7 \tObject: person \tConfidence = 0.8251 \tBbox: [ 441 \t 0 \t 486 \t 132 ]\n",
      "8 \tObject: person \tConfidence = 0.7074 \tBbox: [ 481 \t 0 \t 521 \t 101 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000154 / 1050\n",
      "Frames to be processed: 896  | To do: 85.33 % | Done: 14.67 %\n",
      "\n",
      "2022-04-20 13:11:40.462981\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000154.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 30.6ms pre-process, 172.3ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.922 \tBbox: [ 377 \t 721 \t 672 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9112 \tBbox: [ 482 \t 472 \t 649 \t 753 ]\n",
      "3 \tObject: train \tConfidence = 0.8809 \tBbox: [ 1 \t 1 \t 442 \t 477 ]\n",
      "4 \tObject: person \tConfidence = 0.8741 \tBbox: [ 457 \t 132 \t 536 \t 391 ]\n",
      "5 \tObject: person \tConfidence = 0.8597 \tBbox: [ 563 \t 264 \t 673 \t 498 ]\n",
      "6 \tObject: person \tConfidence = 0.8596 \tBbox: [ 556 \t 2 \t 627 \t 248 ]\n",
      "7 \tObject: person \tConfidence = 0.8315 \tBbox: [ 441 \t 0 \t 487 \t 132 ]\n",
      "8 \tObject: person \tConfidence = 0.7059 \tBbox: [ 481 \t 0 \t 521 \t 101 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000155 / 1050\n",
      "Frames to be processed: 895  | To do: 85.24 % | Done: 14.76 %\n",
      "\n",
      "2022-04-20 13:11:40.918379\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000155.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 37.7ms pre-process, 175.1ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.923 \tBbox: [ 377 \t 722 \t 672 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9096 \tBbox: [ 482 \t 471 \t 647 \t 753 ]\n",
      "3 \tObject: train \tConfidence = 0.8877 \tBbox: [ 1 \t 0 \t 445 \t 505 ]\n",
      "4 \tObject: person \tConfidence = 0.8638 \tBbox: [ 556 \t 3 \t 628 \t 248 ]\n",
      "5 \tObject: person \tConfidence = 0.8596 \tBbox: [ 561 \t 263 \t 670 \t 498 ]\n",
      "6 \tObject: person \tConfidence = 0.8407 \tBbox: [ 449 \t 131 \t 537 \t 391 ]\n",
      "7 \tObject: person \tConfidence = 0.8287 \tBbox: [ 441 \t 0 \t 487 \t 132 ]\n",
      "8 \tObject: person \tConfidence = 0.704 \tBbox: [ 482 \t 0 \t 521 \t 101 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000156 / 1050\n",
      "Frames to be processed: 894  | To do: 85.14 % | Done: 14.86 %\n",
      "\n",
      "2022-04-20 13:11:41.356901\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000156.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 27.3ms pre-process, 180.3ms inference, 4.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9227 \tBbox: [ 377 \t 722 \t 672 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.905 \tBbox: [ 482 \t 471 \t 643 \t 753 ]\n",
      "3 \tObject: person \tConfidence = 0.8774 \tBbox: [ 556 \t 2 \t 627 \t 248 ]\n",
      "4 \tObject: person \tConfidence = 0.8617 \tBbox: [ 559 \t 262 \t 667 \t 497 ]\n",
      "5 \tObject: person \tConfidence = 0.8444 \tBbox: [ 438 \t 131 \t 536 \t 391 ]\n",
      "6 \tObject: person \tConfidence = 0.8302 \tBbox: [ 441 \t 0 \t 487 \t 132 ]\n",
      "7 \tObject: person \tConfidence = 0.7143 \tBbox: [ 481 \t 0 \t 521 \t 101 ]\n",
      "8 \tObject: train \tConfidence = 0.5901 \tBbox: [ 1 \t 1 \t 447 \t 532 ]\n",
      "9 \tObject: person \tConfidence = 0.3088 \tBbox: [ 458 \t 193 \t 531 \t 350 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000157 / 1050\n",
      "Frames to be processed: 893  | To do: 85.05 % | Done: 14.95 %\n",
      "\n",
      "2022-04-20 13:11:41.783277\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000157.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 27.4ms pre-process, 170.1ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9235 \tBbox: [ 377 \t 721 \t 671 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9042 \tBbox: [ 483 \t 470 \t 640 \t 754 ]\n",
      "3 \tObject: person \tConfidence = 0.8783 \tBbox: [ 556 \t 2 \t 628 \t 248 ]\n",
      "4 \tObject: person \tConfidence = 0.8569 \tBbox: [ 558 \t 261 \t 665 \t 495 ]\n",
      "5 \tObject: person \tConfidence = 0.8418 \tBbox: [ 441 \t 0 \t 487 \t 132 ]\n",
      "6 \tObject: person \tConfidence = 0.8297 \tBbox: [ 442 \t 131 \t 537 \t 391 ]\n",
      "7 \tObject: train \tConfidence = 0.7853 \tBbox: [ 1 \t 0 \t 445 \t 538 ]\n",
      "8 \tObject: person \tConfidence = 0.699 \tBbox: [ 482 \t 0 \t 521 \t 100 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000158 / 1050\n",
      "Frames to be processed: 892  | To do: 84.95 % | Done: 15.05 %\n",
      "\n",
      "2022-04-20 13:11:42.201016\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000158.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 23.9ms pre-process, 175.6ms inference, 12.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9237 \tBbox: [ 377 \t 721 \t 671 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9002 \tBbox: [ 482 \t 470 \t 638 \t 754 ]\n",
      "3 \tObject: person \tConfidence = 0.8694 \tBbox: [ 556 \t 2 \t 628 \t 248 ]\n",
      "4 \tObject: person \tConfidence = 0.8594 \tBbox: [ 558 \t 259 \t 664 \t 492 ]\n",
      "5 \tObject: person \tConfidence = 0.8452 \tBbox: [ 441 \t 0 \t 487 \t 132 ]\n",
      "6 \tObject: person \tConfidence = 0.8236 \tBbox: [ 444 \t 131 \t 538 \t 391 ]\n",
      "7 \tObject: train \tConfidence = 0.7297 \tBbox: [ 1 \t 0 \t 448 \t 573 ]\n",
      "8 \tObject: person \tConfidence = 0.7074 \tBbox: [ 482 \t 0 \t 521 \t 100 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000159 / 1050\n",
      "Frames to be processed: 891  | To do: 84.86 % | Done: 15.14 %\n",
      "\n",
      "2022-04-20 13:11:42.623801\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000159.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 35.0ms pre-process, 167.9ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9254 \tBbox: [ 377 \t 721 \t 673 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9039 \tBbox: [ 484 \t 470 \t 638 \t 752 ]\n",
      "3 \tObject: person \tConfidence = 0.8736 \tBbox: [ 556 \t 4 \t 629 \t 248 ]\n",
      "4 \tObject: person \tConfidence = 0.8721 \tBbox: [ 436 \t 130 \t 535 \t 391 ]\n",
      "5 \tObject: person \tConfidence = 0.8604 \tBbox: [ 557 \t 257 \t 661 \t 489 ]\n",
      "6 \tObject: person \tConfidence = 0.8368 \tBbox: [ 441 \t 0 \t 487 \t 132 ]\n",
      "7 \tObject: person \tConfidence = 0.721 \tBbox: [ 482 \t 0 \t 522 \t 100 ]\n",
      "8 \tObject: train \tConfidence = 0.6475 \tBbox: [ 1 \t 2 \t 448 \t 646 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000160 / 1050\n",
      "Frames to be processed: 890  | To do: 84.76 % | Done: 15.24 %\n",
      "\n",
      "2022-04-20 13:11:43.249584\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000160.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 36.2ms pre-process, 176.4ms inference, 10.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9243 \tBbox: [ 377 \t 721 \t 671 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9011 \tBbox: [ 484 \t 470 \t 638 \t 749 ]\n",
      "3 \tObject: train \tConfidence = 0.8842 \tBbox: [ 1 \t 0 \t 447 \t 667 ]\n",
      "4 \tObject: person \tConfidence = 0.8764 \tBbox: [ 556 \t 11 \t 629 \t 248 ]\n",
      "5 \tObject: person \tConfidence = 0.8746 \tBbox: [ 436 \t 131 \t 536 \t 391 ]\n",
      "6 \tObject: person \tConfidence = 0.8523 \tBbox: [ 556 \t 256 \t 659 \t 489 ]\n",
      "7 \tObject: person \tConfidence = 0.8376 \tBbox: [ 441 \t 0 \t 488 \t 132 ]\n",
      "8 \tObject: person \tConfidence = 0.7092 \tBbox: [ 482 \t 0 \t 522 \t 100 ]\n",
      "9 \tObject: person \tConfidence = 0.3278 \tBbox: [ 577 \t 0 \t 633 \t 59 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000161 / 1050\n",
      "Frames to be processed: 889  | To do: 84.67 % | Done: 15.33 %\n",
      "\n",
      "2022-04-20 13:11:43.817732\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000161.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 25.7ms pre-process, 177.8ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9234 \tBbox: [ 377 \t 721 \t 670 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9033 \tBbox: [ 484 \t 470 \t 637 \t 749 ]\n",
      "3 \tObject: train \tConfidence = 0.8923 \tBbox: [ 0 \t 1 \t 446 \t 707 ]\n",
      "4 \tObject: person \tConfidence = 0.8808 \tBbox: [ 556 \t 10 \t 630 \t 248 ]\n",
      "5 \tObject: person \tConfidence = 0.8733 \tBbox: [ 437 \t 131 \t 536 \t 391 ]\n",
      "6 \tObject: person \tConfidence = 0.8566 \tBbox: [ 555 \t 255 \t 657 \t 490 ]\n",
      "7 \tObject: person \tConfidence = 0.8332 \tBbox: [ 441 \t 0 \t 488 \t 132 ]\n",
      "8 \tObject: person \tConfidence = 0.6995 \tBbox: [ 482 \t 0 \t 522 \t 100 ]\n",
      "9 \tObject: person \tConfidence = 0.4055 \tBbox: [ 572 \t 0 \t 635 \t 53 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000162 / 1050\n",
      "Frames to be processed: 888  | To do: 84.57 % | Done: 15.43 %\n",
      "\n",
      "2022-04-20 13:11:44.246704\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000162.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 30.9ms pre-process, 175.3ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.925 \tBbox: [ 377 \t 721 \t 671 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.905 \tBbox: [ 485 \t 471 \t 637 \t 749 ]\n",
      "3 \tObject: train \tConfidence = 0.8895 \tBbox: [ 1 \t 0 \t 450 \t 751 ]\n",
      "4 \tObject: person \tConfidence = 0.8805 \tBbox: [ 556 \t 14 \t 630 \t 248 ]\n",
      "5 \tObject: person \tConfidence = 0.868 \tBbox: [ 437 \t 131 \t 535 \t 392 ]\n",
      "6 \tObject: person \tConfidence = 0.8466 \tBbox: [ 552 \t 254 \t 654 \t 490 ]\n",
      "7 \tObject: person \tConfidence = 0.837 \tBbox: [ 440 \t 0 \t 487 \t 132 ]\n",
      "8 \tObject: person \tConfidence = 0.7021 \tBbox: [ 482 \t 0 \t 522 \t 100 ]\n",
      "9 \tObject: person \tConfidence = 0.4129 \tBbox: [ 570 \t 0 \t 633 \t 58 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000163 / 1050\n",
      "Frames to be processed: 887  | To do: 84.48 % | Done: 15.52 %\n",
      "\n",
      "2022-04-20 13:11:44.758571\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000163.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 49.5ms pre-process, 169.0ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9247 \tBbox: [ 378 \t 721 \t 671 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9028 \tBbox: [ 485 \t 472 \t 636 \t 748 ]\n",
      "3 \tObject: person \tConfidence = 0.8798 \tBbox: [ 556 \t 19 \t 630 \t 248 ]\n",
      "4 \tObject: person \tConfidence = 0.8615 \tBbox: [ 439 \t 132 \t 535 \t 391 ]\n",
      "5 \tObject: person \tConfidence = 0.8431 \tBbox: [ 440 \t 0 \t 488 \t 132 ]\n",
      "6 \tObject: train \tConfidence = 0.8337 \tBbox: [ 0 \t 1 \t 450 \t 839 ]\n",
      "7 \tObject: person \tConfidence = 0.8238 \tBbox: [ 550 \t 253 \t 652 \t 490 ]\n",
      "8 \tObject: person \tConfidence = 0.7054 \tBbox: [ 483 \t 0 \t 522 \t 100 ]\n",
      "9 \tObject: person \tConfidence = 0.3133 \tBbox: [ 572 \t 0 \t 616 \t 49 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000164 / 1050\n",
      "Frames to be processed: 886  | To do: 84.38 % | Done: 15.62 %\n",
      "\n",
      "2022-04-20 13:11:45.187410\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000164.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 28.5ms pre-process, 172.4ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9264 \tBbox: [ 378 \t 721 \t 672 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9004 \tBbox: [ 485 \t 470 \t 636 \t 747 ]\n",
      "3 \tObject: train \tConfidence = 0.8933 \tBbox: [ 1 \t 1 \t 446 \t 942 ]\n",
      "4 \tObject: person \tConfidence = 0.8808 \tBbox: [ 556 \t 16 \t 630 \t 247 ]\n",
      "5 \tObject: person \tConfidence = 0.8574 \tBbox: [ 518 \t 253 \t 648 \t 534 ]\n",
      "6 \tObject: person \tConfidence = 0.8531 \tBbox: [ 440 \t 133 \t 536 \t 391 ]\n",
      "7 \tObject: person \tConfidence = 0.8446 \tBbox: [ 440 \t 0 \t 488 \t 132 ]\n",
      "8 \tObject: person \tConfidence = 0.713 \tBbox: [ 482 \t 0 \t 521 \t 100 ]\n",
      "9 \tObject: person \tConfidence = 0.4963 \tBbox: [ 612 \t 0 \t 633 \t 59 ]\n",
      "10 \tObject: person \tConfidence = 0.3887 \tBbox: [ 572 \t 0 \t 615 \t 49 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000165 / 1050\n",
      "Frames to be processed: 885  | To do: 84.29 % | Done: 15.71 %\n",
      "\n",
      "2022-04-20 13:11:45.627926\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000165.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 28.8ms pre-process, 177.8ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9285 \tBbox: [ 378 \t 721 \t 673 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9114 \tBbox: [ 1 \t 1 \t 446 \t 984 ]\n",
      "3 \tObject: person \tConfidence = 0.8978 \tBbox: [ 485 \t 472 \t 636 \t 747 ]\n",
      "4 \tObject: person \tConfidence = 0.874 \tBbox: [ 556 \t 15 \t 629 \t 247 ]\n",
      "5 \tObject: person \tConfidence = 0.8479 \tBbox: [ 439 \t 133 \t 536 \t 391 ]\n",
      "6 \tObject: person \tConfidence = 0.8446 \tBbox: [ 441 \t 0 \t 487 \t 132 ]\n",
      "7 \tObject: person \tConfidence = 0.8436 \tBbox: [ 522 \t 252 \t 647 \t 533 ]\n",
      "8 \tObject: person \tConfidence = 0.7024 \tBbox: [ 482 \t 0 \t 521 \t 100 ]\n",
      "9 \tObject: person \tConfidence = 0.4358 \tBbox: [ 572 \t 0 \t 617 \t 50 ]\n",
      "10 \tObject: person \tConfidence = 0.3019 \tBbox: [ 612 \t 0 \t 633 \t 54 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000166 / 1050\n",
      "Frames to be processed: 884  | To do: 84.19 % | Done: 15.81 %\n",
      "\n",
      "2022-04-20 13:11:46.054214\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000166.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 32.0ms pre-process, 180.1ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9245 \tBbox: [ 378 \t 721 \t 673 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9161 \tBbox: [ 0 \t 3 \t 450 \t 1032 ]\n",
      "3 \tObject: person \tConfidence = 0.9038 \tBbox: [ 485 \t 471 \t 636 \t 747 ]\n",
      "4 \tObject: person \tConfidence = 0.87 \tBbox: [ 556 \t 12 \t 629 \t 247 ]\n",
      "5 \tObject: person \tConfidence = 0.8525 \tBbox: [ 438 \t 133 \t 535 \t 391 ]\n",
      "6 \tObject: person \tConfidence = 0.8444 \tBbox: [ 441 \t 0 \t 488 \t 132 ]\n",
      "7 \tObject: person \tConfidence = 0.8409 \tBbox: [ 521 \t 252 \t 644 \t 533 ]\n",
      "8 \tObject: person \tConfidence = 0.6604 \tBbox: [ 483 \t 0 \t 521 \t 100 ]\n",
      "9 \tObject: person \tConfidence = 0.3914 \tBbox: [ 573 \t 0 \t 615 \t 50 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000167 / 1050\n",
      "Frames to be processed: 883  | To do: 84.1 % | Done: 15.9 %\n",
      "\n",
      "2022-04-20 13:11:46.514717\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000167.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 26.3ms pre-process, 180.8ms inference, 4.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9214 \tBbox: [ 377 \t 721 \t 670 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9214 \tBbox: [ 0 \t 2 \t 451 \t 1063 ]\n",
      "3 \tObject: person \tConfidence = 0.9025 \tBbox: [ 485 \t 472 \t 635 \t 748 ]\n",
      "4 \tObject: person \tConfidence = 0.8659 \tBbox: [ 556 \t 14 \t 629 \t 247 ]\n",
      "5 \tObject: person \tConfidence = 0.8549 \tBbox: [ 519 \t 252 \t 642 \t 534 ]\n",
      "6 \tObject: person \tConfidence = 0.8401 \tBbox: [ 442 \t 133 \t 536 \t 391 ]\n",
      "7 \tObject: person \tConfidence = 0.8375 \tBbox: [ 441 \t 0 \t 487 \t 132 ]\n",
      "8 \tObject: person \tConfidence = 0.6601 \tBbox: [ 483 \t 0 \t 522 \t 99 ]\n",
      "9 \tObject: person \tConfidence = 0.3494 \tBbox: [ 572 \t 0 \t 616 \t 53 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000168 / 1050\n",
      "Frames to be processed: 882  | To do: 84.0 % | Done: 16.0 %\n",
      "\n",
      "2022-04-20 13:11:46.989674\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000168.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 26.7ms pre-process, 185.1ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9188 \tBbox: [ 378 \t 721 \t 671 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9034 \tBbox: [ 485 \t 471 \t 635 \t 747 ]\n",
      "3 \tObject: train \tConfidence = 0.9029 \tBbox: [ 0 \t 2 \t 448 \t 1071 ]\n",
      "4 \tObject: person \tConfidence = 0.8633 \tBbox: [ 557 \t 15 \t 629 \t 245 ]\n",
      "5 \tObject: person \tConfidence = 0.85 \tBbox: [ 439 \t 133 \t 535 \t 391 ]\n",
      "6 \tObject: person \tConfidence = 0.8445 \tBbox: [ 441 \t 0 \t 488 \t 132 ]\n",
      "7 \tObject: person \tConfidence = 0.844 \tBbox: [ 520 \t 251 \t 640 \t 533 ]\n",
      "8 \tObject: person \tConfidence = 0.6526 \tBbox: [ 483 \t 0 \t 522 \t 100 ]\n",
      "9 \tObject: person \tConfidence = 0.323 \tBbox: [ 583 \t 1 \t 622 \t 42 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000169 / 1050\n",
      "Frames to be processed: 881  | To do: 83.9 % | Done: 16.1 %\n",
      "\n",
      "2022-04-20 13:11:47.432753\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000169.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 28.5ms pre-process, 182.5ms inference, 3.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9174 \tBbox: [ 379 \t 721 \t 670 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9037 \tBbox: [ 486 \t 472 \t 636 \t 747 ]\n",
      "3 \tObject: train \tConfidence = 0.8863 \tBbox: [ 0 \t 2 \t 449 \t 1073 ]\n",
      "4 \tObject: person \tConfidence = 0.8685 \tBbox: [ 557 \t 5 \t 630 \t 244 ]\n",
      "5 \tObject: person \tConfidence = 0.8589 \tBbox: [ 523 \t 251 \t 631 \t 530 ]\n",
      "6 \tObject: person \tConfidence = 0.8565 \tBbox: [ 441 \t 0 \t 489 \t 131 ]\n",
      "7 \tObject: person \tConfidence = 0.8315 \tBbox: [ 450 \t 134 \t 536 \t 390 ]\n",
      "8 \tObject: person \tConfidence = 0.6605 \tBbox: [ 483 \t 0 \t 522 \t 99 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000170 / 1050\n",
      "Frames to be processed: 880  | To do: 83.81 % | Done: 16.19 %\n",
      "\n",
      "2022-04-20 13:11:47.895438\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000170.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 31.6ms pre-process, 172.6ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9202 \tBbox: [ 380 \t 720 \t 672 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9012 \tBbox: [ 486 \t 472 \t 636 \t 748 ]\n",
      "3 \tObject: train \tConfidence = 0.8844 \tBbox: [ 0 \t 2 \t 449 \t 1074 ]\n",
      "4 \tObject: person \tConfidence = 0.8573 \tBbox: [ 523 \t 251 \t 628 \t 529 ]\n",
      "5 \tObject: person \tConfidence = 0.8557 \tBbox: [ 441 \t 0 \t 488 \t 131 ]\n",
      "6 \tObject: person \tConfidence = 0.8438 \tBbox: [ 457 \t 134 \t 535 \t 390 ]\n",
      "7 \tObject: person \tConfidence = 0.8399 \tBbox: [ 557 \t 5 \t 629 \t 245 ]\n",
      "8 \tObject: person \tConfidence = 0.6649 \tBbox: [ 484 \t 0 \t 522 \t 100 ]\n",
      "9 \tObject: person \tConfidence = 0.3198 \tBbox: [ 584 \t 1 \t 618 \t 45 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000171 / 1050\n",
      "Frames to be processed: 879  | To do: 83.71 % | Done: 16.29 %\n",
      "\n",
      "2022-04-20 13:11:48.403911\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000171.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 27.9ms pre-process, 176.5ms inference, 9.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9145 \tBbox: [ 381 \t 721 \t 671 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9093 \tBbox: [ 0 \t 2 \t 450 \t 1074 ]\n",
      "3 \tObject: person \tConfidence = 0.8951 \tBbox: [ 486 \t 471 \t 636 \t 748 ]\n",
      "4 \tObject: person \tConfidence = 0.869 \tBbox: [ 519 \t 250 \t 626 \t 534 ]\n",
      "5 \tObject: person \tConfidence = 0.851 \tBbox: [ 558 \t 12 \t 630 \t 246 ]\n",
      "6 \tObject: person \tConfidence = 0.8479 \tBbox: [ 441 \t 0 \t 488 \t 131 ]\n",
      "7 \tObject: person \tConfidence = 0.8326 \tBbox: [ 450 \t 134 \t 536 \t 390 ]\n",
      "8 \tObject: person \tConfidence = 0.6692 \tBbox: [ 483 \t 0 \t 522 \t 100 ]\n",
      "9 \tObject: person \tConfidence = 0.3713 \tBbox: [ 584 \t 1 \t 618 \t 39 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000172 / 1050\n",
      "Frames to be processed: 878  | To do: 83.62 % | Done: 16.38 %\n",
      "\n",
      "2022-04-20 13:11:48.847396\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000172.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 37.8ms pre-process, 180.2ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.914 \tBbox: [ 381 \t 720 \t 669 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8943 \tBbox: [ 486 \t 471 \t 636 \t 749 ]\n",
      "3 \tObject: train \tConfidence = 0.8876 \tBbox: [ 0 \t 2 \t 450 \t 1073 ]\n",
      "4 \tObject: person \tConfidence = 0.8691 \tBbox: [ 518 \t 250 \t 623 \t 534 ]\n",
      "5 \tObject: person \tConfidence = 0.8409 \tBbox: [ 441 \t 0 \t 488 \t 132 ]\n",
      "6 \tObject: person \tConfidence = 0.8375 \tBbox: [ 446 \t 134 \t 536 \t 390 ]\n",
      "7 \tObject: person \tConfidence = 0.8368 \tBbox: [ 558 \t 15 \t 630 \t 245 ]\n",
      "8 \tObject: person \tConfidence = 0.667 \tBbox: [ 483 \t 0 \t 522 \t 100 ]\n",
      "9 \tObject: person \tConfidence = 0.4032 \tBbox: [ 574 \t 1 \t 616 \t 54 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000173 / 1050\n",
      "Frames to be processed: 877  | To do: 83.52 % | Done: 16.48 %\n",
      "\n",
      "2022-04-20 13:11:49.288940\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000173.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 23.9ms pre-process, 180.4ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9153 \tBbox: [ 381 \t 720 \t 672 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9065 \tBbox: [ 0 \t 2 \t 451 \t 1073 ]\n",
      "3 \tObject: person \tConfidence = 0.9004 \tBbox: [ 486 \t 470 \t 636 \t 749 ]\n",
      "4 \tObject: person \tConfidence = 0.8601 \tBbox: [ 517 \t 250 \t 620 \t 534 ]\n",
      "5 \tObject: person \tConfidence = 0.8471 \tBbox: [ 558 \t 15 \t 631 \t 244 ]\n",
      "6 \tObject: person \tConfidence = 0.8442 \tBbox: [ 441 \t 0 \t 488 \t 132 ]\n",
      "7 \tObject: person \tConfidence = 0.8372 \tBbox: [ 449 \t 135 \t 536 \t 389 ]\n",
      "8 \tObject: person \tConfidence = 0.6543 \tBbox: [ 484 \t 0 \t 523 \t 99 ]\n",
      "9 \tObject: person \tConfidence = 0.4934 \tBbox: [ 571 \t 1 \t 616 \t 55 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000174 / 1050\n",
      "Frames to be processed: 876  | To do: 83.43 % | Done: 16.57 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 26.5ms pre-process, 166.8ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:11:49.736056\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000174.jpg ------------------------------ \n",
      "\n",
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9135 \tBbox: [ 381 \t 720 \t 672 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9057 \tBbox: [ 0 \t 1 \t 453 \t 1068 ]\n",
      "3 \tObject: person \tConfidence = 0.8942 \tBbox: [ 486 \t 469 \t 636 \t 749 ]\n",
      "4 \tObject: person \tConfidence = 0.8704 \tBbox: [ 559 \t 16 \t 632 \t 245 ]\n",
      "5 \tObject: person \tConfidence = 0.8514 \tBbox: [ 516 \t 248 \t 617 \t 535 ]\n",
      "6 \tObject: person \tConfidence = 0.8462 \tBbox: [ 441 \t 0 \t 489 \t 131 ]\n",
      "7 \tObject: person \tConfidence = 0.8324 \tBbox: [ 445 \t 135 \t 535 \t 389 ]\n",
      "8 \tObject: person \tConfidence = 0.6469 \tBbox: [ 483 \t 0 \t 524 \t 99 ]\n",
      "9 \tObject: person \tConfidence = 0.567 \tBbox: [ 569 \t 0 \t 612 \t 55 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000175 / 1050\n",
      "Frames to be processed: 875  | To do: 83.33 % | Done: 16.67 %\n",
      "\n",
      "2022-04-20 13:11:50.181470\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000175.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 30.5ms pre-process, 173.2ms inference, 5.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9193 \tBbox: [ 381 \t 719 \t 673 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.8959 \tBbox: [ 0 \t 2 \t 456 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.8953 \tBbox: [ 485 \t 471 \t 636 \t 749 ]\n",
      "4 \tObject: person \tConfidence = 0.8728 \tBbox: [ 560 \t 15 \t 632 \t 244 ]\n",
      "5 \tObject: person \tConfidence = 0.8491 \tBbox: [ 516 \t 247 \t 616 \t 534 ]\n",
      "6 \tObject: person \tConfidence = 0.8405 \tBbox: [ 442 \t 0 \t 489 \t 131 ]\n",
      "7 \tObject: person \tConfidence = 0.8272 \tBbox: [ 446 \t 135 \t 536 \t 390 ]\n",
      "8 \tObject: person \tConfidence = 0.6459 \tBbox: [ 486 \t 0 \t 525 \t 97 ]\n",
      "9 \tObject: person \tConfidence = 0.5896 \tBbox: [ 570 \t 1 \t 611 \t 55 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000176 / 1050\n",
      "Frames to be processed: 874  | To do: 83.24 % | Done: 16.76 %\n",
      "\n",
      "2022-04-20 13:11:50.647033\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000176.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 27.9ms pre-process, 173.1ms inference, 4.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9178 \tBbox: [ 381 \t 719 \t 671 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9056 \tBbox: [ 0 \t 2 \t 453 \t 1072 ]\n",
      "3 \tObject: person \tConfidence = 0.8937 \tBbox: [ 484 \t 471 \t 636 \t 749 ]\n",
      "4 \tObject: person \tConfidence = 0.8666 \tBbox: [ 561 \t 15 \t 633 \t 245 ]\n",
      "5 \tObject: person \tConfidence = 0.8462 \tBbox: [ 516 \t 246 \t 615 \t 534 ]\n",
      "6 \tObject: person \tConfidence = 0.8378 \tBbox: [ 442 \t 0 \t 491 \t 132 ]\n",
      "7 \tObject: person \tConfidence = 0.8316 \tBbox: [ 442 \t 135 \t 536 \t 389 ]\n",
      "8 \tObject: person \tConfidence = 0.6051 \tBbox: [ 486 \t 0 \t 525 \t 96 ]\n",
      "9 \tObject: person \tConfidence = 0.5739 \tBbox: [ 568 \t 0 \t 612 \t 59 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000177 / 1050\n",
      "Frames to be processed: 873  | To do: 83.14 % | Done: 16.86 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 26.0ms pre-process, 165.4ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:11:51.074088\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000177.jpg ------------------------------ \n",
      "\n",
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9205 \tBbox: [ 382 \t 719 \t 672 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.8963 \tBbox: [ 0 \t 2 \t 455 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.8644 \tBbox: [ 561 \t 15 \t 633 \t 244 ]\n",
      "4 \tObject: person \tConfidence = 0.8627 \tBbox: [ 483 \t 471 \t 636 \t 755 ]\n",
      "5 \tObject: person \tConfidence = 0.8539 \tBbox: [ 515 \t 246 \t 614 \t 534 ]\n",
      "6 \tObject: person \tConfidence = 0.8338 \tBbox: [ 444 \t 135 \t 536 \t 389 ]\n",
      "7 \tObject: person \tConfidence = 0.8248 \tBbox: [ 442 \t 0 \t 490 \t 132 ]\n",
      "8 \tObject: person \tConfidence = 0.6571 \tBbox: [ 486 \t 0 \t 527 \t 96 ]\n",
      "9 \tObject: person \tConfidence = 0.5428 \tBbox: [ 568 \t 0 \t 611 \t 65 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000178 / 1050\n",
      "Frames to be processed: 872  | To do: 83.05 % | Done: 16.95 %\n",
      "\n",
      "2022-04-20 13:11:51.540701\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000178.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 28.1ms pre-process, 174.5ms inference, 11.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9209 \tBbox: [ 381 \t 718 \t 673 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8914 \tBbox: [ 483 \t 472 \t 635 \t 748 ]\n",
      "3 \tObject: train \tConfidence = 0.8792 \tBbox: [ 0 \t 0 \t 455 \t 1049 ]\n",
      "4 \tObject: person \tConfidence = 0.8745 \tBbox: [ 561 \t 15 \t 634 \t 245 ]\n",
      "5 \tObject: person \tConfidence = 0.8508 \tBbox: [ 515 \t 244 \t 613 \t 533 ]\n",
      "6 \tObject: person \tConfidence = 0.833 \tBbox: [ 443 \t 0 \t 491 \t 132 ]\n",
      "7 \tObject: person \tConfidence = 0.825 \tBbox: [ 444 \t 135 \t 536 \t 389 ]\n",
      "8 \tObject: person \tConfidence = 0.7363 \tBbox: [ 485 \t 0 \t 527 \t 98 ]\n",
      "9 \tObject: person \tConfidence = 0.5885 \tBbox: [ 566 \t 0 \t 612 \t 63 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000179 / 1050\n",
      "Frames to be processed: 871  | To do: 82.95 % | Done: 17.05 %\n",
      "\n",
      "2022-04-20 13:11:51.976783\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000179.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 24.4ms pre-process, 175.3ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9196 \tBbox: [ 381 \t 718 \t 671 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.8969 \tBbox: [ 0 \t 4 \t 455 \t 1045 ]\n",
      "3 \tObject: person \tConfidence = 0.8911 \tBbox: [ 483 \t 472 \t 636 \t 747 ]\n",
      "4 \tObject: person \tConfidence = 0.8811 \tBbox: [ 562 \t 14 \t 635 \t 243 ]\n",
      "5 \tObject: person \tConfidence = 0.8517 \tBbox: [ 510 \t 243 \t 612 \t 533 ]\n",
      "6 \tObject: person \tConfidence = 0.8324 \tBbox: [ 443 \t 0 \t 490 \t 132 ]\n",
      "7 \tObject: person \tConfidence = 0.8145 \tBbox: [ 452 \t 135 \t 535 \t 388 ]\n",
      "8 \tObject: person \tConfidence = 0.7103 \tBbox: [ 482 \t 0 \t 527 \t 98 ]\n",
      "9 \tObject: person \tConfidence = 0.5048 \tBbox: [ 566 \t 0 \t 612 \t 57 ]\n",
      "10 \tObject: person \tConfidence = 0.3439 \tBbox: [ 563 \t 0 \t 589 \t 53 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000180 / 1050\n",
      "Frames to be processed: 870  | To do: 82.86 % | Done: 17.14 %\n",
      "\n",
      "2022-04-20 13:11:52.391373\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000180.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 26.0ms pre-process, 178.1ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9178 \tBbox: [ 381 \t 717 \t 670 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9002 \tBbox: [ 0 \t 3 \t 454 \t 1074 ]\n",
      "3 \tObject: person \tConfidence = 0.8937 \tBbox: [ 483 \t 472 \t 636 \t 747 ]\n",
      "4 \tObject: person \tConfidence = 0.8802 \tBbox: [ 562 \t 14 \t 635 \t 244 ]\n",
      "5 \tObject: person \tConfidence = 0.8409 \tBbox: [ 509 \t 242 \t 611 \t 530 ]\n",
      "6 \tObject: person \tConfidence = 0.8372 \tBbox: [ 443 \t 0 \t 490 \t 132 ]\n",
      "7 \tObject: person \tConfidence = 0.8193 \tBbox: [ 454 \t 136 \t 535 \t 389 ]\n",
      "8 \tObject: person \tConfidence = 0.7086 \tBbox: [ 482 \t 0 \t 526 \t 97 ]\n",
      "9 \tObject: person \tConfidence = 0.4988 \tBbox: [ 565 \t 0 \t 611 \t 63 ]\n",
      "10 \tObject: person \tConfidence = 0.3304 \tBbox: [ 563 \t 0 \t 588 \t 54 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000181 / 1050\n",
      "Frames to be processed: 869  | To do: 82.76 % | Done: 17.24 %\n",
      "\n",
      "2022-04-20 13:11:52.823324\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000181.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 29.7ms pre-process, 174.4ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9221 \tBbox: [ 381 \t 717 \t 674 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9018 \tBbox: [ 0 \t 1 \t 455 \t 1072 ]\n",
      "3 \tObject: person \tConfidence = 0.8922 \tBbox: [ 483 \t 471 \t 637 \t 746 ]\n",
      "4 \tObject: person \tConfidence = 0.8659 \tBbox: [ 562 \t 14 \t 636 \t 245 ]\n",
      "5 \tObject: person \tConfidence = 0.8401 \tBbox: [ 443 \t 0 \t 490 \t 132 ]\n",
      "6 \tObject: person \tConfidence = 0.838 \tBbox: [ 509 \t 240 \t 610 \t 531 ]\n",
      "7 \tObject: person \tConfidence = 0.8107 \tBbox: [ 454 \t 136 \t 535 \t 390 ]\n",
      "8 \tObject: person \tConfidence = 0.7259 \tBbox: [ 482 \t 0 \t 526 \t 97 ]\n",
      "9 \tObject: person \tConfidence = 0.5317 \tBbox: [ 565 \t 1 \t 613 \t 71 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000182 / 1050\n",
      "Frames to be processed: 868  | To do: 82.67 % | Done: 17.33 %\n",
      "\n",
      "2022-04-20 13:11:53.268580\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000182.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 32.4ms pre-process, 174.2ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9259 \tBbox: [ 382 \t 717 \t 675 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.911 \tBbox: [ 0 \t 3 \t 453 \t 1043 ]\n",
      "3 \tObject: person \tConfidence = 0.8898 \tBbox: [ 482 \t 471 \t 637 \t 746 ]\n",
      "4 \tObject: person \tConfidence = 0.8504 \tBbox: [ 563 \t 14 \t 637 \t 244 ]\n",
      "5 \tObject: person \tConfidence = 0.845 \tBbox: [ 443 \t 0 \t 490 \t 132 ]\n",
      "6 \tObject: person \tConfidence = 0.8424 \tBbox: [ 509 \t 240 \t 609 \t 528 ]\n",
      "7 \tObject: person \tConfidence = 0.8037 \tBbox: [ 452 \t 136 \t 536 \t 389 ]\n",
      "8 \tObject: person \tConfidence = 0.7433 \tBbox: [ 482 \t 0 \t 527 \t 97 ]\n",
      "9 \tObject: person \tConfidence = 0.4711 \tBbox: [ 564 \t 0 \t 614 \t 69 ]\n",
      "10 \tObject: person \tConfidence = 0.4335 \tBbox: [ 558 \t 2 \t 612 \t 157 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000183 / 1050\n",
      "Frames to be processed: 867  | To do: 82.57 % | Done: 17.43 %\n",
      "\n",
      "2022-04-20 13:11:53.691386\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000183.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 25.8ms pre-process, 182.6ms inference, 11.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9286 \tBbox: [ 382 \t 717 \t 674 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9187 \tBbox: [ 0 \t 1 \t 454 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.8886 \tBbox: [ 482 \t 470 \t 638 \t 748 ]\n",
      "4 \tObject: person \tConfidence = 0.8565 \tBbox: [ 565 \t 14 \t 637 \t 242 ]\n",
      "5 \tObject: person \tConfidence = 0.8444 \tBbox: [ 444 \t 0 \t 491 \t 132 ]\n",
      "6 \tObject: person \tConfidence = 0.8287 \tBbox: [ 508 \t 240 \t 607 \t 527 ]\n",
      "7 \tObject: person \tConfidence = 0.7959 \tBbox: [ 449 \t 135 \t 536 \t 388 ]\n",
      "8 \tObject: person \tConfidence = 0.7493 \tBbox: [ 483 \t 0 \t 527 \t 97 ]\n",
      "9 \tObject: person \tConfidence = 0.5389 \tBbox: [ 554 \t 7 \t 614 \t 167 ]\n",
      "10 \tObject: person \tConfidence = 0.4234 \tBbox: [ 563 \t 0 \t 614 \t 64 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000184 / 1050\n",
      "Frames to be processed: 866  | To do: 82.48 % | Done: 17.52 %\n",
      "\n",
      "2022-04-20 13:11:54.129803\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000184.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 26.4ms pre-process, 171.6ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9283 \tBbox: [ 381 \t 717 \t 676 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9184 \tBbox: [ 0 \t 2 \t 450 \t 1075 ]\n",
      "3 \tObject: person \tConfidence = 0.8779 \tBbox: [ 481 \t 469 \t 639 \t 748 ]\n",
      "4 \tObject: person \tConfidence = 0.8556 \tBbox: [ 566 \t 15 \t 637 \t 243 ]\n",
      "5 \tObject: person \tConfidence = 0.8355 \tBbox: [ 443 \t 0 \t 491 \t 131 ]\n",
      "6 \tObject: person \tConfidence = 0.8237 \tBbox: [ 508 \t 239 \t 606 \t 522 ]\n",
      "7 \tObject: person \tConfidence = 0.8067 \tBbox: [ 445 \t 135 \t 536 \t 385 ]\n",
      "8 \tObject: person \tConfidence = 0.74 \tBbox: [ 482 \t 0 \t 527 \t 97 ]\n",
      "9 \tObject: person \tConfidence = 0.6202 \tBbox: [ 545 \t 4 \t 619 \t 170 ]\n",
      "10 \tObject: person \tConfidence = 0.4491 \tBbox: [ 556 \t 0 \t 622 \t 77 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000185 / 1050\n",
      "Frames to be processed: 865  | To do: 82.38 % | Done: 17.62 %\n",
      "\n",
      "2022-04-20 13:11:54.582606\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000185.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 31.6ms pre-process, 175.6ms inference, 11.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9274 \tBbox: [ 381 \t 717 \t 676 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9217 \tBbox: [ 0 \t 2 \t 451 \t 1074 ]\n",
      "3 \tObject: person \tConfidence = 0.8849 \tBbox: [ 481 \t 469 \t 640 \t 746 ]\n",
      "4 \tObject: person \tConfidence = 0.8706 \tBbox: [ 567 \t 13 \t 637 \t 244 ]\n",
      "5 \tObject: person \tConfidence = 0.8412 \tBbox: [ 444 \t 0 \t 490 \t 131 ]\n",
      "6 \tObject: person \tConfidence = 0.8269 \tBbox: [ 508 \t 238 \t 605 \t 524 ]\n",
      "7 \tObject: person \tConfidence = 0.7861 \tBbox: [ 445 \t 135 \t 536 \t 385 ]\n",
      "8 \tObject: person \tConfidence = 0.7544 \tBbox: [ 482 \t 0 \t 527 \t 97 ]\n",
      "9 \tObject: person \tConfidence = 0.7349 \tBbox: [ 543 \t 2 \t 619 \t 169 ]\n",
      "10 \tObject: person \tConfidence = 0.3004 \tBbox: [ 360 \t 0 \t 380 \t 83 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000186 / 1050\n",
      "Frames to be processed: 864  | To do: 82.29 % | Done: 17.71 %\n",
      "\n",
      "2022-04-20 13:11:55.018591\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000186.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 25.5ms pre-process, 179.2ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9251 \tBbox: [ 380 \t 716 \t 675 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.921 \tBbox: [ 0 \t 2 \t 451 \t 1074 ]\n",
      "3 \tObject: person \tConfidence = 0.8832 \tBbox: [ 484 \t 469 \t 639 \t 745 ]\n",
      "4 \tObject: person \tConfidence = 0.8632 \tBbox: [ 567 \t 14 \t 637 \t 243 ]\n",
      "5 \tObject: person \tConfidence = 0.8354 \tBbox: [ 444 \t 0 \t 490 \t 131 ]\n",
      "6 \tObject: person \tConfidence = 0.822 \tBbox: [ 509 \t 237 \t 605 \t 527 ]\n",
      "7 \tObject: person \tConfidence = 0.7816 \tBbox: [ 441 \t 135 \t 535 \t 385 ]\n",
      "8 \tObject: person \tConfidence = 0.7447 \tBbox: [ 482 \t 0 \t 527 \t 96 ]\n",
      "9 \tObject: person \tConfidence = 0.6837 \tBbox: [ 540 \t 3 \t 621 \t 169 ]\n",
      "10 \tObject: person \tConfidence = 0.4396 \tBbox: [ 544 \t 0 \t 622 \t 74 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000187 / 1050\n",
      "Frames to be processed: 863  | To do: 82.19 % | Done: 17.81 %\n",
      "\n",
      "2022-04-20 13:11:55.472656\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000187.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 29.9ms pre-process, 181.7ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9271 \tBbox: [ 379 \t 716 \t 675 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9248 \tBbox: [ 0 \t 1 \t 449 \t 1075 ]\n",
      "3 \tObject: person \tConfidence = 0.8868 \tBbox: [ 485 \t 469 \t 639 \t 744 ]\n",
      "4 \tObject: person \tConfidence = 0.8627 \tBbox: [ 566 \t 11 \t 638 \t 243 ]\n",
      "5 \tObject: person \tConfidence = 0.8394 \tBbox: [ 444 \t 0 \t 490 \t 131 ]\n",
      "6 \tObject: person \tConfidence = 0.8242 \tBbox: [ 509 \t 237 \t 604 \t 528 ]\n",
      "7 \tObject: person \tConfidence = 0.7502 \tBbox: [ 482 \t 0 \t 528 \t 96 ]\n",
      "8 \tObject: person \tConfidence = 0.749 \tBbox: [ 442 \t 136 \t 536 \t 384 ]\n",
      "9 \tObject: person \tConfidence = 0.6902 \tBbox: [ 539 \t 3 \t 621 \t 170 ]\n",
      "10 \tObject: person \tConfidence = 0.3801 \tBbox: [ 542 \t 0 \t 621 \t 73 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000188 / 1050\n",
      "Frames to be processed: 862  | To do: 82.1 % | Done: 17.9 %\n",
      "\n",
      "2022-04-20 13:11:55.940487\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000188.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 31.0ms pre-process, 181.7ms inference, 3.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9264 \tBbox: [ 378 \t 716 \t 675 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9236 \tBbox: [ 0 \t 1 \t 449 \t 1075 ]\n",
      "3 \tObject: person \tConfidence = 0.8899 \tBbox: [ 485 \t 469 \t 639 \t 743 ]\n",
      "4 \tObject: person \tConfidence = 0.8723 \tBbox: [ 566 \t 13 \t 638 \t 243 ]\n",
      "5 \tObject: person \tConfidence = 0.8358 \tBbox: [ 445 \t 0 \t 490 \t 131 ]\n",
      "6 \tObject: person \tConfidence = 0.8073 \tBbox: [ 509 \t 237 \t 604 \t 520 ]\n",
      "7 \tObject: person \tConfidence = 0.7507 \tBbox: [ 539 \t 1 \t 622 \t 172 ]\n",
      "8 \tObject: person \tConfidence = 0.746 \tBbox: [ 482 \t 0 \t 528 \t 96 ]\n",
      "9 \tObject: person \tConfidence = 0.715 \tBbox: [ 446 \t 136 \t 537 \t 387 ]\n",
      "10 \tObject: person \tConfidence = 0.3294 \tBbox: [ 540 \t 0 \t 584 \t 70 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000189 / 1050\n",
      "Frames to be processed: 861  | To do: 82.0 % | Done: 18.0 %\n",
      "\n",
      "2022-04-20 13:11:56.371420\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000189.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 29.4ms pre-process, 180.3ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9238 \tBbox: [ 377 \t 716 \t 676 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9147 \tBbox: [ 0 \t 2 \t 451 \t 1072 ]\n",
      "3 \tObject: person \tConfidence = 0.8975 \tBbox: [ 486 \t 468 \t 639 \t 744 ]\n",
      "4 \tObject: person \tConfidence = 0.8781 \tBbox: [ 567 \t 13 \t 639 \t 241 ]\n",
      "5 \tObject: person \tConfidence = 0.8441 \tBbox: [ 445 \t 0 \t 490 \t 130 ]\n",
      "6 \tObject: person \tConfidence = 0.8126 \tBbox: [ 507 \t 236 \t 603 \t 519 ]\n",
      "7 \tObject: person \tConfidence = 0.7799 \tBbox: [ 482 \t 0 \t 530 \t 96 ]\n",
      "8 \tObject: person \tConfidence = 0.7444 \tBbox: [ 540 \t 2 \t 614 \t 170 ]\n",
      "9 \tObject: person \tConfidence = 0.6873 \tBbox: [ 446 \t 136 \t 537 \t 380 ]\n",
      "10 \tObject: person \tConfidence = 0.5095 \tBbox: [ 541 \t 0 \t 583 \t 71 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000190 / 1050\n",
      "Frames to be processed: 860  | To do: 81.9 % | Done: 18.1 %\n",
      "\n",
      "2022-04-20 13:11:56.824400\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000190.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 31.8ms pre-process, 184.1ms inference, 4.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9255 \tBbox: [ 377 \t 716 \t 676 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9162 \tBbox: [ 0 \t 1 \t 451 \t 1074 ]\n",
      "3 \tObject: person \tConfidence = 0.8984 \tBbox: [ 487 \t 468 \t 639 \t 744 ]\n",
      "4 \tObject: person \tConfidence = 0.8804 \tBbox: [ 567 \t 13 \t 639 \t 241 ]\n",
      "5 \tObject: person \tConfidence = 0.8436 \tBbox: [ 445 \t 0 \t 491 \t 130 ]\n",
      "6 \tObject: person \tConfidence = 0.8179 \tBbox: [ 506 \t 237 \t 603 \t 517 ]\n",
      "7 \tObject: person \tConfidence = 0.7952 \tBbox: [ 482 \t 0 \t 530 \t 96 ]\n",
      "8 \tObject: person \tConfidence = 0.7567 \tBbox: [ 542 \t 3 \t 604 \t 169 ]\n",
      "9 \tObject: person \tConfidence = 0.714 \tBbox: [ 451 \t 137 \t 537 \t 373 ]\n",
      "10 \tObject: person \tConfidence = 0.5934 \tBbox: [ 541 \t 0 \t 582 \t 70 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000191 / 1050\n",
      "Frames to be processed: 859  | To do: 81.81 % | Done: 18.19 %\n",
      "\n",
      "2022-04-20 13:11:57.289612\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000191.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 41.8ms pre-process, 185.0ms inference, 3.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9247 \tBbox: [ 377 \t 716 \t 676 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.919 \tBbox: [ 0 \t 1 \t 451 \t 1074 ]\n",
      "3 \tObject: person \tConfidence = 0.8964 \tBbox: [ 487 \t 468 \t 640 \t 744 ]\n",
      "4 \tObject: person \tConfidence = 0.8719 \tBbox: [ 567 \t 13 \t 640 \t 242 ]\n",
      "5 \tObject: person \tConfidence = 0.849 \tBbox: [ 446 \t 0 \t 491 \t 129 ]\n",
      "6 \tObject: person \tConfidence = 0.818 \tBbox: [ 505 \t 236 \t 603 \t 517 ]\n",
      "7 \tObject: person \tConfidence = 0.7818 \tBbox: [ 482 \t 0 \t 530 \t 96 ]\n",
      "8 \tObject: person \tConfidence = 0.7339 \tBbox: [ 543 \t 3 \t 601 \t 167 ]\n",
      "9 \tObject: person \tConfidence = 0.637 \tBbox: [ 454 \t 137 \t 537 \t 359 ]\n",
      "10 \tObject: person \tConfidence = 0.534 \tBbox: [ 541 \t 0 \t 578 \t 71 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000192 / 1050\n",
      "Frames to be processed: 858  | To do: 81.71 % | Done: 18.29 %\n",
      "\n",
      "2022-04-20 13:11:57.741346\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000192.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 30.1ms pre-process, 182.1ms inference, 3.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9211 \tBbox: [ 377 \t 716 \t 676 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9147 \tBbox: [ 0 \t 1 \t 454 \t 1074 ]\n",
      "3 \tObject: person \tConfidence = 0.8983 \tBbox: [ 487 \t 468 \t 640 \t 743 ]\n",
      "4 \tObject: person \tConfidence = 0.8768 \tBbox: [ 567 \t 13 \t 640 \t 242 ]\n",
      "5 \tObject: person \tConfidence = 0.8577 \tBbox: [ 447 \t 0 \t 491 \t 129 ]\n",
      "6 \tObject: person \tConfidence = 0.825 \tBbox: [ 505 \t 236 \t 603 \t 516 ]\n",
      "7 \tObject: person \tConfidence = 0.7774 \tBbox: [ 482 \t 0 \t 531 \t 96 ]\n",
      "8 \tObject: person \tConfidence = 0.7419 \tBbox: [ 543 \t 2 \t 601 \t 168 ]\n",
      "9 \tObject: person \tConfidence = 0.6243 \tBbox: [ 444 \t 137 \t 537 \t 365 ]\n",
      "10 \tObject: person \tConfidence = 0.6161 \tBbox: [ 542 \t 0 \t 575 \t 71 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000193 / 1050\n",
      "Frames to be processed: 857  | To do: 81.62 % | Done: 18.38 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 28.4ms pre-process, 163.7ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:11:58.188577\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000193.jpg ------------------------------ \n",
      "\n",
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9185 \tBbox: [ 377 \t 716 \t 676 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9104 \tBbox: [ 0 \t 1 \t 456 \t 1073 ]\n",
      "3 \tObject: person \tConfidence = 0.8857 \tBbox: [ 486 \t 468 \t 641 \t 742 ]\n",
      "4 \tObject: person \tConfidence = 0.8784 \tBbox: [ 567 \t 13 \t 640 \t 242 ]\n",
      "5 \tObject: person \tConfidence = 0.86 \tBbox: [ 447 \t 0 \t 491 \t 129 ]\n",
      "6 \tObject: person \tConfidence = 0.8366 \tBbox: [ 505 \t 233 \t 603 \t 527 ]\n",
      "7 \tObject: person \tConfidence = 0.7885 \tBbox: [ 482 \t 0 \t 531 \t 96 ]\n",
      "8 \tObject: person \tConfidence = 0.7087 \tBbox: [ 544 \t 0 \t 607 \t 167 ]\n",
      "9 \tObject: person \tConfidence = 0.6639 \tBbox: [ 543 \t 0 \t 574 \t 70 ]\n",
      "10 \tObject: person \tConfidence = 0.6636 \tBbox: [ 443 \t 137 \t 537 \t 363 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000194 / 1050\n",
      "Frames to be processed: 856  | To do: 81.52 % | Done: 18.48 %\n",
      "\n",
      "2022-04-20 13:11:58.584775\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000194.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 28.2ms pre-process, 174.0ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9212 \tBbox: [ 377 \t 716 \t 676 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9187 \tBbox: [ 0 \t 1 \t 455 \t 1072 ]\n",
      "3 \tObject: person \tConfidence = 0.889 \tBbox: [ 485 \t 467 \t 641 \t 744 ]\n",
      "4 \tObject: person \tConfidence = 0.8817 \tBbox: [ 567 \t 12 \t 641 \t 242 ]\n",
      "5 \tObject: person \tConfidence = 0.8676 \tBbox: [ 447 \t 0 \t 492 \t 128 ]\n",
      "6 \tObject: person \tConfidence = 0.8336 \tBbox: [ 506 \t 233 \t 603 \t 525 ]\n",
      "7 \tObject: person \tConfidence = 0.806 \tBbox: [ 540 \t 1 \t 599 \t 164 ]\n",
      "8 \tObject: person \tConfidence = 0.769 \tBbox: [ 483 \t 0 \t 531 \t 94 ]\n",
      "9 \tObject: person \tConfidence = 0.69 \tBbox: [ 443 \t 136 \t 536 \t 375 ]\n",
      "10 \tObject: person \tConfidence = 0.6393 \tBbox: [ 543 \t 0 \t 572 \t 69 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000195 / 1050\n",
      "Frames to be processed: 855  | To do: 81.43 % | Done: 18.57 %\n",
      "\n",
      "2022-04-20 13:11:59.043820\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000195.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 25.4ms pre-process, 171.1ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9217 \tBbox: [ 378 \t 717 \t 676 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9208 \tBbox: [ 0 \t 1 \t 456 \t 1068 ]\n",
      "3 \tObject: person \tConfidence = 0.9016 \tBbox: [ 488 \t 467 \t 641 \t 743 ]\n",
      "4 \tObject: person \tConfidence = 0.8793 \tBbox: [ 567 \t 11 \t 642 \t 242 ]\n",
      "5 \tObject: person \tConfidence = 0.8696 \tBbox: [ 447 \t 0 \t 492 \t 128 ]\n",
      "6 \tObject: person \tConfidence = 0.8417 \tBbox: [ 506 \t 234 \t 604 \t 526 ]\n",
      "7 \tObject: person \tConfidence = 0.7956 \tBbox: [ 541 \t 1 \t 599 \t 164 ]\n",
      "8 \tObject: person \tConfidence = 0.7891 \tBbox: [ 450 \t 136 \t 537 \t 378 ]\n",
      "9 \tObject: person \tConfidence = 0.7481 \tBbox: [ 484 \t 0 \t 531 \t 94 ]\n",
      "10 \tObject: person \tConfidence = 0.6859 \tBbox: [ 543 \t 0 \t 571 \t 68 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000196 / 1050\n",
      "Frames to be processed: 854  | To do: 81.33 % | Done: 18.67 %\n",
      "\n",
      "2022-04-20 13:11:59.445932\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000196.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 30.5ms pre-process, 173.9ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9205 \tBbox: [ 0 \t 2 \t 456 \t 1074 ]\n",
      "2 \tObject: person \tConfidence = 0.9203 \tBbox: [ 377 \t 717 \t 676 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9041 \tBbox: [ 488 \t 467 \t 642 \t 744 ]\n",
      "4 \tObject: person \tConfidence = 0.8773 \tBbox: [ 567 \t 12 \t 641 \t 242 ]\n",
      "5 \tObject: person \tConfidence = 0.8632 \tBbox: [ 447 \t 0 \t 492 \t 128 ]\n",
      "6 \tObject: person \tConfidence = 0.8432 \tBbox: [ 506 \t 234 \t 604 \t 527 ]\n",
      "7 \tObject: person \tConfidence = 0.8047 \tBbox: [ 541 \t 1 \t 600 \t 164 ]\n",
      "8 \tObject: person \tConfidence = 0.7985 \tBbox: [ 455 \t 136 \t 537 \t 382 ]\n",
      "9 \tObject: person \tConfidence = 0.7754 \tBbox: [ 484 \t 0 \t 531 \t 94 ]\n",
      "10 \tObject: person \tConfidence = 0.6384 \tBbox: [ 543 \t 0 \t 570 \t 69 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000197 / 1050\n",
      "Frames to be processed: 853  | To do: 81.24 % | Done: 18.76 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 24.5ms pre-process, 167.4ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:11:59.901332\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000197.jpg ------------------------------ \n",
      "\n",
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9221 \tBbox: [ 377 \t 717 \t 677 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9183 \tBbox: [ 0 \t 2 \t 455 \t 1074 ]\n",
      "3 \tObject: person \tConfidence = 0.908 \tBbox: [ 489 \t 467 \t 642 \t 747 ]\n",
      "4 \tObject: person \tConfidence = 0.8762 \tBbox: [ 569 \t 12 \t 642 \t 242 ]\n",
      "5 \tObject: person \tConfidence = 0.8621 \tBbox: [ 447 \t 0 \t 493 \t 127 ]\n",
      "6 \tObject: person \tConfidence = 0.8363 \tBbox: [ 506 \t 233 \t 603 \t 527 ]\n",
      "7 \tObject: person \tConfidence = 0.8022 \tBbox: [ 448 \t 136 \t 536 \t 374 ]\n",
      "8 \tObject: person \tConfidence = 0.7895 \tBbox: [ 541 \t 1 \t 599 \t 164 ]\n",
      "9 \tObject: person \tConfidence = 0.7771 \tBbox: [ 484 \t 0 \t 531 \t 95 ]\n",
      "10 \tObject: person \tConfidence = 0.6032 \tBbox: [ 542 \t 0 \t 569 \t 67 ]\n",
      "11 \tObject: person \tConfidence = 0.3268 \tBbox: [ 586 \t 0 \t 630 \t 31 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000198 / 1050\n",
      "Frames to be processed: 852  | To do: 81.14 % | Done: 18.86 %\n",
      "\n",
      "2022-04-20 13:12:00.330135\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000198.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 25.3ms pre-process, 173.4ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9274 \tBbox: [ 378 \t 718 \t 677 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9198 \tBbox: [ 0 \t 2 \t 453 \t 1075 ]\n",
      "3 \tObject: person \tConfidence = 0.9121 \tBbox: [ 489 \t 467 \t 641 \t 748 ]\n",
      "4 \tObject: person \tConfidence = 0.8665 \tBbox: [ 568 \t 12 \t 642 \t 241 ]\n",
      "5 \tObject: person \tConfidence = 0.8579 \tBbox: [ 448 \t 0 \t 493 \t 127 ]\n",
      "6 \tObject: person \tConfidence = 0.839 \tBbox: [ 507 \t 233 \t 603 \t 526 ]\n",
      "7 \tObject: person \tConfidence = 0.8098 \tBbox: [ 449 \t 136 \t 536 \t 379 ]\n",
      "8 \tObject: person \tConfidence = 0.7681 \tBbox: [ 484 \t 0 \t 531 \t 95 ]\n",
      "9 \tObject: person \tConfidence = 0.7415 \tBbox: [ 542 \t 2 \t 600 \t 163 ]\n",
      "10 \tObject: person \tConfidence = 0.5236 \tBbox: [ 542 \t 0 \t 567 \t 65 ]\n",
      "11 \tObject: person \tConfidence = 0.3112 \tBbox: [ 584 \t 0 \t 629 \t 33 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000199 / 1050\n",
      "Frames to be processed: 851  | To do: 81.05 % | Done: 18.95 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:12:00.755164\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000199.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 25.7ms pre-process, 168.0ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9249 \tBbox: [ 379 \t 718 \t 677 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9235 \tBbox: [ 0 \t 2 \t 454 \t 1074 ]\n",
      "3 \tObject: person \tConfidence = 0.9047 \tBbox: [ 489 \t 466 \t 642 \t 749 ]\n",
      "4 \tObject: person \tConfidence = 0.8751 \tBbox: [ 570 \t 11 \t 643 \t 242 ]\n",
      "5 \tObject: person \tConfidence = 0.8656 \tBbox: [ 448 \t 0 \t 493 \t 127 ]\n",
      "6 \tObject: person \tConfidence = 0.8392 \tBbox: [ 508 \t 233 \t 601 \t 523 ]\n",
      "7 \tObject: person \tConfidence = 0.8151 \tBbox: [ 444 \t 136 \t 535 \t 372 ]\n",
      "8 \tObject: person \tConfidence = 0.7908 \tBbox: [ 542 \t 1 \t 599 \t 166 ]\n",
      "9 \tObject: person \tConfidence = 0.7827 \tBbox: [ 486 \t 0 \t 532 \t 94 ]\n",
      "10 \tObject: person \tConfidence = 0.3738 \tBbox: [ 543 \t 0 \t 563 \t 60 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000200 / 1050\n",
      "Frames to be processed: 850  | To do: 80.95 % | Done: 19.05 %\n",
      "\n",
      "2022-04-20 13:12:01.191444\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000200.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 26.5ms pre-process, 175.1ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9279 \tBbox: [ 379 \t 719 \t 678 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9243 \tBbox: [ 0 \t 2 \t 454 \t 1074 ]\n",
      "3 \tObject: person \tConfidence = 0.9041 \tBbox: [ 488 \t 465 \t 642 \t 750 ]\n",
      "4 \tObject: person \tConfidence = 0.8814 \tBbox: [ 570 \t 11 \t 643 \t 242 ]\n",
      "5 \tObject: person \tConfidence = 0.8625 \tBbox: [ 448 \t 0 \t 493 \t 127 ]\n",
      "6 \tObject: person \tConfidence = 0.8358 \tBbox: [ 511 \t 233 \t 602 \t 525 ]\n",
      "7 \tObject: person \tConfidence = 0.814 \tBbox: [ 541 \t 1 \t 598 \t 164 ]\n",
      "8 \tObject: person \tConfidence = 0.8042 \tBbox: [ 445 \t 136 \t 534 \t 374 ]\n",
      "9 \tObject: person \tConfidence = 0.7602 \tBbox: [ 485 \t 0 \t 532 \t 93 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000201 / 1050\n",
      "Frames to be processed: 849  | To do: 80.86 % | Done: 19.14 %\n",
      "\n",
      "2022-04-20 13:12:01.608131\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000201.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 27.9ms pre-process, 180.3ms inference, 10.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.929 \tBbox: [ 380 \t 718 \t 678 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9234 \tBbox: [ 0 \t 2 \t 455 \t 1075 ]\n",
      "3 \tObject: person \tConfidence = 0.9029 \tBbox: [ 488 \t 465 \t 643 \t 750 ]\n",
      "4 \tObject: person \tConfidence = 0.881 \tBbox: [ 571 \t 11 \t 643 \t 242 ]\n",
      "5 \tObject: person \tConfidence = 0.8609 \tBbox: [ 448 \t 0 \t 493 \t 127 ]\n",
      "6 \tObject: person \tConfidence = 0.8367 \tBbox: [ 512 \t 234 \t 603 \t 525 ]\n",
      "7 \tObject: person \tConfidence = 0.8146 \tBbox: [ 443 \t 135 \t 533 \t 375 ]\n",
      "8 \tObject: person \tConfidence = 0.803 \tBbox: [ 541 \t 1 \t 598 \t 164 ]\n",
      "9 \tObject: person \tConfidence = 0.7544 \tBbox: [ 486 \t 0 \t 532 \t 93 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000202 / 1050\n",
      "Frames to be processed: 848  | To do: 80.76 % | Done: 19.24 %\n",
      "\n",
      "2022-04-20 13:12:02.058593\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000202.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 30.9ms pre-process, 181.1ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9252 \tBbox: [ 381 \t 718 \t 679 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9168 \tBbox: [ 0 \t 2 \t 455 \t 1075 ]\n",
      "3 \tObject: person \tConfidence = 0.9057 \tBbox: [ 489 \t 466 \t 644 \t 746 ]\n",
      "4 \tObject: person \tConfidence = 0.8795 \tBbox: [ 572 \t 10 \t 644 \t 242 ]\n",
      "5 \tObject: person \tConfidence = 0.8583 \tBbox: [ 449 \t 0 \t 493 \t 127 ]\n",
      "6 \tObject: person \tConfidence = 0.8336 \tBbox: [ 441 \t 135 \t 533 \t 368 ]\n",
      "7 \tObject: person \tConfidence = 0.8328 \tBbox: [ 512 \t 233 \t 603 \t 524 ]\n",
      "8 \tObject: person \tConfidence = 0.8127 \tBbox: [ 541 \t 1 \t 599 \t 164 ]\n",
      "9 \tObject: person \tConfidence = 0.7607 \tBbox: [ 485 \t 0 \t 531 \t 93 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000203 / 1050\n",
      "Frames to be processed: 847  | To do: 80.67 % | Done: 19.33 %\n",
      "\n",
      "2022-04-20 13:12:02.567806\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000203.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 24.4ms pre-process, 180.7ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.926 \tBbox: [ 381 \t 718 \t 679 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9173 \tBbox: [ 0 \t 2 \t 455 \t 1074 ]\n",
      "3 \tObject: person \tConfidence = 0.9033 \tBbox: [ 490 \t 466 \t 643 \t 746 ]\n",
      "4 \tObject: person \tConfidence = 0.8787 \tBbox: [ 570 \t 10 \t 645 \t 241 ]\n",
      "5 \tObject: person \tConfidence = 0.8636 \tBbox: [ 440 \t 135 \t 532 \t 365 ]\n",
      "6 \tObject: person \tConfidence = 0.8611 \tBbox: [ 449 \t 1 \t 493 \t 126 ]\n",
      "7 \tObject: person \tConfidence = 0.8369 \tBbox: [ 513 \t 233 \t 602 \t 525 ]\n",
      "8 \tObject: person \tConfidence = 0.8334 \tBbox: [ 541 \t 13 \t 598 \t 163 ]\n",
      "9 \tObject: person \tConfidence = 0.756 \tBbox: [ 485 \t 0 \t 531 \t 93 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000204 / 1050\n",
      "Frames to be processed: 846  | To do: 80.57 % | Done: 19.43 %\n",
      "\n",
      "2022-04-20 13:12:03.025851\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000204.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 44.4ms pre-process, 181.1ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9157 \tBbox: [ 382 \t 718 \t 680 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9045 \tBbox: [ 0 \t 2 \t 456 \t 1074 ]\n",
      "3 \tObject: person \tConfidence = 0.9025 \tBbox: [ 490 \t 465 \t 644 \t 742 ]\n",
      "4 \tObject: person \tConfidence = 0.8835 \tBbox: [ 571 \t 8 \t 645 \t 241 ]\n",
      "5 \tObject: person \tConfidence = 0.8668 \tBbox: [ 440 \t 134 \t 531 \t 365 ]\n",
      "6 \tObject: person \tConfidence = 0.8628 \tBbox: [ 450 \t 1 \t 494 \t 126 ]\n",
      "7 \tObject: person \tConfidence = 0.8495 \tBbox: [ 540 \t 1 \t 598 \t 164 ]\n",
      "8 \tObject: person \tConfidence = 0.835 \tBbox: [ 513 \t 233 \t 604 \t 525 ]\n",
      "9 \tObject: person \tConfidence = 0.711 \tBbox: [ 486 \t 0 \t 532 \t 93 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000205 / 1050\n",
      "Frames to be processed: 845  | To do: 80.48 % | Done: 19.52 %\n",
      "\n",
      "2022-04-20 13:12:03.448347\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000205.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 26.1ms pre-process, 178.3ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9152 \tBbox: [ 383 \t 718 \t 680 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9013 \tBbox: [ 490 \t 465 \t 643 \t 743 ]\n",
      "3 \tObject: person \tConfidence = 0.882 \tBbox: [ 571 \t 8 \t 646 \t 241 ]\n",
      "4 \tObject: person \tConfidence = 0.8642 \tBbox: [ 538 \t 1 \t 594 \t 165 ]\n",
      "5 \tObject: train \tConfidence = 0.8516 \tBbox: [ 0 \t 2 \t 456 \t 1074 ]\n",
      "6 \tObject: person \tConfidence = 0.8497 \tBbox: [ 440 \t 133 \t 530 \t 366 ]\n",
      "7 \tObject: person \tConfidence = 0.8493 \tBbox: [ 450 \t 0 \t 494 \t 126 ]\n",
      "8 \tObject: person \tConfidence = 0.8243 \tBbox: [ 514 \t 232 \t 605 \t 524 ]\n",
      "9 \tObject: person \tConfidence = 0.7482 \tBbox: [ 486 \t 0 \t 532 \t 93 ]\n",
      "10 \tObject: person \tConfidence = 0.3091 \tBbox: [ 594 \t 0 \t 644 \t 33 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000206 / 1050\n",
      "Frames to be processed: 844  | To do: 80.38 % | Done: 19.62 %\n",
      "\n",
      "2022-04-20 13:12:03.872750\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000206.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 28.1ms pre-process, 179.6ms inference, 5.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9088 \tBbox: [ 384 \t 718 \t 679 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8992 \tBbox: [ 490 \t 465 \t 644 \t 744 ]\n",
      "3 \tObject: train \tConfidence = 0.8855 \tBbox: [ 0 \t 2 \t 454 \t 1071 ]\n",
      "4 \tObject: person \tConfidence = 0.8846 \tBbox: [ 572 \t 7 \t 647 \t 241 ]\n",
      "5 \tObject: person \tConfidence = 0.8725 \tBbox: [ 536 \t 1 \t 593 \t 163 ]\n",
      "6 \tObject: person \tConfidence = 0.851 \tBbox: [ 440 \t 132 \t 530 \t 366 ]\n",
      "7 \tObject: person \tConfidence = 0.8409 \tBbox: [ 451 \t 0 \t 494 \t 125 ]\n",
      "8 \tObject: person \tConfidence = 0.8274 \tBbox: [ 514 \t 232 \t 606 \t 522 ]\n",
      "9 \tObject: person \tConfidence = 0.7043 \tBbox: [ 487 \t 0 \t 533 \t 92 ]\n",
      "10 \tObject: person \tConfidence = 0.3097 \tBbox: [ 590 \t 0 \t 645 \t 35 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000207 / 1050\n",
      "Frames to be processed: 843  | To do: 80.29 % | Done: 19.71 %\n",
      "\n",
      "2022-04-20 13:12:04.335139\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000207.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 25.6ms pre-process, 175.0ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9118 \tBbox: [ 385 \t 718 \t 681 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8994 \tBbox: [ 490 \t 464 \t 645 \t 744 ]\n",
      "3 \tObject: train \tConfidence = 0.8802 \tBbox: [ 0 \t 2 \t 453 \t 1073 ]\n",
      "4 \tObject: person \tConfidence = 0.8789 \tBbox: [ 571 \t 7 \t 647 \t 241 ]\n",
      "5 \tObject: person \tConfidence = 0.8787 \tBbox: [ 535 \t 1 \t 593 \t 164 ]\n",
      "6 \tObject: person \tConfidence = 0.8473 \tBbox: [ 450 \t 0 \t 494 \t 124 ]\n",
      "7 \tObject: person \tConfidence = 0.8438 \tBbox: [ 440 \t 132 \t 529 \t 365 ]\n",
      "8 \tObject: person \tConfidence = 0.8268 \tBbox: [ 514 \t 232 \t 607 \t 523 ]\n",
      "9 \tObject: person \tConfidence = 0.7105 \tBbox: [ 487 \t 0 \t 533 \t 92 ]\n",
      "10 \tObject: person \tConfidence = 0.327 \tBbox: [ 585 \t 0 \t 644 \t 37 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000208 / 1050\n",
      "Frames to be processed: 842  | To do: 80.19 % | Done: 19.81 %\n",
      "\n",
      "2022-04-20 13:12:04.821323\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000208.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 30.3ms pre-process, 173.1ms inference, 4.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9046 \tBbox: [ 386 \t 718 \t 678 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8987 \tBbox: [ 490 \t 464 \t 644 \t 745 ]\n",
      "3 \tObject: train \tConfidence = 0.8916 \tBbox: [ 0 \t 2 \t 454 \t 1072 ]\n",
      "4 \tObject: person \tConfidence = 0.8886 \tBbox: [ 572 \t 8 \t 648 \t 241 ]\n",
      "5 \tObject: person \tConfidence = 0.8788 \tBbox: [ 533 \t 0 \t 592 \t 162 ]\n",
      "6 \tObject: person \tConfidence = 0.8501 \tBbox: [ 450 \t 0 \t 494 \t 123 ]\n",
      "7 \tObject: person \tConfidence = 0.8288 \tBbox: [ 440 \t 131 \t 529 \t 373 ]\n",
      "8 \tObject: person \tConfidence = 0.8239 \tBbox: [ 514 \t 232 \t 610 \t 522 ]\n",
      "9 \tObject: person \tConfidence = 0.7233 \tBbox: [ 486 \t 0 \t 532 \t 92 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000209 / 1050\n",
      "Frames to be processed: 841  | To do: 80.1 % | Done: 19.9 %\n",
      "\n",
      "2022-04-20 13:12:05.300082\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000209.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 23.4ms pre-process, 174.9ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9084 \tBbox: [ 386 \t 718 \t 678 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9024 \tBbox: [ 491 \t 464 \t 644 \t 746 ]\n",
      "3 \tObject: train \tConfidence = 0.8931 \tBbox: [ 0 \t 2 \t 454 \t 1072 ]\n",
      "4 \tObject: person \tConfidence = 0.8837 \tBbox: [ 572 \t 8 \t 648 \t 241 ]\n",
      "5 \tObject: person \tConfidence = 0.8757 \tBbox: [ 529 \t 0 \t 591 \t 161 ]\n",
      "6 \tObject: person \tConfidence = 0.8472 \tBbox: [ 450 \t 1 \t 494 \t 122 ]\n",
      "7 \tObject: person \tConfidence = 0.8388 \tBbox: [ 439 \t 130 \t 528 \t 374 ]\n",
      "8 \tObject: person \tConfidence = 0.8338 \tBbox: [ 514 \t 232 \t 610 \t 522 ]\n",
      "9 \tObject: person \tConfidence = 0.7201 \tBbox: [ 486 \t 0 \t 532 \t 92 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000210 / 1050\n",
      "Frames to be processed: 840  | To do: 80.0 % | Done: 20.0 %\n",
      "\n",
      "2022-04-20 13:12:05.770206\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000210.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 45.8ms pre-process, 180.4ms inference, 4.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9116 \tBbox: [ 387 \t 718 \t 679 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9028 \tBbox: [ 491 \t 463 \t 646 \t 746 ]\n",
      "3 \tObject: train \tConfidence = 0.8912 \tBbox: [ 0 \t 2 \t 455 \t 1074 ]\n",
      "4 \tObject: person \tConfidence = 0.887 \tBbox: [ 572 \t 7 \t 649 \t 241 ]\n",
      "5 \tObject: person \tConfidence = 0.8652 \tBbox: [ 520 \t 0 \t 592 \t 162 ]\n",
      "6 \tObject: person \tConfidence = 0.8503 \tBbox: [ 440 \t 129 \t 528 \t 380 ]\n",
      "7 \tObject: person \tConfidence = 0.84 \tBbox: [ 450 \t 0 \t 495 \t 122 ]\n",
      "8 \tObject: person \tConfidence = 0.8329 \tBbox: [ 514 \t 231 \t 610 \t 522 ]\n",
      "9 \tObject: person \tConfidence = 0.7157 \tBbox: [ 486 \t 0 \t 532 \t 92 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000211 / 1050\n",
      "Frames to be processed: 839  | To do: 79.9 % | Done: 20.1 %\n",
      "\n",
      "2022-04-20 13:12:06.234286\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000211.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 30.2ms pre-process, 182.2ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9063 \tBbox: [ 387 \t 718 \t 677 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9032 \tBbox: [ 491 \t 463 \t 645 \t 746 ]\n",
      "3 \tObject: person \tConfidence = 0.8869 \tBbox: [ 572 \t 6 \t 649 \t 240 ]\n",
      "4 \tObject: person \tConfidence = 0.8758 \tBbox: [ 517 \t 1 \t 591 \t 162 ]\n",
      "5 \tObject: person \tConfidence = 0.8556 \tBbox: [ 441 \t 128 \t 529 \t 379 ]\n",
      "6 \tObject: person \tConfidence = 0.8431 \tBbox: [ 450 \t 1 \t 495 \t 122 ]\n",
      "7 \tObject: person \tConfidence = 0.8342 \tBbox: [ 514 \t 232 \t 611 \t 521 ]\n",
      "8 \tObject: train \tConfidence = 0.8265 \tBbox: [ 4 \t 3 \t 456 \t 1069 ]\n",
      "9 \tObject: person \tConfidence = 0.6635 \tBbox: [ 486 \t 0 \t 532 \t 91 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000212 / 1050\n",
      "Frames to be processed: 838  | To do: 79.81 % | Done: 20.19 %\n",
      "\n",
      "2022-04-20 13:12:06.653819\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000212.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 24.0ms pre-process, 170.5ms inference, 11.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9104 \tBbox: [ 388 \t 719 \t 680 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9036 \tBbox: [ 0 \t 2 \t 454 \t 1072 ]\n",
      "3 \tObject: person \tConfidence = 0.9013 \tBbox: [ 492 \t 463 \t 644 \t 746 ]\n",
      "4 \tObject: person \tConfidence = 0.8853 \tBbox: [ 512 \t 0 \t 591 \t 161 ]\n",
      "5 \tObject: person \tConfidence = 0.8844 \tBbox: [ 573 \t 5 \t 649 \t 240 ]\n",
      "6 \tObject: person \tConfidence = 0.8588 \tBbox: [ 442 \t 127 \t 530 \t 383 ]\n",
      "7 \tObject: person \tConfidence = 0.842 \tBbox: [ 450 \t 0 \t 495 \t 121 ]\n",
      "8 \tObject: person \tConfidence = 0.8335 \tBbox: [ 515 \t 232 \t 612 \t 515 ]\n",
      "9 \tObject: person \tConfidence = 0.7006 \tBbox: [ 487 \t 0 \t 532 \t 91 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000213 / 1050\n",
      "Frames to be processed: 837  | To do: 79.71 % | Done: 20.29 %\n",
      "\n",
      "2022-04-20 13:12:07.138154\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000213.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 26.4ms pre-process, 179.6ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9146 \tBbox: [ 388 \t 719 \t 681 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.909 \tBbox: [ 0 \t 1 \t 455 \t 1075 ]\n",
      "3 \tObject: person \tConfidence = 0.9009 \tBbox: [ 492 \t 463 \t 644 \t 747 ]\n",
      "4 \tObject: person \tConfidence = 0.8902 \tBbox: [ 511 \t 0 \t 590 \t 161 ]\n",
      "5 \tObject: person \tConfidence = 0.8826 \tBbox: [ 573 \t 5 \t 649 \t 239 ]\n",
      "6 \tObject: person \tConfidence = 0.8621 \tBbox: [ 443 \t 125 \t 529 \t 386 ]\n",
      "7 \tObject: person \tConfidence = 0.8446 \tBbox: [ 450 \t 0 \t 495 \t 121 ]\n",
      "8 \tObject: person \tConfidence = 0.84 \tBbox: [ 515 \t 231 \t 612 \t 514 ]\n",
      "9 \tObject: person \tConfidence = 0.738 \tBbox: [ 487 \t 0 \t 532 \t 90 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000214 / 1050\n",
      "Frames to be processed: 836  | To do: 79.62 % | Done: 20.38 %\n",
      "\n",
      "2022-04-20 13:12:07.578573\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000214.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 25.6ms pre-process, 181.2ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.914 \tBbox: [ 0 \t 1 \t 455 \t 1075 ]\n",
      "2 \tObject: person \tConfidence = 0.9106 \tBbox: [ 388 \t 718 \t 682 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8954 \tBbox: [ 491 \t 462 \t 646 \t 744 ]\n",
      "4 \tObject: person \tConfidence = 0.8818 \tBbox: [ 511 \t 0 \t 589 \t 161 ]\n",
      "5 \tObject: person \tConfidence = 0.8708 \tBbox: [ 573 \t 4 \t 649 \t 239 ]\n",
      "6 \tObject: person \tConfidence = 0.867 \tBbox: [ 442 \t 124 \t 528 \t 388 ]\n",
      "7 \tObject: person \tConfidence = 0.8341 \tBbox: [ 515 \t 232 \t 612 \t 509 ]\n",
      "8 \tObject: person \tConfidence = 0.8311 \tBbox: [ 450 \t 0 \t 497 \t 121 ]\n",
      "9 \tObject: person \tConfidence = 0.7469 \tBbox: [ 487 \t 0 \t 532 \t 90 ]\n",
      "10 \tObject: person \tConfidence = 0.3725 \tBbox: [ 593 \t 0 \t 643 \t 35 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000215 / 1050\n",
      "Frames to be processed: 835  | To do: 79.52 % | Done: 20.48 %\n",
      "\n",
      "2022-04-20 13:12:08.013100\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000215.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 28.2ms pre-process, 171.3ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9204 \tBbox: [ 0 \t 1 \t 454 \t 1075 ]\n",
      "2 \tObject: person \tConfidence = 0.9021 \tBbox: [ 390 \t 718 \t 681 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9007 \tBbox: [ 493 \t 462 \t 646 \t 742 ]\n",
      "4 \tObject: person \tConfidence = 0.877 \tBbox: [ 510 \t 0 \t 587 \t 161 ]\n",
      "5 \tObject: person \tConfidence = 0.8706 \tBbox: [ 442 \t 123 \t 525 \t 383 ]\n",
      "6 \tObject: person \tConfidence = 0.865 \tBbox: [ 574 \t 4 \t 650 \t 239 ]\n",
      "7 \tObject: person \tConfidence = 0.8465 \tBbox: [ 515 \t 232 \t 614 \t 518 ]\n",
      "8 \tObject: person \tConfidence = 0.832 \tBbox: [ 451 \t 1 \t 499 \t 121 ]\n",
      "9 \tObject: person \tConfidence = 0.6389 \tBbox: [ 488 \t 0 \t 532 \t 90 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000216 / 1050\n",
      "Frames to be processed: 834  | To do: 79.43 % | Done: 20.57 %\n",
      "\n",
      "2022-04-20 13:12:08.443198\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000216.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 29.1ms pre-process, 174.8ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9106 \tBbox: [ 0 \t 2 \t 453 \t 1075 ]\n",
      "2 \tObject: person \tConfidence = 0.906 \tBbox: [ 390 \t 718 \t 682 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9022 \tBbox: [ 493 \t 462 \t 646 \t 741 ]\n",
      "4 \tObject: person \tConfidence = 0.8673 \tBbox: [ 574 \t 4 \t 650 \t 238 ]\n",
      "5 \tObject: person \tConfidence = 0.8646 \tBbox: [ 442 \t 122 \t 524 \t 383 ]\n",
      "6 \tObject: person \tConfidence = 0.8479 \tBbox: [ 508 \t 0 \t 586 \t 160 ]\n",
      "7 \tObject: person \tConfidence = 0.8464 \tBbox: [ 516 \t 231 \t 614 \t 512 ]\n",
      "8 \tObject: person \tConfidence = 0.8236 \tBbox: [ 451 \t 1 \t 496 \t 120 ]\n",
      "9 \tObject: person \tConfidence = 0.6706 \tBbox: [ 487 \t 0 \t 532 \t 90 ]\n",
      "10 \tObject: person \tConfidence = 0.3065 \tBbox: [ 592 \t 0 \t 644 \t 37 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000217 / 1050\n",
      "Frames to be processed: 833  | To do: 79.33 % | Done: 20.67 %\n",
      "\n",
      "2022-04-20 13:12:08.907830\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000217.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 25.0ms pre-process, 174.3ms inference, 4.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9179 \tBbox: [ 390 \t 718 \t 686 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9047 \tBbox: [ 494 \t 462 \t 646 \t 742 ]\n",
      "3 \tObject: person \tConfidence = 0.8732 \tBbox: [ 575 \t 4 \t 650 \t 237 ]\n",
      "4 \tObject: person \tConfidence = 0.8663 \tBbox: [ 442 \t 122 \t 523 \t 384 ]\n",
      "5 \tObject: person \tConfidence = 0.8546 \tBbox: [ 516 \t 231 \t 615 \t 513 ]\n",
      "6 \tObject: person \tConfidence = 0.8482 \tBbox: [ 506 \t 0 \t 584 \t 161 ]\n",
      "7 \tObject: train \tConfidence = 0.8379 \tBbox: [ 0 \t 2 \t 453 \t 1074 ]\n",
      "8 \tObject: person \tConfidence = 0.8316 \tBbox: [ 451 \t 0 \t 496 \t 120 ]\n",
      "9 \tObject: person \tConfidence = 0.5994 \tBbox: [ 488 \t 0 \t 532 \t 90 ]\n",
      "10 \tObject: person \tConfidence = 0.3314 \tBbox: [ 592 \t 0 \t 645 \t 38 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000218 / 1050\n",
      "Frames to be processed: 832  | To do: 79.24 % | Done: 20.76 %\n",
      "\n",
      "2022-04-20 13:12:09.314152\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000218.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 25.9ms pre-process, 168.9ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9171 \tBbox: [ 389 \t 718 \t 685 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9061 \tBbox: [ 494 \t 461 \t 645 \t 742 ]\n",
      "3 \tObject: train \tConfidence = 0.8974 \tBbox: [ 0 \t 2 \t 454 \t 1073 ]\n",
      "4 \tObject: person \tConfidence = 0.8739 \tBbox: [ 440 \t 122 \t 523 \t 382 ]\n",
      "5 \tObject: person \tConfidence = 0.8739 \tBbox: [ 575 \t 3 \t 650 \t 237 ]\n",
      "6 \tObject: person \tConfidence = 0.8585 \tBbox: [ 516 \t 230 \t 615 \t 517 ]\n",
      "7 \tObject: person \tConfidence = 0.846 \tBbox: [ 509 \t 0 \t 583 \t 161 ]\n",
      "8 \tObject: person \tConfidence = 0.8437 \tBbox: [ 451 \t 0 \t 496 \t 119 ]\n",
      "9 \tObject: person \tConfidence = 0.6162 \tBbox: [ 488 \t 0 \t 532 \t 90 ]\n",
      "10 \tObject: person \tConfidence = 0.3308 \tBbox: [ 592 \t 0 \t 643 \t 37 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000219 / 1050\n",
      "Frames to be processed: 831  | To do: 79.14 % | Done: 20.86 %\n",
      "\n",
      "2022-04-20 13:12:09.776539\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000219.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 26.9ms pre-process, 177.9ms inference, 10.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9142 \tBbox: [ 390 \t 718 \t 686 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9025 \tBbox: [ 494 \t 461 \t 645 \t 744 ]\n",
      "3 \tObject: person \tConfidence = 0.8721 \tBbox: [ 575 \t 4 \t 650 \t 236 ]\n",
      "4 \tObject: person \tConfidence = 0.8653 \tBbox: [ 437 \t 122 \t 524 \t 379 ]\n",
      "5 \tObject: train \tConfidence = 0.8556 \tBbox: [ 3 \t 1 \t 456 \t 1065 ]\n",
      "6 \tObject: person \tConfidence = 0.8507 \tBbox: [ 516 \t 230 \t 617 \t 517 ]\n",
      "7 \tObject: person \tConfidence = 0.8505 \tBbox: [ 508 \t 0 \t 582 \t 161 ]\n",
      "8 \tObject: person \tConfidence = 0.8352 \tBbox: [ 451 \t 0 \t 497 \t 120 ]\n",
      "9 \tObject: person \tConfidence = 0.6218 \tBbox: [ 488 \t 0 \t 532 \t 90 ]\n",
      "10 \tObject: person \tConfidence = 0.3598 \tBbox: [ 591 \t 0 \t 642 \t 41 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000220 / 1050\n",
      "Frames to be processed: 830  | To do: 79.05 % | Done: 20.95 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 24.0ms pre-process, 170.0ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:12:10.247870\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000220.jpg ------------------------------ \n",
      "\n",
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9192 \tBbox: [ 390 \t 718 \t 689 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9116 \tBbox: [ 0 \t 1 \t 455 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.9015 \tBbox: [ 494 \t 460 \t 645 \t 744 ]\n",
      "4 \tObject: person \tConfidence = 0.8818 \tBbox: [ 436 \t 121 \t 525 \t 376 ]\n",
      "5 \tObject: person \tConfidence = 0.8729 \tBbox: [ 574 \t 4 \t 650 \t 235 ]\n",
      "6 \tObject: person \tConfidence = 0.8607 \tBbox: [ 517 \t 230 \t 618 \t 521 ]\n",
      "7 \tObject: person \tConfidence = 0.8502 \tBbox: [ 505 \t 0 \t 578 \t 160 ]\n",
      "8 \tObject: person \tConfidence = 0.8082 \tBbox: [ 451 \t 0 \t 497 \t 118 ]\n",
      "9 \tObject: person \tConfidence = 0.5902 \tBbox: [ 488 \t 0 \t 529 \t 89 ]\n",
      "10 \tObject: person \tConfidence = 0.3834 \tBbox: [ 591 \t 0 \t 643 \t 41 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000221 / 1050\n",
      "Frames to be processed: 829  | To do: 78.95 % | Done: 21.05 %\n",
      "\n",
      "2022-04-20 13:12:10.708245\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000221.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 27.9ms pre-process, 175.9ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9136 \tBbox: [ 390 \t 719 \t 689 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9031 \tBbox: [ 495 \t 461 \t 645 \t 744 ]\n",
      "3 \tObject: person \tConfidence = 0.8785 \tBbox: [ 436 \t 120 \t 525 \t 379 ]\n",
      "4 \tObject: person \tConfidence = 0.8764 \tBbox: [ 574 \t 4 \t 650 \t 235 ]\n",
      "5 \tObject: person \tConfidence = 0.8716 \tBbox: [ 506 \t 0 \t 577 \t 160 ]\n",
      "6 \tObject: person \tConfidence = 0.8601 \tBbox: [ 518 \t 230 \t 619 \t 520 ]\n",
      "7 \tObject: train \tConfidence = 0.8542 \tBbox: [ 0 \t 0 \t 455 \t 1048 ]\n",
      "8 \tObject: person \tConfidence = 0.8093 \tBbox: [ 451 \t 0 \t 497 \t 120 ]\n",
      "9 \tObject: person \tConfidence = 0.5997 \tBbox: [ 489 \t 0 \t 528 \t 88 ]\n",
      "10 \tObject: person \tConfidence = 0.3421 \tBbox: [ 591 \t 0 \t 643 \t 38 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000222 / 1050\n",
      "Frames to be processed: 828  | To do: 78.86 % | Done: 21.14 %\n",
      "\n",
      "2022-04-20 13:12:11.180489\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000222.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 36.4ms pre-process, 179.7ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9141 \tBbox: [ 390 \t 719 \t 690 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9025 \tBbox: [ 496 \t 461 \t 646 \t 744 ]\n",
      "3 \tObject: person \tConfidence = 0.888 \tBbox: [ 505 \t 0 \t 577 \t 160 ]\n",
      "4 \tObject: person \tConfidence = 0.8732 \tBbox: [ 575 \t 4 \t 650 \t 236 ]\n",
      "5 \tObject: person \tConfidence = 0.8724 \tBbox: [ 436 \t 119 \t 526 \t 374 ]\n",
      "6 \tObject: person \tConfidence = 0.8554 \tBbox: [ 518 \t 230 \t 619 \t 519 ]\n",
      "7 \tObject: train \tConfidence = 0.8551 \tBbox: [ 0 \t 3 \t 456 \t 934 ]\n",
      "8 \tObject: person \tConfidence = 0.8113 \tBbox: [ 451 \t 0 \t 497 \t 119 ]\n",
      "9 \tObject: person \tConfidence = 0.5913 \tBbox: [ 490 \t 0 \t 527 \t 88 ]\n",
      "10 \tObject: person \tConfidence = 0.3624 \tBbox: [ 591 \t 0 \t 642 \t 39 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000223 / 1050\n",
      "Frames to be processed: 827  | To do: 78.76 % | Done: 21.24 %\n",
      "\n",
      "2022-04-20 13:12:11.606603\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000223.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 30.6ms pre-process, 181.4ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9047 \tBbox: [ 390 \t 718 \t 690 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9024 \tBbox: [ 496 \t 461 \t 647 \t 744 ]\n",
      "3 \tObject: person \tConfidence = 0.8966 \tBbox: [ 506 \t 1 \t 576 \t 160 ]\n",
      "4 \tObject: train \tConfidence = 0.895 \tBbox: [ 0 \t 5 \t 457 \t 1041 ]\n",
      "5 \tObject: person \tConfidence = 0.8733 \tBbox: [ 575 \t 4 \t 650 \t 236 ]\n",
      "6 \tObject: person \tConfidence = 0.8712 \tBbox: [ 435 \t 119 \t 525 \t 376 ]\n",
      "7 \tObject: person \tConfidence = 0.8565 \tBbox: [ 518 \t 229 \t 620 \t 520 ]\n",
      "8 \tObject: person \tConfidence = 0.7952 \tBbox: [ 451 \t 0 \t 497 \t 118 ]\n",
      "9 \tObject: person \tConfidence = 0.5929 \tBbox: [ 489 \t 0 \t 527 \t 88 ]\n",
      "10 \tObject: person \tConfidence = 0.3149 \tBbox: [ 591 \t 0 \t 643 \t 39 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000224 / 1050\n",
      "Frames to be processed: 826  | To do: 78.67 % | Done: 21.33 %\n",
      "\n",
      "2022-04-20 13:12:12.028281\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000224.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 28.3ms pre-process, 168.7ms inference, 4.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9202 \tBbox: [ 390 \t 718 \t 692 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9005 \tBbox: [ 497 \t 461 \t 646 \t 744 ]\n",
      "3 \tObject: person \tConfidence = 0.9004 \tBbox: [ 506 \t 1 \t 575 \t 160 ]\n",
      "4 \tObject: train \tConfidence = 0.8961 \tBbox: [ 0 \t 3 \t 456 \t 1067 ]\n",
      "5 \tObject: person \tConfidence = 0.8761 \tBbox: [ 575 \t 3 \t 649 \t 236 ]\n",
      "6 \tObject: person \tConfidence = 0.8686 \tBbox: [ 433 \t 118 \t 521 \t 376 ]\n",
      "7 \tObject: person \tConfidence = 0.8535 \tBbox: [ 519 \t 229 \t 624 \t 522 ]\n",
      "8 \tObject: person \tConfidence = 0.8066 \tBbox: [ 451 \t 0 \t 498 \t 117 ]\n",
      "9 \tObject: person \tConfidence = 0.5237 \tBbox: [ 491 \t 0 \t 526 \t 87 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000225 / 1050\n",
      "Frames to be processed: 825  | To do: 78.57 % | Done: 21.43 %\n",
      "\n",
      "2022-04-20 13:12:12.435608\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000225.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 25.4ms pre-process, 174.8ms inference, 3.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9218 \tBbox: [ 391 \t 718 \t 693 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9047 \tBbox: [ 497 \t 460 \t 647 \t 744 ]\n",
      "3 \tObject: person \tConfidence = 0.9018 \tBbox: [ 505 \t 0 \t 573 \t 161 ]\n",
      "4 \tObject: person \tConfidence = 0.8785 \tBbox: [ 575 \t 3 \t 650 \t 236 ]\n",
      "5 \tObject: person \tConfidence = 0.8636 \tBbox: [ 432 \t 115 \t 516 \t 372 ]\n",
      "6 \tObject: person \tConfidence = 0.8549 \tBbox: [ 520 \t 229 \t 625 \t 522 ]\n",
      "7 \tObject: train \tConfidence = 0.8354 \tBbox: [ 0 \t 3 \t 456 \t 1070 ]\n",
      "8 \tObject: person \tConfidence = 0.813 \tBbox: [ 452 \t 0 \t 499 \t 116 ]\n",
      "9 \tObject: person \tConfidence = 0.3451 \tBbox: [ 493 \t 0 \t 518 \t 88 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000226 / 1050\n",
      "Frames to be processed: 824  | To do: 78.48 % | Done: 21.52 %\n",
      "\n",
      "2022-04-20 13:12:12.868414\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000226.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 37.6ms pre-process, 179.6ms inference, 12.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9105 \tBbox: [ 392 \t 718 \t 691 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.907 \tBbox: [ 497 \t 461 \t 647 \t 746 ]\n",
      "3 \tObject: person \tConfidence = 0.8988 \tBbox: [ 504 \t 1 \t 573 \t 160 ]\n",
      "4 \tObject: person \tConfidence = 0.8813 \tBbox: [ 575 \t 3 \t 648 \t 235 ]\n",
      "5 \tObject: person \tConfidence = 0.858 \tBbox: [ 520 \t 229 \t 623 \t 521 ]\n",
      "6 \tObject: person \tConfidence = 0.8507 \tBbox: [ 431 \t 113 \t 515 \t 368 ]\n",
      "7 \tObject: train \tConfidence = 0.8369 \tBbox: [ 0 \t 3 \t 458 \t 1068 ]\n",
      "8 \tObject: person \tConfidence = 0.8202 \tBbox: [ 452 \t 0 \t 497 \t 116 ]\n",
      "9 \tObject: person \tConfidence = 0.3157 \tBbox: [ 492 \t 0 \t 516 \t 88 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000227 / 1050\n",
      "Frames to be processed: 823  | To do: 78.38 % | Done: 21.62 %\n",
      "\n",
      "2022-04-20 13:12:13.331641\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000227.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 36.4ms pre-process, 180.0ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9061 \tBbox: [ 497 \t 461 \t 647 \t 746 ]\n",
      "2 \tObject: person \tConfidence = 0.9055 \tBbox: [ 392 \t 719 \t 692 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8924 \tBbox: [ 504 \t 1 \t 570 \t 160 ]\n",
      "4 \tObject: person \tConfidence = 0.88 \tBbox: [ 575 \t 3 \t 648 \t 235 ]\n",
      "5 \tObject: person \tConfidence = 0.8623 \tBbox: [ 519 \t 230 \t 622 \t 521 ]\n",
      "6 \tObject: person \tConfidence = 0.8473 \tBbox: [ 429 \t 113 \t 514 \t 365 ]\n",
      "7 \tObject: person \tConfidence = 0.8115 \tBbox: [ 452 \t 0 \t 498 \t 116 ]\n",
      "8 \tObject: train \tConfidence = 0.7992 \tBbox: [ 0 \t 3 \t 458 \t 1064 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000228 / 1050\n",
      "Frames to be processed: 822  | To do: 78.29 % | Done: 21.71 %\n",
      "\n",
      "2022-04-20 13:12:13.780881\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000228.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 239.5ms pre-process, 174.8ms inference, 11.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9121 \tBbox: [ 392 \t 719 \t 693 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9011 \tBbox: [ 497 \t 461 \t 647 \t 747 ]\n",
      "3 \tObject: person \tConfidence = 0.8912 \tBbox: [ 503 \t 1 \t 568 \t 160 ]\n",
      "4 \tObject: person \tConfidence = 0.8814 \tBbox: [ 575 \t 2 \t 648 \t 235 ]\n",
      "5 \tObject: person \tConfidence = 0.8675 \tBbox: [ 514 \t 230 \t 622 \t 521 ]\n",
      "6 \tObject: person \tConfidence = 0.8117 \tBbox: [ 426 \t 113 \t 508 \t 363 ]\n",
      "7 \tObject: person \tConfidence = 0.7896 \tBbox: [ 451 \t 0 \t 499 \t 117 ]\n",
      "8 \tObject: train \tConfidence = 0.7413 \tBbox: [ 0 \t 0 \t 458 \t 1050 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000229 / 1050\n",
      "Frames to be processed: 821  | To do: 78.19 % | Done: 21.81 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:12:14.442305\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000229.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 25.8ms pre-process, 168.3ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.918 \tBbox: [ 393 \t 719 \t 694 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9068 \tBbox: [ 497 \t 461 \t 647 \t 748 ]\n",
      "3 \tObject: person \tConfidence = 0.8911 \tBbox: [ 505 \t 230 \t 622 \t 523 ]\n",
      "4 \tObject: person \tConfidence = 0.8848 \tBbox: [ 503 \t 1 \t 567 \t 160 ]\n",
      "5 \tObject: person \tConfidence = 0.8817 \tBbox: [ 575 \t 2 \t 648 \t 235 ]\n",
      "6 \tObject: train \tConfidence = 0.8554 \tBbox: [ 0 \t 1 \t 458 \t 1067 ]\n",
      "7 \tObject: person \tConfidence = 0.8137 \tBbox: [ 451 \t 0 \t 499 \t 116 ]\n",
      "8 \tObject: person \tConfidence = 0.8014 \tBbox: [ 425 \t 111 \t 502 \t 362 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000230 / 1050\n",
      "Frames to be processed: 820  | To do: 78.1 % | Done: 21.9 %\n",
      "\n",
      "2022-04-20 13:12:14.844219\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000230.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 22.8ms pre-process, 174.4ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9083 \tBbox: [ 498 \t 461 \t 648 \t 749 ]\n",
      "2 \tObject: train \tConfidence = 0.9079 \tBbox: [ 0 \t 1 \t 460 \t 1072 ]\n",
      "3 \tObject: person \tConfidence = 0.9078 \tBbox: [ 393 \t 720 \t 690 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.892 \tBbox: [ 497 \t 230 \t 623 \t 522 ]\n",
      "5 \tObject: person \tConfidence = 0.8844 \tBbox: [ 575 \t 1 \t 647 \t 234 ]\n",
      "6 \tObject: person \tConfidence = 0.8744 \tBbox: [ 501 \t 0 \t 564 \t 161 ]\n",
      "7 \tObject: person \tConfidence = 0.8079 \tBbox: [ 424 \t 110 \t 501 \t 365 ]\n",
      "8 \tObject: person \tConfidence = 0.8028 \tBbox: [ 450 \t 0 \t 497 \t 117 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000231 / 1050\n",
      "Frames to be processed: 819  | To do: 78.0 % | Done: 22.0 %\n",
      "\n",
      "2022-04-20 13:12:15.282355\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000231.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 36.8ms pre-process, 168.0ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9053 \tBbox: [ 498 \t 461 \t 647 \t 749 ]\n",
      "2 \tObject: train \tConfidence = 0.9035 \tBbox: [ 0 \t 1 \t 461 \t 1073 ]\n",
      "3 \tObject: person \tConfidence = 0.9012 \tBbox: [ 393 \t 720 \t 692 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8942 \tBbox: [ 499 \t 230 \t 624 \t 523 ]\n",
      "5 \tObject: person \tConfidence = 0.8826 \tBbox: [ 575 \t 2 \t 647 \t 235 ]\n",
      "6 \tObject: person \tConfidence = 0.8677 \tBbox: [ 501 \t 0 \t 562 \t 161 ]\n",
      "7 \tObject: person \tConfidence = 0.8208 \tBbox: [ 449 \t 0 \t 496 \t 117 ]\n",
      "8 \tObject: person \tConfidence = 0.8138 \tBbox: [ 424 \t 111 \t 500 \t 364 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000232 / 1050\n",
      "Frames to be processed: 818  | To do: 77.9 % | Done: 22.1 %\n",
      "\n",
      "2022-04-20 13:12:15.717904\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000232.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 24.0ms pre-process, 174.2ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9031 \tBbox: [ 394 \t 719 \t 692 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9029 \tBbox: [ 498 \t 461 \t 649 \t 749 ]\n",
      "3 \tObject: train \tConfidence = 0.8945 \tBbox: [ 0 \t 2 \t 458 \t 1072 ]\n",
      "4 \tObject: person \tConfidence = 0.8938 \tBbox: [ 502 \t 231 \t 626 \t 523 ]\n",
      "5 \tObject: person \tConfidence = 0.8817 \tBbox: [ 576 \t 2 \t 646 \t 235 ]\n",
      "6 \tObject: person \tConfidence = 0.8485 \tBbox: [ 449 \t 0 \t 495 \t 117 ]\n",
      "7 \tObject: person \tConfidence = 0.8481 \tBbox: [ 501 \t 0 \t 562 \t 160 ]\n",
      "8 \tObject: person \tConfidence = 0.8203 \tBbox: [ 420 \t 110 \t 499 \t 365 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000233 / 1050\n",
      "Frames to be processed: 817  | To do: 77.81 % | Done: 22.19 %\n",
      "\n",
      "2022-04-20 13:12:16.148099\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000233.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 26.3ms pre-process, 173.2ms inference, 3.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9037 \tBbox: [ 0 \t 2 \t 458 \t 1073 ]\n",
      "2 \tObject: person \tConfidence = 0.9005 \tBbox: [ 394 \t 720 \t 688 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8988 \tBbox: [ 498 \t 461 \t 649 \t 749 ]\n",
      "4 \tObject: person \tConfidence = 0.8954 \tBbox: [ 506 \t 232 \t 626 \t 523 ]\n",
      "5 \tObject: person \tConfidence = 0.8805 \tBbox: [ 576 \t 2 \t 645 \t 236 ]\n",
      "6 \tObject: person \tConfidence = 0.8473 \tBbox: [ 501 \t 0 \t 562 \t 160 ]\n",
      "7 \tObject: person \tConfidence = 0.844 \tBbox: [ 417 \t 109 \t 498 \t 363 ]\n",
      "8 \tObject: person \tConfidence = 0.8296 \tBbox: [ 448 \t 0 \t 496 \t 116 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000234 / 1050\n",
      "Frames to be processed: 816  | To do: 77.71 % | Done: 22.29 %\n",
      "\n",
      "2022-04-20 13:12:16.582443\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000234.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 36.8ms pre-process, 175.2ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9018 \tBbox: [ 395 \t 719 \t 686 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8961 \tBbox: [ 498 \t 461 \t 649 \t 749 ]\n",
      "3 \tObject: train \tConfidence = 0.8928 \tBbox: [ 0 \t 2 \t 457 \t 1073 ]\n",
      "4 \tObject: person \tConfidence = 0.8838 \tBbox: [ 508 \t 233 \t 627 \t 523 ]\n",
      "5 \tObject: person \tConfidence = 0.8685 \tBbox: [ 576 \t 2 \t 646 \t 234 ]\n",
      "6 \tObject: person \tConfidence = 0.8516 \tBbox: [ 413 \t 108 \t 497 \t 364 ]\n",
      "7 \tObject: person \tConfidence = 0.8496 \tBbox: [ 501 \t 0 \t 561 \t 159 ]\n",
      "8 \tObject: person \tConfidence = 0.8267 \tBbox: [ 447 \t 0 \t 499 \t 116 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000235 / 1050\n",
      "Frames to be processed: 815  | To do: 77.62 % | Done: 22.38 %\n",
      "\n",
      "2022-04-20 13:12:16.999925\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000235.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 26.7ms pre-process, 177.7ms inference, 10.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8981 \tBbox: [ 395 \t 720 \t 688 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8821 \tBbox: [ 498 \t 461 \t 648 \t 755 ]\n",
      "3 \tObject: person \tConfidence = 0.8752 \tBbox: [ 509 \t 236 \t 627 \t 523 ]\n",
      "4 \tObject: person \tConfidence = 0.8731 \tBbox: [ 410 \t 108 \t 493 \t 363 ]\n",
      "5 \tObject: person \tConfidence = 0.8686 \tBbox: [ 577 \t 1 \t 645 \t 236 ]\n",
      "6 \tObject: train \tConfidence = 0.8494 \tBbox: [ 0 \t 2 \t 459 \t 1070 ]\n",
      "7 \tObject: person \tConfidence = 0.8349 \tBbox: [ 446 \t 0 \t 498 \t 117 ]\n",
      "8 \tObject: person \tConfidence = 0.7922 \tBbox: [ 496 \t 0 \t 558 \t 160 ]\n",
      "9 \tObject: person \tConfidence = 0.3708 \tBbox: [ 594 \t 0 \t 647 \t 43 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000236 / 1050\n",
      "Frames to be processed: 814  | To do: 77.52 % | Done: 22.48 %\n",
      "\n",
      "2022-04-20 13:12:17.522282\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000236.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 25.5ms pre-process, 180.7ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8966 \tBbox: [ 396 \t 720 \t 686 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8912 \tBbox: [ 498 \t 461 \t 647 \t 753 ]\n",
      "3 \tObject: person \tConfidence = 0.8793 \tBbox: [ 409 \t 110 \t 491 \t 363 ]\n",
      "4 \tObject: person \tConfidence = 0.8736 \tBbox: [ 509 \t 237 \t 628 \t 518 ]\n",
      "5 \tObject: person \tConfidence = 0.8665 \tBbox: [ 576 \t 2 \t 643 \t 235 ]\n",
      "6 \tObject: person \tConfidence = 0.8296 \tBbox: [ 447 \t 0 \t 497 \t 118 ]\n",
      "7 \tObject: train \tConfidence = 0.8228 \tBbox: [ 1 \t 4 \t 459 \t 1061 ]\n",
      "8 \tObject: person \tConfidence = 0.7829 \tBbox: [ 496 \t 0 \t 557 \t 160 ]\n",
      "9 \tObject: person \tConfidence = 0.4812 \tBbox: [ 593 \t 0 \t 648 \t 45 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000237 / 1050\n",
      "Frames to be processed: 813  | To do: 77.43 % | Done: 22.57 %\n",
      "\n",
      "2022-04-20 13:12:17.995232\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000237.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 24.9ms pre-process, 174.7ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9039 \tBbox: [ 396 \t 720 \t 692 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8961 \tBbox: [ 497 \t 461 \t 646 \t 753 ]\n",
      "3 \tObject: person \tConfidence = 0.8658 \tBbox: [ 508 \t 239 \t 628 \t 516 ]\n",
      "4 \tObject: person \tConfidence = 0.865 \tBbox: [ 575 \t 1 \t 644 \t 234 ]\n",
      "5 \tObject: person \tConfidence = 0.864 \tBbox: [ 410 \t 110 \t 491 \t 363 ]\n",
      "6 \tObject: train \tConfidence = 0.8356 \tBbox: [ 0 \t 3 \t 458 \t 1068 ]\n",
      "7 \tObject: person \tConfidence = 0.8303 \tBbox: [ 447 \t 0 \t 498 \t 119 ]\n",
      "8 \tObject: person \tConfidence = 0.8179 \tBbox: [ 496 \t 0 \t 557 \t 159 ]\n",
      "9 \tObject: person \tConfidence = 0.4353 \tBbox: [ 592 \t 0 \t 648 \t 45 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000238 / 1050\n",
      "Frames to be processed: 812  | To do: 77.33 % | Done: 22.67 %\n",
      "\n",
      "2022-04-20 13:12:18.444865\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000238.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 28.0ms pre-process, 181.0ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9063 \tBbox: [ 396 \t 720 \t 687 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8874 \tBbox: [ 497 \t 461 \t 643 \t 754 ]\n",
      "3 \tObject: person \tConfidence = 0.8863 \tBbox: [ 410 \t 110 \t 490 \t 363 ]\n",
      "4 \tObject: person \tConfidence = 0.8776 \tBbox: [ 573 \t 2 \t 642 \t 235 ]\n",
      "5 \tObject: person \tConfidence = 0.8759 \tBbox: [ 508 \t 240 \t 628 \t 508 ]\n",
      "6 \tObject: train \tConfidence = 0.8702 \tBbox: [ 0 \t 3 \t 457 \t 964 ]\n",
      "7 \tObject: person \tConfidence = 0.8457 \tBbox: [ 496 \t 0 \t 555 \t 160 ]\n",
      "8 \tObject: person \tConfidence = 0.8152 \tBbox: [ 446 \t 0 \t 497 \t 120 ]\n",
      "9 \tObject: person \tConfidence = 0.3237 \tBbox: [ 625 \t 0 \t 649 \t 47 ]\n",
      "10 \tObject: person \tConfidence = 0.3005 \tBbox: [ 592 \t 0 \t 647 \t 44 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000239 / 1050\n",
      "Frames to be processed: 811  | To do: 77.24 % | Done: 22.76 %\n",
      "\n",
      "2022-04-20 13:12:18.926963\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000239.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 30.9ms pre-process, 179.0ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9008 \tBbox: [ 396 \t 720 \t 692 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8924 \tBbox: [ 410 \t 111 \t 489 \t 363 ]\n",
      "3 \tObject: person \tConfidence = 0.8887 \tBbox: [ 508 \t 241 \t 628 \t 502 ]\n",
      "4 \tObject: person \tConfidence = 0.8851 \tBbox: [ 570 \t 2 \t 641 \t 234 ]\n",
      "5 \tObject: train \tConfidence = 0.8718 \tBbox: [ 3 \t 2 \t 459 \t 1055 ]\n",
      "6 \tObject: person \tConfidence = 0.8555 \tBbox: [ 494 \t 461 \t 643 \t 757 ]\n",
      "7 \tObject: person \tConfidence = 0.8331 \tBbox: [ 493 \t 0 \t 555 \t 160 ]\n",
      "8 \tObject: person \tConfidence = 0.8233 \tBbox: [ 446 \t 0 \t 497 \t 120 ]\n",
      "9 \tObject: person \tConfidence = 0.3699 \tBbox: [ 627 \t 0 \t 649 \t 47 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000240 / 1050\n",
      "Frames to be processed: 810  | To do: 77.14 % | Done: 22.86 %\n",
      "\n",
      "2022-04-20 13:12:19.373590\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000240.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 26.8ms pre-process, 180.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9127 \tBbox: [ 0 \t 1 \t 457 \t 1074 ]\n",
      "2 \tObject: person \tConfidence = 0.9041 \tBbox: [ 397 \t 720 \t 693 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8931 \tBbox: [ 411 \t 113 \t 488 \t 363 ]\n",
      "4 \tObject: person \tConfidence = 0.8808 \tBbox: [ 508 \t 242 \t 625 \t 501 ]\n",
      "5 \tObject: person \tConfidence = 0.8792 \tBbox: [ 563 \t 1 \t 642 \t 230 ]\n",
      "6 \tObject: person \tConfidence = 0.8538 \tBbox: [ 493 \t 0 \t 554 \t 160 ]\n",
      "7 \tObject: person \tConfidence = 0.8248 \tBbox: [ 446 \t 0 \t 499 \t 120 ]\n",
      "8 \tObject: person \tConfidence = 0.8164 \tBbox: [ 484 \t 460 \t 638 \t 808 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000241 / 1050\n",
      "Frames to be processed: 809  | To do: 77.05 % | Done: 22.95 %\n",
      "\n",
      "2022-04-20 13:12:19.796028\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000241.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 29.0ms pre-process, 182.2ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9146 \tBbox: [ 397 \t 720 \t 701 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9042 \tBbox: [ 1 \t 1 \t 461 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.887 \tBbox: [ 507 \t 243 \t 626 \t 500 ]\n",
      "4 \tObject: person \tConfidence = 0.8869 \tBbox: [ 410 \t 114 \t 487 \t 363 ]\n",
      "5 \tObject: person \tConfidence = 0.8761 \tBbox: [ 557 \t 1 \t 641 \t 229 ]\n",
      "6 \tObject: person \tConfidence = 0.8357 \tBbox: [ 492 \t 0 \t 553 \t 160 ]\n",
      "7 \tObject: person \tConfidence = 0.8307 \tBbox: [ 446 \t 0 \t 498 \t 120 ]\n",
      "8 \tObject: person \tConfidence = 0.8094 \tBbox: [ 479 \t 460 \t 638 \t 794 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000242 / 1050\n",
      "Frames to be processed: 808  | To do: 76.95 % | Done: 23.05 %\n",
      "\n",
      "2022-04-20 13:12:20.244766\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000242.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 28.4ms pre-process, 181.6ms inference, 6.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9145 \tBbox: [ 398 \t 720 \t 699 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.8986 \tBbox: [ 1 \t 2 \t 460 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.8953 \tBbox: [ 409 \t 115 \t 488 \t 363 ]\n",
      "4 \tObject: person \tConfidence = 0.8836 \tBbox: [ 507 \t 244 \t 627 \t 500 ]\n",
      "5 \tObject: person \tConfidence = 0.88 \tBbox: [ 555 \t 2 \t 639 \t 229 ]\n",
      "6 \tObject: person \tConfidence = 0.8425 \tBbox: [ 493 \t 0 \t 552 \t 159 ]\n",
      "7 \tObject: person \tConfidence = 0.8386 \tBbox: [ 446 \t 0 \t 502 \t 120 ]\n",
      "8 \tObject: person \tConfidence = 0.8342 \tBbox: [ 480 \t 460 \t 635 \t 792 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000243 / 1050\n",
      "Frames to be processed: 807  | To do: 76.86 % | Done: 23.14 %\n",
      "\n",
      "2022-04-20 13:12:20.666760\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000243.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 24.3ms pre-process, 173.3ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9119 \tBbox: [ 398 \t 721 \t 698 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9094 \tBbox: [ 0 \t 2 \t 455 \t 1074 ]\n",
      "3 \tObject: person \tConfidence = 0.8916 \tBbox: [ 409 \t 115 \t 487 \t 364 ]\n",
      "4 \tObject: person \tConfidence = 0.8773 \tBbox: [ 552 \t 2 \t 640 \t 228 ]\n",
      "5 \tObject: person \tConfidence = 0.8591 \tBbox: [ 507 \t 244 \t 626 \t 497 ]\n",
      "6 \tObject: person \tConfidence = 0.8568 \tBbox: [ 481 \t 461 \t 632 \t 790 ]\n",
      "7 \tObject: person \tConfidence = 0.8459 \tBbox: [ 447 \t 0 \t 503 \t 120 ]\n",
      "8 \tObject: person \tConfidence = 0.8443 \tBbox: [ 493 \t 0 \t 551 \t 160 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000244 / 1050\n",
      "Frames to be processed: 806  | To do: 76.76 % | Done: 23.24 %\n",
      "\n",
      "2022-04-20 13:12:21.146141\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000244.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 24.9ms pre-process, 176.4ms inference, 15.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9179 \tBbox: [ 0 \t 2 \t 456 \t 1074 ]\n",
      "2 \tObject: person \tConfidence = 0.9025 \tBbox: [ 399 \t 721 \t 691 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9014 \tBbox: [ 548 \t 3 \t 635 \t 229 ]\n",
      "4 \tObject: person \tConfidence = 0.898 \tBbox: [ 409 \t 115 \t 487 \t 364 ]\n",
      "5 \tObject: person \tConfidence = 0.8599 \tBbox: [ 476 \t 460 \t 631 \t 799 ]\n",
      "6 \tObject: person \tConfidence = 0.8572 \tBbox: [ 507 \t 244 \t 627 \t 494 ]\n",
      "7 \tObject: person \tConfidence = 0.8534 \tBbox: [ 493 \t 0 \t 552 \t 160 ]\n",
      "8 \tObject: person \tConfidence = 0.8448 \tBbox: [ 446 \t 0 \t 501 \t 119 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000245 / 1050\n",
      "Frames to be processed: 805  | To do: 76.67 % | Done: 23.33 %\n",
      "\n",
      "2022-04-20 13:12:21.562675\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000245.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 28.1ms pre-process, 177.7ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9028 \tBbox: [ 407 \t 117 \t 487 \t 365 ]\n",
      "2 \tObject: person \tConfidence = 0.9021 \tBbox: [ 546 \t 4 \t 635 \t 229 ]\n",
      "3 \tObject: train \tConfidence = 0.8972 \tBbox: [ 0 \t 2 \t 455 \t 1072 ]\n",
      "4 \tObject: person \tConfidence = 0.8897 \tBbox: [ 400 \t 721 \t 697 \t 1078 ]\n",
      "5 \tObject: person \tConfidence = 0.856 \tBbox: [ 506 \t 247 \t 629 \t 463 ]\n",
      "6 \tObject: person \tConfidence = 0.8461 \tBbox: [ 447 \t 0 \t 497 \t 120 ]\n",
      "7 \tObject: person \tConfidence = 0.8246 \tBbox: [ 492 \t 0 \t 550 \t 160 ]\n",
      "8 \tObject: person \tConfidence = 0.817 \tBbox: [ 467 \t 460 \t 626 \t 803 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000246 / 1050\n",
      "Frames to be processed: 804  | To do: 76.57 % | Done: 23.43 %\n",
      "\n",
      "2022-04-20 13:12:22.002740\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000246.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 30.3ms pre-process, 181.2ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9014 \tBbox: [ 544 \t 4 \t 636 \t 230 ]\n",
      "2 \tObject: person \tConfidence = 0.8991 \tBbox: [ 406 \t 118 \t 486 \t 365 ]\n",
      "3 \tObject: train \tConfidence = 0.8944 \tBbox: [ 0 \t 1 \t 455 \t 1067 ]\n",
      "4 \tObject: person \tConfidence = 0.8757 \tBbox: [ 400 \t 721 \t 701 \t 1078 ]\n",
      "5 \tObject: person \tConfidence = 0.854 \tBbox: [ 506 \t 247 \t 629 \t 465 ]\n",
      "6 \tObject: person \tConfidence = 0.8521 \tBbox: [ 447 \t 0 \t 496 \t 120 ]\n",
      "7 \tObject: person \tConfidence = 0.8391 \tBbox: [ 464 \t 459 \t 622 \t 812 ]\n",
      "8 \tObject: person \tConfidence = 0.7855 \tBbox: [ 492 \t 0 \t 548 \t 160 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000247 / 1050\n",
      "Frames to be processed: 803  | To do: 76.48 % | Done: 23.52 %\n",
      "\n",
      "2022-04-20 13:12:22.444522\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000247.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 30.5ms pre-process, 181.1ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9004 \tBbox: [ 544 \t 6 \t 632 \t 231 ]\n",
      "2 \tObject: person \tConfidence = 0.8959 \tBbox: [ 405 \t 118 \t 486 \t 365 ]\n",
      "3 \tObject: train \tConfidence = 0.8938 \tBbox: [ 0 \t 2 \t 456 \t 1072 ]\n",
      "4 \tObject: person \tConfidence = 0.8749 \tBbox: [ 452 \t 460 \t 618 \t 843 ]\n",
      "5 \tObject: person \tConfidence = 0.8605 \tBbox: [ 401 \t 722 \t 702 \t 1078 ]\n",
      "6 \tObject: person \tConfidence = 0.8535 \tBbox: [ 506 \t 247 \t 628 \t 467 ]\n",
      "7 \tObject: person \tConfidence = 0.8447 \tBbox: [ 447 \t 0 \t 496 \t 120 ]\n",
      "8 \tObject: person \tConfidence = 0.7701 \tBbox: [ 492 \t 0 \t 548 \t 160 ]\n",
      "9 \tObject: person \tConfidence = 0.3823 \tBbox: [ 532 \t 0 \t 555 \t 44 ]\n",
      "10 \tObject: person \tConfidence = 0.3548 \tBbox: [ 594 \t 0 \t 642 \t 47 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000248 / 1050\n",
      "Frames to be processed: 802  | To do: 76.38 % | Done: 23.62 %\n",
      "\n",
      "2022-04-20 13:12:22.881726\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000248.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 29.3ms pre-process, 173.1ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9057 \tBbox: [ 544 \t 8 \t 629 \t 231 ]\n",
      "2 \tObject: person \tConfidence = 0.8968 \tBbox: [ 405 \t 119 \t 485 \t 366 ]\n",
      "3 \tObject: person \tConfidence = 0.8936 \tBbox: [ 450 \t 461 \t 614 \t 845 ]\n",
      "4 \tObject: train \tConfidence = 0.8931 \tBbox: [ 0 \t 2 \t 456 \t 1069 ]\n",
      "5 \tObject: person \tConfidence = 0.8807 \tBbox: [ 401 \t 721 \t 699 \t 1078 ]\n",
      "6 \tObject: person \tConfidence = 0.8633 \tBbox: [ 505 \t 248 \t 627 \t 470 ]\n",
      "7 \tObject: person \tConfidence = 0.8496 \tBbox: [ 447 \t 0 \t 496 \t 120 ]\n",
      "8 \tObject: person \tConfidence = 0.77 \tBbox: [ 492 \t 0 \t 548 \t 160 ]\n",
      "9 \tObject: person \tConfidence = 0.4478 \tBbox: [ 533 \t 0 \t 556 \t 45 ]\n",
      "10 \tObject: person \tConfidence = 0.3456 \tBbox: [ 594 \t 0 \t 641 \t 44 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000249 / 1050\n",
      "Frames to be processed: 801  | To do: 76.29 % | Done: 23.71 %\n",
      "\n",
      "2022-04-20 13:12:23.325736\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000249.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 37.2ms pre-process, 180.0ms inference, 4.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9043 \tBbox: [ 544 \t 7 \t 628 \t 231 ]\n",
      "2 \tObject: train \tConfidence = 0.8928 \tBbox: [ 0 \t 2 \t 457 \t 1073 ]\n",
      "3 \tObject: person \tConfidence = 0.8867 \tBbox: [ 403 \t 119 \t 485 \t 365 ]\n",
      "4 \tObject: person \tConfidence = 0.8848 \tBbox: [ 451 \t 462 \t 612 \t 845 ]\n",
      "5 \tObject: person \tConfidence = 0.8642 \tBbox: [ 505 \t 247 \t 625 \t 476 ]\n",
      "6 \tObject: person \tConfidence = 0.8446 \tBbox: [ 447 \t 0 \t 496 \t 121 ]\n",
      "7 \tObject: person \tConfidence = 0.8269 \tBbox: [ 403 \t 723 \t 698 \t 1078 ]\n",
      "8 \tObject: person \tConfidence = 0.7843 \tBbox: [ 491 \t 0 \t 548 \t 159 ]\n",
      "9 \tObject: person \tConfidence = 0.4203 \tBbox: [ 594 \t 0 \t 641 \t 43 ]\n",
      "10 \tObject: person \tConfidence = 0.3657 \tBbox: [ 533 \t 0 \t 555 \t 45 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000250 / 1050\n",
      "Frames to be processed: 800  | To do: 76.19 % | Done: 23.81 %\n",
      "\n",
      "2022-04-20 13:12:23.759896\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000250.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 25.1ms pre-process, 174.0ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9029 \tBbox: [ 444 \t 465 \t 608 \t 848 ]\n",
      "2 \tObject: person \tConfidence = 0.899 \tBbox: [ 545 \t 10 \t 626 \t 232 ]\n",
      "3 \tObject: train \tConfidence = 0.8921 \tBbox: [ 0 \t 0 \t 456 \t 1045 ]\n",
      "4 \tObject: person \tConfidence = 0.8781 \tBbox: [ 402 \t 721 \t 695 \t 1078 ]\n",
      "5 \tObject: person \tConfidence = 0.8771 \tBbox: [ 504 \t 247 \t 623 \t 486 ]\n",
      "6 \tObject: person \tConfidence = 0.8718 \tBbox: [ 402 \t 119 \t 483 \t 365 ]\n",
      "7 \tObject: person \tConfidence = 0.8462 \tBbox: [ 447 \t 0 \t 496 \t 121 ]\n",
      "8 \tObject: person \tConfidence = 0.7898 \tBbox: [ 491 \t 0 \t 547 \t 158 ]\n",
      "9 \tObject: person \tConfidence = 0.5127 \tBbox: [ 593 \t 0 \t 642 \t 46 ]\n",
      "10 \tObject: person \tConfidence = 0.3462 \tBbox: [ 532 \t 0 \t 555 \t 44 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000251 / 1050\n",
      "Frames to be processed: 799  | To do: 76.1 % | Done: 23.9 %\n",
      "\n",
      "2022-04-20 13:12:24.240432\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000251.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 25.1ms pre-process, 175.3ms inference, 15.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9078 \tBbox: [ 0 \t 1 \t 456 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.9019 \tBbox: [ 449 \t 466 \t 600 \t 846 ]\n",
      "3 \tObject: person \tConfidence = 0.8921 \tBbox: [ 545 \t 8 \t 626 \t 232 ]\n",
      "4 \tObject: person \tConfidence = 0.8878 \tBbox: [ 504 \t 247 \t 625 \t 492 ]\n",
      "5 \tObject: person \tConfidence = 0.87 \tBbox: [ 402 \t 120 \t 483 \t 366 ]\n",
      "6 \tObject: person \tConfidence = 0.8492 \tBbox: [ 447 \t 0 \t 497 \t 121 ]\n",
      "7 \tObject: person \tConfidence = 0.8314 \tBbox: [ 404 \t 721 \t 695 \t 1078 ]\n",
      "8 \tObject: person \tConfidence = 0.7416 \tBbox: [ 491 \t 1 \t 547 \t 163 ]\n",
      "9 \tObject: person \tConfidence = 0.4765 \tBbox: [ 592 \t 0 \t 642 \t 48 ]\n",
      "10 \tObject: person \tConfidence = 0.4749 \tBbox: [ 532 \t 0 \t 555 \t 43 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000252 / 1050\n",
      "Frames to be processed: 798  | To do: 76.0 % | Done: 24.0 %\n",
      "\n",
      "2022-04-20 13:12:24.683345\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000252.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 27.5ms pre-process, 175.9ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9084 \tBbox: [ 0 \t 2 \t 458 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8889 \tBbox: [ 449 \t 466 \t 593 \t 841 ]\n",
      "3 \tObject: person \tConfidence = 0.883 \tBbox: [ 544 \t 7 \t 627 \t 232 ]\n",
      "4 \tObject: person \tConfidence = 0.8775 \tBbox: [ 504 \t 247 \t 625 \t 501 ]\n",
      "5 \tObject: person \tConfidence = 0.8585 \tBbox: [ 402 \t 121 \t 483 \t 366 ]\n",
      "6 \tObject: person \tConfidence = 0.8422 \tBbox: [ 448 \t 0 \t 497 \t 121 ]\n",
      "7 \tObject: person \tConfidence = 0.7618 \tBbox: [ 403 \t 721 \t 710 \t 1078 ]\n",
      "8 \tObject: person \tConfidence = 0.741 \tBbox: [ 491 \t 0 \t 548 \t 159 ]\n",
      "9 \tObject: person \tConfidence = 0.4841 \tBbox: [ 592 \t 0 \t 642 \t 48 ]\n",
      "10 \tObject: person \tConfidence = 0.413 \tBbox: [ 532 \t 0 \t 555 \t 43 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000253 / 1050\n",
      "Frames to be processed: 797  | To do: 75.9 % | Done: 24.1 %\n",
      "\n",
      "2022-04-20 13:12:25.118972\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000253.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 25.8ms pre-process, 179.4ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9219 \tBbox: [ 0 \t 2 \t 457 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.9085 \tBbox: [ 447 \t 466 \t 589 \t 843 ]\n",
      "3 \tObject: person \tConfidence = 0.8996 \tBbox: [ 404 \t 720 \t 711 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8824 \tBbox: [ 504 \t 247 \t 625 \t 503 ]\n",
      "5 \tObject: person \tConfidence = 0.8713 \tBbox: [ 544 \t 6 \t 628 \t 232 ]\n",
      "6 \tObject: person \tConfidence = 0.8455 \tBbox: [ 402 \t 120 \t 480 \t 366 ]\n",
      "7 \tObject: person \tConfidence = 0.8422 \tBbox: [ 448 \t 0 \t 497 \t 121 ]\n",
      "8 \tObject: person \tConfidence = 0.7168 \tBbox: [ 491 \t 0 \t 547 \t 159 ]\n",
      "9 \tObject: person \tConfidence = 0.4943 \tBbox: [ 532 \t 0 \t 555 \t 43 ]\n",
      "10 \tObject: person \tConfidence = 0.4046 \tBbox: [ 591 \t 0 \t 642 \t 48 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000254 / 1050\n",
      "Frames to be processed: 796  | To do: 75.81 % | Done: 24.19 %\n",
      "\n",
      "2022-04-20 13:12:25.572662\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000254.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 29.0ms pre-process, 181.9ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9229 \tBbox: [ 0 \t 2 \t 458 \t 1076 ]\n",
      "2 \tObject: person \tConfidence = 0.8952 \tBbox: [ 445 \t 466 \t 585 \t 842 ]\n",
      "3 \tObject: person \tConfidence = 0.8684 \tBbox: [ 544 \t 7 \t 629 \t 232 ]\n",
      "4 \tObject: person \tConfidence = 0.8559 \tBbox: [ 503 \t 249 \t 625 \t 506 ]\n",
      "5 \tObject: person \tConfidence = 0.8549 \tBbox: [ 402 \t 121 \t 479 \t 366 ]\n",
      "6 \tObject: person \tConfidence = 0.8334 \tBbox: [ 448 \t 0 \t 497 \t 121 ]\n",
      "7 \tObject: person \tConfidence = 0.8252 \tBbox: [ 406 \t 721 \t 713 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.7647 \tBbox: [ 490 \t 0 \t 549 \t 158 ]\n",
      "9 \tObject: person \tConfidence = 0.4964 \tBbox: [ 532 \t 0 \t 555 \t 43 ]\n",
      "10 \tObject: person \tConfidence = 0.4195 \tBbox: [ 592 \t 0 \t 642 \t 48 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000255 / 1050\n",
      "Frames to be processed: 795  | To do: 75.71 % | Done: 24.29 %\n",
      "\n",
      "2022-04-20 13:12:25.988422\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000255.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 26.3ms pre-process, 182.4ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9162 \tBbox: [ 1 \t 4 \t 458 \t 956 ]\n",
      "2 \tObject: person \tConfidence = 0.8893 \tBbox: [ 439 \t 467 \t 577 \t 841 ]\n",
      "3 \tObject: person \tConfidence = 0.8686 \tBbox: [ 503 \t 248 \t 625 \t 531 ]\n",
      "4 \tObject: person \tConfidence = 0.8532 \tBbox: [ 544 \t 8 \t 625 \t 234 ]\n",
      "5 \tObject: person \tConfidence = 0.8523 \tBbox: [ 408 \t 719 \t 715 \t 1078 ]\n",
      "6 \tObject: person \tConfidence = 0.8388 \tBbox: [ 403 \t 122 \t 474 \t 366 ]\n",
      "7 \tObject: person \tConfidence = 0.8295 \tBbox: [ 448 \t 0 \t 497 \t 121 ]\n",
      "8 \tObject: person \tConfidence = 0.7136 \tBbox: [ 489 \t 0 \t 544 \t 159 ]\n",
      "9 \tObject: person \tConfidence = 0.6594 \tBbox: [ 594 \t 0 \t 642 \t 122 ]\n",
      "10 \tObject: person \tConfidence = 0.5842 \tBbox: [ 532 \t 0 \t 556 \t 42 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000256 / 1050\n",
      "Frames to be processed: 794  | To do: 75.62 % | Done: 24.38 %\n",
      "\n",
      "2022-04-20 13:12:26.429723\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000256.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 33.3ms pre-process, 172.9ms inference, 3.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.921 \tBbox: [ 0 \t 6 \t 459 \t 1028 ]\n",
      "2 \tObject: person \tConfidence = 0.8737 \tBbox: [ 436 \t 468 \t 574 \t 835 ]\n",
      "3 \tObject: person \tConfidence = 0.8635 \tBbox: [ 503 \t 247 \t 624 \t 532 ]\n",
      "4 \tObject: person \tConfidence = 0.841 \tBbox: [ 544 \t 10 \t 622 \t 233 ]\n",
      "5 \tObject: person \tConfidence = 0.8385 \tBbox: [ 402 \t 122 \t 472 \t 366 ]\n",
      "6 \tObject: person \tConfidence = 0.8338 \tBbox: [ 448 \t 0 \t 497 \t 122 ]\n",
      "7 \tObject: person \tConfidence = 0.7805 \tBbox: [ 409 \t 719 \t 715 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.742 \tBbox: [ 489 \t 0 \t 543 \t 159 ]\n",
      "9 \tObject: person \tConfidence = 0.7285 \tBbox: [ 595 \t 0 \t 642 \t 121 ]\n",
      "10 \tObject: person \tConfidence = 0.6329 \tBbox: [ 532 \t 0 \t 556 \t 43 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000257 / 1050\n",
      "Frames to be processed: 793  | To do: 75.52 % | Done: 24.48 %\n",
      "\n",
      "2022-04-20 13:12:26.862849\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000257.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 26.3ms pre-process, 180.3ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9221 \tBbox: [ 0 \t 0 \t 459 \t 1074 ]\n",
      "2 \tObject: person \tConfidence = 0.896 \tBbox: [ 432 \t 467 \t 569 \t 846 ]\n",
      "3 \tObject: person \tConfidence = 0.8665 \tBbox: [ 503 \t 247 \t 624 \t 532 ]\n",
      "4 \tObject: person \tConfidence = 0.842 \tBbox: [ 401 \t 122 \t 470 \t 366 ]\n",
      "5 \tObject: person \tConfidence = 0.838 \tBbox: [ 544 \t 12 \t 621 \t 233 ]\n",
      "6 \tObject: person \tConfidence = 0.8313 \tBbox: [ 448 \t 0 \t 497 \t 121 ]\n",
      "7 \tObject: person \tConfidence = 0.7331 \tBbox: [ 489 \t 0 \t 548 \t 158 ]\n",
      "8 \tObject: person \tConfidence = 0.7258 \tBbox: [ 595 \t 0 \t 643 \t 123 ]\n",
      "9 \tObject: person \tConfidence = 0.7119 \tBbox: [ 411 \t 719 \t 716 \t 1079 ]\n",
      "10 \tObject: person \tConfidence = 0.6031 \tBbox: [ 532 \t 0 \t 556 \t 43 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000258 / 1050\n",
      "Frames to be processed: 792  | To do: 75.43 % | Done: 24.57 %\n",
      "\n",
      "2022-04-20 13:12:27.289381\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000258.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 27.4ms pre-process, 171.7ms inference, 11.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9294 \tBbox: [ 2 \t 2 \t 462 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8964 \tBbox: [ 427 \t 468 \t 566 \t 846 ]\n",
      "3 \tObject: person \tConfidence = 0.872 \tBbox: [ 503 \t 248 \t 625 \t 532 ]\n",
      "4 \tObject: person \tConfidence = 0.8456 \tBbox: [ 399 \t 122 \t 469 \t 366 ]\n",
      "5 \tObject: person \tConfidence = 0.8337 \tBbox: [ 544 \t 10 \t 623 \t 233 ]\n",
      "6 \tObject: person \tConfidence = 0.8333 \tBbox: [ 448 \t 0 \t 497 \t 122 ]\n",
      "7 \tObject: person \tConfidence = 0.7922 \tBbox: [ 489 \t 0 \t 552 \t 159 ]\n",
      "8 \tObject: person \tConfidence = 0.7059 \tBbox: [ 411 \t 717 \t 715 \t 1079 ]\n",
      "9 \tObject: person \tConfidence = 0.5497 \tBbox: [ 533 \t 0 \t 556 \t 43 ]\n",
      "10 \tObject: person \tConfidence = 0.549 \tBbox: [ 596 \t 0 \t 643 \t 127 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000259 / 1050\n",
      "Frames to be processed: 791  | To do: 75.33 % | Done: 24.67 %\n",
      "\n",
      "2022-04-20 13:12:27.737093\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000259.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 32.3ms pre-process, 174.5ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9258 \tBbox: [ 0 \t 1 \t 460 \t 1076 ]\n",
      "2 \tObject: person \tConfidence = 0.8729 \tBbox: [ 502 \t 247 \t 623 \t 532 ]\n",
      "3 \tObject: person \tConfidence = 0.8629 \tBbox: [ 421 \t 469 \t 562 \t 844 ]\n",
      "4 \tObject: person \tConfidence = 0.8499 \tBbox: [ 398 \t 122 \t 469 \t 366 ]\n",
      "5 \tObject: person \tConfidence = 0.8412 \tBbox: [ 544 \t 10 \t 622 \t 233 ]\n",
      "6 \tObject: person \tConfidence = 0.8273 \tBbox: [ 448 \t 0 \t 497 \t 122 ]\n",
      "7 \tObject: person \tConfidence = 0.77 \tBbox: [ 489 \t 0 \t 551 \t 160 ]\n",
      "8 \tObject: person \tConfidence = 0.6711 \tBbox: [ 412 \t 718 \t 715 \t 1079 ]\n",
      "9 \tObject: person \tConfidence = 0.5769 \tBbox: [ 594 \t 0 \t 642 \t 131 ]\n",
      "10 \tObject: person \tConfidence = 0.5683 \tBbox: [ 532 \t 0 \t 556 \t 43 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000260 / 1050\n",
      "Frames to be processed: 790  | To do: 75.24 % | Done: 24.76 %\n",
      "\n",
      "2022-04-20 13:12:28.194578\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000260.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 24.9ms pre-process, 179.7ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9295 \tBbox: [ 1 \t 1 \t 460 \t 1076 ]\n",
      "2 \tObject: person \tConfidence = 0.876 \tBbox: [ 502 \t 247 \t 623 \t 532 ]\n",
      "3 \tObject: person \tConfidence = 0.8574 \tBbox: [ 543 \t 13 \t 613 \t 233 ]\n",
      "4 \tObject: person \tConfidence = 0.8447 \tBbox: [ 423 \t 471 \t 558 \t 846 ]\n",
      "5 \tObject: person \tConfidence = 0.8418 \tBbox: [ 398 \t 123 \t 469 \t 366 ]\n",
      "6 \tObject: person \tConfidence = 0.8252 \tBbox: [ 447 \t 0 \t 497 \t 122 ]\n",
      "7 \tObject: person \tConfidence = 0.7675 \tBbox: [ 594 \t 0 \t 642 \t 134 ]\n",
      "8 \tObject: person \tConfidence = 0.7621 \tBbox: [ 489 \t 0 \t 551 \t 160 ]\n",
      "9 \tObject: person \tConfidence = 0.6753 \tBbox: [ 414 \t 716 \t 714 \t 1079 ]\n",
      "10 \tObject: person \tConfidence = 0.5509 \tBbox: [ 532 \t 0 \t 556 \t 43 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000261 / 1050\n",
      "Frames to be processed: 789  | To do: 75.14 % | Done: 24.86 %\n",
      "\n",
      "2022-04-20 13:12:28.682503\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000261.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 40.9ms pre-process, 172.7ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9314 \tBbox: [ 1 \t 1 \t 460 \t 1075 ]\n",
      "2 \tObject: person \tConfidence = 0.8791 \tBbox: [ 502 \t 247 \t 623 \t 532 ]\n",
      "3 \tObject: person \tConfidence = 0.857 \tBbox: [ 543 \t 12 \t 612 \t 232 ]\n",
      "4 \tObject: person \tConfidence = 0.8509 \tBbox: [ 415 \t 711 \t 714 \t 1080 ]\n",
      "5 \tObject: person \tConfidence = 0.8466 \tBbox: [ 421 \t 471 \t 556 \t 848 ]\n",
      "6 \tObject: person \tConfidence = 0.8409 \tBbox: [ 398 \t 122 \t 468 \t 366 ]\n",
      "7 \tObject: person \tConfidence = 0.8156 \tBbox: [ 447 \t 0 \t 497 \t 122 ]\n",
      "8 \tObject: person \tConfidence = 0.8061 \tBbox: [ 488 \t 0 \t 554 \t 161 ]\n",
      "9 \tObject: person \tConfidence = 0.7884 \tBbox: [ 594 \t 0 \t 642 \t 133 ]\n",
      "10 \tObject: person \tConfidence = 0.4439 \tBbox: [ 532 \t 0 \t 555 \t 43 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000262 / 1050\n",
      "Frames to be processed: 788  | To do: 75.05 % | Done: 24.95 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 25.5ms pre-process, 168.8ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:12:29.168303\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000262.jpg ------------------------------ \n",
      "\n",
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.929 \tBbox: [ 0 \t 2 \t 458 \t 1074 ]\n",
      "2 \tObject: person \tConfidence = 0.8793 \tBbox: [ 502 \t 247 \t 623 \t 532 ]\n",
      "3 \tObject: person \tConfidence = 0.8635 \tBbox: [ 419 \t 471 \t 553 \t 848 ]\n",
      "4 \tObject: person \tConfidence = 0.8531 \tBbox: [ 543 \t 12 \t 612 \t 232 ]\n",
      "5 \tObject: person \tConfidence = 0.841 \tBbox: [ 398 \t 122 \t 468 \t 366 ]\n",
      "6 \tObject: person \tConfidence = 0.8216 \tBbox: [ 488 \t 0 \t 554 \t 161 ]\n",
      "7 \tObject: person \tConfidence = 0.819 \tBbox: [ 593 \t 0 \t 643 \t 134 ]\n",
      "8 \tObject: person \tConfidence = 0.812 \tBbox: [ 447 \t 0 \t 497 \t 122 ]\n",
      "9 \tObject: person \tConfidence = 0.7775 \tBbox: [ 414 \t 714 \t 711 \t 1079 ]\n",
      "10 \tObject: person \tConfidence = 0.3515 \tBbox: [ 533 \t 0 \t 555 \t 43 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000263 / 1050\n",
      "Frames to be processed: 787  | To do: 74.95 % | Done: 25.05 %\n",
      "\n",
      "2022-04-20 13:12:29.574483\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000263.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 25.1ms pre-process, 175.1ms inference, 4.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9262 \tBbox: [ 0 \t 2 \t 459 \t 1074 ]\n",
      "2 \tObject: person \tConfidence = 0.8744 \tBbox: [ 413 \t 713 \t 711 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8707 \tBbox: [ 502 \t 247 \t 622 \t 532 ]\n",
      "4 \tObject: person \tConfidence = 0.8502 \tBbox: [ 396 \t 471 \t 551 \t 847 ]\n",
      "5 \tObject: person \tConfidence = 0.8488 \tBbox: [ 593 \t 0 \t 643 \t 134 ]\n",
      "6 \tObject: person \tConfidence = 0.8422 \tBbox: [ 543 \t 13 \t 611 \t 232 ]\n",
      "7 \tObject: person \tConfidence = 0.8398 \tBbox: [ 397 \t 121 \t 467 \t 366 ]\n",
      "8 \tObject: person \tConfidence = 0.8363 \tBbox: [ 489 \t 0 \t 555 \t 160 ]\n",
      "9 \tObject: person \tConfidence = 0.8198 \tBbox: [ 447 \t 0 \t 497 \t 122 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000264 / 1050\n",
      "Frames to be processed: 786  | To do: 74.86 % | Done: 25.14 %\n",
      "\n",
      "2022-04-20 13:12:30.006777\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000264.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 38.3ms pre-process, 170.1ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9206 \tBbox: [ 0 \t 2 \t 459 \t 1073 ]\n",
      "2 \tObject: person \tConfidence = 0.8781 \tBbox: [ 411 \t 712 \t 709 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8642 \tBbox: [ 502 \t 247 \t 622 \t 532 ]\n",
      "4 \tObject: person \tConfidence = 0.8425 \tBbox: [ 397 \t 122 \t 468 \t 366 ]\n",
      "5 \tObject: person \tConfidence = 0.8393 \tBbox: [ 413 \t 470 \t 547 \t 846 ]\n",
      "6 \tObject: person \tConfidence = 0.839 \tBbox: [ 591 \t 0 \t 644 \t 134 ]\n",
      "7 \tObject: person \tConfidence = 0.8282 \tBbox: [ 489 \t 0 \t 555 \t 161 ]\n",
      "8 \tObject: person \tConfidence = 0.8243 \tBbox: [ 542 \t 17 \t 609 \t 232 ]\n",
      "9 \tObject: person \tConfidence = 0.8239 \tBbox: [ 448 \t 0 \t 496 \t 122 ]\n",
      "10 \tObject: person \tConfidence = 0.3195 \tBbox: [ 533 \t 0 \t 555 \t 43 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000265 / 1050\n",
      "Frames to be processed: 785  | To do: 74.76 % | Done: 25.24 %\n",
      "\n",
      "2022-04-20 13:12:30.437379\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000265.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 27.1ms pre-process, 175.3ms inference, 15.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9127 \tBbox: [ 0 \t 2 \t 459 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8919 \tBbox: [ 398 \t 711 \t 701 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8826 \tBbox: [ 541 \t 12 \t 606 \t 232 ]\n",
      "4 \tObject: person \tConfidence = 0.8695 \tBbox: [ 591 \t 0 \t 644 \t 134 ]\n",
      "5 \tObject: person \tConfidence = 0.8651 \tBbox: [ 503 \t 246 \t 621 \t 532 ]\n",
      "6 \tObject: person \tConfidence = 0.862 \tBbox: [ 376 \t 471 \t 543 \t 841 ]\n",
      "7 \tObject: person \tConfidence = 0.8472 \tBbox: [ 488 \t 0 \t 555 \t 160 ]\n",
      "8 \tObject: person \tConfidence = 0.8388 \tBbox: [ 398 \t 121 \t 468 \t 366 ]\n",
      "9 \tObject: person \tConfidence = 0.829 \tBbox: [ 448 \t 0 \t 498 \t 122 ]\n",
      "10 \tObject: person \tConfidence = 0.3026 \tBbox: [ 533 \t 0 \t 554 \t 44 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000266 / 1050\n",
      "Frames to be processed: 784  | To do: 74.67 % | Done: 25.33 %\n",
      "\n",
      "2022-04-20 13:12:30.920304\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000266.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 26.4ms pre-process, 174.5ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9064 \tBbox: [ 1 \t 0 \t 460 \t 1067 ]\n",
      "2 \tObject: person \tConfidence = 0.8881 \tBbox: [ 538 \t 11 \t 606 \t 232 ]\n",
      "3 \tObject: person \tConfidence = 0.8742 \tBbox: [ 590 \t 0 \t 645 \t 136 ]\n",
      "4 \tObject: person \tConfidence = 0.8647 \tBbox: [ 503 \t 246 \t 621 \t 532 ]\n",
      "5 \tObject: person \tConfidence = 0.8579 \tBbox: [ 377 \t 469 \t 541 \t 844 ]\n",
      "6 \tObject: person \tConfidence = 0.8492 \tBbox: [ 488 \t 0 \t 555 \t 160 ]\n",
      "7 \tObject: person \tConfidence = 0.8475 \tBbox: [ 399 \t 711 \t 696 \t 1078 ]\n",
      "8 \tObject: person \tConfidence = 0.8435 \tBbox: [ 398 \t 120 \t 468 \t 366 ]\n",
      "9 \tObject: person \tConfidence = 0.8256 \tBbox: [ 448 \t 0 \t 498 \t 122 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000267 / 1050\n",
      "Frames to be processed: 783  | To do: 74.57 % | Done: 25.43 %\n",
      "\n",
      "2022-04-20 13:12:31.414228\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000267.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 31.8ms pre-process, 170.1ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9136 \tBbox: [ 370 \t 470 \t 538 \t 844 ]\n",
      "2 \tObject: train \tConfidence = 0.9123 \tBbox: [ 0 \t 0 \t 460 \t 1072 ]\n",
      "3 \tObject: person \tConfidence = 0.8743 \tBbox: [ 536 \t 11 \t 606 \t 232 ]\n",
      "4 \tObject: person \tConfidence = 0.873 \tBbox: [ 591 \t 0 \t 645 \t 138 ]\n",
      "5 \tObject: person \tConfidence = 0.8671 \tBbox: [ 398 \t 711 \t 692 \t 1078 ]\n",
      "6 \tObject: person \tConfidence = 0.8669 \tBbox: [ 503 \t 246 \t 620 \t 533 ]\n",
      "7 \tObject: person \tConfidence = 0.8473 \tBbox: [ 398 \t 119 \t 468 \t 366 ]\n",
      "8 \tObject: person \tConfidence = 0.847 \tBbox: [ 488 \t 0 \t 556 \t 160 ]\n",
      "9 \tObject: person \tConfidence = 0.8299 \tBbox: [ 448 \t 0 \t 498 \t 122 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000268 / 1050\n",
      "Frames to be processed: 782  | To do: 74.48 % | Done: 25.52 %\n",
      "\n",
      "2022-04-20 13:12:31.865881\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000268.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 40.0ms pre-process, 167.3ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9095 \tBbox: [ 0 \t 1 \t 460 \t 1073 ]\n",
      "2 \tObject: person \tConfidence = 0.8942 \tBbox: [ 369 \t 470 \t 534 \t 832 ]\n",
      "3 \tObject: person \tConfidence = 0.8795 \tBbox: [ 534 \t 12 \t 606 \t 233 ]\n",
      "4 \tObject: person \tConfidence = 0.8761 \tBbox: [ 393 \t 711 \t 689 \t 1078 ]\n",
      "5 \tObject: person \tConfidence = 0.872 \tBbox: [ 591 \t 0 \t 646 \t 136 ]\n",
      "6 \tObject: person \tConfidence = 0.8602 \tBbox: [ 504 \t 245 \t 620 \t 532 ]\n",
      "7 \tObject: person \tConfidence = 0.8493 \tBbox: [ 398 \t 119 \t 468 \t 366 ]\n",
      "8 \tObject: person \tConfidence = 0.8327 \tBbox: [ 447 \t 0 \t 497 \t 122 ]\n",
      "9 \tObject: person \tConfidence = 0.8314 \tBbox: [ 488 \t 0 \t 555 \t 160 ]\n",
      "10 \tObject: person \tConfidence = 0.3075 \tBbox: [ 534 \t 0 \t 555 \t 43 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000269 / 1050\n",
      "Frames to be processed: 781  | To do: 74.38 % | Done: 25.62 %\n",
      "\n",
      "2022-04-20 13:12:32.316325\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000269.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 24.2ms pre-process, 174.8ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9199 \tBbox: [ 0 \t 1 \t 461 \t 1074 ]\n",
      "2 \tObject: person \tConfidence = 0.8912 \tBbox: [ 389 \t 710 \t 679 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8793 \tBbox: [ 533 \t 13 \t 605 \t 233 ]\n",
      "4 \tObject: person \tConfidence = 0.8773 \tBbox: [ 590 \t 0 \t 646 \t 136 ]\n",
      "5 \tObject: person \tConfidence = 0.8602 \tBbox: [ 505 \t 245 \t 621 \t 532 ]\n",
      "6 \tObject: person \tConfidence = 0.8496 \tBbox: [ 397 \t 119 \t 468 \t 366 ]\n",
      "7 \tObject: person \tConfidence = 0.8287 \tBbox: [ 383 \t 469 \t 531 \t 832 ]\n",
      "8 \tObject: person \tConfidence = 0.8245 \tBbox: [ 448 \t 0 \t 497 \t 122 ]\n",
      "9 \tObject: person \tConfidence = 0.7691 \tBbox: [ 488 \t 0 \t 553 \t 160 ]\n",
      "10 \tObject: person \tConfidence = 0.3874 \tBbox: [ 534 \t 0 \t 555 \t 43 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000270 / 1050\n",
      "Frames to be processed: 780  | To do: 74.29 % | Done: 25.71 %\n",
      "\n",
      "2022-04-20 13:12:32.797197\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000270.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 28.9ms pre-process, 180.5ms inference, 4.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9185 \tBbox: [ 0 \t 0 \t 461 \t 1075 ]\n",
      "2 \tObject: person \tConfidence = 0.8852 \tBbox: [ 521 \t 13 \t 604 \t 233 ]\n",
      "3 \tObject: person \tConfidence = 0.879 \tBbox: [ 384 \t 709 \t 674 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8599 \tBbox: [ 507 \t 244 \t 622 \t 532 ]\n",
      "5 \tObject: person \tConfidence = 0.8534 \tBbox: [ 396 \t 118 \t 468 \t 365 ]\n",
      "6 \tObject: person \tConfidence = 0.8512 \tBbox: [ 588 \t 0 \t 646 \t 145 ]\n",
      "7 \tObject: person \tConfidence = 0.8245 \tBbox: [ 448 \t 0 \t 497 \t 122 ]\n",
      "8 \tObject: person \tConfidence = 0.8219 \tBbox: [ 372 \t 465 \t 523 \t 852 ]\n",
      "9 \tObject: person \tConfidence = 0.8004 \tBbox: [ 488 \t 0 \t 554 \t 160 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000271 / 1050\n",
      "Frames to be processed: 779  | To do: 74.19 % | Done: 25.81 %\n",
      "\n",
      "2022-04-20 13:12:33.282354\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000271.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 27.8ms pre-process, 174.7ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9143 \tBbox: [ 0 \t 1 \t 460 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.8884 \tBbox: [ 380 \t 709 \t 667 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8861 \tBbox: [ 521 \t 12 \t 602 \t 233 ]\n",
      "4 \tObject: person \tConfidence = 0.8692 \tBbox: [ 507 \t 244 \t 622 \t 532 ]\n",
      "5 \tObject: person \tConfidence = 0.8541 \tBbox: [ 395 \t 118 \t 469 \t 366 ]\n",
      "6 \tObject: person \tConfidence = 0.844 \tBbox: [ 587 \t 0 \t 647 \t 149 ]\n",
      "7 \tObject: person \tConfidence = 0.8228 \tBbox: [ 379 \t 464 \t 518 \t 854 ]\n",
      "8 \tObject: person \tConfidence = 0.8173 \tBbox: [ 448 \t 0 \t 497 \t 122 ]\n",
      "9 \tObject: person \tConfidence = 0.7029 \tBbox: [ 488 \t 0 \t 545 \t 162 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000272 / 1050\n",
      "Frames to be processed: 778  | To do: 74.1 % | Done: 25.9 %\n",
      "\n",
      "2022-04-20 13:12:33.686563\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000272.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 29.6ms pre-process, 169.6ms inference, 7.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9142 \tBbox: [ 0 \t 1 \t 460 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8875 \tBbox: [ 521 \t 12 \t 602 \t 233 ]\n",
      "3 \tObject: person \tConfidence = 0.8853 \tBbox: [ 378 \t 710 \t 663 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.871 \tBbox: [ 508 \t 243 \t 622 \t 532 ]\n",
      "5 \tObject: person \tConfidence = 0.8646 \tBbox: [ 589 \t 0 \t 647 \t 152 ]\n",
      "6 \tObject: person \tConfidence = 0.8559 \tBbox: [ 394 \t 117 \t 468 \t 366 ]\n",
      "7 \tObject: person \tConfidence = 0.8193 \tBbox: [ 449 \t 0 \t 497 \t 122 ]\n",
      "8 \tObject: person \tConfidence = 0.7957 \tBbox: [ 374 \t 464 \t 512 \t 847 ]\n",
      "9 \tObject: person \tConfidence = 0.7417 \tBbox: [ 488 \t 0 \t 551 \t 160 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000273 / 1050\n",
      "Frames to be processed: 777  | To do: 74.0 % | Done: 26.0 %\n",
      "\n",
      "2022-04-20 13:12:34.116994\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000273.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 25.1ms pre-process, 176.0ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9015 \tBbox: [ 0 \t 0 \t 460 \t 1061 ]\n",
      "2 \tObject: person \tConfidence = 0.8968 \tBbox: [ 376 \t 711 \t 654 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8862 \tBbox: [ 520 \t 11 \t 601 \t 234 ]\n",
      "4 \tObject: person \tConfidence = 0.8696 \tBbox: [ 508 \t 244 \t 623 \t 532 ]\n",
      "5 \tObject: person \tConfidence = 0.8542 \tBbox: [ 587 \t 0 \t 646 \t 153 ]\n",
      "6 \tObject: person \tConfidence = 0.8517 \tBbox: [ 395 \t 117 \t 468 \t 366 ]\n",
      "7 \tObject: person \tConfidence = 0.8079 \tBbox: [ 449 \t 0 \t 499 \t 122 ]\n",
      "8 \tObject: person \tConfidence = 0.7771 \tBbox: [ 369 \t 463 \t 508 \t 843 ]\n",
      "9 \tObject: person \tConfidence = 0.7238 \tBbox: [ 488 \t 0 \t 549 \t 159 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000274 / 1050\n",
      "Frames to be processed: 776  | To do: 73.9 % | Done: 26.1 %\n",
      "\n",
      "2022-04-20 13:12:34.577141\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000274.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 27.7ms pre-process, 169.0ms inference, 10.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9191 \tBbox: [ 0 \t 0 \t 461 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8997 \tBbox: [ 368 \t 711 \t 650 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8877 \tBbox: [ 521 \t 11 \t 601 \t 233 ]\n",
      "4 \tObject: person \tConfidence = 0.8712 \tBbox: [ 509 \t 244 \t 624 \t 532 ]\n",
      "5 \tObject: person \tConfidence = 0.8614 \tBbox: [ 586 \t 0 \t 646 \t 154 ]\n",
      "6 \tObject: person \tConfidence = 0.8509 \tBbox: [ 395 \t 118 \t 469 \t 366 ]\n",
      "7 \tObject: person \tConfidence = 0.8155 \tBbox: [ 449 \t 0 \t 499 \t 121 ]\n",
      "8 \tObject: person \tConfidence = 0.7906 \tBbox: [ 488 \t 0 \t 544 \t 161 ]\n",
      "9 \tObject: person \tConfidence = 0.7409 \tBbox: [ 364 \t 464 \t 503 \t 840 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000275 / 1050\n",
      "Frames to be processed: 775  | To do: 73.81 % | Done: 26.19 %\n",
      "\n",
      "2022-04-20 13:12:35.037675\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000275.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 28.7ms pre-process, 174.7ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9191 \tBbox: [ 0 \t 2 \t 462 \t 1073 ]\n",
      "2 \tObject: person \tConfidence = 0.889 \tBbox: [ 362 \t 713 \t 632 \t 1079 ]\n",
      "3 \tObject: person \tConfidence = 0.8735 \tBbox: [ 586 \t 0 \t 647 \t 155 ]\n",
      "4 \tObject: person \tConfidence = 0.8716 \tBbox: [ 358 \t 462 \t 501 \t 810 ]\n",
      "5 \tObject: person \tConfidence = 0.8706 \tBbox: [ 516 \t 14 \t 601 \t 233 ]\n",
      "6 \tObject: person \tConfidence = 0.8659 \tBbox: [ 510 \t 244 \t 623 \t 532 ]\n",
      "7 \tObject: person \tConfidence = 0.8529 \tBbox: [ 394 \t 118 \t 469 \t 366 ]\n",
      "8 \tObject: person \tConfidence = 0.8375 \tBbox: [ 488 \t 0 \t 543 \t 161 ]\n",
      "9 \tObject: person \tConfidence = 0.8064 \tBbox: [ 449 \t 0 \t 499 \t 122 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000276 / 1050\n",
      "Frames to be processed: 774  | To do: 73.71 % | Done: 26.29 %\n",
      "\n",
      "2022-04-20 13:12:35.476381\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000276.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 30.2ms pre-process, 178.0ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9198 \tBbox: [ 0 \t 2 \t 461 \t 1075 ]\n",
      "2 \tObject: person \tConfidence = 0.8986 \tBbox: [ 358 \t 715 \t 626 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8799 \tBbox: [ 513 \t 13 \t 599 \t 233 ]\n",
      "4 \tObject: person \tConfidence = 0.8791 \tBbox: [ 357 \t 459 \t 499 \t 812 ]\n",
      "5 \tObject: person \tConfidence = 0.8736 \tBbox: [ 586 \t 0 \t 648 \t 155 ]\n",
      "6 \tObject: person \tConfidence = 0.8591 \tBbox: [ 511 \t 244 \t 622 \t 532 ]\n",
      "7 \tObject: person \tConfidence = 0.8487 \tBbox: [ 395 \t 117 \t 469 \t 366 ]\n",
      "8 \tObject: person \tConfidence = 0.8373 \tBbox: [ 487 \t 0 \t 542 \t 161 ]\n",
      "9 \tObject: person \tConfidence = 0.8167 \tBbox: [ 449 \t 0 \t 498 \t 123 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000277 / 1050\n",
      "Frames to be processed: 773  | To do: 73.62 % | Done: 26.38 %\n",
      "\n",
      "2022-04-20 13:12:35.888757\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000277.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 26.9ms pre-process, 169.4ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9228 \tBbox: [ 0 \t 2 \t 461 \t 1075 ]\n",
      "2 \tObject: person \tConfidence = 0.9031 \tBbox: [ 353 \t 715 \t 618 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8854 \tBbox: [ 356 \t 460 \t 501 \t 802 ]\n",
      "4 \tObject: person \tConfidence = 0.8805 \tBbox: [ 512 \t 13 \t 598 \t 233 ]\n",
      "5 \tObject: person \tConfidence = 0.8707 \tBbox: [ 587 \t 0 \t 647 \t 155 ]\n",
      "6 \tObject: person \tConfidence = 0.8536 \tBbox: [ 511 \t 244 \t 621 \t 532 ]\n",
      "7 \tObject: person \tConfidence = 0.8454 \tBbox: [ 487 \t 0 \t 542 \t 161 ]\n",
      "8 \tObject: person \tConfidence = 0.8441 \tBbox: [ 395 \t 117 \t 469 \t 366 ]\n",
      "9 \tObject: person \tConfidence = 0.7871 \tBbox: [ 450 \t 0 \t 498 \t 123 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000278 / 1050\n",
      "Frames to be processed: 772  | To do: 73.52 % | Done: 26.48 %\n",
      "\n",
      "2022-04-20 13:12:36.343514\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000278.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 26.3ms pre-process, 175.2ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9198 \tBbox: [ 0 \t 2 \t 462 \t 1074 ]\n",
      "2 \tObject: person \tConfidence = 0.9162 \tBbox: [ 346 \t 716 \t 616 \t 1079 ]\n",
      "3 \tObject: person \tConfidence = 0.883 \tBbox: [ 512 \t 10 \t 599 \t 234 ]\n",
      "4 \tObject: person \tConfidence = 0.8817 \tBbox: [ 586 \t 0 \t 646 \t 155 ]\n",
      "5 \tObject: person \tConfidence = 0.8607 \tBbox: [ 353 \t 456 \t 490 \t 807 ]\n",
      "6 \tObject: person \tConfidence = 0.8524 \tBbox: [ 511 \t 244 \t 621 \t 532 ]\n",
      "7 \tObject: person \tConfidence = 0.8477 \tBbox: [ 394 \t 117 \t 469 \t 366 ]\n",
      "8 \tObject: person \tConfidence = 0.8467 \tBbox: [ 486 \t 0 \t 541 \t 161 ]\n",
      "9 \tObject: person \tConfidence = 0.7922 \tBbox: [ 451 \t 0 \t 498 \t 123 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000279 / 1050\n",
      "Frames to be processed: 771  | To do: 73.43 % | Done: 26.57 %\n",
      "\n",
      "2022-04-20 13:12:36.804286\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000279.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 25.5ms pre-process, 170.8ms inference, 4.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9254 \tBbox: [ 2 \t 4 \t 464 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.9163 \tBbox: [ 341 \t 717 \t 607 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8853 \tBbox: [ 586 \t 0 \t 646 \t 155 ]\n",
      "4 \tObject: person \tConfidence = 0.8813 \tBbox: [ 350 \t 457 \t 484 \t 804 ]\n",
      "5 \tObject: person \tConfidence = 0.88 \tBbox: [ 513 \t 10 \t 597 \t 233 ]\n",
      "6 \tObject: person \tConfidence = 0.8561 \tBbox: [ 511 \t 244 \t 622 \t 532 ]\n",
      "7 \tObject: person \tConfidence = 0.8552 \tBbox: [ 486 \t 0 \t 540 \t 161 ]\n",
      "8 \tObject: person \tConfidence = 0.8529 \tBbox: [ 394 \t 117 \t 469 \t 366 ]\n",
      "9 \tObject: person \tConfidence = 0.7983 \tBbox: [ 451 \t 0 \t 498 \t 123 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000280 / 1050\n",
      "Frames to be processed: 770  | To do: 73.33 % | Done: 26.67 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:12:37.262555\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000280.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 22.8ms pre-process, 172.9ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9246 \tBbox: [ 2 \t 2 \t 463 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.9017 \tBbox: [ 330 \t 719 \t 595 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8904 \tBbox: [ 349 \t 456 \t 479 \t 799 ]\n",
      "4 \tObject: person \tConfidence = 0.8858 \tBbox: [ 585 \t 0 \t 648 \t 156 ]\n",
      "5 \tObject: person \tConfidence = 0.8825 \tBbox: [ 511 \t 9 \t 593 \t 233 ]\n",
      "6 \tObject: person \tConfidence = 0.8519 \tBbox: [ 512 \t 245 \t 622 \t 533 ]\n",
      "7 \tObject: person \tConfidence = 0.8487 \tBbox: [ 486 \t 0 \t 539 \t 161 ]\n",
      "8 \tObject: person \tConfidence = 0.8478 \tBbox: [ 393 \t 116 \t 467 \t 367 ]\n",
      "9 \tObject: person \tConfidence = 0.811 \tBbox: [ 449 \t 0 \t 498 \t 123 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000281 / 1050\n",
      "Frames to be processed: 769  | To do: 73.24 % | Done: 26.76 %\n",
      "\n",
      "2022-04-20 13:12:37.687633\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000281.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 26.9ms pre-process, 177.9ms inference, 10.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9244 \tBbox: [ 0 \t 2 \t 461 \t 1073 ]\n",
      "2 \tObject: person \tConfidence = 0.9052 \tBbox: [ 324 \t 720 \t 593 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8891 \tBbox: [ 586 \t 0 \t 648 \t 160 ]\n",
      "4 \tObject: person \tConfidence = 0.8864 \tBbox: [ 512 \t 8 \t 591 \t 233 ]\n",
      "5 \tObject: person \tConfidence = 0.8808 \tBbox: [ 349 \t 454 \t 478 \t 801 ]\n",
      "6 \tObject: person \tConfidence = 0.8518 \tBbox: [ 512 \t 245 \t 622 \t 533 ]\n",
      "7 \tObject: person \tConfidence = 0.8496 \tBbox: [ 393 \t 116 \t 467 \t 367 ]\n",
      "8 \tObject: person \tConfidence = 0.8472 \tBbox: [ 486 \t 0 \t 538 \t 160 ]\n",
      "9 \tObject: person \tConfidence = 0.8027 \tBbox: [ 450 \t 0 \t 498 \t 123 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000282 / 1050\n",
      "Frames to be processed: 768  | To do: 73.14 % | Done: 26.86 %\n",
      "\n",
      "2022-04-20 13:12:38.148567\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000282.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 31.0ms pre-process, 170.4ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9224 \tBbox: [ 0 \t 2 \t 460 \t 1074 ]\n",
      "2 \tObject: person \tConfidence = 0.9152 \tBbox: [ 323 \t 720 \t 592 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8849 \tBbox: [ 512 \t 8 \t 590 \t 233 ]\n",
      "4 \tObject: person \tConfidence = 0.8842 \tBbox: [ 586 \t 1 \t 646 \t 160 ]\n",
      "5 \tObject: person \tConfidence = 0.8486 \tBbox: [ 512 \t 244 \t 620 \t 533 ]\n",
      "6 \tObject: person \tConfidence = 0.8478 \tBbox: [ 394 \t 116 \t 466 \t 367 ]\n",
      "7 \tObject: person \tConfidence = 0.842 \tBbox: [ 345 \t 453 \t 476 \t 799 ]\n",
      "8 \tObject: person \tConfidence = 0.8285 \tBbox: [ 486 \t 0 \t 538 \t 161 ]\n",
      "9 \tObject: person \tConfidence = 0.7994 \tBbox: [ 449 \t 0 \t 498 \t 123 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000283 / 1050\n",
      "Frames to be processed: 767  | To do: 73.05 % | Done: 26.95 %\n",
      "\n",
      "2022-04-20 13:12:38.628689\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000283.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 31.6ms pre-process, 173.5ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9181 \tBbox: [ 0 \t 2 \t 461 \t 1074 ]\n",
      "2 \tObject: person \tConfidence = 0.8906 \tBbox: [ 319 \t 720 \t 584 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8903 \tBbox: [ 511 \t 7 \t 588 \t 233 ]\n",
      "4 \tObject: person \tConfidence = 0.887 \tBbox: [ 586 \t 1 \t 646 \t 162 ]\n",
      "5 \tObject: person \tConfidence = 0.8485 \tBbox: [ 393 \t 116 \t 465 \t 367 ]\n",
      "6 \tObject: person \tConfidence = 0.846 \tBbox: [ 513 \t 245 \t 621 \t 533 ]\n",
      "7 \tObject: person \tConfidence = 0.8382 \tBbox: [ 342 \t 453 \t 475 \t 800 ]\n",
      "8 \tObject: person \tConfidence = 0.8245 \tBbox: [ 487 \t 0 \t 538 \t 160 ]\n",
      "9 \tObject: person \tConfidence = 0.8019 \tBbox: [ 448 \t 0 \t 498 \t 123 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000284 / 1050\n",
      "Frames to be processed: 766  | To do: 72.95 % | Done: 27.05 %\n",
      "\n",
      "2022-04-20 13:12:39.066199\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000284.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 25.1ms pre-process, 175.3ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9133 \tBbox: [ 0 \t 2 \t 462 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.9042 \tBbox: [ 314 \t 720 \t 579 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8946 \tBbox: [ 512 \t 6 \t 587 \t 233 ]\n",
      "4 \tObject: person \tConfidence = 0.8886 \tBbox: [ 586 \t 2 \t 644 \t 163 ]\n",
      "5 \tObject: person \tConfidence = 0.8492 \tBbox: [ 393 \t 116 \t 465 \t 367 ]\n",
      "6 \tObject: person \tConfidence = 0.8488 \tBbox: [ 513 \t 244 \t 620 \t 533 ]\n",
      "7 \tObject: person \tConfidence = 0.8451 \tBbox: [ 341 \t 453 \t 474 \t 795 ]\n",
      "8 \tObject: person \tConfidence = 0.8248 \tBbox: [ 487 \t 0 \t 537 \t 160 ]\n",
      "9 \tObject: person \tConfidence = 0.7881 \tBbox: [ 449 \t 0 \t 496 \t 123 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000285 / 1050\n",
      "Frames to be processed: 765  | To do: 72.86 % | Done: 27.14 %\n",
      "\n",
      "2022-04-20 13:12:39.480951\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000285.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 25.1ms pre-process, 175.0ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9012 \tBbox: [ 306 \t 719 \t 571 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.8976 \tBbox: [ 1 \t 3 \t 464 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.8921 \tBbox: [ 512 \t 5 \t 584 \t 234 ]\n",
      "4 \tObject: person \tConfidence = 0.8883 \tBbox: [ 340 \t 453 \t 469 \t 772 ]\n",
      "5 \tObject: person \tConfidence = 0.8717 \tBbox: [ 581 \t 2 \t 648 \t 167 ]\n",
      "6 \tObject: person \tConfidence = 0.8445 \tBbox: [ 393 \t 117 \t 465 \t 367 ]\n",
      "7 \tObject: person \tConfidence = 0.8396 \tBbox: [ 515 \t 245 \t 618 \t 533 ]\n",
      "8 \tObject: person \tConfidence = 0.8298 \tBbox: [ 486 \t 0 \t 538 \t 161 ]\n",
      "9 \tObject: person \tConfidence = 0.7975 \tBbox: [ 448 \t 0 \t 495 \t 123 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000286 / 1050\n",
      "Frames to be processed: 764  | To do: 72.76 % | Done: 27.24 %\n",
      "\n",
      "2022-04-20 13:12:39.961535\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000286.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 27.3ms pre-process, 178.4ms inference, 3.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8925 \tBbox: [ 303 \t 719 \t 569 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.89 \tBbox: [ 576 \t 4 \t 649 \t 176 ]\n",
      "3 \tObject: person \tConfidence = 0.8816 \tBbox: [ 511 \t 4 \t 582 \t 234 ]\n",
      "4 \tObject: person \tConfidence = 0.8757 \tBbox: [ 338 \t 455 \t 468 \t 775 ]\n",
      "5 \tObject: train \tConfidence = 0.8717 \tBbox: [ 0 \t 2 \t 461 \t 1072 ]\n",
      "6 \tObject: person \tConfidence = 0.8422 \tBbox: [ 393 \t 116 \t 464 \t 368 ]\n",
      "7 \tObject: person \tConfidence = 0.8402 \tBbox: [ 515 \t 246 \t 618 \t 533 ]\n",
      "8 \tObject: person \tConfidence = 0.8132 \tBbox: [ 446 \t 0 \t 496 \t 123 ]\n",
      "9 \tObject: person \tConfidence = 0.7952 \tBbox: [ 486 \t 0 \t 537 \t 161 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000287 / 1050\n",
      "Frames to be processed: 763  | To do: 72.67 % | Done: 27.33 %\n",
      "\n",
      "2022-04-20 13:12:40.375525\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000287.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 29.6ms pre-process, 177.0ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8973 \tBbox: [ 576 \t 5 \t 648 \t 175 ]\n",
      "2 \tObject: person \tConfidence = 0.8963 \tBbox: [ 335 \t 467 \t 467 \t 758 ]\n",
      "3 \tObject: person \tConfidence = 0.8786 \tBbox: [ 511 \t 5 \t 580 \t 234 ]\n",
      "4 \tObject: train \tConfidence = 0.8762 \tBbox: [ 2 \t 1 \t 463 \t 1068 ]\n",
      "5 \tObject: person \tConfidence = 0.8728 \tBbox: [ 299 \t 719 \t 565 \t 1078 ]\n",
      "6 \tObject: person \tConfidence = 0.8449 \tBbox: [ 515 \t 247 \t 618 \t 533 ]\n",
      "7 \tObject: person \tConfidence = 0.8422 \tBbox: [ 393 \t 117 \t 463 \t 368 ]\n",
      "8 \tObject: person \tConfidence = 0.7956 \tBbox: [ 448 \t 0 \t 496 \t 123 ]\n",
      "9 \tObject: person \tConfidence = 0.77 \tBbox: [ 486 \t 0 \t 537 \t 161 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000288 / 1050\n",
      "Frames to be processed: 762  | To do: 72.57 % | Done: 27.43 %\n",
      "\n",
      "2022-04-20 13:12:40.846123\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000288.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 25.1ms pre-process, 170.1ms inference, 6.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9067 \tBbox: [ 576 \t 7 \t 648 \t 175 ]\n",
      "2 \tObject: person \tConfidence = 0.9043 \tBbox: [ 294 \t 718 \t 562 \t 1078 ]\n",
      "3 \tObject: train \tConfidence = 0.8978 \tBbox: [ 3 \t 2 \t 466 \t 1068 ]\n",
      "4 \tObject: person \tConfidence = 0.8891 \tBbox: [ 334 \t 471 \t 466 \t 758 ]\n",
      "5 \tObject: person \tConfidence = 0.8754 \tBbox: [ 512 \t 6 \t 579 \t 235 ]\n",
      "6 \tObject: person \tConfidence = 0.8453 \tBbox: [ 515 \t 246 \t 617 \t 533 ]\n",
      "7 \tObject: person \tConfidence = 0.8444 \tBbox: [ 393 \t 117 \t 463 \t 369 ]\n",
      "8 \tObject: person \tConfidence = 0.8035 \tBbox: [ 447 \t 0 \t 495 \t 123 ]\n",
      "9 \tObject: person \tConfidence = 0.7867 \tBbox: [ 486 \t 0 \t 538 \t 160 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000289 / 1050\n",
      "Frames to be processed: 761  | To do: 72.48 % | Done: 27.52 %\n",
      "\n",
      "2022-04-20 13:12:41.286494\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000289.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 28.1ms pre-process, 176.1ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9014 \tBbox: [ 293 \t 717 \t 555 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9014 \tBbox: [ 578 \t 7 \t 649 \t 175 ]\n",
      "3 \tObject: person \tConfidence = 0.8904 \tBbox: [ 334 \t 473 \t 466 \t 754 ]\n",
      "4 \tObject: train \tConfidence = 0.8831 \tBbox: [ 3 \t 2 \t 465 \t 1069 ]\n",
      "5 \tObject: person \tConfidence = 0.8715 \tBbox: [ 510 \t 6 \t 578 \t 235 ]\n",
      "6 \tObject: person \tConfidence = 0.8409 \tBbox: [ 515 \t 246 \t 618 \t 534 ]\n",
      "7 \tObject: person \tConfidence = 0.8405 \tBbox: [ 392 \t 118 \t 462 \t 369 ]\n",
      "8 \tObject: person \tConfidence = 0.8061 \tBbox: [ 448 \t 0 \t 495 \t 124 ]\n",
      "9 \tObject: person \tConfidence = 0.7485 \tBbox: [ 485 \t 0 \t 539 \t 158 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000290 / 1050\n",
      "Frames to be processed: 760  | To do: 72.38 % | Done: 27.62 %\n",
      "\n",
      "2022-04-20 13:12:41.759382\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000290.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 41.4ms pre-process, 181.0ms inference, 10.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8926 \tBbox: [ 579 \t 9 \t 649 \t 176 ]\n",
      "2 \tObject: person \tConfidence = 0.8893 \tBbox: [ 286 \t 715 \t 552 \t 1078 ]\n",
      "3 \tObject: train \tConfidence = 0.879 \tBbox: [ 2 \t 0 \t 465 \t 1072 ]\n",
      "4 \tObject: person \tConfidence = 0.8639 \tBbox: [ 510 \t 7 \t 577 \t 237 ]\n",
      "5 \tObject: person \tConfidence = 0.8512 \tBbox: [ 331 \t 474 \t 464 \t 752 ]\n",
      "6 \tObject: person \tConfidence = 0.8487 \tBbox: [ 392 \t 118 \t 462 \t 369 ]\n",
      "7 \tObject: person \tConfidence = 0.8455 \tBbox: [ 515 \t 245 \t 618 \t 534 ]\n",
      "8 \tObject: person \tConfidence = 0.8318 \tBbox: [ 447 \t 0 \t 496 \t 125 ]\n",
      "9 \tObject: person \tConfidence = 0.7573 \tBbox: [ 485 \t 0 \t 537 \t 157 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000291 / 1050\n",
      "Frames to be processed: 759  | To do: 72.29 % | Done: 27.71 %\n",
      "\n",
      "2022-04-20 13:12:42.222661\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000291.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 24.7ms pre-process, 181.4ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8952 \tBbox: [ 579 \t 9 \t 648 \t 176 ]\n",
      "2 \tObject: person \tConfidence = 0.8832 \tBbox: [ 284 \t 714 \t 552 \t 1078 ]\n",
      "3 \tObject: train \tConfidence = 0.879 \tBbox: [ 2 \t 1 \t 465 \t 1070 ]\n",
      "4 \tObject: person \tConfidence = 0.8601 \tBbox: [ 510 \t 6 \t 575 \t 235 ]\n",
      "5 \tObject: person \tConfidence = 0.8592 \tBbox: [ 331 \t 477 \t 466 \t 746 ]\n",
      "6 \tObject: person \tConfidence = 0.8516 \tBbox: [ 392 \t 118 \t 462 \t 369 ]\n",
      "7 \tObject: person \tConfidence = 0.8479 \tBbox: [ 515 \t 246 \t 618 \t 534 ]\n",
      "8 \tObject: person \tConfidence = 0.8045 \tBbox: [ 446 \t 0 \t 496 \t 125 ]\n",
      "9 \tObject: person \tConfidence = 0.732 \tBbox: [ 485 \t 0 \t 534 \t 157 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000292 / 1050\n",
      "Frames to be processed: 758  | To do: 72.19 % | Done: 27.81 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 26.4ms pre-process, 167.2ms inference, 1.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:12:42.638563\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000292.jpg ------------------------------ \n",
      "\n",
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8907 \tBbox: [ 579 \t 9 \t 648 \t 176 ]\n",
      "2 \tObject: person \tConfidence = 0.8873 \tBbox: [ 281 \t 713 \t 553 \t 1078 ]\n",
      "3 \tObject: train \tConfidence = 0.8816 \tBbox: [ 0 \t 2 \t 463 \t 1072 ]\n",
      "4 \tObject: person \tConfidence = 0.8586 \tBbox: [ 510 \t 6 \t 575 \t 235 ]\n",
      "5 \tObject: person \tConfidence = 0.856 \tBbox: [ 392 \t 118 \t 462 \t 369 ]\n",
      "6 \tObject: person \tConfidence = 0.8488 \tBbox: [ 330 \t 478 \t 465 \t 754 ]\n",
      "7 \tObject: person \tConfidence = 0.8486 \tBbox: [ 515 \t 245 \t 620 \t 534 ]\n",
      "8 \tObject: person \tConfidence = 0.8093 \tBbox: [ 446 \t 0 \t 496 \t 125 ]\n",
      "9 \tObject: person \tConfidence = 0.7379 \tBbox: [ 485 \t 0 \t 533 \t 156 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000293 / 1050\n",
      "Frames to be processed: 757  | To do: 72.1 % | Done: 27.9 %\n",
      "\n",
      "2022-04-20 13:12:43.072557\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000293.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 27.4ms pre-process, 173.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8944 \tBbox: [ 580 \t 10 \t 648 \t 176 ]\n",
      "2 \tObject: train \tConfidence = 0.8917 \tBbox: [ 0 \t 2 \t 463 \t 1072 ]\n",
      "3 \tObject: person \tConfidence = 0.8749 \tBbox: [ 280 \t 712 \t 548 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8544 \tBbox: [ 392 \t 118 \t 462 \t 369 ]\n",
      "5 \tObject: person \tConfidence = 0.8494 \tBbox: [ 510 \t 10 \t 573 \t 235 ]\n",
      "6 \tObject: person \tConfidence = 0.8482 \tBbox: [ 328 \t 477 \t 464 \t 788 ]\n",
      "7 \tObject: person \tConfidence = 0.8425 \tBbox: [ 515 \t 245 \t 620 \t 535 ]\n",
      "8 \tObject: person \tConfidence = 0.8047 \tBbox: [ 446 \t 0 \t 495 \t 125 ]\n",
      "9 \tObject: person \tConfidence = 0.764 \tBbox: [ 484 \t 1 \t 531 \t 159 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000294 / 1050\n",
      "Frames to be processed: 756  | To do: 72.0 % | Done: 28.0 %\n",
      "\n",
      "2022-04-20 13:12:43.538038\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000294.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 28.7ms pre-process, 168.8ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8929 \tBbox: [ 3 \t 2 \t 465 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8885 \tBbox: [ 278 \t 711 \t 551 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8873 \tBbox: [ 580 \t 11 \t 648 \t 177 ]\n",
      "4 \tObject: person \tConfidence = 0.8599 \tBbox: [ 328 \t 477 \t 467 \t 789 ]\n",
      "5 \tObject: person \tConfidence = 0.8553 \tBbox: [ 392 \t 118 \t 462 \t 369 ]\n",
      "6 \tObject: person \tConfidence = 0.8542 \tBbox: [ 515 \t 244 \t 621 \t 535 ]\n",
      "7 \tObject: person \tConfidence = 0.8428 \tBbox: [ 510 \t 9 \t 571 \t 234 ]\n",
      "8 \tObject: person \tConfidence = 0.7782 \tBbox: [ 447 \t 0 \t 494 \t 126 ]\n",
      "9 \tObject: person \tConfidence = 0.7062 \tBbox: [ 484 \t 0 \t 531 \t 155 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000295 / 1050\n",
      "Frames to be processed: 755  | To do: 71.9 % | Done: 28.1 %\n",
      "\n",
      "2022-04-20 13:12:43.967675\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000295.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 33.1ms pre-process, 175.0ms inference, 3.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9006 \tBbox: [ 3 \t 3 \t 464 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.8989 \tBbox: [ 580 \t 15 \t 648 \t 183 ]\n",
      "3 \tObject: person \tConfidence = 0.8885 \tBbox: [ 278 \t 709 \t 547 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8642 \tBbox: [ 326 \t 478 \t 465 \t 775 ]\n",
      "5 \tObject: person \tConfidence = 0.855 \tBbox: [ 392 \t 119 \t 462 \t 370 ]\n",
      "6 \tObject: person \tConfidence = 0.8486 \tBbox: [ 515 \t 243 \t 621 \t 535 ]\n",
      "7 \tObject: person \tConfidence = 0.8247 \tBbox: [ 511 \t 2 \t 569 \t 229 ]\n",
      "8 \tObject: person \tConfidence = 0.7515 \tBbox: [ 447 \t 0 \t 495 \t 126 ]\n",
      "9 \tObject: person \tConfidence = 0.6805 \tBbox: [ 483 \t 0 \t 530 \t 154 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000296 / 1050\n",
      "Frames to be processed: 754  | To do: 71.81 % | Done: 28.19 %\n",
      "\n",
      "2022-04-20 13:12:44.442330\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000296.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 28.8ms pre-process, 181.0ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9042 \tBbox: [ 2 \t 3 \t 465 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.8984 \tBbox: [ 580 \t 17 \t 647 \t 184 ]\n",
      "3 \tObject: person \tConfidence = 0.8834 \tBbox: [ 279 \t 707 \t 545 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.8687 \tBbox: [ 326 \t 481 \t 465 \t 755 ]\n",
      "5 \tObject: person \tConfidence = 0.8563 \tBbox: [ 392 \t 119 \t 462 \t 370 ]\n",
      "6 \tObject: person \tConfidence = 0.8486 \tBbox: [ 514 \t 243 \t 618 \t 535 ]\n",
      "7 \tObject: person \tConfidence = 0.8272 \tBbox: [ 513 \t 2 \t 567 \t 233 ]\n",
      "8 \tObject: person \tConfidence = 0.7331 \tBbox: [ 447 \t 0 \t 495 \t 127 ]\n",
      "9 \tObject: person \tConfidence = 0.7053 \tBbox: [ 483 \t 0 \t 530 \t 160 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000297 / 1050\n",
      "Frames to be processed: 753  | To do: 71.71 % | Done: 28.29 %\n",
      "\n",
      "2022-04-20 13:12:44.942663\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000297.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 48.7ms pre-process, 172.5ms inference, 4.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9111 \tBbox: [ 2 \t 3 \t 464 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.9035 \tBbox: [ 580 \t 18 \t 647 \t 184 ]\n",
      "3 \tObject: person \tConfidence = 0.8731 \tBbox: [ 326 \t 481 \t 465 \t 762 ]\n",
      "4 \tObject: person \tConfidence = 0.8559 \tBbox: [ 391 \t 119 \t 462 \t 370 ]\n",
      "5 \tObject: person \tConfidence = 0.8517 \tBbox: [ 279 \t 705 \t 540 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.8441 \tBbox: [ 512 \t 242 \t 617 \t 535 ]\n",
      "7 \tObject: person \tConfidence = 0.8019 \tBbox: [ 512 \t 2 \t 567 \t 231 ]\n",
      "8 \tObject: person \tConfidence = 0.7429 \tBbox: [ 447 \t 0 \t 496 \t 126 ]\n",
      "9 \tObject: person \tConfidence = 0.6776 \tBbox: [ 483 \t 0 \t 529 \t 159 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000298 / 1050\n",
      "Frames to be processed: 752  | To do: 71.62 % | Done: 28.38 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 24.6ms pre-process, 168.5ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:12:45.419893\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000298.jpg ------------------------------ \n",
      "\n",
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9086 \tBbox: [ 2 \t 2 \t 462 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8939 \tBbox: [ 580 \t 21 \t 646 \t 187 ]\n",
      "3 \tObject: person \tConfidence = 0.8732 \tBbox: [ 326 \t 481 \t 465 \t 754 ]\n",
      "4 \tObject: person \tConfidence = 0.858 \tBbox: [ 391 \t 119 \t 462 \t 371 ]\n",
      "5 \tObject: person \tConfidence = 0.8479 \tBbox: [ 509 \t 242 \t 615 \t 535 ]\n",
      "6 \tObject: person \tConfidence = 0.7913 \tBbox: [ 284 \t 703 \t 537 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.7658 \tBbox: [ 511 \t 2 \t 566 \t 230 ]\n",
      "8 \tObject: person \tConfidence = 0.7586 \tBbox: [ 448 \t 0 \t 495 \t 126 ]\n",
      "9 \tObject: person \tConfidence = 0.6368 \tBbox: [ 482 \t 0 \t 530 \t 153 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000299 / 1050\n",
      "Frames to be processed: 751  | To do: 71.52 % | Done: 28.48 %\n",
      "\n",
      "2022-04-20 13:12:45.914058\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000299.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 25.5ms pre-process, 175.8ms inference, 10.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8946 \tBbox: [ 3 \t 2 \t 464 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.8917 \tBbox: [ 579 \t 24 \t 646 \t 193 ]\n",
      "3 \tObject: person \tConfidence = 0.8764 \tBbox: [ 325 \t 480 \t 464 \t 751 ]\n",
      "4 \tObject: person \tConfidence = 0.8569 \tBbox: [ 391 \t 120 \t 462 \t 371 ]\n",
      "5 \tObject: person \tConfidence = 0.8487 \tBbox: [ 285 \t 701 \t 531 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.8301 \tBbox: [ 507 \t 242 \t 615 \t 535 ]\n",
      "7 \tObject: person \tConfidence = 0.7676 \tBbox: [ 509 \t 4 \t 565 \t 233 ]\n",
      "8 \tObject: person \tConfidence = 0.7217 \tBbox: [ 448 \t 0 \t 496 \t 126 ]\n",
      "9 \tObject: person \tConfidence = 0.5901 \tBbox: [ 481 \t 0 \t 530 \t 152 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000300 / 1050\n",
      "Frames to be processed: 750  | To do: 71.43 % | Done: 28.57 %\n",
      "\n",
      "2022-04-20 13:12:46.390276\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000300.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 26.4ms pre-process, 177.3ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9066 \tBbox: [ 2 \t 4 \t 464 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.9015 \tBbox: [ 579 \t 27 \t 646 \t 198 ]\n",
      "3 \tObject: person \tConfidence = 0.8664 \tBbox: [ 293 \t 697 \t 522 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8645 \tBbox: [ 326 \t 481 \t 464 \t 745 ]\n",
      "5 \tObject: person \tConfidence = 0.852 \tBbox: [ 391 \t 119 \t 461 \t 371 ]\n",
      "6 \tObject: person \tConfidence = 0.8191 \tBbox: [ 508 \t 241 \t 617 \t 535 ]\n",
      "7 \tObject: person \tConfidence = 0.7241 \tBbox: [ 448 \t 0 \t 496 \t 127 ]\n",
      "8 \tObject: person \tConfidence = 0.7078 \tBbox: [ 492 \t 3 \t 563 \t 235 ]\n",
      "9 \tObject: person \tConfidence = 0.4397 \tBbox: [ 480 \t 0 \t 539 \t 149 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000301 / 1050\n",
      "Frames to be processed: 749  | To do: 71.33 % | Done: 28.67 %\n",
      "\n",
      "2022-04-20 13:12:46.828413\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000301.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 25.4ms pre-process, 179.5ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9087 \tBbox: [ 0 \t 0 \t 462 \t 1074 ]\n",
      "2 \tObject: person \tConfidence = 0.9024 \tBbox: [ 578 \t 26 \t 646 \t 198 ]\n",
      "3 \tObject: person \tConfidence = 0.8833 \tBbox: [ 292 \t 693 \t 515 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8514 \tBbox: [ 391 \t 119 \t 461 \t 371 ]\n",
      "5 \tObject: person \tConfidence = 0.8513 \tBbox: [ 325 \t 482 \t 464 \t 745 ]\n",
      "6 \tObject: person \tConfidence = 0.8429 \tBbox: [ 510 \t 241 \t 615 \t 536 ]\n",
      "7 \tObject: person \tConfidence = 0.7371 \tBbox: [ 447 \t 0 \t 496 \t 128 ]\n",
      "8 \tObject: person \tConfidence = 0.634 \tBbox: [ 482 \t 0 \t 562 \t 231 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000302 / 1050\n",
      "Frames to be processed: 748  | To do: 71.24 % | Done: 28.76 %\n",
      "\n",
      "2022-04-20 13:12:47.283777\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000302.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 28.4ms pre-process, 173.3ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9038 \tBbox: [ 578 \t 25 \t 646 \t 200 ]\n",
      "2 \tObject: person \tConfidence = 0.8886 \tBbox: [ 298 \t 691 \t 511 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8807 \tBbox: [ 326 \t 483 \t 464 \t 718 ]\n",
      "4 \tObject: train \tConfidence = 0.878 \tBbox: [ 3 \t 2 \t 462 \t 1068 ]\n",
      "5 \tObject: person \tConfidence = 0.853 \tBbox: [ 391 \t 119 \t 461 \t 371 ]\n",
      "6 \tObject: person \tConfidence = 0.8324 \tBbox: [ 521 \t 241 \t 618 \t 536 ]\n",
      "7 \tObject: person \tConfidence = 0.7461 \tBbox: [ 476 \t 0 \t 561 \t 233 ]\n",
      "8 \tObject: person \tConfidence = 0.7309 \tBbox: [ 448 \t 0 \t 494 \t 129 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000303 / 1050\n",
      "Frames to be processed: 747  | To do: 71.14 % | Done: 28.86 %\n",
      "\n",
      "2022-04-20 13:12:47.780065\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000303.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 27.6ms pre-process, 175.7ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9049 \tBbox: [ 578 \t 26 \t 647 \t 198 ]\n",
      "2 \tObject: train \tConfidence = 0.9036 \tBbox: [ 3 \t 1 \t 462 \t 1069 ]\n",
      "3 \tObject: person \tConfidence = 0.8969 \tBbox: [ 296 \t 687 \t 509 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8653 \tBbox: [ 325 \t 483 \t 464 \t 717 ]\n",
      "5 \tObject: person \tConfidence = 0.8486 \tBbox: [ 527 \t 242 \t 623 \t 536 ]\n",
      "6 \tObject: person \tConfidence = 0.8453 \tBbox: [ 391 \t 120 \t 461 \t 371 ]\n",
      "7 \tObject: person \tConfidence = 0.7617 \tBbox: [ 448 \t 0 \t 494 \t 130 ]\n",
      "8 \tObject: person \tConfidence = 0.7457 \tBbox: [ 471 \t 0 \t 560 \t 232 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000304 / 1050\n",
      "Frames to be processed: 746  | To do: 71.05 % | Done: 28.95 %\n",
      "\n",
      "2022-04-20 13:12:48.285744\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000304.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 43.6ms pre-process, 177.9ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9059 \tBbox: [ 297 \t 685 \t 507 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8977 \tBbox: [ 577 \t 26 \t 647 \t 197 ]\n",
      "3 \tObject: train \tConfidence = 0.8961 \tBbox: [ 3 \t 0 \t 461 \t 1070 ]\n",
      "4 \tObject: person \tConfidence = 0.876 \tBbox: [ 325 \t 483 \t 464 \t 711 ]\n",
      "5 \tObject: person \tConfidence = 0.8439 \tBbox: [ 391 \t 120 \t 461 \t 371 ]\n",
      "6 \tObject: person \tConfidence = 0.8407 \tBbox: [ 528 \t 242 \t 619 \t 536 ]\n",
      "7 \tObject: person \tConfidence = 0.8025 \tBbox: [ 447 \t 0 \t 494 \t 131 ]\n",
      "8 \tObject: person \tConfidence = 0.7979 \tBbox: [ 483 \t 1 \t 559 \t 233 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000305 / 1050\n",
      "Frames to be processed: 745  | To do: 70.95 % | Done: 29.05 %\n",
      "\n",
      "2022-04-20 13:12:48.787500\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000305.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 25.8ms pre-process, 173.0ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9085 \tBbox: [ 2 \t 2 \t 463 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.8927 \tBbox: [ 295 \t 678 \t 502 \t 1079 ]\n",
      "3 \tObject: person \tConfidence = 0.8915 \tBbox: [ 577 \t 25 \t 646 \t 198 ]\n",
      "4 \tObject: person \tConfidence = 0.8888 \tBbox: [ 325 \t 484 \t 463 \t 706 ]\n",
      "5 \tObject: person \tConfidence = 0.8494 \tBbox: [ 527 \t 242 \t 614 \t 536 ]\n",
      "6 \tObject: person \tConfidence = 0.8443 \tBbox: [ 391 \t 120 \t 461 \t 371 ]\n",
      "7 \tObject: person \tConfidence = 0.8163 \tBbox: [ 483 \t 1 \t 557 \t 234 ]\n",
      "8 \tObject: person \tConfidence = 0.7932 \tBbox: [ 446 \t 0 \t 495 \t 131 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000306 / 1050\n",
      "Frames to be processed: 744  | To do: 70.86 % | Done: 29.14 %\n",
      "\n",
      "2022-04-20 13:12:49.308073\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000306.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 47.7ms pre-process, 180.1ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9163 \tBbox: [ 0 \t 0 \t 459 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.8979 \tBbox: [ 297 \t 677 \t 500 \t 1079 ]\n",
      "3 \tObject: person \tConfidence = 0.8912 \tBbox: [ 577 \t 25 \t 644 \t 200 ]\n",
      "4 \tObject: person \tConfidence = 0.8844 \tBbox: [ 325 \t 484 \t 463 \t 708 ]\n",
      "5 \tObject: person \tConfidence = 0.8527 \tBbox: [ 525 \t 242 \t 613 \t 536 ]\n",
      "6 \tObject: person \tConfidence = 0.8351 \tBbox: [ 484 \t 0 \t 558 \t 233 ]\n",
      "7 \tObject: person \tConfidence = 0.8263 \tBbox: [ 392 \t 120 \t 461 \t 372 ]\n",
      "8 \tObject: person \tConfidence = 0.7983 \tBbox: [ 446 \t 0 \t 498 \t 131 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000307 / 1050\n",
      "Frames to be processed: 743  | To do: 70.76 % | Done: 29.24 %\n",
      "\n",
      "2022-04-20 13:12:49.825383\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000307.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 24.1ms pre-process, 172.2ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9145 \tBbox: [ 0 \t 1 \t 460 \t 1073 ]\n",
      "2 \tObject: person \tConfidence = 0.8944 \tBbox: [ 577 \t 27 \t 644 \t 205 ]\n",
      "3 \tObject: person \tConfidence = 0.8793 \tBbox: [ 325 \t 484 \t 463 \t 709 ]\n",
      "4 \tObject: person \tConfidence = 0.8671 \tBbox: [ 293 \t 673 \t 498 \t 1079 ]\n",
      "5 \tObject: person \tConfidence = 0.8579 \tBbox: [ 525 \t 242 \t 614 \t 536 ]\n",
      "6 \tObject: person \tConfidence = 0.8498 \tBbox: [ 483 \t 0 \t 557 \t 233 ]\n",
      "7 \tObject: person \tConfidence = 0.8373 \tBbox: [ 391 \t 120 \t 461 \t 373 ]\n",
      "8 \tObject: person \tConfidence = 0.7945 \tBbox: [ 447 \t 0 \t 496 \t 132 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000308 / 1050\n",
      "Frames to be processed: 742  | To do: 70.67 % | Done: 29.33 %\n",
      "\n",
      "2022-04-20 13:12:50.270387\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000308.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 29.5ms pre-process, 174.8ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8856 \tBbox: [ 578 \t 28 \t 644 \t 205 ]\n",
      "2 \tObject: person \tConfidence = 0.8762 \tBbox: [ 325 \t 484 \t 463 \t 712 ]\n",
      "3 \tObject: person \tConfidence = 0.8707 \tBbox: [ 483 \t 0 \t 556 \t 234 ]\n",
      "4 \tObject: person \tConfidence = 0.8525 \tBbox: [ 525 \t 242 \t 616 \t 537 ]\n",
      "5 \tObject: person \tConfidence = 0.8371 \tBbox: [ 391 \t 121 \t 461 \t 373 ]\n",
      "6 \tObject: person \tConfidence = 0.831 \tBbox: [ 290 \t 670 \t 495 \t 1079 ]\n",
      "7 \tObject: train \tConfidence = 0.8273 \tBbox: [ 0 \t 3 \t 462 \t 856 ]\n",
      "8 \tObject: person \tConfidence = 0.7871 \tBbox: [ 447 \t 0 \t 496 \t 131 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000309 / 1050\n",
      "Frames to be processed: 741  | To do: 70.57 % | Done: 29.43 %\n",
      "\n",
      "2022-04-20 13:12:50.740942\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000309.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 28.7ms pre-process, 180.7ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8835 \tBbox: [ 481 \t 0 \t 554 \t 234 ]\n",
      "2 \tObject: person \tConfidence = 0.8751 \tBbox: [ 578 \t 30 \t 642 \t 209 ]\n",
      "3 \tObject: person \tConfidence = 0.8746 \tBbox: [ 324 \t 484 \t 463 \t 713 ]\n",
      "4 \tObject: person \tConfidence = 0.8539 \tBbox: [ 525 \t 242 \t 617 \t 537 ]\n",
      "5 \tObject: person \tConfidence = 0.8441 \tBbox: [ 391 \t 121 \t 462 \t 373 ]\n",
      "6 \tObject: train \tConfidence = 0.8163 \tBbox: [ 0 \t 4 \t 462 \t 885 ]\n",
      "7 \tObject: person \tConfidence = 0.8148 \tBbox: [ 447 \t 0 \t 495 \t 131 ]\n",
      "8 \tObject: person \tConfidence = 0.7154 \tBbox: [ 286 \t 667 \t 493 \t 1079 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000310 / 1050\n",
      "Frames to be processed: 740  | To do: 70.48 % | Done: 29.52 %\n",
      "\n",
      "2022-04-20 13:12:51.163871\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000310.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 23.7ms pre-process, 180.9ms inference, 4.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8951 \tBbox: [ 0 \t 4 \t 460 \t 998 ]\n",
      "2 \tObject: person \tConfidence = 0.8879 \tBbox: [ 578 \t 36 \t 650 \t 214 ]\n",
      "3 \tObject: person \tConfidence = 0.884 \tBbox: [ 322 \t 484 \t 462 \t 714 ]\n",
      "4 \tObject: person \tConfidence = 0.8838 \tBbox: [ 480 \t 0 \t 554 \t 232 ]\n",
      "5 \tObject: person \tConfidence = 0.8483 \tBbox: [ 391 \t 120 \t 462 \t 373 ]\n",
      "6 \tObject: person \tConfidence = 0.8432 \tBbox: [ 527 \t 243 \t 617 \t 537 ]\n",
      "7 \tObject: person \tConfidence = 0.8387 \tBbox: [ 287 \t 663 \t 489 \t 1078 ]\n",
      "8 \tObject: person \tConfidence = 0.7939 \tBbox: [ 447 \t 0 \t 494 \t 130 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000311 / 1050\n",
      "Frames to be processed: 739  | To do: 70.38 % | Done: 29.62 %\n",
      "\n",
      "2022-04-20 13:12:51.635064\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000311.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 25.5ms pre-process, 180.8ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.887 \tBbox: [ 321 \t 483 \t 461 \t 713 ]\n",
      "2 \tObject: person \tConfidence = 0.8817 \tBbox: [ 579 \t 37 \t 651 \t 217 ]\n",
      "3 \tObject: train \tConfidence = 0.8661 \tBbox: [ 0 \t 3 \t 462 \t 1049 ]\n",
      "4 \tObject: person \tConfidence = 0.8613 \tBbox: [ 481 \t 0 \t 552 \t 231 ]\n",
      "5 \tObject: person \tConfidence = 0.8538 \tBbox: [ 283 \t 661 \t 487 \t 1078 ]\n",
      "6 \tObject: person \tConfidence = 0.8484 \tBbox: [ 392 \t 120 \t 463 \t 373 ]\n",
      "7 \tObject: person \tConfidence = 0.8406 \tBbox: [ 527 \t 243 \t 616 \t 537 ]\n",
      "8 \tObject: person \tConfidence = 0.8004 \tBbox: [ 447 \t 0 \t 494 \t 131 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000312 / 1050\n",
      "Frames to be processed: 738  | To do: 70.29 % | Done: 29.71 %\n",
      "\n",
      "2022-04-20 13:12:52.095887\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000312.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 24.3ms pre-process, 179.7ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8919 \tBbox: [ 321 \t 482 \t 460 \t 712 ]\n",
      "2 \tObject: person \tConfidence = 0.8907 \tBbox: [ 580 \t 39 \t 652 \t 221 ]\n",
      "3 \tObject: person \tConfidence = 0.8699 \tBbox: [ 481 \t 0 \t 552 \t 232 ]\n",
      "4 \tObject: person \tConfidence = 0.859 \tBbox: [ 277 \t 659 \t 486 \t 1078 ]\n",
      "5 \tObject: person \tConfidence = 0.8461 \tBbox: [ 392 \t 121 \t 463 \t 374 ]\n",
      "6 \tObject: train \tConfidence = 0.8438 \tBbox: [ 0 \t 2 \t 464 \t 1071 ]\n",
      "7 \tObject: person \tConfidence = 0.8404 \tBbox: [ 526 \t 242 \t 614 \t 538 ]\n",
      "8 \tObject: person \tConfidence = 0.7696 \tBbox: [ 448 \t 0 \t 494 \t 130 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000313 / 1050\n",
      "Frames to be processed: 737  | To do: 70.19 % | Done: 29.81 %\n",
      "\n",
      "2022-04-20 13:12:52.496862\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000313.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 25.7ms pre-process, 178.2ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9003 \tBbox: [ 580 \t 39 \t 654 \t 225 ]\n",
      "2 \tObject: person \tConfidence = 0.8904 \tBbox: [ 321 \t 483 \t 459 \t 709 ]\n",
      "3 \tObject: person \tConfidence = 0.8738 \tBbox: [ 481 \t 1 \t 551 \t 233 ]\n",
      "4 \tObject: train \tConfidence = 0.858 \tBbox: [ 0 \t 1 \t 465 \t 1071 ]\n",
      "5 \tObject: person \tConfidence = 0.854 \tBbox: [ 279 \t 657 \t 483 \t 1078 ]\n",
      "6 \tObject: person \tConfidence = 0.8442 \tBbox: [ 392 \t 121 \t 463 \t 374 ]\n",
      "7 \tObject: person \tConfidence = 0.8435 \tBbox: [ 526 \t 242 \t 613 \t 538 ]\n",
      "8 \tObject: person \tConfidence = 0.7779 \tBbox: [ 447 \t 0 \t 493 \t 130 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000314 / 1050\n",
      "Frames to be processed: 736  | To do: 70.1 % | Done: 29.9 %\n",
      "\n",
      "2022-04-20 13:12:52.916062\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000314.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 28.1ms pre-process, 178.6ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8959 \tBbox: [ 580 \t 41 \t 654 \t 227 ]\n",
      "2 \tObject: person \tConfidence = 0.8749 \tBbox: [ 322 \t 482 \t 458 \t 708 ]\n",
      "3 \tObject: person \tConfidence = 0.8658 \tBbox: [ 481 \t 0 \t 551 \t 235 ]\n",
      "4 \tObject: person \tConfidence = 0.8508 \tBbox: [ 526 \t 243 \t 612 \t 538 ]\n",
      "5 \tObject: person \tConfidence = 0.8455 \tBbox: [ 392 \t 121 \t 463 \t 374 ]\n",
      "6 \tObject: person \tConfidence = 0.8072 \tBbox: [ 277 \t 655 \t 481 \t 1078 ]\n",
      "7 \tObject: train \tConfidence = 0.7963 \tBbox: [ 0 \t 1 \t 464 \t 1071 ]\n",
      "8 \tObject: person \tConfidence = 0.7638 \tBbox: [ 448 \t 0 \t 493 \t 130 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000315 / 1050\n",
      "Frames to be processed: 735  | To do: 70.0 % | Done: 30.0 %\n",
      "\n",
      "2022-04-20 13:12:53.362772\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000315.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 26.3ms pre-process, 171.5ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8954 \tBbox: [ 581 \t 41 \t 656 \t 227 ]\n",
      "2 \tObject: person \tConfidence = 0.8759 \tBbox: [ 481 \t 0 \t 549 \t 235 ]\n",
      "3 \tObject: person \tConfidence = 0.8562 \tBbox: [ 526 \t 243 \t 611 \t 538 ]\n",
      "4 \tObject: person \tConfidence = 0.8471 \tBbox: [ 392 \t 121 \t 463 \t 374 ]\n",
      "5 \tObject: person \tConfidence = 0.8361 \tBbox: [ 318 \t 482 \t 458 \t 707 ]\n",
      "6 \tObject: person \tConfidence = 0.8338 \tBbox: [ 277 \t 652 \t 478 \t 1078 ]\n",
      "7 \tObject: person \tConfidence = 0.7748 \tBbox: [ 448 \t 0 \t 491 \t 131 ]\n",
      "8 \tObject: train \tConfidence = 0.5675 \tBbox: [ 0 \t 2 \t 463 \t 1069 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000316 / 1050\n",
      "Frames to be processed: 734  | To do: 69.9 % | Done: 30.1 %\n",
      "\n",
      "2022-04-20 13:12:53.795917\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000316.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 41.0ms pre-process, 175.7ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9033 \tBbox: [ 581 \t 42 \t 656 \t 228 ]\n",
      "2 \tObject: person \tConfidence = 0.8754 \tBbox: [ 482 \t 0 \t 548 \t 235 ]\n",
      "3 \tObject: person \tConfidence = 0.8576 \tBbox: [ 319 \t 482 \t 458 \t 708 ]\n",
      "4 \tObject: person \tConfidence = 0.8568 \tBbox: [ 526 \t 243 \t 611 \t 539 ]\n",
      "5 \tObject: person \tConfidence = 0.8546 \tBbox: [ 391 \t 121 \t 463 \t 374 ]\n",
      "6 \tObject: person \tConfidence = 0.8496 \tBbox: [ 274 \t 651 \t 476 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.8091 \tBbox: [ 447 \t 0 \t 492 \t 131 ]\n",
      "8 \tObject: train \tConfidence = 0.6549 \tBbox: [ 0 \t 2 \t 464 \t 1063 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000317 / 1050\n",
      "Frames to be processed: 733  | To do: 69.81 % | Done: 30.19 %\n",
      "\n",
      "2022-04-20 13:12:54.245736\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000317.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 26.1ms pre-process, 180.6ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9044 \tBbox: [ 579 \t 41 \t 656 \t 227 ]\n",
      "2 \tObject: person \tConfidence = 0.8742 \tBbox: [ 482 \t 0 \t 547 \t 236 ]\n",
      "3 \tObject: person \tConfidence = 0.858 \tBbox: [ 391 \t 121 \t 463 \t 374 ]\n",
      "4 \tObject: person \tConfidence = 0.8559 \tBbox: [ 526 \t 243 \t 611 \t 539 ]\n",
      "5 \tObject: person \tConfidence = 0.8413 \tBbox: [ 320 \t 481 \t 458 \t 708 ]\n",
      "6 \tObject: person \tConfidence = 0.8326 \tBbox: [ 274 \t 649 \t 475 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.7941 \tBbox: [ 447 \t 0 \t 492 \t 129 ]\n",
      "8 \tObject: train \tConfidence = 0.7136 \tBbox: [ 0 \t 0 \t 463 \t 1056 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000318 / 1050\n",
      "Frames to be processed: 732  | To do: 69.71 % | Done: 30.29 %\n",
      "\n",
      "2022-04-20 13:12:54.704530\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000318.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 31.1ms pre-process, 173.5ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9087 \tBbox: [ 578 \t 41 \t 656 \t 226 ]\n",
      "2 \tObject: person \tConfidence = 0.8689 \tBbox: [ 483 \t 0 \t 547 \t 235 ]\n",
      "3 \tObject: person \tConfidence = 0.8597 \tBbox: [ 526 \t 243 \t 612 \t 539 ]\n",
      "4 \tObject: person \tConfidence = 0.8595 \tBbox: [ 390 \t 121 \t 463 \t 374 ]\n",
      "5 \tObject: person \tConfidence = 0.8422 \tBbox: [ 321 \t 481 \t 457 \t 707 ]\n",
      "6 \tObject: train \tConfidence = 0.815 \tBbox: [ 0 \t 1 \t 466 \t 1067 ]\n",
      "7 \tObject: person \tConfidence = 0.7683 \tBbox: [ 447 \t 0 \t 489 \t 132 ]\n",
      "8 \tObject: person \tConfidence = 0.7622 \tBbox: [ 251 \t 647 \t 474 \t 1078 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000319 / 1050\n",
      "Frames to be processed: 731  | To do: 69.62 % | Done: 30.38 %\n",
      "\n",
      "2022-04-20 13:12:55.173498\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000319.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 28.3ms pre-process, 175.0ms inference, 4.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9107 \tBbox: [ 576 \t 41 \t 656 \t 227 ]\n",
      "2 \tObject: person \tConfidence = 0.8646 \tBbox: [ 483 \t 1 \t 546 \t 234 ]\n",
      "3 \tObject: train \tConfidence = 0.8602 \tBbox: [ 0 \t 0 \t 464 \t 1066 ]\n",
      "4 \tObject: person \tConfidence = 0.857 \tBbox: [ 390 \t 122 \t 463 \t 374 ]\n",
      "5 \tObject: person \tConfidence = 0.8557 \tBbox: [ 526 \t 243 \t 612 \t 539 ]\n",
      "6 \tObject: person \tConfidence = 0.8402 \tBbox: [ 320 \t 480 \t 457 \t 706 ]\n",
      "7 \tObject: person \tConfidence = 0.8089 \tBbox: [ 271 \t 646 \t 472 \t 1078 ]\n",
      "8 \tObject: person \tConfidence = 0.7506 \tBbox: [ 448 \t 0 \t 490 \t 133 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000320 / 1050\n",
      "Frames to be processed: 730  | To do: 69.52 % | Done: 30.48 %\n",
      "\n",
      "2022-04-20 13:12:55.640840\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000320.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 23.5ms pre-process, 177.8ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9043 \tBbox: [ 574 \t 44 \t 654 \t 231 ]\n",
      "2 \tObject: train \tConfidence = 0.8815 \tBbox: [ 0 \t 2 \t 463 \t 1068 ]\n",
      "3 \tObject: person \tConfidence = 0.8636 \tBbox: [ 480 \t 0 \t 546 \t 235 ]\n",
      "4 \tObject: person \tConfidence = 0.8568 \tBbox: [ 391 \t 122 \t 463 \t 374 ]\n",
      "5 \tObject: person \tConfidence = 0.8557 \tBbox: [ 526 \t 243 \t 613 \t 540 ]\n",
      "6 \tObject: person \tConfidence = 0.796 \tBbox: [ 322 \t 480 \t 456 \t 708 ]\n",
      "7 \tObject: person \tConfidence = 0.7389 \tBbox: [ 448 \t 0 \t 493 \t 132 ]\n",
      "8 \tObject: person \tConfidence = 0.735 \tBbox: [ 272 \t 643 \t 470 \t 1078 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000321 / 1050\n",
      "Frames to be processed: 729  | To do: 69.43 % | Done: 30.57 %\n",
      "\n",
      "2022-04-20 13:12:56.087172\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000321.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 24.9ms pre-process, 176.1ms inference, 10.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9052 \tBbox: [ 2 \t 1 \t 464 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.9042 \tBbox: [ 574 \t 45 \t 654 \t 235 ]\n",
      "3 \tObject: person \tConfidence = 0.8675 \tBbox: [ 480 \t 0 \t 545 \t 236 ]\n",
      "4 \tObject: person \tConfidence = 0.8588 \tBbox: [ 322 \t 480 \t 456 \t 710 ]\n",
      "5 \tObject: person \tConfidence = 0.8572 \tBbox: [ 526 \t 244 \t 613 \t 540 ]\n",
      "6 \tObject: person \tConfidence = 0.8535 \tBbox: [ 391 \t 122 \t 463 \t 375 ]\n",
      "7 \tObject: person \tConfidence = 0.7917 \tBbox: [ 267 \t 642 \t 467 \t 1078 ]\n",
      "8 \tObject: person \tConfidence = 0.7214 \tBbox: [ 448 \t 0 \t 500 \t 129 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000322 / 1050\n",
      "Frames to be processed: 728  | To do: 69.33 % | Done: 30.67 %\n",
      "\n",
      "2022-04-20 13:12:56.530339\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000322.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 26.4ms pre-process, 169.6ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9057 \tBbox: [ 574 \t 46 \t 653 \t 237 ]\n",
      "2 \tObject: train \tConfidence = 0.9047 \tBbox: [ 2 \t 1 \t 464 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.8551 \tBbox: [ 526 \t 244 \t 613 \t 540 ]\n",
      "4 \tObject: person \tConfidence = 0.8548 \tBbox: [ 391 \t 122 \t 464 \t 375 ]\n",
      "5 \tObject: person \tConfidence = 0.8518 \tBbox: [ 479 \t 3 \t 545 \t 237 ]\n",
      "6 \tObject: person \tConfidence = 0.8331 \tBbox: [ 321 \t 480 \t 455 \t 712 ]\n",
      "7 \tObject: person \tConfidence = 0.8155 \tBbox: [ 262 \t 642 \t 467 \t 1078 ]\n",
      "8 \tObject: person \tConfidence = 0.7341 \tBbox: [ 448 \t 0 \t 504 \t 131 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000323 / 1050\n",
      "Frames to be processed: 727  | To do: 69.24 % | Done: 30.76 %\n",
      "\n",
      "2022-04-20 13:12:56.981949\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000323.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 26.2ms pre-process, 174.7ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9119 \tBbox: [ 574 \t 51 \t 651 \t 238 ]\n",
      "2 \tObject: train \tConfidence = 0.9086 \tBbox: [ 2 \t 2 \t 462 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.859 \tBbox: [ 526 \t 244 \t 612 \t 541 ]\n",
      "4 \tObject: person \tConfidence = 0.8542 \tBbox: [ 391 \t 122 \t 464 \t 375 ]\n",
      "5 \tObject: person \tConfidence = 0.8485 \tBbox: [ 479 \t 6 \t 544 \t 237 ]\n",
      "6 \tObject: person \tConfidence = 0.8402 \tBbox: [ 266 \t 642 \t 464 \t 1078 ]\n",
      "7 \tObject: person \tConfidence = 0.7648 \tBbox: [ 320 \t 480 \t 455 \t 713 ]\n",
      "8 \tObject: person \tConfidence = 0.7318 \tBbox: [ 448 \t 0 \t 501 \t 131 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000324 / 1050\n",
      "Frames to be processed: 726  | To do: 69.14 % | Done: 30.86 %\n",
      "\n",
      "2022-04-20 13:12:57.457906\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000324.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 24.8ms pre-process, 172.7ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8988 \tBbox: [ 574 \t 56 \t 650 \t 244 ]\n",
      "2 \tObject: train \tConfidence = 0.8851 \tBbox: [ 0 \t 3 \t 459 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.8513 \tBbox: [ 526 \t 244 \t 612 \t 540 ]\n",
      "4 \tObject: person \tConfidence = 0.8507 \tBbox: [ 391 \t 123 \t 463 \t 376 ]\n",
      "5 \tObject: person \tConfidence = 0.846 \tBbox: [ 479 \t 1 \t 544 \t 237 ]\n",
      "6 \tObject: person \tConfidence = 0.822 \tBbox: [ 263 \t 642 \t 463 \t 1078 ]\n",
      "7 \tObject: person \tConfidence = 0.8154 \tBbox: [ 323 \t 481 \t 454 \t 714 ]\n",
      "8 \tObject: person \tConfidence = 0.7245 \tBbox: [ 447 \t 0 \t 500 \t 132 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000325 / 1050\n",
      "Frames to be processed: 725  | To do: 69.05 % | Done: 30.95 %\n",
      "\n",
      "2022-04-20 13:12:57.866029\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000325.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 27.5ms pre-process, 167.0ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8925 \tBbox: [ 576 \t 61 \t 650 \t 252 ]\n",
      "2 \tObject: person \tConfidence = 0.8674 \tBbox: [ 256 \t 644 \t 461 \t 1077 ]\n",
      "3 \tObject: train \tConfidence = 0.8583 \tBbox: [ 0 \t 3 \t 461 \t 1067 ]\n",
      "4 \tObject: person \tConfidence = 0.8522 \tBbox: [ 391 \t 122 \t 463 \t 376 ]\n",
      "5 \tObject: person \tConfidence = 0.8446 \tBbox: [ 526 \t 244 \t 614 \t 541 ]\n",
      "6 \tObject: person \tConfidence = 0.8164 \tBbox: [ 477 \t 3 \t 544 \t 237 ]\n",
      "7 \tObject: person \tConfidence = 0.8024 \tBbox: [ 325 \t 479 \t 454 \t 720 ]\n",
      "8 \tObject: person \tConfidence = 0.7102 \tBbox: [ 448 \t 0 \t 506 \t 133 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000326 / 1050\n",
      "Frames to be processed: 724  | To do: 68.95 % | Done: 31.05 %\n",
      "\n",
      "2022-04-20 13:12:58.321590\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000326.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 26.9ms pre-process, 174.4ms inference, 4.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9044 \tBbox: [ 576 \t 62 \t 649 \t 253 ]\n",
      "2 \tObject: train \tConfidence = 0.8725 \tBbox: [ 1 \t 1 \t 461 \t 1066 ]\n",
      "3 \tObject: person \tConfidence = 0.861 \tBbox: [ 390 \t 123 \t 463 \t 376 ]\n",
      "4 \tObject: person \tConfidence = 0.8493 \tBbox: [ 526 \t 244 \t 613 \t 541 ]\n",
      "5 \tObject: person \tConfidence = 0.8482 \tBbox: [ 252 \t 644 \t 460 \t 1077 ]\n",
      "6 \tObject: person \tConfidence = 0.8286 \tBbox: [ 477 \t 4 \t 543 \t 238 ]\n",
      "7 \tObject: person \tConfidence = 0.7171 \tBbox: [ 448 \t 0 \t 504 \t 132 ]\n",
      "8 \tObject: person \tConfidence = 0.7089 \tBbox: [ 326 \t 480 \t 454 \t 722 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000327 / 1050\n",
      "Frames to be processed: 723  | To do: 68.86 % | Done: 31.14 %\n",
      "\n",
      "2022-04-20 13:12:58.799205\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000327.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 27.8ms pre-process, 168.5ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9056 \tBbox: [ 576 \t 63 \t 649 \t 254 ]\n",
      "2 \tObject: person \tConfidence = 0.8846 \tBbox: [ 252 \t 643 \t 458 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8567 \tBbox: [ 391 \t 123 \t 462 \t 377 ]\n",
      "4 \tObject: train \tConfidence = 0.8532 \tBbox: [ 1 \t 0 \t 461 \t 1033 ]\n",
      "5 \tObject: person \tConfidence = 0.8523 \tBbox: [ 526 \t 245 \t 613 \t 541 ]\n",
      "6 \tObject: person \tConfidence = 0.8285 \tBbox: [ 477 \t 5 \t 543 \t 238 ]\n",
      "7 \tObject: person \tConfidence = 0.7736 \tBbox: [ 326 \t 480 \t 453 \t 726 ]\n",
      "8 \tObject: person \tConfidence = 0.7094 \tBbox: [ 447 \t 0 \t 506 \t 132 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000328 / 1050\n",
      "Frames to be processed: 722  | To do: 68.76 % | Done: 31.24 %\n",
      "\n",
      "2022-04-20 13:12:59.227870\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000328.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 25.1ms pre-process, 167.4ms inference, 10.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9094 \tBbox: [ 576 \t 63 \t 649 \t 255 ]\n",
      "2 \tObject: person \tConfidence = 0.8803 \tBbox: [ 248 \t 643 \t 457 \t 1078 ]\n",
      "3 \tObject: train \tConfidence = 0.8584 \tBbox: [ 1 \t 1 \t 462 \t 1051 ]\n",
      "4 \tObject: person \tConfidence = 0.8559 \tBbox: [ 391 \t 124 \t 462 \t 377 ]\n",
      "5 \tObject: person \tConfidence = 0.8531 \tBbox: [ 526 \t 245 \t 614 \t 542 ]\n",
      "6 \tObject: person \tConfidence = 0.8342 \tBbox: [ 477 \t 10 \t 542 \t 238 ]\n",
      "7 \tObject: person \tConfidence = 0.7411 \tBbox: [ 326 \t 480 \t 453 \t 728 ]\n",
      "8 \tObject: person \tConfidence = 0.7156 \tBbox: [ 448 \t 0 \t 505 \t 132 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000329 / 1050\n",
      "Frames to be processed: 721  | To do: 68.67 % | Done: 31.33 %\n",
      "\n",
      "2022-04-20 13:12:59.655322\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000329.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 23.6ms pre-process, 174.5ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9066 \tBbox: [ 576 \t 63 \t 650 \t 255 ]\n",
      "2 \tObject: person \tConfidence = 0.8895 \tBbox: [ 242 \t 644 \t 449 \t 1077 ]\n",
      "3 \tObject: person \tConfidence = 0.8563 \tBbox: [ 391 \t 124 \t 462 \t 377 ]\n",
      "4 \tObject: person \tConfidence = 0.8508 \tBbox: [ 526 \t 245 \t 614 \t 542 ]\n",
      "5 \tObject: train \tConfidence = 0.8488 \tBbox: [ 1 \t 3 \t 462 \t 1064 ]\n",
      "6 \tObject: person \tConfidence = 0.8318 \tBbox: [ 477 \t 14 \t 542 \t 239 ]\n",
      "7 \tObject: person \tConfidence = 0.6751 \tBbox: [ 448 \t 0 \t 517 \t 132 ]\n",
      "8 \tObject: person \tConfidence = 0.6549 \tBbox: [ 326 \t 479 \t 453 \t 754 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000330 / 1050\n",
      "Frames to be processed: 720  | To do: 68.57 % | Done: 31.43 %\n",
      "\n",
      "2022-04-20 13:13:00.104259\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000330.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 28.4ms pre-process, 168.5ms inference, 4.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9145 \tBbox: [ 576 \t 63 \t 651 \t 255 ]\n",
      "2 \tObject: person \tConfidence = 0.8814 \tBbox: [ 230 \t 644 \t 447 \t 1077 ]\n",
      "3 \tObject: train \tConfidence = 0.8618 \tBbox: [ 0 \t 3 \t 461 \t 1068 ]\n",
      "4 \tObject: person \tConfidence = 0.8601 \tBbox: [ 391 \t 124 \t 461 \t 378 ]\n",
      "5 \tObject: person \tConfidence = 0.8518 \tBbox: [ 526 \t 245 \t 614 \t 542 ]\n",
      "6 \tObject: person \tConfidence = 0.8496 \tBbox: [ 477 \t 17 \t 542 \t 240 ]\n",
      "7 \tObject: person \tConfidence = 0.8234 \tBbox: [ 325 \t 479 \t 451 \t 736 ]\n",
      "8 \tObject: person \tConfidence = 0.7325 \tBbox: [ 446 \t 0 \t 497 \t 132 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000331 / 1050\n",
      "Frames to be processed: 719  | To do: 68.48 % | Done: 31.52 %\n",
      "\n",
      "2022-04-20 13:13:00.607665\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000331.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 27.2ms pre-process, 174.3ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.92 \tBbox: [ 577 \t 64 \t 654 \t 256 ]\n",
      "2 \tObject: person \tConfidence = 0.8611 \tBbox: [ 391 \t 125 \t 461 \t 378 ]\n",
      "3 \tObject: person \tConfidence = 0.8531 \tBbox: [ 526 \t 246 \t 614 \t 542 ]\n",
      "4 \tObject: person \tConfidence = 0.8431 \tBbox: [ 477 \t 17 \t 542 \t 239 ]\n",
      "5 \tObject: person \tConfidence = 0.8391 \tBbox: [ 225 \t 642 \t 443 \t 1078 ]\n",
      "6 \tObject: train \tConfidence = 0.7717 \tBbox: [ 0 \t 3 \t 460 \t 1053 ]\n",
      "7 \tObject: person \tConfidence = 0.7336 \tBbox: [ 325 \t 480 \t 451 \t 744 ]\n",
      "8 \tObject: person \tConfidence = 0.7178 \tBbox: [ 446 \t 0 \t 496 \t 132 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000332 / 1050\n",
      "Frames to be processed: 718  | To do: 68.38 % | Done: 31.62 %\n",
      "\n",
      "2022-04-20 13:13:01.007517\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000332.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 26.4ms pre-process, 174.9ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9236 \tBbox: [ 579 \t 64 \t 656 \t 258 ]\n",
      "2 \tObject: train \tConfidence = 0.8907 \tBbox: [ 2 \t 1 \t 463 \t 1069 ]\n",
      "3 \tObject: person \tConfidence = 0.862 \tBbox: [ 391 \t 125 \t 461 \t 378 ]\n",
      "4 \tObject: person \tConfidence = 0.8551 \tBbox: [ 526 \t 246 \t 614 \t 543 ]\n",
      "5 \tObject: person \tConfidence = 0.8505 \tBbox: [ 222 \t 644 \t 440 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.8437 \tBbox: [ 476 \t 17 \t 542 \t 239 ]\n",
      "7 \tObject: person \tConfidence = 0.7032 \tBbox: [ 447 \t 0 \t 498 \t 132 ]\n",
      "8 \tObject: person \tConfidence = 0.6065 \tBbox: [ 325 \t 479 \t 452 \t 870 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000333 / 1050\n",
      "Frames to be processed: 717  | To do: 68.29 % | Done: 31.71 %\n",
      "\n",
      "2022-04-20 13:13:01.441893\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000333.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 26.1ms pre-process, 171.1ms inference, 4.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9223 \tBbox: [ 580 \t 65 \t 658 \t 259 ]\n",
      "2 \tObject: train \tConfidence = 0.9046 \tBbox: [ 2 \t 1 \t 463 \t 1065 ]\n",
      "3 \tObject: person \tConfidence = 0.865 \tBbox: [ 390 \t 125 \t 461 \t 378 ]\n",
      "4 \tObject: person \tConfidence = 0.8467 \tBbox: [ 209 \t 646 \t 441 \t 1079 ]\n",
      "5 \tObject: person \tConfidence = 0.8422 \tBbox: [ 526 \t 246 \t 615 \t 543 ]\n",
      "6 \tObject: person \tConfidence = 0.8291 \tBbox: [ 476 \t 11 \t 542 \t 239 ]\n",
      "7 \tObject: person \tConfidence = 0.7122 \tBbox: [ 447 \t 0 \t 499 \t 134 ]\n",
      "8 \tObject: person \tConfidence = 0.6156 \tBbox: [ 324 \t 479 \t 450 \t 762 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000334 / 1050\n",
      "Frames to be processed: 716  | To do: 68.19 % | Done: 31.81 %\n",
      "\n",
      "2022-04-20 13:13:01.879705\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000334.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 28.5ms pre-process, 178.4ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9255 \tBbox: [ 582 \t 67 \t 659 \t 267 ]\n",
      "2 \tObject: train \tConfidence = 0.9032 \tBbox: [ 2 \t 2 \t 464 \t 1064 ]\n",
      "3 \tObject: person \tConfidence = 0.867 \tBbox: [ 388 \t 125 \t 461 \t 378 ]\n",
      "4 \tObject: person \tConfidence = 0.8638 \tBbox: [ 211 \t 646 \t 435 \t 1078 ]\n",
      "5 \tObject: person \tConfidence = 0.8487 \tBbox: [ 525 \t 246 \t 619 \t 544 ]\n",
      "6 \tObject: person \tConfidence = 0.8473 \tBbox: [ 476 \t 16 \t 542 \t 239 ]\n",
      "7 \tObject: person \tConfidence = 0.7432 \tBbox: [ 447 \t 0 \t 498 \t 135 ]\n",
      "8 \tObject: person \tConfidence = 0.6102 \tBbox: [ 324 \t 479 \t 450 \t 763 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000335 / 1050\n",
      "Frames to be processed: 715  | To do: 68.1 % | Done: 31.9 %\n",
      "\n",
      "2022-04-20 13:13:02.358442\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000335.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 28.4ms pre-process, 169.6ms inference, 11.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9164 \tBbox: [ 584 \t 71 \t 665 \t 271 ]\n",
      "2 \tObject: train \tConfidence = 0.9105 \tBbox: [ 2 \t 3 \t 465 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.9065 \tBbox: [ 199 \t 648 \t 426 \t 1077 ]\n",
      "4 \tObject: person \tConfidence = 0.863 \tBbox: [ 389 \t 126 \t 461 \t 379 ]\n",
      "5 \tObject: person \tConfidence = 0.8501 \tBbox: [ 526 \t 246 \t 615 \t 544 ]\n",
      "6 \tObject: person \tConfidence = 0.8435 \tBbox: [ 476 \t 13 \t 542 \t 240 ]\n",
      "7 \tObject: person \tConfidence = 0.76 \tBbox: [ 447 \t 0 \t 497 \t 135 ]\n",
      "8 \tObject: person \tConfidence = 0.7488 \tBbox: [ 324 \t 479 \t 450 \t 871 ]\n",
      "9 \tObject: person \tConfidence = 0.4061 \tBbox: [ 744 \t 5 \t 765 \t 243 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000336 / 1050\n",
      "Frames to be processed: 714  | To do: 68.0 % | Done: 32.0 %\n",
      "\n",
      "2022-04-20 13:13:02.812417\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000336.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 28.0ms pre-process, 167.9ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9224 \tBbox: [ 1 \t 2 \t 464 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.9096 \tBbox: [ 585 \t 73 \t 666 \t 271 ]\n",
      "3 \tObject: person \tConfidence = 0.8893 \tBbox: [ 203 \t 649 \t 424 \t 1077 ]\n",
      "4 \tObject: person \tConfidence = 0.8612 \tBbox: [ 389 \t 127 \t 461 \t 379 ]\n",
      "5 \tObject: person \tConfidence = 0.8469 \tBbox: [ 525 \t 247 \t 618 \t 545 ]\n",
      "6 \tObject: person \tConfidence = 0.8347 \tBbox: [ 476 \t 11 \t 542 \t 241 ]\n",
      "7 \tObject: person \tConfidence = 0.765 \tBbox: [ 447 \t 0 \t 498 \t 135 ]\n",
      "8 \tObject: person \tConfidence = 0.746 \tBbox: [ 324 \t 479 \t 450 \t 877 ]\n",
      "9 \tObject: person \tConfidence = 0.4385 \tBbox: [ 740 \t 5 \t 765 \t 248 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000337 / 1050\n",
      "Frames to be processed: 713  | To do: 67.9 % | Done: 32.1 %\n",
      "\n",
      "2022-04-20 13:13:03.269682\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000337.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 26.3ms pre-process, 174.3ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.916 \tBbox: [ 2 \t 2 \t 463 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.9074 \tBbox: [ 587 \t 75 \t 669 \t 274 ]\n",
      "3 \tObject: person \tConfidence = 0.8882 \tBbox: [ 199 \t 650 \t 424 \t 1077 ]\n",
      "4 \tObject: person \tConfidence = 0.8607 \tBbox: [ 388 \t 127 \t 461 \t 379 ]\n",
      "5 \tObject: person \tConfidence = 0.8515 \tBbox: [ 525 \t 247 \t 620 \t 545 ]\n",
      "6 \tObject: person \tConfidence = 0.8311 \tBbox: [ 476 \t 2 \t 542 \t 241 ]\n",
      "7 \tObject: person \tConfidence = 0.7542 \tBbox: [ 447 \t 0 \t 499 \t 138 ]\n",
      "8 \tObject: person \tConfidence = 0.7417 \tBbox: [ 324 \t 479 \t 450 \t 874 ]\n",
      "9 \tObject: person \tConfidence = 0.3998 \tBbox: [ 730 \t 7 \t 765 \t 247 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000338 / 1050\n",
      "Frames to be processed: 712  | To do: 67.81 % | Done: 32.19 %\n",
      "\n",
      "2022-04-20 13:13:03.728254\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000338.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 28.6ms pre-process, 180.5ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9164 \tBbox: [ 1 \t 2 \t 464 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.9106 \tBbox: [ 588 \t 79 \t 671 \t 282 ]\n",
      "3 \tObject: person \tConfidence = 0.8931 \tBbox: [ 198 \t 651 \t 420 \t 1077 ]\n",
      "4 \tObject: person \tConfidence = 0.8576 \tBbox: [ 388 \t 127 \t 461 \t 379 ]\n",
      "5 \tObject: person \tConfidence = 0.8497 \tBbox: [ 525 \t 247 \t 620 \t 545 ]\n",
      "6 \tObject: person \tConfidence = 0.8467 \tBbox: [ 476 \t 2 \t 541 \t 241 ]\n",
      "7 \tObject: person \tConfidence = 0.7638 \tBbox: [ 447 \t 0 \t 496 \t 138 ]\n",
      "8 \tObject: person \tConfidence = 0.7588 \tBbox: [ 324 \t 479 \t 450 \t 879 ]\n",
      "9 \tObject: person \tConfidence = 0.512 \tBbox: [ 723 \t 3 \t 765 \t 254 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000339 / 1050\n",
      "Frames to be processed: 711  | To do: 67.71 % | Done: 32.29 %\n",
      "\n",
      "2022-04-20 13:13:04.223727\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000339.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 30.2ms pre-process, 172.9ms inference, 3.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.914 \tBbox: [ 0 \t 2 \t 461 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.8933 \tBbox: [ 198 \t 652 \t 415 \t 1077 ]\n",
      "3 \tObject: person \tConfidence = 0.8901 \tBbox: [ 592 \t 81 \t 672 \t 283 ]\n",
      "4 \tObject: person \tConfidence = 0.8509 \tBbox: [ 476 \t 1 \t 542 \t 241 ]\n",
      "5 \tObject: person \tConfidence = 0.8495 \tBbox: [ 525 \t 247 \t 620 \t 546 ]\n",
      "6 \tObject: person \tConfidence = 0.8479 \tBbox: [ 389 \t 127 \t 461 \t 380 ]\n",
      "7 \tObject: person \tConfidence = 0.7769 \tBbox: [ 447 \t 0 \t 494 \t 138 ]\n",
      "8 \tObject: person \tConfidence = 0.7266 \tBbox: [ 718 \t 2 \t 765 \t 256 ]\n",
      "9 \tObject: person \tConfidence = 0.6908 \tBbox: [ 323 \t 479 \t 450 \t 879 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000340 / 1050\n",
      "Frames to be processed: 710  | To do: 67.62 % | Done: 32.38 %\n",
      "\n",
      "2022-04-20 13:13:04.692500\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000340.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 26.6ms pre-process, 171.6ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9031 \tBbox: [ 595 \t 84 \t 674 \t 288 ]\n",
      "2 \tObject: train \tConfidence = 0.8888 \tBbox: [ 1 \t 2 \t 463 \t 1072 ]\n",
      "3 \tObject: person \tConfidence = 0.881 \tBbox: [ 191 \t 653 \t 414 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8469 \tBbox: [ 525 \t 247 \t 620 \t 546 ]\n",
      "5 \tObject: person \tConfidence = 0.8442 \tBbox: [ 389 \t 127 \t 461 \t 380 ]\n",
      "6 \tObject: person \tConfidence = 0.8417 \tBbox: [ 476 \t 2 \t 541 \t 242 ]\n",
      "7 \tObject: person \tConfidence = 0.7852 \tBbox: [ 448 \t 0 \t 494 \t 139 ]\n",
      "8 \tObject: person \tConfidence = 0.7465 \tBbox: [ 322 \t 479 \t 450 \t 871 ]\n",
      "9 \tObject: person \tConfidence = 0.7449 \tBbox: [ 712 \t 4 \t 765 \t 262 ]\n",
      "10 \tObject: person \tConfidence = 0.3979 \tBbox: [ 672 \t 0 \t 693 \t 95 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000341 / 1050\n",
      "Frames to be processed: 709  | To do: 67.52 % | Done: 32.48 %\n",
      "\n",
      "2022-04-20 13:13:05.177759\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000341.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 26.2ms pre-process, 175.1ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9126 \tBbox: [ 2 \t 2 \t 466 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.9041 \tBbox: [ 595 \t 85 \t 675 \t 288 ]\n",
      "3 \tObject: person \tConfidence = 0.8885 \tBbox: [ 188 \t 652 \t 415 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.85 \tBbox: [ 476 \t 2 \t 542 \t 242 ]\n",
      "5 \tObject: person \tConfidence = 0.8481 \tBbox: [ 525 \t 248 \t 622 \t 546 ]\n",
      "6 \tObject: person \tConfidence = 0.8362 \tBbox: [ 389 \t 128 \t 461 \t 381 ]\n",
      "7 \tObject: person \tConfidence = 0.8002 \tBbox: [ 448 \t 0 \t 494 \t 139 ]\n",
      "8 \tObject: person \tConfidence = 0.7723 \tBbox: [ 712 \t 5 \t 765 \t 267 ]\n",
      "9 \tObject: person \tConfidence = 0.7534 \tBbox: [ 323 \t 478 \t 450 \t 869 ]\n",
      "10 \tObject: person \tConfidence = 0.3325 \tBbox: [ 671 \t 0 \t 693 \t 97 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000342 / 1050\n",
      "Frames to be processed: 708  | To do: 67.43 % | Done: 32.57 %\n",
      "\n",
      "2022-04-20 13:13:05.612246\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000342.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 26.4ms pre-process, 175.6ms inference, 4.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9049 \tBbox: [ 596 \t 86 \t 675 \t 288 ]\n",
      "2 \tObject: train \tConfidence = 0.9011 \tBbox: [ 2 \t 2 \t 465 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.8888 \tBbox: [ 182 \t 654 \t 411 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8467 \tBbox: [ 525 \t 248 \t 621 \t 546 ]\n",
      "5 \tObject: person \tConfidence = 0.8402 \tBbox: [ 389 \t 129 \t 461 \t 381 ]\n",
      "6 \tObject: person \tConfidence = 0.8356 \tBbox: [ 476 \t 3 \t 542 \t 242 ]\n",
      "7 \tObject: person \tConfidence = 0.7802 \tBbox: [ 447 \t 0 \t 494 \t 139 ]\n",
      "8 \tObject: person \tConfidence = 0.763 \tBbox: [ 322 \t 479 \t 449 \t 879 ]\n",
      "9 \tObject: person \tConfidence = 0.7444 \tBbox: [ 713 \t 5 \t 765 \t 271 ]\n",
      "10 \tObject: person \tConfidence = 0.648 \tBbox: [ 668 \t 0 \t 693 \t 95 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000343 / 1050\n",
      "Frames to be processed: 707  | To do: 67.33 % | Done: 32.67 %\n",
      "\n",
      "2022-04-20 13:13:06.031148\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000343.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 35.3ms pre-process, 178.2ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9065 \tBbox: [ 595 \t 86 \t 674 \t 289 ]\n",
      "2 \tObject: train \tConfidence = 0.8967 \tBbox: [ 2 \t 1 \t 465 \t 1072 ]\n",
      "3 \tObject: person \tConfidence = 0.8882 \tBbox: [ 180 \t 655 \t 410 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8418 \tBbox: [ 525 \t 249 \t 625 \t 546 ]\n",
      "5 \tObject: person \tConfidence = 0.84 \tBbox: [ 389 \t 129 \t 461 \t 382 ]\n",
      "6 \tObject: person \tConfidence = 0.8361 \tBbox: [ 476 \t 4 \t 542 \t 242 ]\n",
      "7 \tObject: person \tConfidence = 0.7953 \tBbox: [ 447 \t 0 \t 494 \t 139 ]\n",
      "8 \tObject: person \tConfidence = 0.7831 \tBbox: [ 714 \t 6 \t 765 \t 271 ]\n",
      "9 \tObject: person \tConfidence = 0.7277 \tBbox: [ 321 \t 480 \t 449 \t 876 ]\n",
      "10 \tObject: person \tConfidence = 0.4128 \tBbox: [ 665 \t 0 \t 693 \t 95 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000344 / 1050\n",
      "Frames to be processed: 706  | To do: 67.24 % | Done: 32.76 %\n",
      "\n",
      "2022-04-20 13:13:06.460827\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000344.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 28.7ms pre-process, 182.1ms inference, 11.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9013 \tBbox: [ 594 \t 86 \t 674 \t 289 ]\n",
      "2 \tObject: train \tConfidence = 0.8953 \tBbox: [ 2 \t 2 \t 467 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.8908 \tBbox: [ 175 \t 655 \t 405 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8428 \tBbox: [ 389 \t 128 \t 461 \t 382 ]\n",
      "5 \tObject: person \tConfidence = 0.8416 \tBbox: [ 476 \t 3 \t 543 \t 242 ]\n",
      "6 \tObject: person \tConfidence = 0.8375 \tBbox: [ 525 \t 250 \t 626 \t 546 ]\n",
      "7 \tObject: person \tConfidence = 0.8062 \tBbox: [ 447 \t 0 \t 493 \t 140 ]\n",
      "8 \tObject: person \tConfidence = 0.7298 \tBbox: [ 714 \t 10 \t 765 \t 271 ]\n",
      "9 \tObject: person \tConfidence = 0.7182 \tBbox: [ 321 \t 480 \t 449 \t 883 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000345 / 1050\n",
      "Frames to be processed: 705  | To do: 67.14 % | Done: 32.86 %\n",
      "\n",
      "2022-04-20 13:13:06.902520\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000345.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 26.8ms pre-process, 180.7ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9048 \tBbox: [ 179 \t 656 \t 403 \t 1077 ]\n",
      "2 \tObject: person \tConfidence = 0.8904 \tBbox: [ 591 \t 88 \t 674 \t 290 ]\n",
      "3 \tObject: train \tConfidence = 0.883 \tBbox: [ 2 \t 0 \t 468 \t 1071 ]\n",
      "4 \tObject: person \tConfidence = 0.8555 \tBbox: [ 389 \t 130 \t 461 \t 382 ]\n",
      "5 \tObject: person \tConfidence = 0.8457 \tBbox: [ 476 \t 7 \t 543 \t 243 ]\n",
      "6 \tObject: person \tConfidence = 0.827 \tBbox: [ 525 \t 249 \t 620 \t 547 ]\n",
      "7 \tObject: person \tConfidence = 0.8143 \tBbox: [ 448 \t 0 \t 494 \t 140 ]\n",
      "8 \tObject: person \tConfidence = 0.8034 \tBbox: [ 715 \t 52 \t 765 \t 272 ]\n",
      "9 \tObject: person \tConfidence = 0.7271 \tBbox: [ 320 \t 481 \t 449 \t 881 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000346 / 1050\n",
      "Frames to be processed: 704  | To do: 67.05 % | Done: 32.95 %\n",
      "\n",
      "2022-04-20 13:13:07.398715\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000346.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 29.0ms pre-process, 173.5ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9066 \tBbox: [ 587 \t 89 \t 673 \t 296 ]\n",
      "2 \tObject: person \tConfidence = 0.9046 \tBbox: [ 176 \t 657 \t 402 \t 1078 ]\n",
      "3 \tObject: train \tConfidence = 0.9009 \tBbox: [ 2 \t 1 \t 467 \t 1071 ]\n",
      "4 \tObject: person \tConfidence = 0.8568 \tBbox: [ 476 \t 6 \t 543 \t 243 ]\n",
      "5 \tObject: person \tConfidence = 0.8514 \tBbox: [ 389 \t 130 \t 461 \t 382 ]\n",
      "6 \tObject: person \tConfidence = 0.8209 \tBbox: [ 448 \t 0 \t 494 \t 140 ]\n",
      "7 \tObject: person \tConfidence = 0.8189 \tBbox: [ 525 \t 249 \t 619 \t 548 ]\n",
      "8 \tObject: person \tConfidence = 0.8074 \tBbox: [ 713 \t 48 \t 766 \t 271 ]\n",
      "9 \tObject: person \tConfidence = 0.6954 \tBbox: [ 320 \t 480 \t 450 \t 860 ]\n",
      "10 \tObject: person \tConfidence = 0.3952 \tBbox: [ 655 \t 0 \t 693 \t 93 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000347 / 1050\n",
      "Frames to be processed: 703  | To do: 66.95 % | Done: 33.05 %\n",
      "\n",
      "2022-04-20 13:13:07.849662\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000347.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 25.9ms pre-process, 176.0ms inference, 2.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9097 \tBbox: [ 177 \t 658 \t 402 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9074 \tBbox: [ 2 \t 1 \t 467 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.8868 \tBbox: [ 585 \t 91 \t 673 \t 300 ]\n",
      "4 \tObject: person \tConfidence = 0.8683 \tBbox: [ 476 \t 4 \t 543 \t 243 ]\n",
      "5 \tObject: person \tConfidence = 0.854 \tBbox: [ 389 \t 130 \t 461 \t 382 ]\n",
      "6 \tObject: person \tConfidence = 0.826 \tBbox: [ 711 \t 49 \t 766 \t 272 ]\n",
      "7 \tObject: person \tConfidence = 0.8235 \tBbox: [ 449 \t 1 \t 492 \t 139 ]\n",
      "8 \tObject: person \tConfidence = 0.8158 \tBbox: [ 525 \t 249 \t 619 \t 548 ]\n",
      "9 \tObject: person \tConfidence = 0.7368 \tBbox: [ 319 \t 480 \t 450 \t 869 ]\n",
      "10 \tObject: person \tConfidence = 0.4132 \tBbox: [ 655 \t 0 \t 693 \t 94 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000348 / 1050\n",
      "Frames to be processed: 702  | To do: 66.86 % | Done: 33.14 %\n",
      "\n",
      "2022-04-20 13:13:08.300712\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000348.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 37.7ms pre-process, 180.1ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9126 \tBbox: [ 176 \t 658 \t 401 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.8919 \tBbox: [ 2 \t 1 \t 468 \t 1073 ]\n",
      "3 \tObject: person \tConfidence = 0.8684 \tBbox: [ 476 \t 5 \t 543 \t 244 ]\n",
      "4 \tObject: person \tConfidence = 0.8562 \tBbox: [ 389 \t 130 \t 461 \t 382 ]\n",
      "5 \tObject: person \tConfidence = 0.8477 \tBbox: [ 583 \t 96 \t 674 \t 304 ]\n",
      "6 \tObject: person \tConfidence = 0.8174 \tBbox: [ 526 \t 251 \t 625 \t 547 ]\n",
      "7 \tObject: person \tConfidence = 0.8109 \tBbox: [ 449 \t 0 \t 494 \t 140 ]\n",
      "8 \tObject: person \tConfidence = 0.7972 \tBbox: [ 709 \t 49 \t 765 \t 272 ]\n",
      "9 \tObject: person \tConfidence = 0.7284 \tBbox: [ 319 \t 480 \t 450 \t 858 ]\n",
      "10 \tObject: person \tConfidence = 0.4988 \tBbox: [ 655 \t 0 \t 694 \t 92 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000349 / 1050\n",
      "Frames to be processed: 701  | To do: 66.76 % | Done: 33.24 %\n",
      "\n",
      "2022-04-20 13:13:08.797956\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000349.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 27.4ms pre-process, 174.0ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9083 \tBbox: [ 177 \t 658 \t 400 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9026 \tBbox: [ 2 \t 2 \t 468 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.865 \tBbox: [ 476 \t 7 \t 543 \t 244 ]\n",
      "4 \tObject: person \tConfidence = 0.8619 \tBbox: [ 389 \t 130 \t 460 \t 382 ]\n",
      "5 \tObject: person \tConfidence = 0.8307 \tBbox: [ 582 \t 96 \t 673 \t 313 ]\n",
      "6 \tObject: person \tConfidence = 0.8196 \tBbox: [ 526 \t 251 \t 625 \t 547 ]\n",
      "7 \tObject: person \tConfidence = 0.7858 \tBbox: [ 448 \t 0 \t 495 \t 140 ]\n",
      "8 \tObject: person \tConfidence = 0.7379 \tBbox: [ 704 \t 48 \t 766 \t 271 ]\n",
      "9 \tObject: person \tConfidence = 0.7293 \tBbox: [ 318 \t 481 \t 450 \t 881 ]\n",
      "10 \tObject: person \tConfidence = 0.5827 \tBbox: [ 654 \t 0 \t 694 \t 91 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000350 / 1050\n",
      "Frames to be processed: 700  | To do: 66.67 % | Done: 33.33 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:13:09.239183\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000350.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 24.8ms pre-process, 168.4ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9031 \tBbox: [ 176 \t 658 \t 403 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.8854 \tBbox: [ 0 \t 1 \t 466 \t 1067 ]\n",
      "3 \tObject: person \tConfidence = 0.8656 \tBbox: [ 388 \t 131 \t 461 \t 382 ]\n",
      "4 \tObject: person \tConfidence = 0.8653 \tBbox: [ 477 \t 7 \t 543 \t 244 ]\n",
      "5 \tObject: person \tConfidence = 0.8442 \tBbox: [ 698 \t 51 \t 765 \t 278 ]\n",
      "6 \tObject: person \tConfidence = 0.8369 \tBbox: [ 579 \t 103 \t 673 \t 334 ]\n",
      "7 \tObject: person \tConfidence = 0.8229 \tBbox: [ 526 \t 251 \t 623 \t 547 ]\n",
      "8 \tObject: person \tConfidence = 0.7677 \tBbox: [ 448 \t 1 \t 493 \t 140 ]\n",
      "9 \tObject: person \tConfidence = 0.7 \tBbox: [ 319 \t 479 \t 450 \t 835 ]\n",
      "10 \tObject: person \tConfidence = 0.603 \tBbox: [ 653 \t 0 \t 695 \t 92 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000351 / 1050\n",
      "Frames to be processed: 699  | To do: 66.57 % | Done: 33.43 %\n",
      "\n",
      "2022-04-20 13:13:09.665637\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000351.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 32.6ms pre-process, 174.8ms inference, 4.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9079 \tBbox: [ 175 \t 658 \t 401 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.8914 \tBbox: [ 2 \t 3 \t 468 \t 1067 ]\n",
      "3 \tObject: person \tConfidence = 0.8778 \tBbox: [ 694 \t 52 \t 765 \t 284 ]\n",
      "4 \tObject: person \tConfidence = 0.8669 \tBbox: [ 388 \t 131 \t 461 \t 383 ]\n",
      "5 \tObject: person \tConfidence = 0.8627 \tBbox: [ 579 \t 108 \t 673 \t 329 ]\n",
      "6 \tObject: person \tConfidence = 0.8579 \tBbox: [ 476 \t 9 \t 543 \t 244 ]\n",
      "7 \tObject: person \tConfidence = 0.8136 \tBbox: [ 526 \t 252 \t 619 \t 547 ]\n",
      "8 \tObject: person \tConfidence = 0.7708 \tBbox: [ 449 \t 1 \t 494 \t 140 ]\n",
      "9 \tObject: person \tConfidence = 0.7385 \tBbox: [ 651 \t 0 \t 695 \t 92 ]\n",
      "10 \tObject: person \tConfidence = 0.723 \tBbox: [ 319 \t 480 \t 450 \t 878 ]\n",
      "11 \tObject: person \tConfidence = 0.3203 \tBbox: [ 395 \t 215 \t 459 \t 339 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000352 / 1050\n",
      "Frames to be processed: 698  | To do: 66.48 % | Done: 33.52 %\n",
      "\n",
      "2022-04-20 13:13:10.126277\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000352.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 27.4ms pre-process, 183.3ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9183 \tBbox: [ 2 \t 3 \t 467 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.9073 \tBbox: [ 176 \t 658 \t 403 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8798 \tBbox: [ 580 \t 109 \t 674 \t 333 ]\n",
      "4 \tObject: person \tConfidence = 0.8729 \tBbox: [ 692 \t 53 \t 765 \t 290 ]\n",
      "5 \tObject: person \tConfidence = 0.8666 \tBbox: [ 476 \t 4 \t 544 \t 244 ]\n",
      "6 \tObject: person \tConfidence = 0.8646 \tBbox: [ 389 \t 131 \t 460 \t 383 ]\n",
      "7 \tObject: person \tConfidence = 0.8177 \tBbox: [ 526 \t 252 \t 618 \t 547 ]\n",
      "8 \tObject: person \tConfidence = 0.7906 \tBbox: [ 448 \t 1 \t 493 \t 141 ]\n",
      "9 \tObject: person \tConfidence = 0.776 \tBbox: [ 649 \t 0 \t 695 \t 92 ]\n",
      "10 \tObject: person \tConfidence = 0.7102 \tBbox: [ 319 \t 480 \t 451 \t 825 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000353 / 1050\n",
      "Frames to be processed: 697  | To do: 66.38 % | Done: 33.62 %\n",
      "\n",
      "2022-04-20 13:13:10.599371\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000353.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 31.5ms pre-process, 173.6ms inference, 14.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9272 \tBbox: [ 2 \t 3 \t 466 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.9075 \tBbox: [ 174 \t 658 \t 405 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8992 \tBbox: [ 689 \t 54 \t 765 \t 296 ]\n",
      "4 \tObject: person \tConfidence = 0.8802 \tBbox: [ 581 \t 110 \t 674 \t 333 ]\n",
      "5 \tObject: person \tConfidence = 0.8658 \tBbox: [ 389 \t 131 \t 460 \t 384 ]\n",
      "6 \tObject: person \tConfidence = 0.8609 \tBbox: [ 476 \t 6 \t 544 \t 245 ]\n",
      "7 \tObject: person \tConfidence = 0.8159 \tBbox: [ 526 \t 252 \t 621 \t 547 ]\n",
      "8 \tObject: person \tConfidence = 0.7611 \tBbox: [ 650 \t 0 \t 695 \t 94 ]\n",
      "9 \tObject: person \tConfidence = 0.7516 \tBbox: [ 449 \t 1 \t 494 \t 142 ]\n",
      "10 \tObject: person \tConfidence = 0.7318 \tBbox: [ 319 \t 480 \t 452 \t 827 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000354 / 1050\n",
      "Frames to be processed: 696  | To do: 66.29 % | Done: 33.71 %\n",
      "\n",
      "2022-04-20 13:13:11.039297\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000354.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 26.6ms pre-process, 175.3ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.927 \tBbox: [ 2 \t 2 \t 465 \t 1067 ]\n",
      "2 \tObject: person \tConfidence = 0.9075 \tBbox: [ 176 \t 658 \t 405 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8939 \tBbox: [ 689 \t 55 \t 765 \t 296 ]\n",
      "4 \tObject: person \tConfidence = 0.8839 \tBbox: [ 581 \t 111 \t 675 \t 332 ]\n",
      "5 \tObject: person \tConfidence = 0.8621 \tBbox: [ 389 \t 132 \t 460 \t 384 ]\n",
      "6 \tObject: person \tConfidence = 0.8547 \tBbox: [ 476 \t 15 \t 544 \t 245 ]\n",
      "7 \tObject: person \tConfidence = 0.8111 \tBbox: [ 526 \t 252 \t 617 \t 547 ]\n",
      "8 \tObject: person \tConfidence = 0.766 \tBbox: [ 647 \t 0 \t 697 \t 94 ]\n",
      "9 \tObject: person \tConfidence = 0.7402 \tBbox: [ 448 \t 0 \t 495 \t 141 ]\n",
      "10 \tObject: person \tConfidence = 0.7261 \tBbox: [ 319 \t 481 \t 452 \t 810 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000355 / 1050\n",
      "Frames to be processed: 695  | To do: 66.19 % | Done: 33.81 %\n",
      "\n",
      "2022-04-20 13:13:11.557266\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000355.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 31.6ms pre-process, 179.8ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9148 \tBbox: [ 2 \t 3 \t 465 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.9102 \tBbox: [ 176 \t 658 \t 405 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9088 \tBbox: [ 686 \t 60 \t 765 \t 307 ]\n",
      "4 \tObject: person \tConfidence = 0.8932 \tBbox: [ 580 \t 112 \t 676 \t 332 ]\n",
      "5 \tObject: person \tConfidence = 0.8501 \tBbox: [ 476 \t 16 \t 544 \t 246 ]\n",
      "6 \tObject: person \tConfidence = 0.8425 \tBbox: [ 390 \t 132 \t 461 \t 385 ]\n",
      "7 \tObject: person \tConfidence = 0.8108 \tBbox: [ 526 \t 253 \t 617 \t 548 ]\n",
      "8 \tObject: person \tConfidence = 0.7779 \tBbox: [ 648 \t 0 \t 696 \t 95 ]\n",
      "9 \tObject: person \tConfidence = 0.7281 \tBbox: [ 319 \t 481 \t 452 \t 809 ]\n",
      "10 \tObject: person \tConfidence = 0.6486 \tBbox: [ 448 \t 0 \t 496 \t 141 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000356 / 1050\n",
      "Frames to be processed: 694  | To do: 66.1 % | Done: 33.9 %\n",
      "\n",
      "2022-04-20 13:13:12.051081\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000356.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 28.6ms pre-process, 181.4ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9206 \tBbox: [ 0 \t 1 \t 464 \t 1075 ]\n",
      "2 \tObject: person \tConfidence = 0.9113 \tBbox: [ 685 \t 62 \t 766 \t 307 ]\n",
      "3 \tObject: person \tConfidence = 0.9093 \tBbox: [ 176 \t 659 \t 407 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8849 \tBbox: [ 582 \t 112 \t 677 \t 329 ]\n",
      "5 \tObject: person \tConfidence = 0.855 \tBbox: [ 477 \t 17 \t 544 \t 246 ]\n",
      "6 \tObject: person \tConfidence = 0.8423 \tBbox: [ 389 \t 132 \t 461 \t 385 ]\n",
      "7 \tObject: person \tConfidence = 0.8278 \tBbox: [ 648 \t 0 \t 695 \t 93 ]\n",
      "8 \tObject: person \tConfidence = 0.8107 \tBbox: [ 526 \t 253 \t 620 \t 548 ]\n",
      "9 \tObject: person \tConfidence = 0.7348 \tBbox: [ 319 \t 482 \t 451 \t 808 ]\n",
      "10 \tObject: person \tConfidence = 0.7076 \tBbox: [ 449 \t 1 \t 494 \t 140 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000357 / 1050\n",
      "Frames to be processed: 693  | To do: 66.0 % | Done: 34.0 %\n",
      "\n",
      "2022-04-20 13:13:12.486507\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000357.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 34.0ms pre-process, 182.0ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9129 \tBbox: [ 0 \t 1 \t 463 \t 1073 ]\n",
      "2 \tObject: person \tConfidence = 0.9091 \tBbox: [ 686 \t 64 \t 766 \t 307 ]\n",
      "3 \tObject: person \tConfidence = 0.908 \tBbox: [ 177 \t 658 \t 406 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8911 \tBbox: [ 586 \t 112 \t 679 \t 328 ]\n",
      "5 \tObject: person \tConfidence = 0.8565 \tBbox: [ 476 \t 17 \t 544 \t 246 ]\n",
      "6 \tObject: person \tConfidence = 0.8438 \tBbox: [ 390 \t 133 \t 460 \t 385 ]\n",
      "7 \tObject: person \tConfidence = 0.8064 \tBbox: [ 526 \t 253 \t 622 \t 548 ]\n",
      "8 \tObject: person \tConfidence = 0.7939 \tBbox: [ 647 \t 0 \t 692 \t 92 ]\n",
      "9 \tObject: person \tConfidence = 0.7264 \tBbox: [ 450 \t 0 \t 494 \t 140 ]\n",
      "10 \tObject: person \tConfidence = 0.7142 \tBbox: [ 319 \t 480 \t 450 \t 823 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000358 / 1050\n",
      "Frames to be processed: 692  | To do: 65.9 % | Done: 34.1 %\n",
      "\n",
      "2022-04-20 13:13:12.955620\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000358.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 29.3ms pre-process, 173.2ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9183 \tBbox: [ 2 \t 3 \t 467 \t 1065 ]\n",
      "2 \tObject: person \tConfidence = 0.9053 \tBbox: [ 686 \t 64 \t 766 \t 307 ]\n",
      "3 \tObject: person \tConfidence = 0.9004 \tBbox: [ 176 \t 658 \t 416 \t 1077 ]\n",
      "4 \tObject: person \tConfidence = 0.8951 \tBbox: [ 588 \t 113 \t 681 \t 331 ]\n",
      "5 \tObject: person \tConfidence = 0.8582 \tBbox: [ 477 \t 16 \t 544 \t 246 ]\n",
      "6 \tObject: person \tConfidence = 0.8502 \tBbox: [ 390 \t 133 \t 460 \t 385 ]\n",
      "7 \tObject: person \tConfidence = 0.7999 \tBbox: [ 526 \t 253 \t 619 \t 549 ]\n",
      "8 \tObject: person \tConfidence = 0.7855 \tBbox: [ 645 \t 0 \t 692 \t 90 ]\n",
      "9 \tObject: person \tConfidence = 0.7539 \tBbox: [ 449 \t 0 \t 493 \t 140 ]\n",
      "10 \tObject: person \tConfidence = 0.7111 \tBbox: [ 319 \t 482 \t 451 \t 809 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000359 / 1050\n",
      "Frames to be processed: 691  | To do: 65.81 % | Done: 34.19 %\n",
      "\n",
      "2022-04-20 13:13:13.438444\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000359.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 24.7ms pre-process, 175.1ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9329 \tBbox: [ 2 \t 2 \t 466 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.9112 \tBbox: [ 686 \t 65 \t 766 \t 306 ]\n",
      "3 \tObject: person \tConfidence = 0.9056 \tBbox: [ 592 \t 115 \t 683 \t 334 ]\n",
      "4 \tObject: person \tConfidence = 0.9021 \tBbox: [ 177 \t 658 \t 416 \t 1077 ]\n",
      "5 \tObject: person \tConfidence = 0.8604 \tBbox: [ 476 \t 20 \t 544 \t 246 ]\n",
      "6 \tObject: person \tConfidence = 0.8537 \tBbox: [ 389 \t 133 \t 460 \t 385 ]\n",
      "7 \tObject: person \tConfidence = 0.8008 \tBbox: [ 525 \t 253 \t 619 \t 549 ]\n",
      "8 \tObject: person \tConfidence = 0.7636 \tBbox: [ 646 \t 0 \t 689 \t 89 ]\n",
      "9 \tObject: person \tConfidence = 0.7334 \tBbox: [ 448 \t 0 \t 493 \t 139 ]\n",
      "10 \tObject: person \tConfidence = 0.7196 \tBbox: [ 319 \t 481 \t 451 \t 820 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000360 / 1050\n",
      "Frames to be processed: 690  | To do: 65.71 % | Done: 34.29 %\n",
      "\n",
      "2022-04-20 13:13:13.860744\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000360.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 26.8ms pre-process, 177.6ms inference, 3.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9371 \tBbox: [ 2 \t 3 \t 466 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.9028 \tBbox: [ 178 \t 658 \t 418 \t 1077 ]\n",
      "3 \tObject: person \tConfidence = 0.9023 \tBbox: [ 687 \t 67 \t 766 \t 307 ]\n",
      "4 \tObject: person \tConfidence = 0.889 \tBbox: [ 595 \t 120 \t 689 \t 347 ]\n",
      "5 \tObject: person \tConfidence = 0.8653 \tBbox: [ 389 \t 134 \t 460 \t 385 ]\n",
      "6 \tObject: person \tConfidence = 0.8582 \tBbox: [ 477 \t 21 \t 544 \t 247 ]\n",
      "7 \tObject: person \tConfidence = 0.8084 \tBbox: [ 525 \t 253 \t 618 \t 549 ]\n",
      "8 \tObject: person \tConfidence = 0.7763 \tBbox: [ 646 \t 0 \t 689 \t 90 ]\n",
      "9 \tObject: person \tConfidence = 0.7285 \tBbox: [ 320 \t 481 \t 450 \t 817 ]\n",
      "10 \tObject: person \tConfidence = 0.6748 \tBbox: [ 448 \t 0 \t 496 \t 141 ]\n",
      "11 \tObject: person \tConfidence = 0.3471 \tBbox: [ 516 \t 0 \t 540 \t 36 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000361 / 1050\n",
      "Frames to be processed: 689  | To do: 65.62 % | Done: 34.38 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:13:14.280822\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000361.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 26.4ms pre-process, 169.0ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9349 \tBbox: [ 2 \t 3 \t 465 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.9153 \tBbox: [ 178 \t 657 \t 431 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9065 \tBbox: [ 597 \t 124 \t 689 \t 349 ]\n",
      "4 \tObject: person \tConfidence = 0.9011 \tBbox: [ 686 \t 67 \t 766 \t 307 ]\n",
      "5 \tObject: person \tConfidence = 0.8745 \tBbox: [ 387 \t 134 \t 460 \t 386 ]\n",
      "6 \tObject: person \tConfidence = 0.8591 \tBbox: [ 477 \t 21 \t 543 \t 246 ]\n",
      "7 \tObject: person \tConfidence = 0.8077 \tBbox: [ 525 \t 252 \t 620 \t 549 ]\n",
      "8 \tObject: person \tConfidence = 0.7833 \tBbox: [ 644 \t 0 \t 688 \t 91 ]\n",
      "9 \tObject: person \tConfidence = 0.7467 \tBbox: [ 321 \t 482 \t 450 \t 809 ]\n",
      "10 \tObject: person \tConfidence = 0.6576 \tBbox: [ 449 \t 0 \t 496 \t 140 ]\n",
      "11 \tObject: person \tConfidence = 0.373 \tBbox: [ 516 \t 0 \t 540 \t 35 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000362 / 1050\n",
      "Frames to be processed: 688  | To do: 65.52 % | Done: 34.48 %\n",
      "\n",
      "2022-04-20 13:13:14.723910\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000362.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 40.9ms pre-process, 175.6ms inference, 10.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.94 \tBbox: [ 2 \t 2 \t 467 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.9154 \tBbox: [ 180 \t 658 \t 433 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9116 \tBbox: [ 598 \t 126 \t 691 \t 351 ]\n",
      "4 \tObject: person \tConfidence = 0.898 \tBbox: [ 685 \t 67 \t 766 \t 307 ]\n",
      "5 \tObject: person \tConfidence = 0.8685 \tBbox: [ 386 \t 134 \t 461 \t 386 ]\n",
      "6 \tObject: person \tConfidence = 0.858 \tBbox: [ 477 \t 20 \t 543 \t 247 ]\n",
      "7 \tObject: person \tConfidence = 0.8077 \tBbox: [ 525 \t 252 \t 618 \t 549 ]\n",
      "8 \tObject: person \tConfidence = 0.7913 \tBbox: [ 636 \t 0 \t 686 \t 92 ]\n",
      "9 \tObject: person \tConfidence = 0.7565 \tBbox: [ 321 \t 482 \t 450 \t 809 ]\n",
      "10 \tObject: person \tConfidence = 0.5539 \tBbox: [ 450 \t 0 \t 503 \t 141 ]\n",
      "11 \tObject: person \tConfidence = 0.3461 \tBbox: [ 515 \t 0 \t 540 \t 36 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000363 / 1050\n",
      "Frames to be processed: 687  | To do: 65.43 % | Done: 34.57 %\n",
      "\n",
      "2022-04-20 13:13:15.204307\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000363.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 27.3ms pre-process, 173.0ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9392 \tBbox: [ 2 \t 3 \t 467 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.9109 \tBbox: [ 599 \t 130 \t 691 \t 354 ]\n",
      "3 \tObject: person \tConfidence = 0.9094 \tBbox: [ 179 \t 658 \t 426 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8982 \tBbox: [ 685 \t 68 \t 766 \t 307 ]\n",
      "5 \tObject: person \tConfidence = 0.8715 \tBbox: [ 387 \t 134 \t 461 \t 386 ]\n",
      "6 \tObject: person \tConfidence = 0.8496 \tBbox: [ 477 \t 17 \t 543 \t 247 ]\n",
      "7 \tObject: person \tConfidence = 0.8149 \tBbox: [ 525 \t 252 \t 618 \t 549 ]\n",
      "8 \tObject: person \tConfidence = 0.7633 \tBbox: [ 321 \t 482 \t 450 \t 808 ]\n",
      "9 \tObject: person \tConfidence = 0.7392 \tBbox: [ 644 \t 0 \t 684 \t 90 ]\n",
      "10 \tObject: person \tConfidence = 0.5436 \tBbox: [ 450 \t 1 \t 500 \t 141 ]\n",
      "11 \tObject: person \tConfidence = 0.3432 \tBbox: [ 630 \t 14 \t 657 \t 88 ]\n",
      "12 \tObject: person \tConfidence = 0.3188 \tBbox: [ 515 \t 0 \t 540 \t 34 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000364 / 1050\n",
      "Frames to be processed: 686  | To do: 65.33 % | Done: 34.67 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:13:15.670013\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000364.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 25.7ms pre-process, 169.2ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9385 \tBbox: [ 2 \t 2 \t 468 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.9142 \tBbox: [ 179 \t 658 \t 433 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9002 \tBbox: [ 600 \t 134 \t 691 \t 356 ]\n",
      "4 \tObject: person \tConfidence = 0.8958 \tBbox: [ 681 \t 69 \t 765 \t 310 ]\n",
      "5 \tObject: person \tConfidence = 0.8729 \tBbox: [ 386 \t 135 \t 461 \t 386 ]\n",
      "6 \tObject: person \tConfidence = 0.8434 \tBbox: [ 477 \t 17 \t 544 \t 247 ]\n",
      "7 \tObject: person \tConfidence = 0.8089 \tBbox: [ 524 \t 251 \t 620 \t 549 ]\n",
      "8 \tObject: person \tConfidence = 0.7447 \tBbox: [ 321 \t 482 \t 450 \t 809 ]\n",
      "9 \tObject: person \tConfidence = 0.7221 \tBbox: [ 643 \t 0 \t 684 \t 90 ]\n",
      "10 \tObject: person \tConfidence = 0.5431 \tBbox: [ 449 \t 0 \t 498 \t 142 ]\n",
      "11 \tObject: person \tConfidence = 0.3658 \tBbox: [ 628 \t 8 \t 659 \t 89 ]\n",
      "12 \tObject: person \tConfidence = 0.3126 \tBbox: [ 514 \t 0 \t 540 \t 33 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000365 / 1050\n",
      "Frames to be processed: 685  | To do: 65.24 % | Done: 34.76 %\n",
      "\n",
      "2022-04-20 13:13:16.212489\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000365.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 33.2ms pre-process, 177.7ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9316 \tBbox: [ 2 \t 2 \t 467 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.9164 \tBbox: [ 670 \t 72 \t 766 \t 315 ]\n",
      "3 \tObject: person \tConfidence = 0.9063 \tBbox: [ 180 \t 659 \t 421 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8963 \tBbox: [ 602 \t 137 \t 695 \t 372 ]\n",
      "5 \tObject: person \tConfidence = 0.8745 \tBbox: [ 387 \t 135 \t 460 \t 386 ]\n",
      "6 \tObject: person \tConfidence = 0.8358 \tBbox: [ 477 \t 12 \t 544 \t 247 ]\n",
      "7 \tObject: person \tConfidence = 0.8176 \tBbox: [ 524 \t 249 \t 617 \t 551 ]\n",
      "8 \tObject: person \tConfidence = 0.8049 \tBbox: [ 621 \t 0 \t 682 \t 90 ]\n",
      "9 \tObject: person \tConfidence = 0.757 \tBbox: [ 321 \t 483 \t 449 \t 804 ]\n",
      "10 \tObject: person \tConfidence = 0.612 \tBbox: [ 449 \t 0 \t 497 \t 141 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000366 / 1050\n",
      "Frames to be processed: 684  | To do: 65.14 % | Done: 34.86 %\n",
      "\n",
      "2022-04-20 13:13:16.679963\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000366.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 32.2ms pre-process, 172.6ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9328 \tBbox: [ 1 \t 2 \t 469 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.9171 \tBbox: [ 665 \t 74 \t 766 \t 320 ]\n",
      "3 \tObject: person \tConfidence = 0.907 \tBbox: [ 179 \t 659 \t 425 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8954 \tBbox: [ 603 \t 140 \t 695 \t 372 ]\n",
      "5 \tObject: person \tConfidence = 0.8758 \tBbox: [ 387 \t 135 \t 460 \t 387 ]\n",
      "6 \tObject: person \tConfidence = 0.8331 \tBbox: [ 477 \t 15 \t 544 \t 247 ]\n",
      "7 \tObject: person \tConfidence = 0.8158 \tBbox: [ 523 \t 248 \t 618 \t 551 ]\n",
      "8 \tObject: person \tConfidence = 0.7949 \tBbox: [ 618 \t 0 \t 682 \t 89 ]\n",
      "9 \tObject: person \tConfidence = 0.7824 \tBbox: [ 321 \t 484 \t 450 \t 798 ]\n",
      "10 \tObject: person \tConfidence = 0.5557 \tBbox: [ 449 \t 1 \t 498 \t 141 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000367 / 1050\n",
      "Frames to be processed: 683  | To do: 65.05 % | Done: 34.95 %\n",
      "\n",
      "2022-04-20 13:13:17.174188\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000367.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 30.9ms pre-process, 176.6ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9312 \tBbox: [ 1 \t 1 \t 469 \t 1073 ]\n",
      "2 \tObject: person \tConfidence = 0.9116 \tBbox: [ 662 \t 77 \t 766 \t 327 ]\n",
      "3 \tObject: person \tConfidence = 0.9108 \tBbox: [ 179 \t 659 \t 428 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8981 \tBbox: [ 603 \t 142 \t 695 \t 371 ]\n",
      "5 \tObject: person \tConfidence = 0.877 \tBbox: [ 387 \t 135 \t 460 \t 387 ]\n",
      "6 \tObject: person \tConfidence = 0.8357 \tBbox: [ 478 \t 17 \t 543 \t 247 ]\n",
      "7 \tObject: person \tConfidence = 0.8273 \tBbox: [ 523 \t 247 \t 616 \t 551 ]\n",
      "8 \tObject: person \tConfidence = 0.7495 \tBbox: [ 321 \t 483 \t 450 \t 803 ]\n",
      "9 \tObject: person \tConfidence = 0.7397 \tBbox: [ 621 \t 0 \t 680 \t 89 ]\n",
      "10 \tObject: person \tConfidence = 0.5712 \tBbox: [ 449 \t 0 \t 497 \t 142 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000368 / 1050\n",
      "Frames to be processed: 682  | To do: 64.95 % | Done: 35.05 %\n",
      "\n",
      "2022-04-20 13:13:17.584062\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000368.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 31.6ms pre-process, 180.4ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.922 \tBbox: [ 1 \t 1 \t 467 \t 1073 ]\n",
      "2 \tObject: person \tConfidence = 0.9086 \tBbox: [ 179 \t 659 \t 428 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9058 \tBbox: [ 602 \t 143 \t 695 \t 372 ]\n",
      "4 \tObject: person \tConfidence = 0.9021 \tBbox: [ 664 \t 79 \t 766 \t 332 ]\n",
      "5 \tObject: person \tConfidence = 0.8779 \tBbox: [ 387 \t 135 \t 460 \t 387 ]\n",
      "6 \tObject: person \tConfidence = 0.8313 \tBbox: [ 477 \t 14 \t 544 \t 247 ]\n",
      "7 \tObject: person \tConfidence = 0.8302 \tBbox: [ 523 \t 247 \t 615 \t 551 ]\n",
      "8 \tObject: person \tConfidence = 0.8038 \tBbox: [ 617 \t 0 \t 679 \t 91 ]\n",
      "9 \tObject: person \tConfidence = 0.7491 \tBbox: [ 321 \t 484 \t 450 \t 801 ]\n",
      "10 \tObject: person \tConfidence = 0.5949 \tBbox: [ 448 \t 0 \t 495 \t 140 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000369 / 1050\n",
      "Frames to be processed: 681  | To do: 64.86 % | Done: 35.14 %\n",
      "\n",
      "2022-04-20 13:13:18.036813\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000369.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 26.6ms pre-process, 173.0ms inference, 4.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9271 \tBbox: [ 1 \t 1 \t 465 \t 1073 ]\n",
      "2 \tObject: person \tConfidence = 0.9109 \tBbox: [ 179 \t 659 \t 430 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9028 \tBbox: [ 602 \t 144 \t 695 \t 372 ]\n",
      "4 \tObject: person \tConfidence = 0.8916 \tBbox: [ 664 \t 81 \t 766 \t 333 ]\n",
      "5 \tObject: person \tConfidence = 0.8749 \tBbox: [ 387 \t 135 \t 460 \t 387 ]\n",
      "6 \tObject: person \tConfidence = 0.8354 \tBbox: [ 523 \t 247 \t 611 \t 551 ]\n",
      "7 \tObject: person \tConfidence = 0.8023 \tBbox: [ 478 \t 21 \t 543 \t 248 ]\n",
      "8 \tObject: person \tConfidence = 0.7333 \tBbox: [ 623 \t 0 \t 678 \t 91 ]\n",
      "9 \tObject: person \tConfidence = 0.7298 \tBbox: [ 320 \t 485 \t 449 \t 795 ]\n",
      "10 \tObject: person \tConfidence = 0.6039 \tBbox: [ 448 \t 0 \t 498 \t 141 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000370 / 1050\n",
      "Frames to be processed: 680  | To do: 64.76 % | Done: 35.24 %\n",
      "\n",
      "2022-04-20 13:13:18.500920\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000370.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 28.0ms pre-process, 175.0ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9268 \tBbox: [ 0 \t 1 \t 465 \t 1073 ]\n",
      "2 \tObject: person \tConfidence = 0.9088 \tBbox: [ 179 \t 659 \t 430 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9084 \tBbox: [ 597 \t 147 \t 695 \t 372 ]\n",
      "4 \tObject: person \tConfidence = 0.872 \tBbox: [ 387 \t 135 \t 460 \t 387 ]\n",
      "5 \tObject: person \tConfidence = 0.8571 \tBbox: [ 523 \t 245 \t 608 \t 552 ]\n",
      "6 \tObject: person \tConfidence = 0.8394 \tBbox: [ 667 \t 85 \t 763 \t 332 ]\n",
      "7 \tObject: person \tConfidence = 0.8085 \tBbox: [ 616 \t 0 \t 676 \t 91 ]\n",
      "8 \tObject: person \tConfidence = 0.7905 \tBbox: [ 478 \t 17 \t 543 \t 248 ]\n",
      "9 \tObject: person \tConfidence = 0.7441 \tBbox: [ 320 \t 485 \t 449 \t 795 ]\n",
      "10 \tObject: person \tConfidence = 0.6349 \tBbox: [ 447 \t 0 \t 496 \t 141 ]\n",
      "11 \tObject: person \tConfidence = 0.3895 \tBbox: [ 673 \t 0 \t 695 \t 61 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000371 / 1050\n",
      "Frames to be processed: 679  | To do: 64.67 % | Done: 35.33 %\n",
      "\n",
      "2022-04-20 13:13:18.919094\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000371.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 28.2ms pre-process, 181.1ms inference, 3.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9309 \tBbox: [ 1 \t 0 \t 468 \t 1073 ]\n",
      "2 \tObject: person \tConfidence = 0.9148 \tBbox: [ 595 \t 148 \t 694 \t 373 ]\n",
      "3 \tObject: person \tConfidence = 0.9085 \tBbox: [ 180 \t 659 \t 428 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8693 \tBbox: [ 387 \t 135 \t 460 \t 387 ]\n",
      "5 \tObject: person \tConfidence = 0.862 \tBbox: [ 522 \t 245 \t 608 \t 552 ]\n",
      "6 \tObject: person \tConfidence = 0.8497 \tBbox: [ 667 \t 86 \t 760 \t 332 ]\n",
      "7 \tObject: person \tConfidence = 0.8042 \tBbox: [ 478 \t 8 \t 544 \t 248 ]\n",
      "8 \tObject: person \tConfidence = 0.7551 \tBbox: [ 616 \t 0 \t 676 \t 90 ]\n",
      "9 \tObject: person \tConfidence = 0.7435 \tBbox: [ 320 \t 484 \t 450 \t 795 ]\n",
      "10 \tObject: person \tConfidence = 0.6561 \tBbox: [ 448 \t 0 \t 494 \t 142 ]\n",
      "11 \tObject: person \tConfidence = 0.44 \tBbox: [ 672 \t 0 \t 696 \t 65 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000372 / 1050\n",
      "Frames to be processed: 678  | To do: 64.57 % | Done: 35.43 %\n",
      "\n",
      "2022-04-20 13:13:19.382326\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000372.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 30.8ms pre-process, 172.6ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.926 \tBbox: [ 0 \t 1 \t 466 \t 1074 ]\n",
      "2 \tObject: person \tConfidence = 0.916 \tBbox: [ 594 \t 150 \t 695 \t 372 ]\n",
      "3 \tObject: person \tConfidence = 0.9051 \tBbox: [ 181 \t 659 \t 424 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8628 \tBbox: [ 387 \t 135 \t 460 \t 387 ]\n",
      "5 \tObject: person \tConfidence = 0.8575 \tBbox: [ 522 \t 244 \t 608 \t 552 ]\n",
      "6 \tObject: person \tConfidence = 0.8539 \tBbox: [ 669 \t 87 \t 758 \t 323 ]\n",
      "7 \tObject: person \tConfidence = 0.8352 \tBbox: [ 478 \t 9 \t 544 \t 248 ]\n",
      "8 \tObject: person \tConfidence = 0.8082 \tBbox: [ 616 \t 0 \t 672 \t 89 ]\n",
      "9 \tObject: person \tConfidence = 0.7529 \tBbox: [ 320 \t 483 \t 451 \t 794 ]\n",
      "10 \tObject: person \tConfidence = 0.6917 \tBbox: [ 448 \t 0 \t 493 \t 142 ]\n",
      "11 \tObject: person \tConfidence = 0.4945 \tBbox: [ 668 \t 0 \t 694 \t 73 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000373 / 1050\n",
      "Frames to be processed: 677  | To do: 64.48 % | Done: 35.52 %\n",
      "\n",
      "2022-04-20 13:13:19.822514\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000373.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 25.7ms pre-process, 176.3ms inference, 10.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9241 \tBbox: [ 0 \t 1 \t 465 \t 1073 ]\n",
      "2 \tObject: person \tConfidence = 0.9045 \tBbox: [ 182 \t 659 \t 423 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9035 \tBbox: [ 591 \t 151 \t 694 \t 373 ]\n",
      "4 \tObject: person \tConfidence = 0.8609 \tBbox: [ 387 \t 135 \t 460 \t 387 ]\n",
      "5 \tObject: person \tConfidence = 0.8605 \tBbox: [ 670 \t 88 \t 756 \t 318 ]\n",
      "6 \tObject: person \tConfidence = 0.8587 \tBbox: [ 522 \t 243 \t 608 \t 552 ]\n",
      "7 \tObject: person \tConfidence = 0.8515 \tBbox: [ 615 \t 0 \t 671 \t 88 ]\n",
      "8 \tObject: person \tConfidence = 0.8283 \tBbox: [ 478 \t 13 \t 544 \t 248 ]\n",
      "9 \tObject: person \tConfidence = 0.7675 \tBbox: [ 320 \t 483 \t 450 \t 795 ]\n",
      "10 \tObject: person \tConfidence = 0.7119 \tBbox: [ 448 \t 0 \t 494 \t 143 ]\n",
      "11 \tObject: person \tConfidence = 0.3679 \tBbox: [ 668 \t 0 \t 694 \t 73 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000374 / 1050\n",
      "Frames to be processed: 676  | To do: 64.38 % | Done: 35.62 %\n",
      "\n",
      "2022-04-20 13:13:20.270953\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000374.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 24.9ms pre-process, 180.1ms inference, 2.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9154 \tBbox: [ 0 \t 0 \t 465 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.9044 \tBbox: [ 184 \t 660 \t 418 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9041 \tBbox: [ 588 \t 149 \t 694 \t 374 ]\n",
      "4 \tObject: person \tConfidence = 0.8622 \tBbox: [ 387 \t 135 \t 460 \t 387 ]\n",
      "5 \tObject: person \tConfidence = 0.8541 \tBbox: [ 669 \t 88 \t 754 \t 323 ]\n",
      "6 \tObject: person \tConfidence = 0.849 \tBbox: [ 521 \t 242 \t 609 \t 551 ]\n",
      "7 \tObject: person \tConfidence = 0.8311 \tBbox: [ 478 \t 17 \t 543 \t 248 ]\n",
      "8 \tObject: person \tConfidence = 0.7924 \tBbox: [ 319 \t 483 \t 451 \t 794 ]\n",
      "9 \tObject: person \tConfidence = 0.7518 \tBbox: [ 618 \t 0 \t 669 \t 87 ]\n",
      "10 \tObject: person \tConfidence = 0.6829 \tBbox: [ 448 \t 0 \t 494 \t 143 ]\n",
      "11 \tObject: person \tConfidence = 0.4379 \tBbox: [ 664 \t 0 \t 694 \t 75 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000375 / 1050\n",
      "Frames to be processed: 675  | To do: 64.29 % | Done: 35.71 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:13:20.734380\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000375.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 26.0ms pre-process, 168.6ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9278 \tBbox: [ 2 \t 0 \t 466 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.9104 \tBbox: [ 582 \t 159 \t 692 \t 374 ]\n",
      "3 \tObject: person \tConfidence = 0.9058 \tBbox: [ 183 \t 660 \t 420 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8623 \tBbox: [ 387 \t 135 \t 460 \t 388 ]\n",
      "5 \tObject: person \tConfidence = 0.8544 \tBbox: [ 477 \t 14 \t 544 \t 248 ]\n",
      "6 \tObject: person \tConfidence = 0.8521 \tBbox: [ 668 \t 88 \t 750 \t 322 ]\n",
      "7 \tObject: person \tConfidence = 0.8418 \tBbox: [ 521 \t 240 \t 611 \t 550 ]\n",
      "8 \tObject: person \tConfidence = 0.7744 \tBbox: [ 617 \t 0 \t 667 \t 87 ]\n",
      "9 \tObject: person \tConfidence = 0.7726 \tBbox: [ 319 \t 483 \t 450 \t 794 ]\n",
      "10 \tObject: person \tConfidence = 0.6981 \tBbox: [ 448 \t 0 \t 493 \t 143 ]\n",
      "11 \tObject: person \tConfidence = 0.6819 \tBbox: [ 657 \t 4 \t 695 \t 142 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000376 / 1050\n",
      "Frames to be processed: 674  | To do: 64.19 % | Done: 35.81 %\n",
      "\n",
      "2022-04-20 13:13:21.146965\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000376.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 45.2ms pre-process, 174.5ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9258 \tBbox: [ 2 \t 0 \t 467 \t 1065 ]\n",
      "2 \tObject: person \tConfidence = 0.907 \tBbox: [ 183 \t 661 \t 418 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8999 \tBbox: [ 581 \t 162 \t 690 \t 374 ]\n",
      "4 \tObject: person \tConfidence = 0.887 \tBbox: [ 665 \t 88 \t 749 \t 327 ]\n",
      "5 \tObject: person \tConfidence = 0.8583 \tBbox: [ 387 \t 135 \t 460 \t 388 ]\n",
      "6 \tObject: person \tConfidence = 0.8554 \tBbox: [ 477 \t 17 \t 543 \t 248 ]\n",
      "7 \tObject: person \tConfidence = 0.8476 \tBbox: [ 520 \t 240 \t 610 \t 549 ]\n",
      "8 \tObject: person \tConfidence = 0.7643 \tBbox: [ 319 \t 483 \t 450 \t 794 ]\n",
      "9 \tObject: person \tConfidence = 0.7497 \tBbox: [ 655 \t 4 \t 694 \t 143 ]\n",
      "10 \tObject: person \tConfidence = 0.7289 \tBbox: [ 618 \t 0 \t 666 \t 84 ]\n",
      "11 \tObject: person \tConfidence = 0.6947 \tBbox: [ 449 \t 0 \t 493 \t 142 ]\n",
      "12 \tObject: person \tConfidence = 0.3004 \tBbox: [ 513 \t 0 \t 540 \t 32 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000377 / 1050\n",
      "Frames to be processed: 673  | To do: 64.1 % | Done: 35.9 %\n",
      "\n",
      "2022-04-20 13:13:21.616769\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000377.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 27.2ms pre-process, 171.7ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9328 \tBbox: [ 2 \t 0 \t 468 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.9062 \tBbox: [ 182 \t 660 \t 420 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8922 \tBbox: [ 663 \t 89 \t 747 \t 331 ]\n",
      "4 \tObject: person \tConfidence = 0.8622 \tBbox: [ 581 \t 164 \t 690 \t 382 ]\n",
      "5 \tObject: person \tConfidence = 0.8539 \tBbox: [ 388 \t 135 \t 460 \t 388 ]\n",
      "6 \tObject: person \tConfidence = 0.8538 \tBbox: [ 477 \t 18 \t 543 \t 248 ]\n",
      "7 \tObject: person \tConfidence = 0.839 \tBbox: [ 520 \t 239 \t 612 \t 548 ]\n",
      "8 \tObject: person \tConfidence = 0.7746 \tBbox: [ 617 \t 0 \t 665 \t 86 ]\n",
      "9 \tObject: person \tConfidence = 0.7447 \tBbox: [ 319 \t 483 \t 450 \t 795 ]\n",
      "10 \tObject: person \tConfidence = 0.7346 \tBbox: [ 654 \t 2 \t 694 \t 143 ]\n",
      "11 \tObject: person \tConfidence = 0.651 \tBbox: [ 448 \t 0 \t 493 \t 142 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000378 / 1050\n",
      "Frames to be processed: 672  | To do: 64.0 % | Done: 36.0 %\n",
      "\n",
      "2022-04-20 13:13:22.092228\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000378.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 30.0ms pre-process, 174.0ms inference, 3.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9247 \tBbox: [ 1 \t 0 \t 465 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.9071 \tBbox: [ 182 \t 660 \t 423 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8982 \tBbox: [ 660 \t 89 \t 746 \t 337 ]\n",
      "4 \tObject: person \tConfidence = 0.8631 \tBbox: [ 581 \t 166 \t 690 \t 414 ]\n",
      "5 \tObject: person \tConfidence = 0.8547 \tBbox: [ 388 \t 135 \t 460 \t 388 ]\n",
      "6 \tObject: person \tConfidence = 0.8527 \tBbox: [ 476 \t 16 \t 543 \t 248 ]\n",
      "7 \tObject: person \tConfidence = 0.8418 \tBbox: [ 519 \t 238 \t 614 \t 547 ]\n",
      "8 \tObject: person \tConfidence = 0.8018 \tBbox: [ 653 \t 2 \t 694 \t 141 ]\n",
      "9 \tObject: person \tConfidence = 0.75 \tBbox: [ 619 \t 0 \t 663 \t 85 ]\n",
      "10 \tObject: person \tConfidence = 0.7402 \tBbox: [ 319 \t 483 \t 450 \t 796 ]\n",
      "11 \tObject: person \tConfidence = 0.6829 \tBbox: [ 448 \t 0 \t 493 \t 142 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000379 / 1050\n",
      "Frames to be processed: 671  | To do: 63.9 % | Done: 36.1 %\n",
      "\n",
      "2022-04-20 13:13:22.548652\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000379.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 23.4ms pre-process, 180.0ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9301 \tBbox: [ 2 \t 0 \t 467 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.9092 \tBbox: [ 181 \t 661 \t 425 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8891 \tBbox: [ 658 \t 91 \t 745 \t 346 ]\n",
      "4 \tObject: person \tConfidence = 0.8689 \tBbox: [ 582 \t 165 \t 690 \t 418 ]\n",
      "5 \tObject: person \tConfidence = 0.8557 \tBbox: [ 387 \t 135 \t 460 \t 388 ]\n",
      "6 \tObject: person \tConfidence = 0.8508 \tBbox: [ 477 \t 17 \t 543 \t 248 ]\n",
      "7 \tObject: person \tConfidence = 0.8343 \tBbox: [ 516 \t 238 \t 611 \t 546 ]\n",
      "8 \tObject: person \tConfidence = 0.7778 \tBbox: [ 651 \t 1 \t 693 \t 141 ]\n",
      "9 \tObject: person \tConfidence = 0.7706 \tBbox: [ 617 \t 0 \t 663 \t 88 ]\n",
      "10 \tObject: person \tConfidence = 0.7525 \tBbox: [ 318 \t 482 \t 451 \t 796 ]\n",
      "11 \tObject: person \tConfidence = 0.6713 \tBbox: [ 448 \t 0 \t 493 \t 142 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000380 / 1050\n",
      "Frames to be processed: 670  | To do: 63.81 % | Done: 36.19 %\n",
      "\n",
      "2022-04-20 13:13:22.999231\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000380.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 32.2ms pre-process, 180.7ms inference, 4.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9356 \tBbox: [ 1 \t 1 \t 467 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.9105 \tBbox: [ 181 \t 662 \t 426 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9017 \tBbox: [ 654 \t 91 \t 744 \t 352 ]\n",
      "4 \tObject: person \tConfidence = 0.8974 \tBbox: [ 581 \t 167 \t 690 \t 420 ]\n",
      "5 \tObject: person \tConfidence = 0.8601 \tBbox: [ 388 \t 135 \t 460 \t 388 ]\n",
      "6 \tObject: person \tConfidence = 0.8528 \tBbox: [ 477 \t 18 \t 543 \t 248 ]\n",
      "7 \tObject: person \tConfidence = 0.8389 \tBbox: [ 511 \t 238 \t 610 \t 545 ]\n",
      "8 \tObject: person \tConfidence = 0.7728 \tBbox: [ 318 \t 483 \t 449 \t 796 ]\n",
      "9 \tObject: person \tConfidence = 0.7627 \tBbox: [ 649 \t 0 \t 693 \t 141 ]\n",
      "10 \tObject: person \tConfidence = 0.7212 \tBbox: [ 616 \t 0 \t 660 \t 88 ]\n",
      "11 \tObject: person \tConfidence = 0.6989 \tBbox: [ 449 \t 0 \t 493 \t 141 ]\n",
      "12 \tObject: person \tConfidence = 0.3235 \tBbox: [ 513 \t 0 \t 540 \t 32 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000381 / 1050\n",
      "Frames to be processed: 669  | To do: 63.71 % | Done: 36.29 %\n",
      "\n",
      "2022-04-20 13:13:23.425435\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000381.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 25.3ms pre-process, 170.8ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9364 \tBbox: [ 2 \t 1 \t 467 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.9101 \tBbox: [ 180 \t 662 \t 428 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8843 \tBbox: [ 651 \t 95 \t 741 \t 364 ]\n",
      "4 \tObject: person \tConfidence = 0.8775 \tBbox: [ 585 \t 168 \t 691 \t 421 ]\n",
      "5 \tObject: person \tConfidence = 0.859 \tBbox: [ 477 \t 23 \t 543 \t 248 ]\n",
      "6 \tObject: person \tConfidence = 0.8558 \tBbox: [ 388 \t 135 \t 460 \t 387 ]\n",
      "7 \tObject: person \tConfidence = 0.8493 \tBbox: [ 501 \t 238 \t 601 \t 540 ]\n",
      "8 \tObject: person \tConfidence = 0.7695 \tBbox: [ 317 \t 481 \t 453 \t 797 ]\n",
      "9 \tObject: person \tConfidence = 0.7506 \tBbox: [ 641 \t 0 \t 694 \t 143 ]\n",
      "10 \tObject: person \tConfidence = 0.7157 \tBbox: [ 615 \t 0 \t 656 \t 86 ]\n",
      "11 \tObject: person \tConfidence = 0.6738 \tBbox: [ 448 \t 0 \t 493 \t 142 ]\n",
      "12 \tObject: person \tConfidence = 0.3847 \tBbox: [ 514 \t 0 \t 539 \t 33 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000382 / 1050\n",
      "Frames to be processed: 668  | To do: 63.62 % | Done: 36.38 %\n",
      "\n",
      "2022-04-20 13:13:23.908446\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000382.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 25.9ms pre-process, 173.0ms inference, 10.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9392 \tBbox: [ 2 \t 0 \t 466 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.912 \tBbox: [ 178 \t 662 \t 425 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8645 \tBbox: [ 651 \t 96 \t 738 \t 368 ]\n",
      "4 \tObject: person \tConfidence = 0.8611 \tBbox: [ 496 \t 237 \t 601 \t 537 ]\n",
      "5 \tObject: person \tConfidence = 0.8574 \tBbox: [ 477 \t 23 \t 543 \t 248 ]\n",
      "6 \tObject: person \tConfidence = 0.8568 \tBbox: [ 388 \t 135 \t 460 \t 388 ]\n",
      "7 \tObject: person \tConfidence = 0.8498 \tBbox: [ 588 \t 168 \t 692 \t 422 ]\n",
      "8 \tObject: person \tConfidence = 0.8374 \tBbox: [ 634 \t 0 \t 695 \t 144 ]\n",
      "9 \tObject: person \tConfidence = 0.7861 \tBbox: [ 317 \t 475 \t 461 \t 803 ]\n",
      "10 \tObject: person \tConfidence = 0.7247 \tBbox: [ 615 \t 0 \t 656 \t 86 ]\n",
      "11 \tObject: person \tConfidence = 0.6504 \tBbox: [ 448 \t 0 \t 493 \t 142 ]\n",
      "12 \tObject: person \tConfidence = 0.5633 \tBbox: [ 711 \t 540 \t 766 \t 604 ]\n",
      "13 \tObject: person \tConfidence = 0.3784 \tBbox: [ 514 \t 0 \t 539 \t 33 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000383 / 1050\n",
      "Frames to be processed: 667  | To do: 63.52 % | Done: 36.48 %\n",
      "\n",
      "2022-04-20 13:13:24.368931\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000383.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 25.7ms pre-process, 175.6ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9322 \tBbox: [ 2 \t 1 \t 466 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.912 \tBbox: [ 177 \t 662 \t 425 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8665 \tBbox: [ 628 \t 0 \t 696 \t 145 ]\n",
      "4 \tObject: person \tConfidence = 0.8585 \tBbox: [ 591 \t 168 \t 693 \t 422 ]\n",
      "5 \tObject: person \tConfidence = 0.8566 \tBbox: [ 388 \t 135 \t 460 \t 388 ]\n",
      "6 \tObject: person \tConfidence = 0.8564 \tBbox: [ 490 \t 237 \t 602 \t 536 ]\n",
      "7 \tObject: person \tConfidence = 0.8499 \tBbox: [ 477 \t 22 \t 543 \t 248 ]\n",
      "8 \tObject: person \tConfidence = 0.7752 \tBbox: [ 651 \t 99 \t 737 \t 340 ]\n",
      "9 \tObject: person \tConfidence = 0.7639 \tBbox: [ 317 \t 475 \t 459 \t 804 ]\n",
      "10 \tObject: person \tConfidence = 0.6728 \tBbox: [ 615 \t 0 \t 654 \t 87 ]\n",
      "11 \tObject: person \tConfidence = 0.6393 \tBbox: [ 448 \t 0 \t 494 \t 141 ]\n",
      "12 \tObject: person \tConfidence = 0.3449 \tBbox: [ 514 \t 0 \t 539 \t 33 ]\n",
      "13 \tObject: person \tConfidence = 0.3017 \tBbox: [ 712 \t 380 \t 765 \t 602 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000384 / 1050\n",
      "Frames to be processed: 666  | To do: 63.43 % | Done: 36.57 %\n",
      "\n",
      "2022-04-20 13:13:24.793972\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000384.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 26.3ms pre-process, 169.7ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9337 \tBbox: [ 2 \t 1 \t 467 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.912 \tBbox: [ 177 \t 662 \t 428 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8826 \tBbox: [ 595 \t 168 \t 695 \t 421 ]\n",
      "4 \tObject: person \tConfidence = 0.8567 \tBbox: [ 388 \t 135 \t 460 \t 387 ]\n",
      "5 \tObject: person \tConfidence = 0.8472 \tBbox: [ 477 \t 21 \t 543 \t 248 ]\n",
      "6 \tObject: person \tConfidence = 0.8419 \tBbox: [ 625 \t 1 \t 695 \t 146 ]\n",
      "7 \tObject: person \tConfidence = 0.8228 \tBbox: [ 486 \t 237 \t 605 \t 533 ]\n",
      "8 \tObject: person \tConfidence = 0.8042 \tBbox: [ 651 \t 104 \t 736 \t 285 ]\n",
      "9 \tObject: person \tConfidence = 0.7626 \tBbox: [ 317 \t 482 \t 452 \t 799 ]\n",
      "10 \tObject: person \tConfidence = 0.652 \tBbox: [ 448 \t 0 \t 493 \t 141 ]\n",
      "11 \tObject: person \tConfidence = 0.6499 \tBbox: [ 614 \t 0 \t 654 \t 84 ]\n",
      "12 \tObject: person \tConfidence = 0.5294 \tBbox: [ 711 \t 387 \t 765 \t 603 ]\n",
      "13 \tObject: person \tConfidence = 0.3356 \tBbox: [ 513 \t 0 \t 539 \t 33 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000385 / 1050\n",
      "Frames to be processed: 665  | To do: 63.33 % | Done: 36.67 %\n",
      "\n",
      "2022-04-20 13:13:25.267232\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000385.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 33.9ms pre-process, 174.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.93 \tBbox: [ 2 \t 1 \t 467 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.9134 \tBbox: [ 176 \t 662 \t 429 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8967 \tBbox: [ 597 \t 169 \t 697 \t 420 ]\n",
      "4 \tObject: person \tConfidence = 0.8608 \tBbox: [ 388 \t 135 \t 460 \t 388 ]\n",
      "5 \tObject: person \tConfidence = 0.8474 \tBbox: [ 477 \t 22 \t 542 \t 248 ]\n",
      "6 \tObject: person \tConfidence = 0.8405 \tBbox: [ 481 \t 235 \t 599 \t 531 ]\n",
      "7 \tObject: person \tConfidence = 0.8342 \tBbox: [ 620 \t 0 \t 694 \t 148 ]\n",
      "8 \tObject: person \tConfidence = 0.7864 \tBbox: [ 650 \t 106 \t 735 \t 287 ]\n",
      "9 \tObject: person \tConfidence = 0.6939 \tBbox: [ 316 \t 483 \t 451 \t 800 ]\n",
      "10 \tObject: person \tConfidence = 0.6449 \tBbox: [ 613 \t 0 \t 653 \t 82 ]\n",
      "11 \tObject: person \tConfidence = 0.6014 \tBbox: [ 448 \t 0 \t 494 \t 141 ]\n",
      "12 \tObject: person \tConfidence = 0.5527 \tBbox: [ 710 \t 382 \t 766 \t 600 ]\n",
      "13 \tObject: person \tConfidence = 0.3324 \tBbox: [ 513 \t 0 \t 539 \t 34 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000386 / 1050\n",
      "Frames to be processed: 664  | To do: 63.24 % | Done: 36.76 %\n",
      "\n",
      "2022-04-20 13:13:25.730288\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000386.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 46.9ms pre-process, 175.9ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9291 \tBbox: [ 2 \t 3 \t 466 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.9124 \tBbox: [ 600 \t 173 \t 703 \t 430 ]\n",
      "3 \tObject: person \tConfidence = 0.9094 \tBbox: [ 176 \t 662 \t 424 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8717 \tBbox: [ 647 \t 109 \t 734 \t 274 ]\n",
      "5 \tObject: person \tConfidence = 0.8584 \tBbox: [ 387 \t 135 \t 460 \t 388 ]\n",
      "6 \tObject: person \tConfidence = 0.8495 \tBbox: [ 475 \t 235 \t 602 \t 529 ]\n",
      "7 \tObject: person \tConfidence = 0.8472 \tBbox: [ 477 \t 22 \t 543 \t 248 ]\n",
      "8 \tObject: person \tConfidence = 0.8127 \tBbox: [ 620 \t 0 \t 692 \t 156 ]\n",
      "9 \tObject: person \tConfidence = 0.7121 \tBbox: [ 316 \t 482 \t 452 \t 801 ]\n",
      "10 \tObject: person \tConfidence = 0.6325 \tBbox: [ 710 \t 359 \t 765 \t 604 ]\n",
      "11 \tObject: person \tConfidence = 0.5522 \tBbox: [ 611 \t 0 \t 651 \t 83 ]\n",
      "12 \tObject: person \tConfidence = 0.5491 \tBbox: [ 449 \t 1 \t 500 \t 143 ]\n",
      "13 \tObject: person \tConfidence = 0.3257 \tBbox: [ 513 \t 0 \t 539 \t 33 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000387 / 1050\n",
      "Frames to be processed: 663  | To do: 63.14 % | Done: 36.86 %\n",
      "\n",
      "2022-04-20 13:13:26.206037\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000387.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 25.4ms pre-process, 178.3ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.935 \tBbox: [ 2 \t 2 \t 466 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.9112 \tBbox: [ 176 \t 663 \t 426 \t 1077 ]\n",
      "3 \tObject: person \tConfidence = 0.9103 \tBbox: [ 602 \t 174 \t 707 \t 436 ]\n",
      "4 \tObject: person \tConfidence = 0.8638 \tBbox: [ 387 \t 135 \t 460 \t 388 ]\n",
      "5 \tObject: person \tConfidence = 0.8531 \tBbox: [ 472 \t 234 \t 599 \t 529 ]\n",
      "6 \tObject: person \tConfidence = 0.8436 \tBbox: [ 477 \t 22 \t 542 \t 248 ]\n",
      "7 \tObject: person \tConfidence = 0.8417 \tBbox: [ 646 \t 111 \t 732 \t 275 ]\n",
      "8 \tObject: person \tConfidence = 0.7723 \tBbox: [ 616 \t 0 \t 691 \t 158 ]\n",
      "9 \tObject: person \tConfidence = 0.6972 \tBbox: [ 315 \t 484 \t 448 \t 801 ]\n",
      "10 \tObject: person \tConfidence = 0.6248 \tBbox: [ 707 \t 354 \t 766 \t 601 ]\n",
      "11 \tObject: person \tConfidence = 0.5026 \tBbox: [ 450 \t 1 \t 501 \t 142 ]\n",
      "12 \tObject: person \tConfidence = 0.4908 \tBbox: [ 609 \t 0 \t 650 \t 83 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000388 / 1050\n",
      "Frames to be processed: 662  | To do: 63.05 % | Done: 36.95 %\n",
      "\n",
      "2022-04-20 13:13:26.630797\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000388.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 24.6ms pre-process, 171.3ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9272 \tBbox: [ 1 \t 2 \t 467 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.9131 \tBbox: [ 603 \t 176 \t 708 \t 438 ]\n",
      "3 \tObject: person \tConfidence = 0.9129 \tBbox: [ 176 \t 662 \t 425 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.867 \tBbox: [ 387 \t 135 \t 460 \t 387 ]\n",
      "5 \tObject: person \tConfidence = 0.8547 \tBbox: [ 469 \t 235 \t 613 \t 529 ]\n",
      "6 \tObject: person \tConfidence = 0.8509 \tBbox: [ 477 \t 23 \t 542 \t 248 ]\n",
      "7 \tObject: person \tConfidence = 0.8462 \tBbox: [ 643 \t 113 \t 731 \t 277 ]\n",
      "8 \tObject: person \tConfidence = 0.7812 \tBbox: [ 614 \t 0 \t 690 \t 159 ]\n",
      "9 \tObject: person \tConfidence = 0.7276 \tBbox: [ 315 \t 484 \t 446 \t 800 ]\n",
      "10 \tObject: person \tConfidence = 0.6718 \tBbox: [ 708 \t 296 \t 766 \t 604 ]\n",
      "11 \tObject: person \tConfidence = 0.5252 \tBbox: [ 448 \t 0 \t 499 \t 142 ]\n",
      "12 \tObject: person \tConfidence = 0.4905 \tBbox: [ 609 \t 0 \t 649 \t 80 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000389 / 1050\n",
      "Frames to be processed: 661  | To do: 62.95 % | Done: 37.05 %\n",
      "\n",
      "2022-04-20 13:13:27.072271\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000389.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 28.6ms pre-process, 178.7ms inference, 3.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.932 \tBbox: [ 2 \t 2 \t 465 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.913 \tBbox: [ 175 \t 663 \t 427 \t 1077 ]\n",
      "3 \tObject: person \tConfidence = 0.9022 \tBbox: [ 604 \t 181 \t 711 \t 439 ]\n",
      "4 \tObject: person \tConfidence = 0.8798 \tBbox: [ 465 \t 234 \t 614 \t 530 ]\n",
      "5 \tObject: person \tConfidence = 0.8664 \tBbox: [ 387 \t 135 \t 460 \t 387 ]\n",
      "6 \tObject: person \tConfidence = 0.85 \tBbox: [ 477 \t 23 \t 542 \t 248 ]\n",
      "7 \tObject: person \tConfidence = 0.8369 \tBbox: [ 641 \t 113 \t 730 \t 280 ]\n",
      "8 \tObject: person \tConfidence = 0.7713 \tBbox: [ 615 \t 0 \t 688 \t 159 ]\n",
      "9 \tObject: person \tConfidence = 0.7201 \tBbox: [ 315 \t 485 \t 445 \t 801 ]\n",
      "10 \tObject: person \tConfidence = 0.696 \tBbox: [ 705 \t 288 \t 766 \t 620 ]\n",
      "11 \tObject: person \tConfidence = 0.5047 \tBbox: [ 449 \t 1 \t 503 \t 142 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000390 / 1050\n",
      "Frames to be processed: 660  | To do: 62.86 % | Done: 37.14 %\n",
      "\n",
      "2022-04-20 13:13:27.540855\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000390.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 28.4ms pre-process, 170.3ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9262 \tBbox: [ 2 \t 1 \t 464 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.9197 \tBbox: [ 175 \t 662 \t 432 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9008 \tBbox: [ 605 \t 185 \t 713 \t 444 ]\n",
      "4 \tObject: person \tConfidence = 0.897 \tBbox: [ 463 \t 234 \t 613 \t 530 ]\n",
      "5 \tObject: person \tConfidence = 0.8656 \tBbox: [ 389 \t 136 \t 460 \t 388 ]\n",
      "6 \tObject: person \tConfidence = 0.8539 \tBbox: [ 477 \t 23 \t 542 \t 248 ]\n",
      "7 \tObject: person \tConfidence = 0.8336 \tBbox: [ 631 \t 115 \t 730 \t 281 ]\n",
      "8 \tObject: person \tConfidence = 0.7806 \tBbox: [ 614 \t 0 \t 684 \t 159 ]\n",
      "9 \tObject: person \tConfidence = 0.7756 \tBbox: [ 700 \t 282 \t 766 \t 628 ]\n",
      "10 \tObject: person \tConfidence = 0.7222 \tBbox: [ 315 \t 483 \t 445 \t 807 ]\n",
      "11 \tObject: person \tConfidence = 0.534 \tBbox: [ 450 \t 4 \t 505 \t 143 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000391 / 1050\n",
      "Frames to be processed: 659  | To do: 62.76 % | Done: 37.24 %\n",
      "\n",
      "2022-04-20 13:13:27.980824\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000391.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 23.8ms pre-process, 170.4ms inference, 11.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.928 \tBbox: [ 0 \t 1 \t 465 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.9182 \tBbox: [ 175 \t 662 \t 430 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9073 \tBbox: [ 461 \t 233 \t 614 \t 530 ]\n",
      "4 \tObject: person \tConfidence = 0.8976 \tBbox: [ 682 \t 274 \t 765 \t 624 ]\n",
      "5 \tObject: person \tConfidence = 0.8856 \tBbox: [ 608 \t 191 \t 717 \t 456 ]\n",
      "6 \tObject: person \tConfidence = 0.8672 \tBbox: [ 388 \t 136 \t 460 \t 388 ]\n",
      "7 \tObject: person \tConfidence = 0.8569 \tBbox: [ 477 \t 23 \t 542 \t 248 ]\n",
      "8 \tObject: person \tConfidence = 0.8272 \tBbox: [ 610 \t 0 \t 681 \t 160 ]\n",
      "9 \tObject: person \tConfidence = 0.8045 \tBbox: [ 628 \t 116 \t 727 \t 276 ]\n",
      "10 \tObject: person \tConfidence = 0.7185 \tBbox: [ 315 \t 483 \t 445 \t 809 ]\n",
      "11 \tObject: person \tConfidence = 0.5814 \tBbox: [ 450 \t 5 \t 503 \t 143 ]\n",
      "12 \tObject: person \tConfidence = 0.3042 \tBbox: [ 512 \t 0 \t 538 \t 33 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000392 / 1050\n",
      "Frames to be processed: 658  | To do: 62.67 % | Done: 37.33 %\n",
      "\n",
      "2022-04-20 13:13:28.482651\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000392.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 24.5ms pre-process, 173.8ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9274 \tBbox: [ 1 \t 1 \t 466 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.9176 \tBbox: [ 669 \t 275 \t 766 \t 623 ]\n",
      "3 \tObject: person \tConfidence = 0.9159 \tBbox: [ 175 \t 663 \t 431 \t 1077 ]\n",
      "4 \tObject: person \tConfidence = 0.9003 \tBbox: [ 460 \t 233 \t 613 \t 530 ]\n",
      "5 \tObject: person \tConfidence = 0.8911 \tBbox: [ 610 \t 194 \t 719 \t 465 ]\n",
      "6 \tObject: person \tConfidence = 0.8641 \tBbox: [ 389 \t 136 \t 460 \t 387 ]\n",
      "7 \tObject: person \tConfidence = 0.8608 \tBbox: [ 478 \t 23 \t 542 \t 248 ]\n",
      "8 \tObject: person \tConfidence = 0.843 \tBbox: [ 608 \t 0 \t 680 \t 162 ]\n",
      "9 \tObject: person \tConfidence = 0.8253 \tBbox: [ 628 \t 117 \t 726 \t 271 ]\n",
      "10 \tObject: person \tConfidence = 0.7546 \tBbox: [ 315 \t 484 \t 445 \t 807 ]\n",
      "11 \tObject: person \tConfidence = 0.5786 \tBbox: [ 451 \t 3 \t 502 \t 143 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000393 / 1050\n",
      "Frames to be processed: 657  | To do: 62.57 % | Done: 37.43 %\n",
      "\n",
      "2022-04-20 13:13:28.931560\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000393.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 34.8ms pre-process, 175.3ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.929 \tBbox: [ 1 \t 1 \t 465 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.9258 \tBbox: [ 655 \t 274 \t 765 \t 619 ]\n",
      "3 \tObject: person \tConfidence = 0.9157 \tBbox: [ 175 \t 663 \t 431 \t 1077 ]\n",
      "4 \tObject: person \tConfidence = 0.9065 \tBbox: [ 460 \t 232 \t 612 \t 530 ]\n",
      "5 \tObject: person \tConfidence = 0.8965 \tBbox: [ 611 \t 197 \t 721 \t 468 ]\n",
      "6 \tObject: person \tConfidence = 0.8595 \tBbox: [ 477 \t 23 \t 542 \t 248 ]\n",
      "7 \tObject: person \tConfidence = 0.8576 \tBbox: [ 389 \t 136 \t 460 \t 388 ]\n",
      "8 \tObject: person \tConfidence = 0.8259 \tBbox: [ 608 \t 0 \t 679 \t 166 ]\n",
      "9 \tObject: person \tConfidence = 0.8094 \tBbox: [ 625 \t 117 \t 726 \t 265 ]\n",
      "10 \tObject: person \tConfidence = 0.753 \tBbox: [ 315 \t 483 \t 445 \t 807 ]\n",
      "11 \tObject: person \tConfidence = 0.571 \tBbox: [ 451 \t 4 \t 503 \t 143 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000394 / 1050\n",
      "Frames to be processed: 656  | To do: 62.48 % | Done: 37.52 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:13:29.376564\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000394.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 24.6ms pre-process, 169.2ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9263 \tBbox: [ 1 \t 1 \t 465 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.9226 \tBbox: [ 639 \t 274 \t 765 \t 615 ]\n",
      "3 \tObject: person \tConfidence = 0.9172 \tBbox: [ 175 \t 662 \t 431 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.9042 \tBbox: [ 460 \t 233 \t 612 \t 530 ]\n",
      "5 \tObject: person \tConfidence = 0.8814 \tBbox: [ 614 \t 198 \t 723 \t 468 ]\n",
      "6 \tObject: person \tConfidence = 0.8619 \tBbox: [ 625 \t 117 \t 725 \t 258 ]\n",
      "7 \tObject: person \tConfidence = 0.8576 \tBbox: [ 477 \t 23 \t 542 \t 248 ]\n",
      "8 \tObject: person \tConfidence = 0.8557 \tBbox: [ 389 \t 136 \t 460 \t 388 ]\n",
      "9 \tObject: person \tConfidence = 0.8054 \tBbox: [ 606 \t 0 \t 679 \t 165 ]\n",
      "10 \tObject: person \tConfidence = 0.7486 \tBbox: [ 314 \t 483 \t 445 \t 807 ]\n",
      "11 \tObject: person \tConfidence = 0.5938 \tBbox: [ 450 \t 3 \t 505 \t 143 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000395 / 1050\n",
      "Frames to be processed: 655  | To do: 62.38 % | Done: 37.62 %\n",
      "\n",
      "2022-04-20 13:13:29.845340\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000395.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 23.7ms pre-process, 174.1ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9285 \tBbox: [ 1 \t 2 \t 465 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.9186 \tBbox: [ 626 \t 275 \t 765 \t 612 ]\n",
      "3 \tObject: person \tConfidence = 0.9156 \tBbox: [ 175 \t 663 \t 429 \t 1077 ]\n",
      "4 \tObject: person \tConfidence = 0.9019 \tBbox: [ 461 \t 232 \t 609 \t 530 ]\n",
      "5 \tObject: person \tConfidence = 0.8687 \tBbox: [ 625 \t 118 \t 724 \t 261 ]\n",
      "6 \tObject: person \tConfidence = 0.8617 \tBbox: [ 477 \t 23 \t 541 \t 248 ]\n",
      "7 \tObject: person \tConfidence = 0.8613 \tBbox: [ 614 \t 199 \t 722 \t 467 ]\n",
      "8 \tObject: person \tConfidence = 0.8539 \tBbox: [ 389 \t 136 \t 460 \t 388 ]\n",
      "9 \tObject: person \tConfidence = 0.8198 \tBbox: [ 604 \t 0 \t 681 \t 172 ]\n",
      "10 \tObject: person \tConfidence = 0.7721 \tBbox: [ 314 \t 485 \t 445 \t 803 ]\n",
      "11 \tObject: person \tConfidence = 0.6133 \tBbox: [ 450 \t 3 \t 504 \t 144 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000396 / 1050\n",
      "Frames to be processed: 654  | To do: 62.29 % | Done: 37.71 %\n",
      "\n",
      "2022-04-20 13:13:30.297054\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000396.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 31.0ms pre-process, 176.2ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9305 \tBbox: [ 2 \t 3 \t 466 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.9161 \tBbox: [ 175 \t 663 \t 427 \t 1077 ]\n",
      "3 \tObject: person \tConfidence = 0.9056 \tBbox: [ 611 \t 275 \t 766 \t 609 ]\n",
      "4 \tObject: person \tConfidence = 0.9035 \tBbox: [ 463 \t 232 \t 608 \t 530 ]\n",
      "5 \tObject: person \tConfidence = 0.8604 \tBbox: [ 477 \t 23 \t 542 \t 248 ]\n",
      "6 \tObject: person \tConfidence = 0.8522 \tBbox: [ 388 \t 136 \t 460 \t 388 ]\n",
      "7 \tObject: person \tConfidence = 0.8459 \tBbox: [ 618 \t 202 \t 715 \t 469 ]\n",
      "8 \tObject: person \tConfidence = 0.8397 \tBbox: [ 621 \t 121 \t 721 \t 304 ]\n",
      "9 \tObject: person \tConfidence = 0.8053 \tBbox: [ 601 \t 0 \t 680 \t 169 ]\n",
      "10 \tObject: person \tConfidence = 0.7747 \tBbox: [ 315 \t 485 \t 445 \t 801 ]\n",
      "11 \tObject: person \tConfidence = 0.6413 \tBbox: [ 448 \t 2 \t 504 \t 144 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000397 / 1050\n",
      "Frames to be processed: 653  | To do: 62.19 % | Done: 37.81 %\n",
      "\n",
      "2022-04-20 13:13:30.806383\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000397.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 26.8ms pre-process, 177.2ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9285 \tBbox: [ 2 \t 3 \t 465 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.9162 \tBbox: [ 174 \t 663 \t 428 \t 1077 ]\n",
      "3 \tObject: person \tConfidence = 0.9128 \tBbox: [ 464 \t 232 \t 607 \t 530 ]\n",
      "4 \tObject: person \tConfidence = 0.9107 \tBbox: [ 606 \t 277 \t 766 \t 608 ]\n",
      "5 \tObject: person \tConfidence = 0.8658 \tBbox: [ 477 \t 24 \t 542 \t 248 ]\n",
      "6 \tObject: person \tConfidence = 0.8572 \tBbox: [ 620 \t 122 \t 721 \t 314 ]\n",
      "7 \tObject: person \tConfidence = 0.8517 \tBbox: [ 388 \t 136 \t 460 \t 388 ]\n",
      "8 \tObject: person \tConfidence = 0.8277 \tBbox: [ 620 \t 203 \t 716 \t 459 ]\n",
      "9 \tObject: person \tConfidence = 0.8152 \tBbox: [ 599 \t 0 \t 680 \t 176 ]\n",
      "10 \tObject: person \tConfidence = 0.7508 \tBbox: [ 315 \t 484 \t 445 \t 800 ]\n",
      "11 \tObject: person \tConfidence = 0.6413 \tBbox: [ 448 \t 1 \t 502 \t 144 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000398 / 1050\n",
      "Frames to be processed: 652  | To do: 62.1 % | Done: 37.9 %\n",
      "\n",
      "2022-04-20 13:13:31.254888\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000398.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 27.0ms pre-process, 179.8ms inference, 4.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9306 \tBbox: [ 2 \t 2 \t 464 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.9199 \tBbox: [ 174 \t 663 \t 431 \t 1077 ]\n",
      "3 \tObject: person \tConfidence = 0.9093 \tBbox: [ 466 \t 232 \t 608 \t 530 ]\n",
      "4 \tObject: person \tConfidence = 0.9065 \tBbox: [ 601 \t 279 \t 766 \t 608 ]\n",
      "5 \tObject: person \tConfidence = 0.8639 \tBbox: [ 477 \t 23 \t 542 \t 248 ]\n",
      "6 \tObject: person \tConfidence = 0.8546 \tBbox: [ 388 \t 135 \t 460 \t 388 ]\n",
      "7 \tObject: person \tConfidence = 0.8187 \tBbox: [ 618 \t 201 \t 718 \t 448 ]\n",
      "8 \tObject: person \tConfidence = 0.8055 \tBbox: [ 598 \t 0 \t 679 \t 177 ]\n",
      "9 \tObject: person \tConfidence = 0.7983 \tBbox: [ 315 \t 484 \t 445 \t 801 ]\n",
      "10 \tObject: person \tConfidence = 0.7812 \tBbox: [ 618 \t 124 \t 718 \t 326 ]\n",
      "11 \tObject: person \tConfidence = 0.6345 \tBbox: [ 448 \t 1 \t 503 \t 143 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000399 / 1050\n",
      "Frames to be processed: 651  | To do: 62.0 % | Done: 38.0 %\n",
      "\n",
      "2022-04-20 13:13:31.731619\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000399.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 32.9ms pre-process, 173.0ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9288 \tBbox: [ 2 \t 3 \t 464 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.9193 \tBbox: [ 174 \t 663 \t 431 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9175 \tBbox: [ 599 \t 281 \t 765 \t 606 ]\n",
      "4 \tObject: person \tConfidence = 0.9048 \tBbox: [ 468 \t 231 \t 606 \t 529 ]\n",
      "5 \tObject: person \tConfidence = 0.8622 \tBbox: [ 477 \t 23 \t 542 \t 248 ]\n",
      "6 \tObject: person \tConfidence = 0.8537 \tBbox: [ 388 \t 136 \t 460 \t 388 ]\n",
      "7 \tObject: person \tConfidence = 0.8398 \tBbox: [ 598 \t 0 \t 679 \t 178 ]\n",
      "8 \tObject: person \tConfidence = 0.8066 \tBbox: [ 315 \t 484 \t 445 \t 803 ]\n",
      "9 \tObject: person \tConfidence = 0.7593 \tBbox: [ 617 \t 204 \t 725 \t 391 ]\n",
      "10 \tObject: person \tConfidence = 0.6546 \tBbox: [ 617 \t 125 \t 717 \t 323 ]\n",
      "11 \tObject: person \tConfidence = 0.6284 \tBbox: [ 448 \t 1 \t 500 \t 143 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000400 / 1050\n",
      "Frames to be processed: 650  | To do: 61.9 % | Done: 38.1 %\n",
      "\n",
      "2022-04-20 13:13:32.272873\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000400.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 31.4ms pre-process, 181.1ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9215 \tBbox: [ 2 \t 4 \t 464 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.9209 \tBbox: [ 175 \t 663 \t 431 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.911 \tBbox: [ 596 \t 282 \t 765 \t 606 ]\n",
      "4 \tObject: person \tConfidence = 0.9063 \tBbox: [ 469 \t 232 \t 605 \t 530 ]\n",
      "5 \tObject: person \tConfidence = 0.8621 \tBbox: [ 477 \t 23 \t 542 \t 248 ]\n",
      "6 \tObject: person \tConfidence = 0.852 \tBbox: [ 388 \t 136 \t 460 \t 388 ]\n",
      "7 \tObject: person \tConfidence = 0.8405 \tBbox: [ 596 \t 0 \t 678 \t 179 ]\n",
      "8 \tObject: person \tConfidence = 0.7947 \tBbox: [ 315 \t 484 \t 445 \t 803 ]\n",
      "9 \tObject: person \tConfidence = 0.7636 \tBbox: [ 616 \t 206 \t 724 \t 390 ]\n",
      "10 \tObject: person \tConfidence = 0.7346 \tBbox: [ 614 \t 126 \t 713 \t 330 ]\n",
      "11 \tObject: person \tConfidence = 0.559 \tBbox: [ 448 \t 4 \t 501 \t 143 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000401 / 1050\n",
      "Frames to be processed: 649  | To do: 61.81 % | Done: 38.19 %\n",
      "\n",
      "2022-04-20 13:13:32.784868\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000401.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 33.5ms pre-process, 173.6ms inference, 5.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9299 \tBbox: [ 2 \t 3 \t 466 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.9208 \tBbox: [ 175 \t 664 \t 431 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9055 \tBbox: [ 472 \t 231 \t 599 \t 529 ]\n",
      "4 \tObject: person \tConfidence = 0.8963 \tBbox: [ 593 \t 290 \t 762 \t 606 ]\n",
      "5 \tObject: person \tConfidence = 0.8734 \tBbox: [ 592 \t 0 \t 675 \t 180 ]\n",
      "6 \tObject: person \tConfidence = 0.8593 \tBbox: [ 387 \t 136 \t 460 \t 388 ]\n",
      "7 \tObject: person \tConfidence = 0.8592 \tBbox: [ 477 \t 23 \t 542 \t 248 ]\n",
      "8 \tObject: person \tConfidence = 0.7945 \tBbox: [ 315 \t 485 \t 444 \t 801 ]\n",
      "9 \tObject: person \tConfidence = 0.7279 \tBbox: [ 611 \t 129 \t 706 \t 356 ]\n",
      "10 \tObject: person \tConfidence = 0.6783 \tBbox: [ 612 \t 211 \t 741 \t 389 ]\n",
      "11 \tObject: person \tConfidence = 0.5965 \tBbox: [ 449 \t 3 \t 501 \t 143 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000402 / 1050\n",
      "Frames to be processed: 648  | To do: 61.71 % | Done: 38.29 %\n",
      "\n",
      "2022-04-20 13:13:33.285729\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000402.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 26.5ms pre-process, 169.0ms inference, 3.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9303 \tBbox: [ 2 \t 3 \t 467 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.9186 \tBbox: [ 175 \t 664 \t 430 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9082 \tBbox: [ 474 \t 232 \t 597 \t 530 ]\n",
      "4 \tObject: person \tConfidence = 0.9058 \tBbox: [ 592 \t 284 \t 761 \t 606 ]\n",
      "5 \tObject: person \tConfidence = 0.8605 \tBbox: [ 590 \t 0 \t 673 \t 180 ]\n",
      "6 \tObject: person \tConfidence = 0.8603 \tBbox: [ 387 \t 136 \t 460 \t 388 ]\n",
      "7 \tObject: person \tConfidence = 0.8541 \tBbox: [ 476 \t 23 \t 542 \t 248 ]\n",
      "8 \tObject: person \tConfidence = 0.8024 \tBbox: [ 315 \t 485 \t 444 \t 801 ]\n",
      "9 \tObject: person \tConfidence = 0.7596 \tBbox: [ 607 \t 129 \t 706 \t 383 ]\n",
      "10 \tObject: person \tConfidence = 0.6002 \tBbox: [ 449 \t 3 \t 501 \t 144 ]\n",
      "11 \tObject: person \tConfidence = 0.3201 \tBbox: [ 619 \t 215 \t 746 \t 389 ]\n",
      "12 \tObject: person \tConfidence = 0.3027 \tBbox: [ 512 \t 0 \t 538 \t 32 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000403 / 1050\n",
      "Frames to be processed: 647  | To do: 61.62 % | Done: 38.38 %\n",
      "\n",
      "2022-04-20 13:13:33.721654\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000403.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 24.5ms pre-process, 174.9ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9167 \tBbox: [ 174 \t 664 \t 430 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9125 \tBbox: [ 3 \t 3 \t 466 \t 1069 ]\n",
      "3 \tObject: person \tConfidence = 0.9069 \tBbox: [ 474 \t 231 \t 594 \t 529 ]\n",
      "4 \tObject: person \tConfidence = 0.8965 \tBbox: [ 592 \t 286 \t 758 \t 606 ]\n",
      "5 \tObject: person \tConfidence = 0.8642 \tBbox: [ 590 \t 0 \t 671 \t 180 ]\n",
      "6 \tObject: person \tConfidence = 0.864 \tBbox: [ 386 \t 136 \t 460 \t 388 ]\n",
      "7 \tObject: person \tConfidence = 0.86 \tBbox: [ 476 \t 24 \t 541 \t 248 ]\n",
      "8 \tObject: person \tConfidence = 0.7989 \tBbox: [ 315 \t 485 \t 444 \t 801 ]\n",
      "9 \tObject: person \tConfidence = 0.7589 \tBbox: [ 602 \t 129 \t 703 \t 391 ]\n",
      "10 \tObject: person \tConfidence = 0.6096 \tBbox: [ 448 \t 2 \t 501 \t 144 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000404 / 1050\n",
      "Frames to be processed: 646  | To do: 61.52 % | Done: 38.48 %\n",
      "\n",
      "2022-04-20 13:13:34.190024\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000404.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 23.9ms pre-process, 178.1ms inference, 4.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9276 \tBbox: [ 2 \t 2 \t 468 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.9206 \tBbox: [ 174 \t 664 \t 432 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.905 \tBbox: [ 473 \t 230 \t 591 \t 529 ]\n",
      "4 \tObject: person \tConfidence = 0.8888 \tBbox: [ 591 \t 277 \t 754 \t 607 ]\n",
      "5 \tObject: person \tConfidence = 0.8654 \tBbox: [ 387 \t 136 \t 460 \t 388 ]\n",
      "6 \tObject: person \tConfidence = 0.8567 \tBbox: [ 476 \t 23 \t 541 \t 248 ]\n",
      "7 \tObject: person \tConfidence = 0.8493 \tBbox: [ 590 \t 0 \t 668 \t 180 ]\n",
      "8 \tObject: person \tConfidence = 0.7947 \tBbox: [ 315 \t 485 \t 444 \t 802 ]\n",
      "9 \tObject: person \tConfidence = 0.7557 \tBbox: [ 599 \t 129 \t 701 \t 395 ]\n",
      "10 \tObject: person \tConfidence = 0.5961 \tBbox: [ 447 \t 3 \t 492 \t 142 ]\n",
      "11 \tObject: person \tConfidence = 0.3222 \tBbox: [ 512 \t 0 \t 538 \t 32 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000405 / 1050\n",
      "Frames to be processed: 645  | To do: 61.43 % | Done: 38.57 %\n",
      "\n",
      "2022-04-20 13:13:34.676221\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000405.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 28.0ms pre-process, 180.9ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9214 \tBbox: [ 2 \t 2 \t 468 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.9189 \tBbox: [ 174 \t 664 \t 431 \t 1077 ]\n",
      "3 \tObject: person \tConfidence = 0.9034 \tBbox: [ 473 \t 230 \t 588 \t 529 ]\n",
      "4 \tObject: person \tConfidence = 0.9007 \tBbox: [ 591 \t 278 \t 747 \t 607 ]\n",
      "5 \tObject: person \tConfidence = 0.8657 \tBbox: [ 387 \t 136 \t 460 \t 388 ]\n",
      "6 \tObject: person \tConfidence = 0.8526 \tBbox: [ 596 \t 129 \t 700 \t 387 ]\n",
      "7 \tObject: person \tConfidence = 0.8517 \tBbox: [ 476 \t 23 \t 541 \t 248 ]\n",
      "8 \tObject: person \tConfidence = 0.8382 \tBbox: [ 590 \t 0 \t 666 \t 179 ]\n",
      "9 \tObject: person \tConfidence = 0.7909 \tBbox: [ 315 \t 483 \t 444 \t 809 ]\n",
      "10 \tObject: person \tConfidence = 0.582 \tBbox: [ 450 \t 7 \t 501 \t 143 ]\n",
      "11 \tObject: person \tConfidence = 0.3558 \tBbox: [ 682 \t 260 \t 763 \t 507 ]\n",
      "12 \tObject: person \tConfidence = 0.3099 \tBbox: [ 511 \t 0 \t 538 \t 33 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000406 / 1050\n",
      "Frames to be processed: 644  | To do: 61.33 % | Done: 38.67 %\n",
      "\n",
      "2022-04-20 13:13:35.151876\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000406.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 26.7ms pre-process, 174.0ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9223 \tBbox: [ 2 \t 2 \t 471 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.9141 \tBbox: [ 175 \t 665 \t 428 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9053 \tBbox: [ 590 \t 285 \t 733 \t 607 ]\n",
      "4 \tObject: person \tConfidence = 0.8987 \tBbox: [ 473 \t 228 \t 585 \t 530 ]\n",
      "5 \tObject: person \tConfidence = 0.8758 \tBbox: [ 590 \t 131 \t 695 \t 385 ]\n",
      "6 \tObject: person \tConfidence = 0.8692 \tBbox: [ 387 \t 136 \t 459 \t 388 ]\n",
      "7 \tObject: person \tConfidence = 0.857 \tBbox: [ 586 \t 0 \t 663 \t 180 ]\n",
      "8 \tObject: person \tConfidence = 0.8489 \tBbox: [ 476 \t 23 \t 541 \t 247 ]\n",
      "9 \tObject: person \tConfidence = 0.798 \tBbox: [ 315 \t 483 \t 444 \t 810 ]\n",
      "10 \tObject: person \tConfidence = 0.7755 \tBbox: [ 682 \t 235 \t 764 \t 552 ]\n",
      "11 \tObject: person \tConfidence = 0.6103 \tBbox: [ 446 \t 3 \t 492 \t 142 ]\n",
      "12 \tObject: person \tConfidence = 0.3406 \tBbox: [ 514 \t 0 \t 538 \t 33 ]\n",
      "13 \tObject: person \tConfidence = 0.3301 \tBbox: [ 684 \t 331 \t 766 \t 473 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000407 / 1050\n",
      "Frames to be processed: 643  | To do: 61.24 % | Done: 38.76 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:13:35.632711\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000407.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 27.5ms pre-process, 168.4ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9262 \tBbox: [ 2 \t 2 \t 468 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.9121 \tBbox: [ 175 \t 665 \t 424 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9001 \tBbox: [ 586 \t 131 \t 693 \t 383 ]\n",
      "4 \tObject: person \tConfidence = 0.8997 \tBbox: [ 473 \t 228 \t 583 \t 528 ]\n",
      "5 \tObject: person \tConfidence = 0.8863 \tBbox: [ 583 \t 0 \t 662 \t 187 ]\n",
      "6 \tObject: person \tConfidence = 0.8736 \tBbox: [ 386 \t 136 \t 459 \t 388 ]\n",
      "7 \tObject: person \tConfidence = 0.8681 \tBbox: [ 590 \t 284 \t 722 \t 608 ]\n",
      "8 \tObject: person \tConfidence = 0.85 \tBbox: [ 476 \t 24 \t 541 \t 247 ]\n",
      "9 \tObject: person \tConfidence = 0.8112 \tBbox: [ 683 \t 236 \t 764 \t 554 ]\n",
      "10 \tObject: person \tConfidence = 0.8062 \tBbox: [ 315 \t 483 \t 444 \t 811 ]\n",
      "11 \tObject: person \tConfidence = 0.6292 \tBbox: [ 447 \t 1 \t 499 \t 143 ]\n",
      "12 \tObject: person \tConfidence = 0.3138 \tBbox: [ 515 \t 0 \t 538 \t 32 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000408 / 1050\n",
      "Frames to be processed: 642  | To do: 61.14 % | Done: 38.86 %\n",
      "\n",
      "2022-04-20 13:13:36.098592\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000408.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 37.7ms pre-process, 175.3ms inference, 11.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9233 \tBbox: [ 2 \t 2 \t 468 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.9125 \tBbox: [ 175 \t 665 \t 426 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9093 \tBbox: [ 582 \t 131 \t 692 \t 381 ]\n",
      "4 \tObject: person \tConfidence = 0.8882 \tBbox: [ 473 \t 226 \t 578 \t 529 ]\n",
      "5 \tObject: person \tConfidence = 0.8821 \tBbox: [ 580 \t 1 \t 660 \t 187 ]\n",
      "6 \tObject: person \tConfidence = 0.8725 \tBbox: [ 387 \t 136 \t 459 \t 388 ]\n",
      "7 \tObject: person \tConfidence = 0.8542 \tBbox: [ 476 \t 24 \t 541 \t 246 ]\n",
      "8 \tObject: person \tConfidence = 0.8407 \tBbox: [ 679 \t 238 \t 764 \t 556 ]\n",
      "9 \tObject: person \tConfidence = 0.8263 \tBbox: [ 589 \t 284 \t 707 \t 607 ]\n",
      "10 \tObject: person \tConfidence = 0.7619 \tBbox: [ 315 \t 483 \t 445 \t 812 ]\n",
      "11 \tObject: person \tConfidence = 0.6263 \tBbox: [ 446 \t 1 \t 494 \t 142 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000409 / 1050\n",
      "Frames to be processed: 641  | To do: 61.05 % | Done: 38.95 %\n",
      "\n",
      "2022-04-20 13:13:36.579678\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000409.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 51.3ms pre-process, 174.8ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9258 \tBbox: [ 2 \t 2 \t 468 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.9134 \tBbox: [ 175 \t 665 \t 426 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9048 \tBbox: [ 579 \t 132 \t 691 \t 382 ]\n",
      "4 \tObject: person \tConfidence = 0.8861 \tBbox: [ 578 \t 3 \t 660 \t 191 ]\n",
      "5 \tObject: person \tConfidence = 0.8855 \tBbox: [ 472 \t 226 \t 573 \t 528 ]\n",
      "6 \tObject: person \tConfidence = 0.8722 \tBbox: [ 388 \t 137 \t 459 \t 388 ]\n",
      "7 \tObject: person \tConfidence = 0.8608 \tBbox: [ 476 \t 25 \t 541 \t 239 ]\n",
      "8 \tObject: person \tConfidence = 0.8413 \tBbox: [ 678 \t 241 \t 765 \t 554 ]\n",
      "9 \tObject: person \tConfidence = 0.8013 \tBbox: [ 587 \t 281 \t 707 \t 607 ]\n",
      "10 \tObject: person \tConfidence = 0.7059 \tBbox: [ 314 \t 483 \t 447 \t 812 ]\n",
      "11 \tObject: person \tConfidence = 0.6422 \tBbox: [ 449 \t 2 \t 503 \t 144 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000410 / 1050\n",
      "Frames to be processed: 640  | To do: 60.95 % | Done: 39.05 %\n",
      "\n",
      "2022-04-20 13:13:37.133528\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000410.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 33.8ms pre-process, 180.4ms inference, 10.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9218 \tBbox: [ 2 \t 2 \t 471 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.9138 \tBbox: [ 174 \t 666 \t 428 \t 1077 ]\n",
      "3 \tObject: person \tConfidence = 0.8901 \tBbox: [ 576 \t 132 \t 689 \t 379 ]\n",
      "4 \tObject: person \tConfidence = 0.8868 \tBbox: [ 576 \t 6 \t 658 \t 195 ]\n",
      "5 \tObject: person \tConfidence = 0.8806 \tBbox: [ 471 \t 225 \t 571 \t 528 ]\n",
      "6 \tObject: person \tConfidence = 0.8723 \tBbox: [ 388 \t 137 \t 459 \t 389 ]\n",
      "7 \tObject: person \tConfidence = 0.8494 \tBbox: [ 476 \t 25 \t 541 \t 238 ]\n",
      "8 \tObject: person \tConfidence = 0.8107 \tBbox: [ 679 \t 242 \t 765 \t 553 ]\n",
      "9 \tObject: person \tConfidence = 0.8005 \tBbox: [ 584 \t 287 \t 704 \t 607 ]\n",
      "10 \tObject: person \tConfidence = 0.7612 \tBbox: [ 315 \t 484 \t 445 \t 811 ]\n",
      "11 \tObject: person \tConfidence = 0.6535 \tBbox: [ 446 \t 1 \t 502 \t 144 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000411 / 1050\n",
      "Frames to be processed: 639  | To do: 60.86 % | Done: 39.14 %\n",
      "\n",
      "2022-04-20 13:13:37.760505\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000411.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 25.5ms pre-process, 181.1ms inference, 5.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9239 \tBbox: [ 2 \t 4 \t 468 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.9162 \tBbox: [ 174 \t 666 \t 430 \t 1077 ]\n",
      "3 \tObject: person \tConfidence = 0.8941 \tBbox: [ 575 \t 11 \t 656 \t 198 ]\n",
      "4 \tObject: person \tConfidence = 0.8859 \tBbox: [ 468 \t 223 \t 568 \t 525 ]\n",
      "5 \tObject: person \tConfidence = 0.875 \tBbox: [ 387 \t 137 \t 459 \t 389 ]\n",
      "6 \tObject: person \tConfidence = 0.8622 \tBbox: [ 571 \t 134 \t 688 \t 383 ]\n",
      "7 \tObject: person \tConfidence = 0.8438 \tBbox: [ 476 \t 25 \t 541 \t 235 ]\n",
      "8 \tObject: person \tConfidence = 0.8411 \tBbox: [ 579 \t 281 \t 693 \t 607 ]\n",
      "9 \tObject: person \tConfidence = 0.8244 \tBbox: [ 675 \t 246 \t 766 \t 554 ]\n",
      "10 \tObject: person \tConfidence = 0.7451 \tBbox: [ 315 \t 484 \t 445 \t 810 ]\n",
      "11 \tObject: person \tConfidence = 0.669 \tBbox: [ 445 \t 1 \t 495 \t 144 ]\n",
      "12 \tObject: person \tConfidence = 0.3242 \tBbox: [ 599 \t 0 \t 631 \t 35 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000412 / 1050\n",
      "Frames to be processed: 638  | To do: 60.76 % | Done: 39.24 %\n",
      "\n",
      "2022-04-20 13:13:38.224448\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000412.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 33.9ms pre-process, 180.6ms inference, 12.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9242 \tBbox: [ 2 \t 2 \t 468 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.9162 \tBbox: [ 174 \t 666 \t 429 \t 1077 ]\n",
      "3 \tObject: person \tConfidence = 0.895 \tBbox: [ 466 \t 223 \t 567 \t 521 ]\n",
      "4 \tObject: person \tConfidence = 0.8836 \tBbox: [ 574 \t 13 \t 655 \t 205 ]\n",
      "5 \tObject: person \tConfidence = 0.8734 \tBbox: [ 387 \t 138 \t 459 \t 389 ]\n",
      "6 \tObject: person \tConfidence = 0.8417 \tBbox: [ 569 \t 281 \t 692 \t 608 ]\n",
      "7 \tObject: person \tConfidence = 0.8394 \tBbox: [ 570 \t 137 \t 686 \t 364 ]\n",
      "8 \tObject: person \tConfidence = 0.8367 \tBbox: [ 675 \t 246 \t 766 \t 550 ]\n",
      "9 \tObject: person \tConfidence = 0.8269 \tBbox: [ 476 \t 25 \t 542 \t 232 ]\n",
      "10 \tObject: person \tConfidence = 0.7731 \tBbox: [ 315 \t 484 \t 445 \t 811 ]\n",
      "11 \tObject: person \tConfidence = 0.6479 \tBbox: [ 446 \t 1 \t 495 \t 144 ]\n",
      "12 \tObject: person \tConfidence = 0.3559 \tBbox: [ 598 \t 0 \t 632 \t 32 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000413 / 1050\n",
      "Frames to be processed: 637  | To do: 60.67 % | Done: 39.33 %\n",
      "\n",
      "2022-04-20 13:13:38.721839\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000413.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 24.9ms pre-process, 175.6ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9225 \tBbox: [ 2 \t 2 \t 469 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.914 \tBbox: [ 174 \t 667 \t 427 \t 1077 ]\n",
      "3 \tObject: person \tConfidence = 0.9119 \tBbox: [ 464 \t 223 \t 564 \t 516 ]\n",
      "4 \tObject: person \tConfidence = 0.8875 \tBbox: [ 573 \t 14 \t 654 \t 206 ]\n",
      "5 \tObject: person \tConfidence = 0.8761 \tBbox: [ 387 \t 138 \t 459 \t 389 ]\n",
      "6 \tObject: person \tConfidence = 0.8522 \tBbox: [ 570 \t 138 \t 685 \t 355 ]\n",
      "7 \tObject: person \tConfidence = 0.8325 \tBbox: [ 475 \t 25 \t 541 \t 230 ]\n",
      "8 \tObject: person \tConfidence = 0.7928 \tBbox: [ 673 \t 248 \t 765 \t 552 ]\n",
      "9 \tObject: person \tConfidence = 0.7627 \tBbox: [ 557 \t 280 \t 697 \t 607 ]\n",
      "10 \tObject: person \tConfidence = 0.7523 \tBbox: [ 315 \t 484 \t 446 \t 811 ]\n",
      "11 \tObject: person \tConfidence = 0.6124 \tBbox: [ 447 \t 2 \t 496 \t 144 ]\n",
      "12 \tObject: person \tConfidence = 0.3347 \tBbox: [ 598 \t 0 \t 632 \t 33 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000414 / 1050\n",
      "Frames to be processed: 636  | To do: 60.57 % | Done: 39.43 %\n",
      "\n",
      "2022-04-20 13:13:39.176002\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000414.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 26.6ms pre-process, 171.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9252 \tBbox: [ 1 \t 2 \t 470 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.9138 \tBbox: [ 175 \t 666 \t 427 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9063 \tBbox: [ 463 \t 222 \t 564 \t 514 ]\n",
      "4 \tObject: person \tConfidence = 0.8815 \tBbox: [ 572 \t 14 \t 653 \t 205 ]\n",
      "5 \tObject: person \tConfidence = 0.8734 \tBbox: [ 387 \t 138 \t 459 \t 389 ]\n",
      "6 \tObject: person \tConfidence = 0.8299 \tBbox: [ 569 \t 140 \t 684 \t 320 ]\n",
      "7 \tObject: person \tConfidence = 0.8241 \tBbox: [ 475 \t 25 \t 541 \t 227 ]\n",
      "8 \tObject: person \tConfidence = 0.8058 \tBbox: [ 673 \t 250 \t 765 \t 561 ]\n",
      "9 \tObject: person \tConfidence = 0.7988 \tBbox: [ 315 \t 484 \t 445 \t 812 ]\n",
      "10 \tObject: person \tConfidence = 0.7662 \tBbox: [ 533 \t 280 \t 686 \t 606 ]\n",
      "11 \tObject: person \tConfidence = 0.5739 \tBbox: [ 446 \t 3 \t 490 \t 143 ]\n",
      "12 \tObject: person \tConfidence = 0.4466 \tBbox: [ 96 \t 399 \t 148 \t 515 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000415 / 1050\n",
      "Frames to be processed: 635  | To do: 60.48 % | Done: 39.52 %\n",
      "\n",
      "2022-04-20 13:13:39.681099\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000415.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 34.4ms pre-process, 177.3ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.923 \tBbox: [ 1 \t 3 \t 469 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.911 \tBbox: [ 175 \t 666 \t 422 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9058 \tBbox: [ 461 \t 223 \t 562 \t 510 ]\n",
      "4 \tObject: person \tConfidence = 0.8823 \tBbox: [ 571 \t 15 \t 653 \t 205 ]\n",
      "5 \tObject: person \tConfidence = 0.8768 \tBbox: [ 388 \t 138 \t 459 \t 389 ]\n",
      "6 \tObject: person \tConfidence = 0.858 \tBbox: [ 568 \t 141 \t 683 \t 318 ]\n",
      "7 \tObject: person \tConfidence = 0.8369 \tBbox: [ 475 \t 24 \t 541 \t 227 ]\n",
      "8 \tObject: person \tConfidence = 0.8318 \tBbox: [ 671 \t 253 \t 765 \t 552 ]\n",
      "9 \tObject: person \tConfidence = 0.8237 \tBbox: [ 521 \t 282 \t 675 \t 607 ]\n",
      "10 \tObject: person \tConfidence = 0.7809 \tBbox: [ 315 \t 484 \t 445 \t 809 ]\n",
      "11 \tObject: person \tConfidence = 0.582 \tBbox: [ 446 \t 2 \t 489 \t 143 ]\n",
      "12 \tObject: person \tConfidence = 0.3665 \tBbox: [ 89 \t 403 \t 145 \t 526 ]\n",
      "13 \tObject: person \tConfidence = 0.3297 \tBbox: [ 599 \t 0 \t 631 \t 30 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000416 / 1050\n",
      "Frames to be processed: 634  | To do: 60.38 % | Done: 39.62 %\n",
      "\n",
      "2022-04-20 13:13:40.160672\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000416.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 26.9ms pre-process, 179.9ms inference, 3.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9204 \tBbox: [ 1 \t 4 \t 469 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.9122 \tBbox: [ 175 \t 667 \t 421 \t 1077 ]\n",
      "3 \tObject: person \tConfidence = 0.894 \tBbox: [ 676 \t 262 \t 765 \t 569 ]\n",
      "4 \tObject: person \tConfidence = 0.8922 \tBbox: [ 459 \t 223 \t 558 \t 508 ]\n",
      "5 \tObject: person \tConfidence = 0.8865 \tBbox: [ 568 \t 17 \t 652 \t 205 ]\n",
      "6 \tObject: person \tConfidence = 0.8767 \tBbox: [ 387 \t 138 \t 458 \t 389 ]\n",
      "7 \tObject: person \tConfidence = 0.8277 \tBbox: [ 509 \t 288 \t 671 \t 607 ]\n",
      "8 \tObject: person \tConfidence = 0.8219 \tBbox: [ 568 \t 145 \t 682 \t 313 ]\n",
      "9 \tObject: person \tConfidence = 0.8177 \tBbox: [ 474 \t 24 \t 541 \t 228 ]\n",
      "10 \tObject: person \tConfidence = 0.8051 \tBbox: [ 316 \t 485 \t 445 \t 804 ]\n",
      "11 \tObject: person \tConfidence = 0.5908 \tBbox: [ 446 \t 1 \t 494 \t 144 ]\n",
      "12 \tObject: person \tConfidence = 0.4048 \tBbox: [ 599 \t 0 \t 632 \t 29 ]\n",
      "13 \tObject: person \tConfidence = 0.3344 \tBbox: [ 77 \t 410 \t 138 \t 549 ]\n",
      "14 \tObject: person \tConfidence = 0.325 \tBbox: [ 514 \t 0 \t 539 \t 35 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000417 / 1050\n",
      "Frames to be processed: 633  | To do: 60.29 % | Done: 39.71 %\n",
      "\n",
      "2022-04-20 13:13:40.638553\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000417.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 26.9ms pre-process, 180.0ms inference, 4.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9179 \tBbox: [ 1 \t 4 \t 468 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.9123 \tBbox: [ 175 \t 666 \t 419 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8947 \tBbox: [ 676 \t 269 \t 765 \t 576 ]\n",
      "4 \tObject: person \tConfidence = 0.8802 \tBbox: [ 457 \t 222 \t 556 \t 509 ]\n",
      "5 \tObject: person \tConfidence = 0.8783 \tBbox: [ 567 \t 17 \t 652 \t 205 ]\n",
      "6 \tObject: person \tConfidence = 0.8633 \tBbox: [ 388 \t 138 \t 459 \t 389 ]\n",
      "7 \tObject: person \tConfidence = 0.8527 \tBbox: [ 503 \t 298 \t 675 \t 608 ]\n",
      "8 \tObject: person \tConfidence = 0.8511 \tBbox: [ 570 \t 148 \t 682 \t 332 ]\n",
      "9 \tObject: person \tConfidence = 0.815 \tBbox: [ 474 \t 25 \t 540 \t 227 ]\n",
      "10 \tObject: person \tConfidence = 0.8078 \tBbox: [ 316 \t 485 \t 444 \t 804 ]\n",
      "11 \tObject: person \tConfidence = 0.6106 \tBbox: [ 446 \t 0 \t 495 \t 144 ]\n",
      "12 \tObject: person \tConfidence = 0.4353 \tBbox: [ 599 \t 0 \t 631 \t 28 ]\n",
      "13 \tObject: person \tConfidence = 0.3405 \tBbox: [ 513 \t 0 \t 539 \t 35 ]\n",
      "14 \tObject: person \tConfidence = 0.3007 \tBbox: [ 71 \t 418 \t 136 \t 553 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000418 / 1050\n",
      "Frames to be processed: 632  | To do: 60.19 % | Done: 39.81 %\n",
      "\n",
      "2022-04-20 13:13:41.129662\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000418.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 51.1ms pre-process, 177.3ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9113 \tBbox: [ 1 \t 5 \t 468 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.9111 \tBbox: [ 175 \t 666 \t 416 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8947 \tBbox: [ 679 \t 271 \t 766 \t 581 ]\n",
      "4 \tObject: person \tConfidence = 0.887 \tBbox: [ 566 \t 17 \t 652 \t 205 ]\n",
      "5 \tObject: person \tConfidence = 0.8727 \tBbox: [ 455 \t 222 \t 550 \t 508 ]\n",
      "6 \tObject: person \tConfidence = 0.8652 \tBbox: [ 387 \t 138 \t 458 \t 389 ]\n",
      "7 \tObject: person \tConfidence = 0.8583 \tBbox: [ 500 \t 293 \t 664 \t 607 ]\n",
      "8 \tObject: person \tConfidence = 0.8378 \tBbox: [ 474 \t 24 \t 540 \t 226 ]\n",
      "9 \tObject: person \tConfidence = 0.8365 \tBbox: [ 570 \t 149 \t 682 \t 334 ]\n",
      "10 \tObject: person \tConfidence = 0.817 \tBbox: [ 316 \t 485 \t 444 \t 804 ]\n",
      "11 \tObject: person \tConfidence = 0.5921 \tBbox: [ 446 \t 1 \t 497 \t 144 ]\n",
      "12 \tObject: person \tConfidence = 0.472 \tBbox: [ 68 \t 418 \t 131 \t 558 ]\n",
      "13 \tObject: person \tConfidence = 0.4275 \tBbox: [ 599 \t 0 \t 631 \t 28 ]\n",
      "14 \tObject: person \tConfidence = 0.3525 \tBbox: [ 513 \t 0 \t 539 \t 35 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000419 / 1050\n",
      "Frames to be processed: 631  | To do: 60.1 % | Done: 39.9 %\n",
      "\n",
      "2022-04-20 13:13:41.639216\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000419.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 53.1ms pre-process, 177.1ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9168 \tBbox: [ 1 \t 5 \t 471 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.91 \tBbox: [ 174 \t 667 \t 418 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.898 \tBbox: [ 566 \t 14 \t 651 \t 207 ]\n",
      "4 \tObject: person \tConfidence = 0.8853 \tBbox: [ 679 \t 276 \t 765 \t 590 ]\n",
      "5 \tObject: person \tConfidence = 0.8691 \tBbox: [ 456 \t 220 \t 554 \t 510 ]\n",
      "6 \tObject: person \tConfidence = 0.8602 \tBbox: [ 387 \t 138 \t 458 \t 389 ]\n",
      "7 \tObject: person \tConfidence = 0.8543 \tBbox: [ 498 \t 296 \t 664 \t 608 ]\n",
      "8 \tObject: person \tConfidence = 0.8259 \tBbox: [ 474 \t 27 \t 539 \t 226 ]\n",
      "9 \tObject: person \tConfidence = 0.7931 \tBbox: [ 570 \t 149 \t 683 \t 337 ]\n",
      "10 \tObject: person \tConfidence = 0.7893 \tBbox: [ 315 \t 485 \t 445 \t 804 ]\n",
      "11 \tObject: person \tConfidence = 0.586 \tBbox: [ 446 \t 2 \t 498 \t 144 ]\n",
      "12 \tObject: person \tConfidence = 0.4263 \tBbox: [ 598 \t 0 \t 631 \t 29 ]\n",
      "13 \tObject: person \tConfidence = 0.3502 \tBbox: [ 512 \t 0 \t 538 \t 34 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000420 / 1050\n",
      "Frames to be processed: 630  | To do: 60.0 % | Done: 40.0 %\n",
      "\n",
      "2022-04-20 13:13:42.183302\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000420.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 28.4ms pre-process, 178.1ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.9142 \tBbox: [ 1 \t 5 \t 473 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.9087 \tBbox: [ 174 \t 667 \t 422 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9032 \tBbox: [ 565 \t 16 \t 652 \t 208 ]\n",
      "4 \tObject: person \tConfidence = 0.8877 \tBbox: [ 682 \t 280 \t 766 \t 603 ]\n",
      "5 \tObject: person \tConfidence = 0.8772 \tBbox: [ 496 \t 293 \t 663 \t 608 ]\n",
      "6 \tObject: person \tConfidence = 0.8686 \tBbox: [ 454 \t 220 \t 552 \t 509 ]\n",
      "7 \tObject: person \tConfidence = 0.8605 \tBbox: [ 387 \t 138 \t 458 \t 389 ]\n",
      "8 \tObject: person \tConfidence = 0.8529 \tBbox: [ 566 \t 152 \t 683 \t 342 ]\n",
      "9 \tObject: person \tConfidence = 0.8348 \tBbox: [ 473 \t 25 \t 539 \t 226 ]\n",
      "10 \tObject: person \tConfidence = 0.7881 \tBbox: [ 315 \t 484 \t 446 \t 804 ]\n",
      "11 \tObject: person \tConfidence = 0.6111 \tBbox: [ 446 \t 2 \t 496 \t 145 ]\n",
      "12 \tObject: person \tConfidence = 0.3608 \tBbox: [ 512 \t 0 \t 538 \t 34 ]\n",
      "13 \tObject: person \tConfidence = 0.3364 \tBbox: [ 597 \t 0 \t 630 \t 29 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000421 / 1050\n",
      "Frames to be processed: 629  | To do: 59.9 % | Done: 40.1 %\n",
      "\n",
      "2022-04-20 13:13:42.716803\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000421.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 32.1ms pre-process, 178.1ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9092 \tBbox: [ 174 \t 667 \t 424 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9046 \tBbox: [ 494 \t 288 \t 670 \t 610 ]\n",
      "3 \tObject: person \tConfidence = 0.8935 \tBbox: [ 563 \t 24 \t 652 \t 206 ]\n",
      "4 \tObject: person \tConfidence = 0.8707 \tBbox: [ 453 \t 221 \t 550 \t 510 ]\n",
      "5 \tObject: train \tConfidence = 0.8666 \tBbox: [ 1 \t 5 \t 472 \t 1071 ]\n",
      "6 \tObject: person \tConfidence = 0.8584 \tBbox: [ 387 \t 138 \t 458 \t 389 ]\n",
      "7 \tObject: person \tConfidence = 0.8527 \tBbox: [ 690 \t 287 \t 765 \t 611 ]\n",
      "8 \tObject: person \tConfidence = 0.8359 \tBbox: [ 473 \t 25 \t 538 \t 227 ]\n",
      "9 \tObject: person \tConfidence = 0.7793 \tBbox: [ 315 \t 485 \t 445 \t 805 ]\n",
      "10 \tObject: person \tConfidence = 0.7407 \tBbox: [ 560 \t 154 \t 682 \t 341 ]\n",
      "11 \tObject: person \tConfidence = 0.6144 \tBbox: [ 446 \t 1 \t 496 \t 145 ]\n",
      "12 \tObject: person \tConfidence = 0.538 \tBbox: [ 596 \t 0 \t 630 \t 33 ]\n",
      "13 \tObject: person \tConfidence = 0.3736 \tBbox: [ 512 \t 0 \t 538 \t 35 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000422 / 1050\n",
      "Frames to be processed: 628  | To do: 59.81 % | Done: 40.19 %\n",
      "\n",
      "2022-04-20 13:13:43.266738\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000422.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 32.9ms pre-process, 181.8ms inference, 10.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9058 \tBbox: [ 175 \t 667 \t 421 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9024 \tBbox: [ 492 \t 277 \t 659 \t 609 ]\n",
      "3 \tObject: person \tConfidence = 0.9008 \tBbox: [ 562 \t 27 \t 652 \t 207 ]\n",
      "4 \tObject: train \tConfidence = 0.8689 \tBbox: [ 1 \t 5 \t 471 \t 1071 ]\n",
      "5 \tObject: person \tConfidence = 0.8576 \tBbox: [ 386 \t 138 \t 458 \t 389 ]\n",
      "6 \tObject: person \tConfidence = 0.8522 \tBbox: [ 452 \t 220 \t 542 \t 509 ]\n",
      "7 \tObject: person \tConfidence = 0.8435 \tBbox: [ 692 \t 290 \t 766 \t 613 ]\n",
      "8 \tObject: person \tConfidence = 0.8259 \tBbox: [ 472 \t 25 \t 536 \t 228 ]\n",
      "9 \tObject: person \tConfidence = 0.7925 \tBbox: [ 315 \t 484 \t 445 \t 805 ]\n",
      "10 \tObject: person \tConfidence = 0.7441 \tBbox: [ 576 \t 155 \t 683 \t 348 ]\n",
      "11 \tObject: person \tConfidence = 0.6228 \tBbox: [ 446 \t 0 \t 492 \t 144 ]\n",
      "12 \tObject: person \tConfidence = 0.572 \tBbox: [ 596 \t 0 \t 630 \t 35 ]\n",
      "13 \tObject: person \tConfidence = 0.3971 \tBbox: [ 511 \t 0 \t 538 \t 36 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000423 / 1050\n",
      "Frames to be processed: 627  | To do: 59.71 % | Done: 40.29 %\n",
      "\n",
      "2022-04-20 13:13:43.818923\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000423.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 29.0ms pre-process, 172.2ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.913 \tBbox: [ 492 \t 276 \t 655 \t 608 ]\n",
      "2 \tObject: person \tConfidence = 0.908 \tBbox: [ 175 \t 667 \t 418 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.9066 \tBbox: [ 561 \t 28 \t 652 \t 208 ]\n",
      "4 \tObject: person \tConfidence = 0.8779 \tBbox: [ 692 \t 293 \t 766 \t 611 ]\n",
      "5 \tObject: person \tConfidence = 0.862 \tBbox: [ 453 \t 220 \t 543 \t 510 ]\n",
      "6 \tObject: person \tConfidence = 0.8582 \tBbox: [ 387 \t 138 \t 458 \t 390 ]\n",
      "7 \tObject: person \tConfidence = 0.8259 \tBbox: [ 472 \t 23 \t 536 \t 228 ]\n",
      "8 \tObject: person \tConfidence = 0.8256 \tBbox: [ 575 \t 157 \t 684 \t 345 ]\n",
      "9 \tObject: train \tConfidence = 0.8056 \tBbox: [ 2 \t 3 \t 471 \t 1065 ]\n",
      "10 \tObject: person \tConfidence = 0.7736 \tBbox: [ 315 \t 484 \t 446 \t 805 ]\n",
      "11 \tObject: person \tConfidence = 0.5778 \tBbox: [ 446 \t 0 \t 491 \t 144 ]\n",
      "12 \tObject: person \tConfidence = 0.5403 \tBbox: [ 595 \t 0 \t 629 \t 36 ]\n",
      "13 \tObject: person \tConfidence = 0.4123 \tBbox: [ 510 \t 0 \t 538 \t 37 ]\n",
      "14 \tObject: person \tConfidence = 0.371 \tBbox: [ 31 \t 446 \t 106 \t 607 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000424 / 1050\n",
      "Frames to be processed: 626  | To do: 59.62 % | Done: 40.38 %\n",
      "\n",
      "2022-04-20 13:13:44.326279\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000424.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 32.3ms pre-process, 168.6ms inference, 14.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9152 \tBbox: [ 491 \t 274 \t 653 \t 608 ]\n",
      "2 \tObject: person \tConfidence = 0.9077 \tBbox: [ 174 \t 667 \t 414 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8979 \tBbox: [ 561 \t 30 \t 653 \t 208 ]\n",
      "4 \tObject: person \tConfidence = 0.8707 \tBbox: [ 453 \t 220 \t 540 \t 510 ]\n",
      "5 \tObject: person \tConfidence = 0.8572 \tBbox: [ 387 \t 138 \t 458 \t 390 ]\n",
      "6 \tObject: person \tConfidence = 0.8484 \tBbox: [ 690 \t 297 \t 766 \t 612 ]\n",
      "7 \tObject: person \tConfidence = 0.8403 \tBbox: [ 471 \t 22 \t 535 \t 228 ]\n",
      "8 \tObject: train \tConfidence = 0.8392 \tBbox: [ 2 \t 4 \t 471 \t 1066 ]\n",
      "9 \tObject: person \tConfidence = 0.8019 \tBbox: [ 576 \t 156 \t 685 \t 353 ]\n",
      "10 \tObject: person \tConfidence = 0.7635 \tBbox: [ 315 \t 484 \t 446 \t 805 ]\n",
      "11 \tObject: person \tConfidence = 0.6074 \tBbox: [ 446 \t 2 \t 493 \t 144 ]\n",
      "12 \tObject: person \tConfidence = 0.5074 \tBbox: [ 595 \t 0 \t 629 \t 35 ]\n",
      "13 \tObject: person \tConfidence = 0.419 \tBbox: [ 510 \t 0 \t 538 \t 39 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000425 / 1050\n",
      "Frames to be processed: 625  | To do: 59.52 % | Done: 40.48 %\n",
      "\n",
      "2022-04-20 13:13:44.797597\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000425.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 36.4ms pre-process, 169.3ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9098 \tBbox: [ 174 \t 667 \t 411 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8913 \tBbox: [ 688 \t 300 \t 766 \t 611 ]\n",
      "3 \tObject: person \tConfidence = 0.8902 \tBbox: [ 561 \t 32 \t 653 \t 209 ]\n",
      "4 \tObject: person \tConfidence = 0.8837 \tBbox: [ 491 \t 286 \t 651 \t 607 ]\n",
      "5 \tObject: train \tConfidence = 0.8636 \tBbox: [ 2 \t 2 \t 470 \t 1067 ]\n",
      "6 \tObject: person \tConfidence = 0.86 \tBbox: [ 386 \t 138 \t 458 \t 390 ]\n",
      "7 \tObject: person \tConfidence = 0.8519 \tBbox: [ 452 \t 218 \t 539 \t 511 ]\n",
      "8 \tObject: person \tConfidence = 0.8165 \tBbox: [ 470 \t 23 \t 534 \t 228 ]\n",
      "9 \tObject: person \tConfidence = 0.7902 \tBbox: [ 315 \t 484 \t 445 \t 805 ]\n",
      "10 \tObject: person \tConfidence = 0.7357 \tBbox: [ 576 \t 157 \t 686 \t 358 ]\n",
      "11 \tObject: person \tConfidence = 0.5605 \tBbox: [ 20 \t 454 \t 96 \t 608 ]\n",
      "12 \tObject: person \tConfidence = 0.5203 \tBbox: [ 446 \t 3 \t 496 \t 144 ]\n",
      "13 \tObject: person \tConfidence = 0.3839 \tBbox: [ 509 \t 0 \t 538 \t 37 ]\n",
      "14 \tObject: person \tConfidence = 0.3687 \tBbox: [ 594 \t 0 \t 628 \t 39 ]\n",
      "15 \tObject: person \tConfidence = 0.3166 \tBbox: [ 530 \t 270 \t 594 \t 356 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000426 / 1050\n",
      "Frames to be processed: 624  | To do: 59.43 % | Done: 40.57 %\n",
      "\n",
      "2022-04-20 13:13:45.314268\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000426.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 58.3ms pre-process, 167.2ms inference, 10.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9101 \tBbox: [ 174 \t 667 \t 412 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8936 \tBbox: [ 561 \t 32 \t 654 \t 210 ]\n",
      "3 \tObject: person \tConfidence = 0.8868 \tBbox: [ 678 \t 304 \t 765 \t 611 ]\n",
      "4 \tObject: person \tConfidence = 0.8847 \tBbox: [ 490 \t 283 \t 647 \t 606 ]\n",
      "5 \tObject: train \tConfidence = 0.8735 \tBbox: [ 2 \t 2 \t 468 \t 1068 ]\n",
      "6 \tObject: person \tConfidence = 0.8472 \tBbox: [ 387 \t 138 \t 458 \t 390 ]\n",
      "7 \tObject: person \tConfidence = 0.8237 \tBbox: [ 451 \t 217 \t 536 \t 509 ]\n",
      "8 \tObject: person \tConfidence = 0.8198 \tBbox: [ 468 \t 24 \t 532 \t 233 ]\n",
      "9 \tObject: person \tConfidence = 0.7925 \tBbox: [ 315 \t 483 \t 445 \t 804 ]\n",
      "10 \tObject: person \tConfidence = 0.7907 \tBbox: [ 576 \t 160 \t 687 \t 453 ]\n",
      "11 \tObject: person \tConfidence = 0.5745 \tBbox: [ 446 \t 2 \t 492 \t 144 ]\n",
      "12 \tObject: person \tConfidence = 0.549 \tBbox: [ 593 \t 0 \t 627 \t 52 ]\n",
      "13 \tObject: person \tConfidence = 0.4715 \tBbox: [ 509 \t 0 \t 539 \t 43 ]\n",
      "14 \tObject: person \tConfidence = 0.338 \tBbox: [ 6 \t 463 \t 87 \t 655 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000427 / 1050\n",
      "Frames to be processed: 623  | To do: 59.33 % | Done: 40.67 %\n",
      "\n",
      "2022-04-20 13:13:45.830993\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000427.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 38.1ms pre-process, 178.1ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.908 \tBbox: [ 175 \t 667 \t 415 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9029 \tBbox: [ 2 \t 3 \t 469 \t 1068 ]\n",
      "3 \tObject: person \tConfidence = 0.8963 \tBbox: [ 490 \t 275 \t 645 \t 605 ]\n",
      "4 \tObject: person \tConfidence = 0.8901 \tBbox: [ 675 \t 309 \t 765 \t 613 ]\n",
      "5 \tObject: person \tConfidence = 0.8898 \tBbox: [ 560 \t 32 \t 654 \t 209 ]\n",
      "6 \tObject: person \tConfidence = 0.8649 \tBbox: [ 451 \t 216 \t 536 \t 509 ]\n",
      "7 \tObject: person \tConfidence = 0.8434 \tBbox: [ 386 \t 138 \t 457 \t 390 ]\n",
      "8 \tObject: person \tConfidence = 0.8395 \tBbox: [ 576 \t 162 \t 688 \t 454 ]\n",
      "9 \tObject: person \tConfidence = 0.8161 \tBbox: [ 468 \t 42 \t 531 \t 230 ]\n",
      "10 \tObject: person \tConfidence = 0.7956 \tBbox: [ 315 \t 483 \t 445 \t 804 ]\n",
      "11 \tObject: person \tConfidence = 0.5739 \tBbox: [ 593 \t 0 \t 627 \t 54 ]\n",
      "12 \tObject: person \tConfidence = 0.523 \tBbox: [ 507 \t 0 \t 539 \t 46 ]\n",
      "13 \tObject: person \tConfidence = 0.4669 \tBbox: [ 1 \t 469 \t 82 \t 681 ]\n",
      "14 \tObject: person \tConfidence = 0.4388 \tBbox: [ 447 \t 6 \t 505 \t 145 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000428 / 1050\n",
      "Frames to be processed: 622  | To do: 59.24 % | Done: 40.76 %\n",
      "\n",
      "2022-04-20 13:13:46.437303\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000428.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 29.5ms pre-process, 170.2ms inference, 10.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9078 \tBbox: [ 174 \t 667 \t 416 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.9037 \tBbox: [ 2 \t 3 \t 469 \t 1069 ]\n",
      "3 \tObject: person \tConfidence = 0.8881 \tBbox: [ 490 \t 290 \t 639 \t 604 ]\n",
      "4 \tObject: person \tConfidence = 0.8843 \tBbox: [ 668 \t 313 \t 766 \t 631 ]\n",
      "5 \tObject: person \tConfidence = 0.8765 \tBbox: [ 560 \t 32 \t 654 \t 209 ]\n",
      "6 \tObject: person \tConfidence = 0.851 \tBbox: [ 387 \t 138 \t 457 \t 389 ]\n",
      "7 \tObject: person \tConfidence = 0.8377 \tBbox: [ 467 \t 44 \t 529 \t 230 ]\n",
      "8 \tObject: person \tConfidence = 0.8162 \tBbox: [ 451 \t 216 \t 554 \t 508 ]\n",
      "9 \tObject: person \tConfidence = 0.7989 \tBbox: [ 315 \t 484 \t 445 \t 804 ]\n",
      "10 \tObject: person \tConfidence = 0.7969 \tBbox: [ 577 \t 162 \t 689 \t 453 ]\n",
      "11 \tObject: person \tConfidence = 0.5771 \tBbox: [ 592 \t 0 \t 627 \t 53 ]\n",
      "12 \tObject: person \tConfidence = 0.4907 \tBbox: [ 454 \t 12 \t 513 \t 145 ]\n",
      "13 \tObject: person \tConfidence = 0.3796 \tBbox: [ 506 \t 0 \t 538 \t 44 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000429 / 1050\n",
      "Frames to be processed: 621  | To do: 59.14 % | Done: 40.86 %\n",
      "\n",
      "2022-04-20 13:13:46.979893\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000429.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 33.2ms pre-process, 174.8ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9079 \tBbox: [ 175 \t 667 \t 417 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8889 \tBbox: [ 559 \t 31 \t 654 \t 216 ]\n",
      "3 \tObject: train \tConfidence = 0.8867 \tBbox: [ 2 \t 3 \t 468 \t 1067 ]\n",
      "4 \tObject: person \tConfidence = 0.8838 \tBbox: [ 664 \t 320 \t 765 \t 648 ]\n",
      "5 \tObject: person \tConfidence = 0.8659 \tBbox: [ 490 \t 293 \t 632 \t 603 ]\n",
      "6 \tObject: person \tConfidence = 0.8472 \tBbox: [ 387 \t 138 \t 457 \t 390 ]\n",
      "7 \tObject: person \tConfidence = 0.8442 \tBbox: [ 575 \t 163 \t 690 \t 453 ]\n",
      "8 \tObject: person \tConfidence = 0.8302 \tBbox: [ 450 \t 216 \t 535 \t 508 ]\n",
      "9 \tObject: person \tConfidence = 0.8174 \tBbox: [ 464 \t 42 \t 529 \t 228 ]\n",
      "10 \tObject: person \tConfidence = 0.7942 \tBbox: [ 315 \t 484 \t 445 \t 804 ]\n",
      "11 \tObject: person \tConfidence = 0.6035 \tBbox: [ 591 \t 0 \t 627 \t 53 ]\n",
      "12 \tObject: person \tConfidence = 0.5484 \tBbox: [ 505 \t 0 \t 537 \t 46 ]\n",
      "13 \tObject: person \tConfidence = 0.4727 \tBbox: [ 0 \t 478 \t 72 \t 698 ]\n",
      "14 \tObject: person \tConfidence = 0.4615 \tBbox: [ 448 \t 0 \t 488 \t 146 ]\n",
      "15 \tObject: person \tConfidence = 0.3739 \tBbox: [ 693 \t 58 \t 765 \t 256 ]\n",
      "16 \tObject: person \tConfidence = 0.3497 \tBbox: [ 488 \t 259 \t 571 \t 388 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000430 / 1050\n",
      "Frames to be processed: 620  | To do: 59.05 % | Done: 40.95 %\n",
      "\n",
      "2022-04-20 13:13:47.521503\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000430.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 27.0ms pre-process, 168.3ms inference, 11.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9085 \tBbox: [ 174 \t 667 \t 420 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9045 \tBbox: [ 660 \t 327 \t 765 \t 657 ]\n",
      "3 \tObject: person \tConfidence = 0.876 \tBbox: [ 559 \t 30 \t 654 \t 224 ]\n",
      "4 \tObject: person \tConfidence = 0.8623 \tBbox: [ 573 \t 166 \t 690 \t 454 ]\n",
      "5 \tObject: train \tConfidence = 0.8565 \tBbox: [ 2 \t 3 \t 467 \t 1066 ]\n",
      "6 \tObject: person \tConfidence = 0.8539 \tBbox: [ 489 \t 283 \t 626 \t 606 ]\n",
      "7 \tObject: person \tConfidence = 0.8431 \tBbox: [ 387 \t 138 \t 456 \t 390 ]\n",
      "8 \tObject: person \tConfidence = 0.8321 \tBbox: [ 461 \t 26 \t 528 \t 230 ]\n",
      "9 \tObject: person \tConfidence = 0.8166 \tBbox: [ 450 \t 214 \t 528 \t 507 ]\n",
      "10 \tObject: person \tConfidence = 0.796 \tBbox: [ 313 \t 482 \t 444 \t 810 ]\n",
      "11 \tObject: person \tConfidence = 0.6107 \tBbox: [ 591 \t 0 \t 627 \t 49 ]\n",
      "12 \tObject: person \tConfidence = 0.5409 \tBbox: [ 504 \t 0 \t 536 \t 47 ]\n",
      "13 \tObject: person \tConfidence = 0.531 \tBbox: [ 690 \t 11 \t 766 \t 258 ]\n",
      "14 \tObject: person \tConfidence = 0.4938 \tBbox: [ 446 \t 3 \t 491 \t 146 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000431 / 1050\n",
      "Frames to be processed: 619  | To do: 58.95 % | Done: 41.05 %\n",
      "\n",
      "2022-04-20 13:13:47.993176\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000431.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 32.0ms pre-process, 168.6ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.909 \tBbox: [ 174 \t 667 \t 423 \t 1077 ]\n",
      "2 \tObject: person \tConfidence = 0.9012 \tBbox: [ 559 \t 32 \t 653 \t 235 ]\n",
      "3 \tObject: person \tConfidence = 0.9004 \tBbox: [ 657 \t 338 \t 765 \t 677 ]\n",
      "4 \tObject: person \tConfidence = 0.8681 \tBbox: [ 458 \t 15 \t 525 \t 227 ]\n",
      "5 \tObject: person \tConfidence = 0.8658 \tBbox: [ 572 \t 167 \t 691 \t 455 ]\n",
      "6 \tObject: person \tConfidence = 0.8307 \tBbox: [ 387 \t 138 \t 456 \t 389 ]\n",
      "7 \tObject: person \tConfidence = 0.8168 \tBbox: [ 315 \t 483 \t 444 \t 805 ]\n",
      "8 \tObject: person \tConfidence = 0.816 \tBbox: [ 450 \t 210 \t 529 \t 500 ]\n",
      "9 \tObject: person \tConfidence = 0.8132 \tBbox: [ 484 \t 280 \t 611 \t 609 ]\n",
      "10 \tObject: train \tConfidence = 0.7784 \tBbox: [ 2 \t 3 \t 468 \t 1066 ]\n",
      "11 \tObject: person \tConfidence = 0.6845 \tBbox: [ 589 \t 0 \t 628 \t 56 ]\n",
      "12 \tObject: person \tConfidence = 0.5398 \tBbox: [ 447 \t 0 \t 486 \t 152 ]\n",
      "13 \tObject: person \tConfidence = 0.448 \tBbox: [ 503 \t 0 \t 537 \t 47 ]\n",
      "14 \tObject: person \tConfidence = 0.3936 \tBbox: [ 554 \t 0 \t 569 \t 21 ]\n",
      "15 \tObject: person \tConfidence = 0.391 \tBbox: [ 686 \t 9 \t 765 \t 259 ]\n",
      "16 \tObject: person \tConfidence = 0.3219 \tBbox: [ 488 \t 253 \t 562 \t 366 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000432 / 1050\n",
      "Frames to be processed: 618  | To do: 58.86 % | Done: 41.14 %\n",
      "\n",
      "2022-04-20 13:13:48.463969\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000432.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 22.4ms pre-process, 172.5ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9081 \tBbox: [ 174 \t 666 \t 415 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8968 \tBbox: [ 656 \t 343 \t 765 \t 688 ]\n",
      "3 \tObject: person \tConfidence = 0.8897 \tBbox: [ 558 \t 32 \t 653 \t 241 ]\n",
      "4 \tObject: person \tConfidence = 0.8645 \tBbox: [ 573 \t 171 \t 691 \t 455 ]\n",
      "5 \tObject: person \tConfidence = 0.8294 \tBbox: [ 457 \t 16 \t 524 \t 227 ]\n",
      "6 \tObject: person \tConfidence = 0.8284 \tBbox: [ 481 \t 284 \t 599 \t 613 ]\n",
      "7 \tObject: train \tConfidence = 0.8268 \tBbox: [ 3 \t 3 \t 468 \t 1067 ]\n",
      "8 \tObject: person \tConfidence = 0.8265 \tBbox: [ 387 \t 138 \t 456 \t 389 ]\n",
      "9 \tObject: person \tConfidence = 0.8204 \tBbox: [ 315 \t 483 \t 444 \t 804 ]\n",
      "10 \tObject: person \tConfidence = 0.8179 \tBbox: [ 450 \t 210 \t 532 \t 497 ]\n",
      "11 \tObject: person \tConfidence = 0.6343 \tBbox: [ 589 \t 0 \t 628 \t 56 ]\n",
      "12 \tObject: person \tConfidence = 0.4275 \tBbox: [ 445 \t 3 \t 488 \t 147 ]\n",
      "13 \tObject: person \tConfidence = 0.3995 \tBbox: [ 687 \t 66 \t 765 \t 260 ]\n",
      "14 \tObject: person \tConfidence = 0.3911 \tBbox: [ 502 \t 0 \t 539 \t 54 ]\n",
      "15 \tObject: person \tConfidence = 0.3847 \tBbox: [ 553 \t 0 \t 570 \t 21 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000433 / 1050\n",
      "Frames to be processed: 617  | To do: 58.76 % | Done: 41.24 %\n",
      "\n",
      "2022-04-20 13:13:48.894919\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000433.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 26.9ms pre-process, 177.0ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9104 \tBbox: [ 174 \t 665 \t 420 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8937 \tBbox: [ 558 \t 32 \t 653 \t 247 ]\n",
      "3 \tObject: person \tConfidence = 0.8911 \tBbox: [ 657 \t 348 \t 765 \t 696 ]\n",
      "4 \tObject: person \tConfidence = 0.8521 \tBbox: [ 572 \t 173 \t 690 \t 463 ]\n",
      "5 \tObject: train \tConfidence = 0.8519 \tBbox: [ 2 \t 4 \t 469 \t 1067 ]\n",
      "6 \tObject: person \tConfidence = 0.8503 \tBbox: [ 456 \t 16 \t 523 \t 227 ]\n",
      "7 \tObject: person \tConfidence = 0.8354 \tBbox: [ 315 \t 482 \t 443 \t 804 ]\n",
      "8 \tObject: person \tConfidence = 0.8285 \tBbox: [ 387 \t 138 \t 456 \t 389 ]\n",
      "9 \tObject: person \tConfidence = 0.8224 \tBbox: [ 450 \t 210 \t 533 \t 493 ]\n",
      "10 \tObject: person \tConfidence = 0.8199 \tBbox: [ 481 \t 283 \t 599 \t 615 ]\n",
      "11 \tObject: person \tConfidence = 0.6268 \tBbox: [ 589 \t 0 \t 628 \t 58 ]\n",
      "12 \tObject: person \tConfidence = 0.4746 \tBbox: [ 688 \t 64 \t 765 \t 260 ]\n",
      "13 \tObject: person \tConfidence = 0.3957 \tBbox: [ 501 \t 0 \t 539 \t 61 ]\n",
      "14 \tObject: person \tConfidence = 0.3242 \tBbox: [ 445 \t 1 \t 488 \t 147 ]\n",
      "15 \tObject: person \tConfidence = 0.312 \tBbox: [ 554 \t 0 \t 571 \t 21 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000434 / 1050\n",
      "Frames to be processed: 616  | To do: 58.67 % | Done: 41.33 %\n",
      "\n",
      "2022-04-20 13:13:49.481119\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000434.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 33.4ms pre-process, 173.8ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9144 \tBbox: [ 174 \t 665 \t 410 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8976 \tBbox: [ 557 \t 36 \t 654 \t 246 ]\n",
      "3 \tObject: person \tConfidence = 0.8894 \tBbox: [ 659 \t 352 \t 765 \t 708 ]\n",
      "4 \tObject: person \tConfidence = 0.8729 \tBbox: [ 570 \t 176 \t 691 \t 456 ]\n",
      "5 \tObject: train \tConfidence = 0.8694 \tBbox: [ 2 \t 5 \t 468 \t 1068 ]\n",
      "6 \tObject: person \tConfidence = 0.8435 \tBbox: [ 450 \t 208 \t 530 \t 491 ]\n",
      "7 \tObject: person \tConfidence = 0.8324 \tBbox: [ 315 \t 482 \t 444 \t 802 ]\n",
      "8 \tObject: person \tConfidence = 0.8221 \tBbox: [ 388 \t 138 \t 456 \t 389 ]\n",
      "9 \tObject: person \tConfidence = 0.8141 \tBbox: [ 481 \t 285 \t 590 \t 614 ]\n",
      "10 \tObject: person \tConfidence = 0.8132 \tBbox: [ 456 \t 18 \t 522 \t 227 ]\n",
      "11 \tObject: person \tConfidence = 0.6165 \tBbox: [ 686 \t 64 \t 765 \t 260 ]\n",
      "12 \tObject: person \tConfidence = 0.528 \tBbox: [ 587 \t 0 \t 628 \t 59 ]\n",
      "13 \tObject: person \tConfidence = 0.3954 \tBbox: [ 500 \t 0 \t 539 \t 67 ]\n",
      "14 \tObject: person \tConfidence = 0.3326 \tBbox: [ 554 \t 0 \t 570 \t 21 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000435 / 1050\n",
      "Frames to be processed: 615  | To do: 58.57 % | Done: 41.43 %\n",
      "\n",
      "2022-04-20 13:13:50.023029\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000435.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 54.9ms pre-process, 175.9ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9104 \tBbox: [ 174 \t 665 \t 419 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9026 \tBbox: [ 556 \t 38 \t 654 \t 250 ]\n",
      "3 \tObject: person \tConfidence = 0.8851 \tBbox: [ 660 \t 353 \t 765 \t 709 ]\n",
      "4 \tObject: train \tConfidence = 0.8718 \tBbox: [ 3 \t 5 \t 468 \t 1068 ]\n",
      "5 \tObject: person \tConfidence = 0.8351 \tBbox: [ 570 \t 179 \t 690 \t 477 ]\n",
      "6 \tObject: person \tConfidence = 0.833 \tBbox: [ 455 \t 17 \t 521 \t 228 ]\n",
      "7 \tObject: person \tConfidence = 0.8258 \tBbox: [ 315 \t 481 \t 444 \t 800 ]\n",
      "8 \tObject: person \tConfidence = 0.8257 \tBbox: [ 388 \t 138 \t 457 \t 389 ]\n",
      "9 \tObject: person \tConfidence = 0.8243 \tBbox: [ 449 \t 207 \t 530 \t 489 ]\n",
      "10 \tObject: person \tConfidence = 0.8208 \tBbox: [ 476 \t 286 \t 592 \t 616 ]\n",
      "11 \tObject: person \tConfidence = 0.6168 \tBbox: [ 687 \t 63 \t 765 \t 262 ]\n",
      "12 \tObject: person \tConfidence = 0.5872 \tBbox: [ 586 \t 0 \t 628 \t 66 ]\n",
      "13 \tObject: person \tConfidence = 0.4368 \tBbox: [ 495 \t 0 \t 538 \t 93 ]\n",
      "14 \tObject: person \tConfidence = 0.3426 \tBbox: [ 555 \t 0 \t 570 \t 22 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000436 / 1050\n",
      "Frames to be processed: 614  | To do: 58.48 % | Done: 41.52 %\n",
      "\n",
      "2022-04-20 13:13:50.553244\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000436.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 38.9ms pre-process, 170.2ms inference, 11.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.913 \tBbox: [ 174 \t 665 \t 412 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9061 \tBbox: [ 555 \t 37 \t 653 \t 257 ]\n",
      "3 \tObject: person \tConfidence = 0.8922 \tBbox: [ 662 \t 357 \t 765 \t 710 ]\n",
      "4 \tObject: person \tConfidence = 0.8351 \tBbox: [ 569 \t 185 \t 689 \t 498 ]\n",
      "5 \tObject: train \tConfidence = 0.8252 \tBbox: [ 3 \t 5 \t 468 \t 1071 ]\n",
      "6 \tObject: person \tConfidence = 0.823 \tBbox: [ 388 \t 139 \t 456 \t 391 ]\n",
      "7 \tObject: person \tConfidence = 0.8153 \tBbox: [ 468 \t 281 \t 582 \t 611 ]\n",
      "8 \tObject: person \tConfidence = 0.8095 \tBbox: [ 448 \t 207 \t 528 \t 489 ]\n",
      "9 \tObject: person \tConfidence = 0.782 \tBbox: [ 315 \t 480 \t 443 \t 797 ]\n",
      "10 \tObject: person \tConfidence = 0.775 \tBbox: [ 455 \t 32 \t 520 \t 227 ]\n",
      "11 \tObject: person \tConfidence = 0.6694 \tBbox: [ 584 \t 0 \t 628 \t 75 ]\n",
      "12 \tObject: person \tConfidence = 0.5911 \tBbox: [ 688 \t 62 \t 764 \t 264 ]\n",
      "13 \tObject: person \tConfidence = 0.4975 \tBbox: [ 497 \t 0 \t 537 \t 89 ]\n",
      "14 \tObject: person \tConfidence = 0.4243 \tBbox: [ 556 \t 0 \t 570 \t 23 ]\n",
      "15 \tObject: person \tConfidence = 0.316 \tBbox: [ 609 \t 276 \t 684 \t 418 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000437 / 1050\n",
      "Frames to be processed: 613  | To do: 58.38 % | Done: 41.62 %\n",
      "\n",
      "2022-04-20 13:13:51.090053\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000437.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 29.4ms pre-process, 169.1ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9041 \tBbox: [ 175 \t 664 \t 414 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.881 \tBbox: [ 664 \t 358 \t 765 \t 710 ]\n",
      "3 \tObject: person \tConfidence = 0.8575 \tBbox: [ 555 \t 41 \t 654 \t 266 ]\n",
      "4 \tObject: person \tConfidence = 0.8401 \tBbox: [ 566 \t 189 \t 689 \t 476 ]\n",
      "5 \tObject: person \tConfidence = 0.8276 \tBbox: [ 388 \t 140 \t 456 \t 391 ]\n",
      "6 \tObject: person \tConfidence = 0.8247 \tBbox: [ 456 \t 280 \t 581 \t 608 ]\n",
      "7 \tObject: person \tConfidence = 0.8085 \tBbox: [ 446 \t 207 \t 529 \t 487 ]\n",
      "8 \tObject: train \tConfidence = 0.7912 \tBbox: [ 3 \t 4 \t 468 \t 1068 ]\n",
      "9 \tObject: person \tConfidence = 0.7738 \tBbox: [ 454 \t 30 \t 520 \t 227 ]\n",
      "10 \tObject: person \tConfidence = 0.7715 \tBbox: [ 314 \t 478 \t 442 \t 802 ]\n",
      "11 \tObject: person \tConfidence = 0.7152 \tBbox: [ 583 \t 0 \t 629 \t 78 ]\n",
      "12 \tObject: person \tConfidence = 0.5862 \tBbox: [ 497 \t 0 \t 538 \t 91 ]\n",
      "13 \tObject: person \tConfidence = 0.5475 \tBbox: [ 684 \t 61 \t 762 \t 262 ]\n",
      "14 \tObject: person \tConfidence = 0.4669 \tBbox: [ 558 \t 0 \t 571 \t 26 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000438 / 1050\n",
      "Frames to be processed: 612  | To do: 58.29 % | Done: 41.71 %\n",
      "\n",
      "2022-04-20 13:13:51.714638\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000438.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 29.4ms pre-process, 165.5ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9058 \tBbox: [ 175 \t 664 \t 420 \t 1077 ]\n",
      "2 \tObject: person \tConfidence = 0.8865 \tBbox: [ 667 \t 360 \t 765 \t 710 ]\n",
      "3 \tObject: person \tConfidence = 0.8511 \tBbox: [ 555 \t 46 \t 653 \t 267 ]\n",
      "4 \tObject: person \tConfidence = 0.8367 \tBbox: [ 452 \t 19 \t 519 \t 226 ]\n",
      "5 \tObject: person \tConfidence = 0.8238 \tBbox: [ 388 \t 140 \t 456 \t 391 ]\n",
      "6 \tObject: person \tConfidence = 0.8123 \tBbox: [ 446 \t 283 \t 580 \t 605 ]\n",
      "7 \tObject: train \tConfidence = 0.81 \tBbox: [ 3 \t 4 \t 467 \t 1070 ]\n",
      "8 \tObject: person \tConfidence = 0.8026 \tBbox: [ 565 \t 190 \t 689 \t 512 ]\n",
      "9 \tObject: person \tConfidence = 0.7878 \tBbox: [ 314 \t 477 \t 442 \t 801 ]\n",
      "10 \tObject: person \tConfidence = 0.7419 \tBbox: [ 581 \t 0 \t 629 \t 81 ]\n",
      "11 \tObject: person \tConfidence = 0.7087 \tBbox: [ 445 \t 206 \t 528 \t 484 ]\n",
      "12 \tObject: person \tConfidence = 0.6052 \tBbox: [ 496 \t 0 \t 538 \t 91 ]\n",
      "13 \tObject: person \tConfidence = 0.5958 \tBbox: [ 683 \t 62 \t 758 \t 262 ]\n",
      "14 \tObject: person \tConfidence = 0.4962 \tBbox: [ 558 \t 0 \t 571 \t 26 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000439 / 1050\n",
      "Frames to be processed: 611  | To do: 58.19 % | Done: 41.81 %\n",
      "\n",
      "2022-04-20 13:13:52.185536\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000439.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 51.6ms pre-process, 175.6ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9084 \tBbox: [ 175 \t 663 \t 415 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8862 \tBbox: [ 669 \t 361 \t 765 \t 708 ]\n",
      "3 \tObject: person \tConfidence = 0.8628 \tBbox: [ 556 \t 50 \t 653 \t 267 ]\n",
      "4 \tObject: person \tConfidence = 0.8234 \tBbox: [ 564 \t 191 \t 689 \t 515 ]\n",
      "5 \tObject: person \tConfidence = 0.8173 \tBbox: [ 387 \t 140 \t 455 \t 390 ]\n",
      "6 \tObject: person \tConfidence = 0.8088 \tBbox: [ 314 \t 478 \t 444 \t 796 ]\n",
      "7 \tObject: person \tConfidence = 0.8032 \tBbox: [ 449 \t 16 \t 518 \t 225 ]\n",
      "8 \tObject: person \tConfidence = 0.7686 \tBbox: [ 442 \t 280 \t 581 \t 601 ]\n",
      "9 \tObject: train \tConfidence = 0.7521 \tBbox: [ 3 \t 4 \t 468 \t 1071 ]\n",
      "10 \tObject: person \tConfidence = 0.748 \tBbox: [ 578 \t 0 \t 630 \t 84 ]\n",
      "11 \tObject: person \tConfidence = 0.6356 \tBbox: [ 681 \t 63 \t 755 \t 261 ]\n",
      "12 \tObject: person \tConfidence = 0.5823 \tBbox: [ 496 \t 0 \t 537 \t 92 ]\n",
      "13 \tObject: person \tConfidence = 0.4813 \tBbox: [ 445 \t 209 \t 520 \t 388 ]\n",
      "14 \tObject: person \tConfidence = 0.4494 \tBbox: [ 559 \t 0 \t 572 \t 25 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000440 / 1050\n",
      "Frames to be processed: 610  | To do: 58.1 % | Done: 41.9 %\n",
      "\n",
      "2022-04-20 13:13:52.776403\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000440.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 31.5ms pre-process, 179.8ms inference, 4.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9064 \tBbox: [ 176 \t 664 \t 414 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8819 \tBbox: [ 554 \t 51 \t 654 \t 269 ]\n",
      "3 \tObject: person \tConfidence = 0.8809 \tBbox: [ 675 \t 364 \t 765 \t 708 ]\n",
      "4 \tObject: person \tConfidence = 0.8526 \tBbox: [ 388 \t 140 \t 453 \t 391 ]\n",
      "5 \tObject: person \tConfidence = 0.8292 \tBbox: [ 437 \t 287 \t 584 \t 596 ]\n",
      "6 \tObject: person \tConfidence = 0.8281 \tBbox: [ 562 \t 192 \t 689 \t 516 ]\n",
      "7 \tObject: person \tConfidence = 0.7992 \tBbox: [ 443 \t 9 \t 517 \t 225 ]\n",
      "8 \tObject: person \tConfidence = 0.7464 \tBbox: [ 576 \t 0 \t 630 \t 86 ]\n",
      "9 \tObject: person \tConfidence = 0.6998 \tBbox: [ 314 \t 475 \t 444 \t 805 ]\n",
      "10 \tObject: train \tConfidence = 0.6357 \tBbox: [ 3 \t 4 \t 468 \t 1071 ]\n",
      "11 \tObject: person \tConfidence = 0.6297 \tBbox: [ 443 \t 208 \t 529 \t 377 ]\n",
      "12 \tObject: person \tConfidence = 0.5828 \tBbox: [ 681 \t 62 \t 752 \t 260 ]\n",
      "13 \tObject: person \tConfidence = 0.5449 \tBbox: [ 499 \t 0 \t 536 \t 92 ]\n",
      "14 \tObject: person \tConfidence = 0.4227 \tBbox: [ 559 \t 0 \t 572 \t 25 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000441 / 1050\n",
      "Frames to be processed: 609  | To do: 58.0 % | Done: 42.0 %\n",
      "\n",
      "2022-04-20 13:13:53.252761\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000441.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons\n",
      "Speed: 25.8ms pre-process, 177.3ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9117 \tBbox: [ 173 \t 664 \t 423 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8719 \tBbox: [ 552 \t 51 \t 653 \t 269 ]\n",
      "3 \tObject: person \tConfidence = 0.8699 \tBbox: [ 680 \t 372 \t 766 \t 734 ]\n",
      "4 \tObject: person \tConfidence = 0.8632 \tBbox: [ 387 \t 140 \t 452 \t 391 ]\n",
      "5 \tObject: person \tConfidence = 0.8393 \tBbox: [ 559 \t 194 \t 689 \t 517 ]\n",
      "6 \tObject: person \tConfidence = 0.8294 \tBbox: [ 562 \t 0 \t 630 \t 92 ]\n",
      "7 \tObject: person \tConfidence = 0.8227 \tBbox: [ 436 \t 305 \t 578 \t 590 ]\n",
      "8 \tObject: person \tConfidence = 0.8164 \tBbox: [ 315 \t 478 \t 441 \t 792 ]\n",
      "9 \tObject: person \tConfidence = 0.8126 \tBbox: [ 443 \t 16 \t 513 \t 222 ]\n",
      "10 \tObject: person \tConfidence = 0.6336 \tBbox: [ 441 \t 206 \t 532 \t 367 ]\n",
      "11 \tObject: person \tConfidence = 0.5684 \tBbox: [ 498 \t 0 \t 540 \t 90 ]\n",
      "12 \tObject: person \tConfidence = 0.4795 \tBbox: [ 678 \t 62 \t 748 \t 265 ]\n",
      "13 \tObject: person \tConfidence = 0.4214 \tBbox: [ 559 \t 0 \t 573 \t 25 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000442 / 1050\n",
      "Frames to be processed: 608  | To do: 57.9 % | Done: 42.1 %\n",
      "\n",
      "2022-04-20 13:13:53.715422\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000442.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons\n",
      "Speed: 39.8ms pre-process, 172.0ms inference, 3.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9051 \tBbox: [ 177 \t 664 \t 416 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8709 \tBbox: [ 553 \t 46 \t 653 \t 268 ]\n",
      "3 \tObject: person \tConfidence = 0.8618 \tBbox: [ 386 \t 140 \t 451 \t 392 ]\n",
      "4 \tObject: person \tConfidence = 0.8572 \tBbox: [ 681 \t 375 \t 765 \t 757 ]\n",
      "5 \tObject: person \tConfidence = 0.854 \tBbox: [ 557 \t 195 \t 688 \t 517 ]\n",
      "6 \tObject: person \tConfidence = 0.8363 \tBbox: [ 435 \t 293 \t 570 \t 587 ]\n",
      "7 \tObject: person \tConfidence = 0.8214 \tBbox: [ 560 \t 0 \t 628 \t 94 ]\n",
      "8 \tObject: person \tConfidence = 0.8073 \tBbox: [ 440 \t 21 \t 511 \t 221 ]\n",
      "9 \tObject: person \tConfidence = 0.7831 \tBbox: [ 316 \t 477 \t 440 \t 800 ]\n",
      "10 \tObject: person \tConfidence = 0.697 \tBbox: [ 440 \t 207 \t 517 \t 362 ]\n",
      "11 \tObject: person \tConfidence = 0.5684 \tBbox: [ 498 \t 0 \t 540 \t 92 ]\n",
      "12 \tObject: person \tConfidence = 0.4288 \tBbox: [ 675 \t 62 \t 746 \t 267 ]\n",
      "13 \tObject: person \tConfidence = 0.4149 \tBbox: [ 559 \t 0 \t 573 \t 25 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000443 / 1050\n",
      "Frames to be processed: 607  | To do: 57.81 % | Done: 42.19 %\n",
      "\n",
      "2022-04-20 13:13:54.218164\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000443.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons\n",
      "Speed: 27.1ms pre-process, 175.4ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9139 \tBbox: [ 176 \t 664 \t 418 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8741 \tBbox: [ 680 \t 380 \t 766 \t 768 ]\n",
      "3 \tObject: person \tConfidence = 0.8728 \tBbox: [ 557 \t 198 \t 688 \t 515 ]\n",
      "4 \tObject: person \tConfidence = 0.8666 \tBbox: [ 552 \t 51 \t 653 \t 266 ]\n",
      "5 \tObject: person \tConfidence = 0.8595 \tBbox: [ 386 \t 140 \t 451 \t 392 ]\n",
      "6 \tObject: person \tConfidence = 0.8199 \tBbox: [ 434 \t 283 \t 556 \t 585 ]\n",
      "7 \tObject: person \tConfidence = 0.8168 \tBbox: [ 560 \t 0 \t 629 \t 94 ]\n",
      "8 \tObject: person \tConfidence = 0.81 \tBbox: [ 437 \t 17 \t 509 \t 220 ]\n",
      "9 \tObject: person \tConfidence = 0.7846 \tBbox: [ 316 \t 476 \t 439 \t 799 ]\n",
      "10 \tObject: person \tConfidence = 0.7375 \tBbox: [ 438 \t 206 \t 518 \t 364 ]\n",
      "11 \tObject: person \tConfidence = 0.6026 \tBbox: [ 497 \t 0 \t 539 \t 86 ]\n",
      "12 \tObject: person \tConfidence = 0.4459 \tBbox: [ 672 \t 61 \t 742 \t 266 ]\n",
      "13 \tObject: person \tConfidence = 0.369 \tBbox: [ 558 \t 0 \t 573 \t 25 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000444 / 1050\n",
      "Frames to be processed: 606  | To do: 57.71 % | Done: 42.29 %\n",
      "\n",
      "2022-04-20 13:13:54.647038\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000444.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons\n",
      "Speed: 30.5ms pre-process, 178.2ms inference, 11.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9131 \tBbox: [ 179 \t 665 \t 421 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8765 \tBbox: [ 553 \t 53 \t 653 \t 266 ]\n",
      "3 \tObject: person \tConfidence = 0.8756 \tBbox: [ 558 \t 198 \t 688 \t 516 ]\n",
      "4 \tObject: person \tConfidence = 0.8697 \tBbox: [ 680 \t 388 \t 766 \t 783 ]\n",
      "5 \tObject: person \tConfidence = 0.8432 \tBbox: [ 387 \t 140 \t 450 \t 391 ]\n",
      "6 \tObject: person \tConfidence = 0.8189 \tBbox: [ 559 \t 0 \t 628 \t 95 ]\n",
      "7 \tObject: person \tConfidence = 0.8184 \tBbox: [ 433 \t 23 \t 508 \t 218 ]\n",
      "8 \tObject: person \tConfidence = 0.7895 \tBbox: [ 316 \t 476 \t 439 \t 808 ]\n",
      "9 \tObject: person \tConfidence = 0.7632 \tBbox: [ 433 \t 267 \t 559 \t 584 ]\n",
      "10 \tObject: person \tConfidence = 0.6796 \tBbox: [ 496 \t 0 \t 537 \t 85 ]\n",
      "11 \tObject: person \tConfidence = 0.5643 \tBbox: [ 434 \t 206 \t 508 \t 359 ]\n",
      "12 \tObject: person \tConfidence = 0.5399 \tBbox: [ 671 \t 61 \t 738 \t 229 ]\n",
      "13 \tObject: person \tConfidence = 0.3539 \tBbox: [ 558 \t 0 \t 574 \t 26 ]\n",
      "14 \tObject: person \tConfidence = 0.3352 \tBbox: [ 448 \t 0 \t 495 \t 46 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000445 / 1050\n",
      "Frames to be processed: 605  | To do: 57.62 % | Done: 42.38 %\n",
      "\n",
      "2022-04-20 13:13:55.107607\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000445.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 25.6ms pre-process, 174.2ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9021 \tBbox: [ 184 \t 666 \t 416 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8681 \tBbox: [ 558 \t 199 \t 688 \t 515 ]\n",
      "3 \tObject: person \tConfidence = 0.8672 \tBbox: [ 552 \t 54 \t 653 \t 265 ]\n",
      "4 \tObject: person \tConfidence = 0.8621 \tBbox: [ 680 \t 397 \t 765 \t 791 ]\n",
      "5 \tObject: person \tConfidence = 0.8451 \tBbox: [ 386 \t 140 \t 450 \t 390 ]\n",
      "6 \tObject: person \tConfidence = 0.8172 \tBbox: [ 430 \t 19 \t 503 \t 215 ]\n",
      "7 \tObject: person \tConfidence = 0.7937 \tBbox: [ 424 \t 256 \t 553 \t 584 ]\n",
      "8 \tObject: person \tConfidence = 0.7847 \tBbox: [ 315 \t 474 \t 439 \t 799 ]\n",
      "9 \tObject: person \tConfidence = 0.7813 \tBbox: [ 559 \t 0 \t 627 \t 96 ]\n",
      "10 \tObject: person \tConfidence = 0.7523 \tBbox: [ 661 \t 62 \t 738 \t 264 ]\n",
      "11 \tObject: train \tConfidence = 0.6834 \tBbox: [ 3 \t 3 \t 466 \t 1071 ]\n",
      "12 \tObject: person \tConfidence = 0.6647 \tBbox: [ 497 \t 0 \t 538 \t 86 ]\n",
      "13 \tObject: person \tConfidence = 0.4493 \tBbox: [ 428 \t 207 \t 505 \t 355 ]\n",
      "14 \tObject: person \tConfidence = 0.3349 \tBbox: [ 557 \t 0 \t 575 \t 27 ]\n",
      "15 \tObject: person \tConfidence = 0.3064 \tBbox: [ 447 \t 0 \t 495 \t 46 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000446 / 1050\n",
      "Frames to be processed: 604  | To do: 57.52 % | Done: 42.48 %\n",
      "\n",
      "2022-04-20 13:13:55.630451\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000446.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 66.2ms pre-process, 167.3ms inference, 10.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8851 \tBbox: [ 184 \t 667 \t 416 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8829 \tBbox: [ 553 \t 59 \t 654 \t 265 ]\n",
      "3 \tObject: person \tConfidence = 0.8785 \tBbox: [ 559 \t 200 \t 688 \t 513 ]\n",
      "4 \tObject: person \tConfidence = 0.8752 \tBbox: [ 679 \t 410 \t 765 \t 809 ]\n",
      "5 \tObject: person \tConfidence = 0.8324 \tBbox: [ 384 \t 142 \t 449 \t 388 ]\n",
      "6 \tObject: person \tConfidence = 0.8175 \tBbox: [ 559 \t 0 \t 626 \t 97 ]\n",
      "7 \tObject: person \tConfidence = 0.7923 \tBbox: [ 426 \t 23 \t 499 \t 220 ]\n",
      "8 \tObject: person \tConfidence = 0.7877 \tBbox: [ 654 \t 62 \t 734 \t 267 ]\n",
      "9 \tObject: person \tConfidence = 0.781 \tBbox: [ 315 \t 472 \t 439 \t 805 ]\n",
      "10 \tObject: person \tConfidence = 0.7234 \tBbox: [ 428 \t 287 \t 545 \t 583 ]\n",
      "11 \tObject: person \tConfidence = 0.6218 \tBbox: [ 496 \t 0 \t 540 \t 86 ]\n",
      "12 \tObject: train \tConfidence = 0.6176 \tBbox: [ 2 \t 4 \t 467 \t 1070 ]\n",
      "13 \tObject: person \tConfidence = 0.5613 \tBbox: [ 428 \t 210 \t 503 \t 354 ]\n",
      "14 \tObject: person \tConfidence = 0.3222 \tBbox: [ 446 \t 0 \t 500 \t 55 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000447 / 1050\n",
      "Frames to be processed: 603  | To do: 57.43 % | Done: 42.57 %\n",
      "\n",
      "2022-04-20 13:13:56.150248\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000447.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons\n",
      "Speed: 26.3ms pre-process, 172.8ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8984 \tBbox: [ 558 \t 201 \t 688 \t 514 ]\n",
      "2 \tObject: person \tConfidence = 0.8866 \tBbox: [ 554 \t 59 \t 653 \t 270 ]\n",
      "3 \tObject: person \tConfidence = 0.8848 \tBbox: [ 188 \t 667 \t 416 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8704 \tBbox: [ 676 \t 418 \t 765 \t 817 ]\n",
      "5 \tObject: person \tConfidence = 0.8377 \tBbox: [ 558 \t 0 \t 623 \t 97 ]\n",
      "6 \tObject: person \tConfidence = 0.8035 \tBbox: [ 423 \t 25 \t 500 \t 219 ]\n",
      "7 \tObject: person \tConfidence = 0.7997 \tBbox: [ 315 \t 471 \t 438 \t 802 ]\n",
      "8 \tObject: person \tConfidence = 0.7923 \tBbox: [ 652 \t 63 \t 730 \t 266 ]\n",
      "9 \tObject: person \tConfidence = 0.778 \tBbox: [ 383 \t 143 \t 448 \t 384 ]\n",
      "10 \tObject: person \tConfidence = 0.7674 \tBbox: [ 429 \t 265 \t 567 \t 582 ]\n",
      "11 \tObject: person \tConfidence = 0.6826 \tBbox: [ 496 \t 0 \t 542 \t 85 ]\n",
      "12 \tObject: person \tConfidence = 0.4548 \tBbox: [ 424 \t 211 \t 517 \t 355 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000448 / 1050\n",
      "Frames to be processed: 602  | To do: 57.33 % | Done: 42.67 %\n",
      "\n",
      "2022-04-20 13:13:56.676270\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000448.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 38.6ms pre-process, 170.5ms inference, 11.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9042 \tBbox: [ 192 \t 667 \t 412 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8982 \tBbox: [ 559 \t 202 \t 687 \t 516 ]\n",
      "3 \tObject: person \tConfidence = 0.8904 \tBbox: [ 674 \t 425 \t 765 \t 821 ]\n",
      "4 \tObject: person \tConfidence = 0.8864 \tBbox: [ 555 \t 61 \t 654 \t 273 ]\n",
      "5 \tObject: person \tConfidence = 0.8538 \tBbox: [ 558 \t 0 \t 620 \t 98 ]\n",
      "6 \tObject: person \tConfidence = 0.828 \tBbox: [ 423 \t 29 \t 502 \t 215 ]\n",
      "7 \tObject: person \tConfidence = 0.8048 \tBbox: [ 652 \t 63 \t 727 \t 267 ]\n",
      "8 \tObject: person \tConfidence = 0.7786 \tBbox: [ 315 \t 469 \t 437 \t 813 ]\n",
      "9 \tObject: person \tConfidence = 0.7482 \tBbox: [ 382 \t 143 \t 448 \t 369 ]\n",
      "10 \tObject: person \tConfidence = 0.7337 \tBbox: [ 496 \t 0 \t 542 \t 85 ]\n",
      "11 \tObject: person \tConfidence = 0.7309 \tBbox: [ 423 \t 275 \t 552 \t 582 ]\n",
      "12 \tObject: train \tConfidence = 0.5868 \tBbox: [ 2 \t 3 \t 467 \t 1071 ]\n",
      "13 \tObject: person \tConfidence = 0.3407 \tBbox: [ 427 \t 212 \t 502 \t 350 ]\n",
      "14 \tObject: person \tConfidence = 0.324 \tBbox: [ 448 \t 0 \t 500 \t 54 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000449 / 1050\n",
      "Frames to be processed: 601  | To do: 57.24 % | Done: 42.76 %\n",
      "\n",
      "2022-04-20 13:13:57.239513\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000449.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons\n",
      "Speed: 25.7ms pre-process, 172.4ms inference, 3.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9025 \tBbox: [ 193 \t 667 \t 411 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8931 \tBbox: [ 670 \t 425 \t 766 \t 821 ]\n",
      "3 \tObject: person \tConfidence = 0.8857 \tBbox: [ 555 \t 67 \t 654 \t 271 ]\n",
      "4 \tObject: person \tConfidence = 0.8837 \tBbox: [ 560 \t 204 \t 686 \t 540 ]\n",
      "5 \tObject: person \tConfidence = 0.8506 \tBbox: [ 558 \t 0 \t 617 \t 97 ]\n",
      "6 \tObject: person \tConfidence = 0.8257 \tBbox: [ 420 \t 260 \t 545 \t 581 ]\n",
      "7 \tObject: person \tConfidence = 0.8243 \tBbox: [ 651 \t 63 \t 725 \t 266 ]\n",
      "8 \tObject: person \tConfidence = 0.7922 \tBbox: [ 422 \t 26 \t 503 \t 214 ]\n",
      "9 \tObject: person \tConfidence = 0.7678 \tBbox: [ 315 \t 469 \t 436 \t 799 ]\n",
      "10 \tObject: person \tConfidence = 0.7355 \tBbox: [ 381 \t 143 \t 448 \t 335 ]\n",
      "11 \tObject: person \tConfidence = 0.723 \tBbox: [ 495 \t 0 \t 542 \t 84 ]\n",
      "12 \tObject: person \tConfidence = 0.4996 \tBbox: [ 445 \t 209 \t 511 \t 298 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000450 / 1050\n",
      "Frames to be processed: 600  | To do: 57.14 % | Done: 42.86 %\n",
      "\n",
      "2022-04-20 13:13:57.798737\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000450.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 33.6ms pre-process, 175.5ms inference, 11.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9029 \tBbox: [ 194 \t 669 \t 411 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8982 \tBbox: [ 666 \t 424 \t 765 \t 821 ]\n",
      "3 \tObject: person \tConfidence = 0.8976 \tBbox: [ 555 \t 71 \t 656 \t 269 ]\n",
      "4 \tObject: person \tConfidence = 0.8855 \tBbox: [ 561 \t 208 \t 686 \t 555 ]\n",
      "5 \tObject: person \tConfidence = 0.8506 \tBbox: [ 557 \t 0 \t 617 \t 97 ]\n",
      "6 \tObject: person \tConfidence = 0.8313 \tBbox: [ 421 \t 19 \t 503 \t 215 ]\n",
      "7 \tObject: person \tConfidence = 0.8267 \tBbox: [ 649 \t 64 \t 724 \t 266 ]\n",
      "8 \tObject: person \tConfidence = 0.7993 \tBbox: [ 417 \t 289 \t 543 \t 579 ]\n",
      "9 \tObject: person \tConfidence = 0.7641 \tBbox: [ 314 \t 469 \t 437 \t 793 ]\n",
      "10 \tObject: person \tConfidence = 0.7258 \tBbox: [ 494 \t 0 \t 542 \t 85 ]\n",
      "11 \tObject: person \tConfidence = 0.7016 \tBbox: [ 380 \t 144 \t 447 \t 343 ]\n",
      "12 \tObject: train \tConfidence = 0.6998 \tBbox: [ 2 \t 3 \t 466 \t 1071 ]\n",
      "13 \tObject: person \tConfidence = 0.6277 \tBbox: [ 442 \t 209 \t 511 \t 303 ]\n",
      "14 \tObject: person \tConfidence = 0.4725 \tBbox: [ 448 \t 0 \t 499 \t 56 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000451 / 1050\n",
      "Frames to be processed: 599  | To do: 57.05 % | Done: 42.95 %\n",
      "\n",
      "2022-04-20 13:13:58.294791\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000451.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 26.7ms pre-process, 170.3ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9106 \tBbox: [ 193 \t 669 \t 412 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8856 \tBbox: [ 656 \t 428 \t 765 \t 821 ]\n",
      "3 \tObject: person \tConfidence = 0.8802 \tBbox: [ 561 \t 216 \t 688 \t 568 ]\n",
      "4 \tObject: person \tConfidence = 0.8718 \tBbox: [ 413 \t 262 \t 541 \t 578 ]\n",
      "5 \tObject: person \tConfidence = 0.8522 \tBbox: [ 422 \t 14 \t 502 \t 215 ]\n",
      "6 \tObject: person \tConfidence = 0.8418 \tBbox: [ 558 \t 71 \t 661 \t 282 ]\n",
      "7 \tObject: person \tConfidence = 0.8382 \tBbox: [ 312 \t 468 \t 433 \t 792 ]\n",
      "8 \tObject: person \tConfidence = 0.807 \tBbox: [ 556 \t 0 \t 607 \t 96 ]\n",
      "9 \tObject: person \tConfidence = 0.7384 \tBbox: [ 494 \t 0 \t 542 \t 85 ]\n",
      "10 \tObject: person \tConfidence = 0.7293 \tBbox: [ 382 \t 145 \t 445 \t 337 ]\n",
      "11 \tObject: person \tConfidence = 0.7194 \tBbox: [ 653 \t 63 \t 719 \t 267 ]\n",
      "12 \tObject: train \tConfidence = 0.7116 \tBbox: [ 2 \t 4 \t 461 \t 1070 ]\n",
      "13 \tObject: person \tConfidence = 0.4718 \tBbox: [ 448 \t 0 \t 499 \t 53 ]\n",
      "14 \tObject: person \tConfidence = 0.4587 \tBbox: [ 403 \t 211 \t 488 \t 353 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000452 / 1050\n",
      "Frames to be processed: 598  | To do: 56.95 % | Done: 43.05 %\n",
      "\n",
      "2022-04-20 13:13:58.816692\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000452.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 32.7ms pre-process, 178.0ms inference, 10.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8828 \tBbox: [ 408 \t 256 \t 538 \t 576 ]\n",
      "2 \tObject: person \tConfidence = 0.8827 \tBbox: [ 651 \t 432 \t 766 \t 821 ]\n",
      "3 \tObject: person \tConfidence = 0.8763 \tBbox: [ 561 \t 221 \t 688 \t 570 ]\n",
      "4 \tObject: person \tConfidence = 0.8666 \tBbox: [ 422 \t 12 \t 501 \t 215 ]\n",
      "5 \tObject: person \tConfidence = 0.8617 \tBbox: [ 196 \t 669 \t 411 \t 1078 ]\n",
      "6 \tObject: person \tConfidence = 0.85 \tBbox: [ 558 \t 72 \t 662 \t 281 ]\n",
      "7 \tObject: person \tConfidence = 0.8315 \tBbox: [ 555 \t 0 \t 606 \t 96 ]\n",
      "8 \tObject: person \tConfidence = 0.8038 \tBbox: [ 311 \t 471 \t 432 \t 798 ]\n",
      "9 \tObject: person \tConfidence = 0.7536 \tBbox: [ 494 \t 0 \t 542 \t 84 ]\n",
      "10 \tObject: person \tConfidence = 0.7467 \tBbox: [ 652 \t 63 \t 718 \t 267 ]\n",
      "11 \tObject: train \tConfidence = 0.7305 \tBbox: [ 2 \t 4 \t 462 \t 1069 ]\n",
      "12 \tObject: person \tConfidence = 0.7213 \tBbox: [ 381 \t 145 \t 445 \t 337 ]\n",
      "13 \tObject: person \tConfidence = 0.5898 \tBbox: [ 447 \t 0 \t 498 \t 54 ]\n",
      "14 \tObject: person \tConfidence = 0.4279 \tBbox: [ 428 \t 211 \t 486 \t 300 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000453 / 1050\n",
      "Frames to be processed: 597  | To do: 56.86 % | Done: 43.14 %\n",
      "\n",
      "2022-04-20 13:13:59.392785\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000453.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 53.5ms pre-process, 165.5ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8856 \tBbox: [ 195 \t 670 \t 410 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8762 \tBbox: [ 647 \t 431 \t 766 \t 821 ]\n",
      "3 \tObject: person \tConfidence = 0.8755 \tBbox: [ 404 \t 265 \t 535 \t 576 ]\n",
      "4 \tObject: person \tConfidence = 0.8677 \tBbox: [ 422 \t 11 \t 501 \t 217 ]\n",
      "5 \tObject: person \tConfidence = 0.851 \tBbox: [ 557 \t 72 \t 661 \t 287 ]\n",
      "6 \tObject: person \tConfidence = 0.8417 \tBbox: [ 553 \t 0 \t 605 \t 97 ]\n",
      "7 \tObject: person \tConfidence = 0.8334 \tBbox: [ 561 \t 225 \t 690 \t 563 ]\n",
      "8 \tObject: train \tConfidence = 0.8038 \tBbox: [ 2 \t 4 \t 461 \t 1069 ]\n",
      "9 \tObject: person \tConfidence = 0.8001 \tBbox: [ 308 \t 470 \t 430 \t 805 ]\n",
      "10 \tObject: person \tConfidence = 0.7626 \tBbox: [ 494 \t 0 \t 541 \t 84 ]\n",
      "11 \tObject: person \tConfidence = 0.7452 \tBbox: [ 651 \t 63 \t 717 \t 268 ]\n",
      "12 \tObject: person \tConfidence = 0.7119 \tBbox: [ 378 \t 146 \t 444 \t 334 ]\n",
      "13 \tObject: person \tConfidence = 0.5913 \tBbox: [ 446 \t 0 \t 498 \t 55 ]\n",
      "14 \tObject: person \tConfidence = 0.4322 \tBbox: [ 424 \t 212 \t 484 \t 300 ]\n",
      "15 \tObject: person \tConfidence = 0.3173 \tBbox: [ 579 \t 5 \t 614 \t 89 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000454 / 1050\n",
      "Frames to be processed: 596  | To do: 56.76 % | Done: 43.24 %\n",
      "\n",
      "2022-04-20 13:13:59.879580\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000454.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 38.8ms pre-process, 175.8ms inference, 10.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8882 \tBbox: [ 193 \t 669 \t 410 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8802 \tBbox: [ 640 \t 435 \t 766 \t 820 ]\n",
      "3 \tObject: person \tConfidence = 0.875 \tBbox: [ 402 \t 258 \t 533 \t 576 ]\n",
      "4 \tObject: person \tConfidence = 0.8711 \tBbox: [ 561 \t 225 \t 691 \t 589 ]\n",
      "5 \tObject: person \tConfidence = 0.8578 \tBbox: [ 423 \t 10 \t 501 \t 219 ]\n",
      "6 \tObject: person \tConfidence = 0.8434 \tBbox: [ 552 \t 0 \t 603 \t 96 ]\n",
      "7 \tObject: person \tConfidence = 0.8336 \tBbox: [ 558 \t 71 \t 661 \t 289 ]\n",
      "8 \tObject: person \tConfidence = 0.794 \tBbox: [ 305 \t 470 \t 428 \t 820 ]\n",
      "9 \tObject: train \tConfidence = 0.7801 \tBbox: [ 3 \t 4 \t 459 \t 1070 ]\n",
      "10 \tObject: person \tConfidence = 0.738 \tBbox: [ 494 \t 0 \t 540 \t 84 ]\n",
      "11 \tObject: person \tConfidence = 0.7143 \tBbox: [ 378 \t 146 \t 444 \t 335 ]\n",
      "12 \tObject: person \tConfidence = 0.7025 \tBbox: [ 648 \t 62 \t 716 \t 269 ]\n",
      "13 \tObject: person \tConfidence = 0.536 \tBbox: [ 445 \t 0 \t 498 \t 56 ]\n",
      "14 \tObject: person \tConfidence = 0.4046 \tBbox: [ 421 \t 213 \t 486 \t 298 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000455 / 1050\n",
      "Frames to be processed: 595  | To do: 56.67 % | Done: 43.33 %\n",
      "\n",
      "2022-04-20 13:14:00.436976\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000455.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 28.9ms pre-process, 179.2ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9133 \tBbox: [ 190 \t 673 \t 409 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8812 \tBbox: [ 559 \t 73 \t 667 \t 292 ]\n",
      "3 \tObject: person \tConfidence = 0.875 \tBbox: [ 561 \t 229 \t 692 \t 590 ]\n",
      "4 \tObject: person \tConfidence = 0.8656 \tBbox: [ 400 \t 271 \t 531 \t 575 ]\n",
      "5 \tObject: person \tConfidence = 0.864 \tBbox: [ 635 \t 439 \t 765 \t 846 ]\n",
      "6 \tObject: person \tConfidence = 0.8487 \tBbox: [ 551 \t 0 \t 602 \t 96 ]\n",
      "7 \tObject: person \tConfidence = 0.8461 \tBbox: [ 424 \t 10 \t 502 \t 220 ]\n",
      "8 \tObject: person \tConfidence = 0.7811 \tBbox: [ 304 \t 472 \t 426 \t 865 ]\n",
      "9 \tObject: person \tConfidence = 0.7484 \tBbox: [ 650 \t 62 \t 716 \t 268 ]\n",
      "10 \tObject: train \tConfidence = 0.7458 \tBbox: [ 3 \t 4 \t 457 \t 1070 ]\n",
      "11 \tObject: person \tConfidence = 0.7452 \tBbox: [ 494 \t 0 \t 539 \t 83 ]\n",
      "12 \tObject: person \tConfidence = 0.6768 \tBbox: [ 378 \t 147 \t 443 \t 337 ]\n",
      "13 \tObject: person \tConfidence = 0.4221 \tBbox: [ 402 \t 213 \t 507 \t 345 ]\n",
      "14 \tObject: person \tConfidence = 0.4002 \tBbox: [ 446 \t 0 \t 498 \t 56 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000456 / 1050\n",
      "Frames to be processed: 594  | To do: 56.57 % | Done: 43.43 %\n",
      "\n",
      "2022-04-20 13:14:00.960645\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000456.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 36.8ms pre-process, 178.3ms inference, 11.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9241 \tBbox: [ 185 \t 676 \t 405 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8987 \tBbox: [ 629 \t 474 \t 765 \t 890 ]\n",
      "3 \tObject: person \tConfidence = 0.8964 \tBbox: [ 393 \t 272 \t 528 \t 573 ]\n",
      "4 \tObject: person \tConfidence = 0.8923 \tBbox: [ 559 \t 73 \t 671 \t 303 ]\n",
      "5 \tObject: person \tConfidence = 0.8785 \tBbox: [ 560 \t 235 \t 694 \t 589 ]\n",
      "6 \tObject: person \tConfidence = 0.8546 \tBbox: [ 426 \t 8 \t 502 \t 219 ]\n",
      "7 \tObject: person \tConfidence = 0.8504 \tBbox: [ 549 \t 0 \t 601 \t 98 ]\n",
      "8 \tObject: person \tConfidence = 0.8299 \tBbox: [ 298 \t 475 \t 422 \t 807 ]\n",
      "9 \tObject: person \tConfidence = 0.777 \tBbox: [ 494 \t 0 \t 536 \t 83 ]\n",
      "10 \tObject: train \tConfidence = 0.699 \tBbox: [ 3 \t 5 \t 459 \t 1069 ]\n",
      "11 \tObject: person \tConfidence = 0.6517 \tBbox: [ 645 \t 60 \t 712 \t 264 ]\n",
      "12 \tObject: person \tConfidence = 0.6384 \tBbox: [ 377 \t 147 \t 443 \t 330 ]\n",
      "13 \tObject: person \tConfidence = 0.5866 \tBbox: [ 396 \t 212 \t 496 \t 347 ]\n",
      "14 \tObject: person \tConfidence = 0.4513 \tBbox: [ 448 \t 0 \t 498 \t 54 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000457 / 1050\n",
      "Frames to be processed: 593  | To do: 56.48 % | Done: 43.52 %\n",
      "\n",
      "2022-04-20 13:14:01.478760\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000457.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 32.9ms pre-process, 177.1ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9081 \tBbox: [ 182 \t 676 \t 403 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9001 \tBbox: [ 625 \t 481 \t 765 \t 905 ]\n",
      "3 \tObject: person \tConfidence = 0.8938 \tBbox: [ 392 \t 266 \t 525 \t 573 ]\n",
      "4 \tObject: person \tConfidence = 0.8806 \tBbox: [ 559 \t 238 \t 695 \t 589 ]\n",
      "5 \tObject: person \tConfidence = 0.8759 \tBbox: [ 559 \t 75 \t 670 \t 302 ]\n",
      "6 \tObject: person \tConfidence = 0.8453 \tBbox: [ 426 \t 9 \t 502 \t 222 ]\n",
      "7 \tObject: person \tConfidence = 0.8355 \tBbox: [ 547 \t 0 \t 601 \t 98 ]\n",
      "8 \tObject: person \tConfidence = 0.827 \tBbox: [ 294 \t 477 \t 420 \t 807 ]\n",
      "9 \tObject: person \tConfidence = 0.7939 \tBbox: [ 493 \t 0 \t 535 \t 83 ]\n",
      "10 \tObject: train \tConfidence = 0.6434 \tBbox: [ 3 \t 5 \t 457 \t 1068 ]\n",
      "11 \tObject: person \tConfidence = 0.6155 \tBbox: [ 642 \t 60 \t 711 \t 260 ]\n",
      "12 \tObject: person \tConfidence = 0.6132 \tBbox: [ 377 \t 147 \t 443 \t 340 ]\n",
      "13 \tObject: person \tConfidence = 0.5754 \tBbox: [ 396 \t 212 \t 493 \t 345 ]\n",
      "14 \tObject: person \tConfidence = 0.4213 \tBbox: [ 444 \t 0 \t 497 \t 48 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000458 / 1050\n",
      "Frames to be processed: 592  | To do: 56.38 % | Done: 43.62 %\n",
      "\n",
      "2022-04-20 13:14:01.981215\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000458.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 36.9ms pre-process, 176.6ms inference, 10.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9088 \tBbox: [ 624 \t 498 \t 765 \t 921 ]\n",
      "2 \tObject: person \tConfidence = 0.9033 \tBbox: [ 178 \t 677 \t 399 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8899 \tBbox: [ 558 \t 239 \t 696 \t 590 ]\n",
      "4 \tObject: person \tConfidence = 0.8866 \tBbox: [ 391 \t 263 \t 521 \t 570 ]\n",
      "5 \tObject: person \tConfidence = 0.867 \tBbox: [ 559 \t 77 \t 668 \t 299 ]\n",
      "6 \tObject: person \tConfidence = 0.846 \tBbox: [ 428 \t 8 \t 502 \t 217 ]\n",
      "7 \tObject: person \tConfidence = 0.8159 \tBbox: [ 547 \t 0 \t 601 \t 97 ]\n",
      "8 \tObject: person \tConfidence = 0.7754 \tBbox: [ 494 \t 0 \t 535 \t 83 ]\n",
      "9 \tObject: person \tConfidence = 0.7655 \tBbox: [ 290 \t 477 \t 417 \t 851 ]\n",
      "10 \tObject: person \tConfidence = 0.7616 \tBbox: [ 640 \t 60 \t 713 \t 275 ]\n",
      "11 \tObject: train \tConfidence = 0.7425 \tBbox: [ 3 \t 5 \t 454 \t 1068 ]\n",
      "12 \tObject: person \tConfidence = 0.5391 \tBbox: [ 396 \t 212 \t 503 \t 346 ]\n",
      "13 \tObject: person \tConfidence = 0.5212 \tBbox: [ 376 \t 148 \t 443 \t 341 ]\n",
      "14 \tObject: person \tConfidence = 0.3719 \tBbox: [ 441 \t 0 \t 497 \t 47 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000459 / 1050\n",
      "Frames to be processed: 591  | To do: 56.29 % | Done: 43.71 %\n",
      "\n",
      "2022-04-20 13:14:02.428729\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000459.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 22.6ms pre-process, 179.8ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9203 \tBbox: [ 172 \t 681 \t 397 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9032 \tBbox: [ 387 \t 255 \t 518 \t 570 ]\n",
      "3 \tObject: person \tConfidence = 0.9003 \tBbox: [ 622 \t 508 \t 765 \t 939 ]\n",
      "4 \tObject: person \tConfidence = 0.892 \tBbox: [ 557 \t 239 \t 698 \t 589 ]\n",
      "5 \tObject: person \tConfidence = 0.8681 \tBbox: [ 560 \t 80 \t 668 \t 302 ]\n",
      "6 \tObject: person \tConfidence = 0.8226 \tBbox: [ 428 \t 8 \t 503 \t 216 ]\n",
      "7 \tObject: person \tConfidence = 0.8083 \tBbox: [ 545 \t 0 \t 600 \t 98 ]\n",
      "8 \tObject: person \tConfidence = 0.7933 \tBbox: [ 287 \t 480 \t 412 \t 882 ]\n",
      "9 \tObject: person \tConfidence = 0.7477 \tBbox: [ 636 \t 60 \t 715 \t 266 ]\n",
      "10 \tObject: person \tConfidence = 0.7218 \tBbox: [ 493 \t 0 \t 535 \t 84 ]\n",
      "11 \tObject: train \tConfidence = 0.6925 \tBbox: [ 3 \t 4 \t 457 \t 1069 ]\n",
      "12 \tObject: person \tConfidence = 0.4871 \tBbox: [ 379 \t 148 \t 442 \t 317 ]\n",
      "13 \tObject: person \tConfidence = 0.4781 \tBbox: [ 406 \t 213 \t 491 \t 306 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000460 / 1050\n",
      "Frames to be processed: 590  | To do: 56.19 % | Done: 43.81 %\n",
      "\n",
      "2022-04-20 13:14:02.892297\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000460.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 30.2ms pre-process, 174.4ms inference, 2.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9139 \tBbox: [ 164 \t 684 \t 393 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.9087 \tBbox: [ 385 \t 253 \t 515 \t 570 ]\n",
      "3 \tObject: person \tConfidence = 0.9084 \tBbox: [ 621 \t 510 \t 765 \t 952 ]\n",
      "4 \tObject: person \tConfidence = 0.8999 \tBbox: [ 557 \t 240 \t 698 \t 589 ]\n",
      "5 \tObject: person \tConfidence = 0.8592 \tBbox: [ 560 \t 84 \t 667 \t 303 ]\n",
      "6 \tObject: person \tConfidence = 0.8344 \tBbox: [ 545 \t 0 \t 598 \t 99 ]\n",
      "7 \tObject: person \tConfidence = 0.8253 \tBbox: [ 426 \t 8 \t 501 \t 216 ]\n",
      "8 \tObject: person \tConfidence = 0.8036 \tBbox: [ 284 \t 482 \t 409 \t 894 ]\n",
      "9 \tObject: person \tConfidence = 0.7441 \tBbox: [ 636 \t 59 \t 715 \t 285 ]\n",
      "10 \tObject: train \tConfidence = 0.7343 \tBbox: [ 3 \t 4 \t 456 \t 1068 ]\n",
      "11 \tObject: person \tConfidence = 0.7043 \tBbox: [ 492 \t 0 \t 535 \t 84 ]\n",
      "12 \tObject: person \tConfidence = 0.5343 \tBbox: [ 422 \t 213 \t 474 \t 287 ]\n",
      "13 \tObject: person \tConfidence = 0.5159 \tBbox: [ 379 \t 146 \t 445 \t 341 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000461 / 1050\n",
      "Frames to be processed: 589  | To do: 56.1 % | Done: 43.9 %\n",
      "\n",
      "2022-04-20 13:14:03.419875\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000461.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 39.8ms pre-process, 170.0ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9202 \tBbox: [ 613 \t 526 \t 766 \t 966 ]\n",
      "2 \tObject: person \tConfidence = 0.8977 \tBbox: [ 385 \t 251 \t 508 \t 571 ]\n",
      "3 \tObject: person \tConfidence = 0.8954 \tBbox: [ 555 \t 241 \t 701 \t 591 ]\n",
      "4 \tObject: person \tConfidence = 0.8954 \tBbox: [ 150 \t 690 \t 384 \t 1078 ]\n",
      "5 \tObject: person \tConfidence = 0.8684 \tBbox: [ 561 \t 90 \t 673 \t 304 ]\n",
      "6 \tObject: person \tConfidence = 0.8227 \tBbox: [ 543 \t 0 \t 596 \t 101 ]\n",
      "7 \tObject: person \tConfidence = 0.8174 \tBbox: [ 277 \t 486 \t 403 \t 791 ]\n",
      "8 \tObject: train \tConfidence = 0.7627 \tBbox: [ 3 \t 2 \t 451 \t 1069 ]\n",
      "9 \tObject: person \tConfidence = 0.7262 \tBbox: [ 427 \t 7 \t 502 \t 207 ]\n",
      "10 \tObject: person \tConfidence = 0.7166 \tBbox: [ 639 \t 60 \t 715 \t 253 ]\n",
      "11 \tObject: person \tConfidence = 0.6927 \tBbox: [ 492 \t 0 \t 534 \t 84 ]\n",
      "12 \tObject: person \tConfidence = 0.4909 \tBbox: [ 379 \t 150 \t 443 \t 258 ]\n",
      "13 \tObject: person \tConfidence = 0.3256 \tBbox: [ 380 \t 179 \t 451 \t 316 ]\n",
      "14 \tObject: person \tConfidence = 0.3058 \tBbox: [ 412 \t 213 \t 472 \t 291 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000462 / 1050\n",
      "Frames to be processed: 588  | To do: 56.0 % | Done: 44.0 %\n",
      "\n",
      "2022-04-20 13:14:03.884774\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000462.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 30.8ms pre-process, 166.9ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9201 \tBbox: [ 612 \t 532 \t 765 \t 965 ]\n",
      "2 \tObject: person \tConfidence = 0.9098 \tBbox: [ 144 \t 691 \t 381 \t 1079 ]\n",
      "3 \tObject: person \tConfidence = 0.9064 \tBbox: [ 382 \t 252 \t 505 \t 570 ]\n",
      "4 \tObject: person \tConfidence = 0.891 \tBbox: [ 555 \t 244 \t 702 \t 592 ]\n",
      "5 \tObject: person \tConfidence = 0.8537 \tBbox: [ 559 \t 92 \t 670 \t 305 ]\n",
      "6 \tObject: person \tConfidence = 0.8135 \tBbox: [ 542 \t 0 \t 596 \t 102 ]\n",
      "7 \tObject: train \tConfidence = 0.794 \tBbox: [ 3 \t 2 \t 450 \t 1069 ]\n",
      "8 \tObject: person \tConfidence = 0.7718 \tBbox: [ 276 \t 484 \t 400 \t 828 ]\n",
      "9 \tObject: person \tConfidence = 0.7516 \tBbox: [ 431 \t 4 \t 502 \t 205 ]\n",
      "10 \tObject: person \tConfidence = 0.7003 \tBbox: [ 639 \t 61 \t 706 \t 202 ]\n",
      "11 \tObject: person \tConfidence = 0.6622 \tBbox: [ 491 \t 0 \t 534 \t 83 ]\n",
      "12 \tObject: person \tConfidence = 0.6156 \tBbox: [ 380 \t 150 \t 443 \t 259 ]\n",
      "13 \tObject: person \tConfidence = 0.4237 \tBbox: [ 410 \t 213 \t 478 \t 295 ]\n",
      "14 \tObject: person \tConfidence = 0.3909 \tBbox: [ 652 \t 158 \t 716 \t 257 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000463 / 1050\n",
      "Frames to be processed: 587  | To do: 55.9 % | Done: 44.1 %\n",
      "\n",
      "2022-04-20 13:14:04.384080\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000463.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 29.3ms pre-process, 175.0ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9078 \tBbox: [ 598 \t 535 \t 765 \t 968 ]\n",
      "2 \tObject: person \tConfidence = 0.9028 \tBbox: [ 381 \t 245 \t 503 \t 571 ]\n",
      "3 \tObject: person \tConfidence = 0.9003 \tBbox: [ 136 \t 694 \t 378 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.8989 \tBbox: [ 555 \t 251 \t 702 \t 593 ]\n",
      "5 \tObject: person \tConfidence = 0.868 \tBbox: [ 558 \t 93 \t 673 \t 306 ]\n",
      "6 \tObject: person \tConfidence = 0.806 \tBbox: [ 542 \t 0 \t 592 \t 104 ]\n",
      "7 \tObject: person \tConfidence = 0.7929 \tBbox: [ 272 \t 487 \t 397 \t 805 ]\n",
      "8 \tObject: train \tConfidence = 0.7403 \tBbox: [ 3 \t 2 \t 450 \t 1069 ]\n",
      "9 \tObject: person \tConfidence = 0.7296 \tBbox: [ 428 \t 5 \t 503 \t 207 ]\n",
      "10 \tObject: person \tConfidence = 0.6554 \tBbox: [ 492 \t 0 \t 534 \t 82 ]\n",
      "11 \tObject: person \tConfidence = 0.642 \tBbox: [ 640 \t 62 \t 704 \t 203 ]\n",
      "12 \tObject: person \tConfidence = 0.5118 \tBbox: [ 379 \t 151 \t 444 \t 260 ]\n",
      "13 \tObject: person \tConfidence = 0.4522 \tBbox: [ 656 \t 157 \t 716 \t 259 ]\n",
      "14 \tObject: person \tConfidence = 0.415 \tBbox: [ 410 \t 214 \t 485 \t 317 ]\n",
      "15 \tObject: person \tConfidence = 0.3892 \tBbox: [ 412 \t 6 \t 456 \t 175 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000464 / 1050\n",
      "Frames to be processed: 586  | To do: 55.81 % | Done: 44.19 %\n",
      "\n",
      "2022-04-20 13:14:04.947658\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000464.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 31.0ms pre-process, 180.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9036 \tBbox: [ 129 \t 695 \t 378 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8956 \tBbox: [ 598 \t 540 \t 765 \t 966 ]\n",
      "3 \tObject: person \tConfidence = 0.8922 \tBbox: [ 555 \t 251 \t 701 \t 597 ]\n",
      "4 \tObject: person \tConfidence = 0.8778 \tBbox: [ 378 \t 261 \t 501 \t 569 ]\n",
      "5 \tObject: person \tConfidence = 0.8605 \tBbox: [ 270 \t 490 \t 396 \t 806 ]\n",
      "6 \tObject: person \tConfidence = 0.8391 \tBbox: [ 559 \t 94 \t 670 \t 309 ]\n",
      "7 \tObject: person \tConfidence = 0.8054 \tBbox: [ 541 \t 0 \t 590 \t 104 ]\n",
      "8 \tObject: train \tConfidence = 0.7846 \tBbox: [ 3 \t 1 \t 447 \t 1070 ]\n",
      "9 \tObject: person \tConfidence = 0.7242 \tBbox: [ 640 \t 61 \t 704 \t 257 ]\n",
      "10 \tObject: person \tConfidence = 0.7242 \tBbox: [ 429 \t 7 \t 503 \t 207 ]\n",
      "11 \tObject: person \tConfidence = 0.6547 \tBbox: [ 492 \t 0 \t 533 \t 82 ]\n",
      "12 \tObject: person \tConfidence = 0.6085 \tBbox: [ 400 \t 214 \t 472 \t 292 ]\n",
      "13 \tObject: person \tConfidence = 0.5569 \tBbox: [ 378 \t 151 \t 443 \t 262 ]\n",
      "14 \tObject: person \tConfidence = 0.436 \tBbox: [ 411 \t 6 \t 455 \t 168 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000465 / 1050\n",
      "Frames to be processed: 585  | To do: 55.71 % | Done: 44.29 %\n",
      "\n",
      "2022-04-20 13:14:05.430071\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000465.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 26.6ms pre-process, 173.0ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9138 \tBbox: [ 593 \t 543 \t 764 \t 967 ]\n",
      "2 \tObject: person \tConfidence = 0.8879 \tBbox: [ 124 \t 699 \t 368 \t 1079 ]\n",
      "3 \tObject: person \tConfidence = 0.8789 \tBbox: [ 555 \t 255 \t 702 \t 605 ]\n",
      "4 \tObject: person \tConfidence = 0.8691 \tBbox: [ 374 \t 263 \t 499 \t 570 ]\n",
      "5 \tObject: person \tConfidence = 0.8684 \tBbox: [ 268 \t 491 \t 394 \t 809 ]\n",
      "6 \tObject: person \tConfidence = 0.8316 \tBbox: [ 561 \t 94 \t 665 \t 312 ]\n",
      "7 \tObject: person \tConfidence = 0.8132 \tBbox: [ 638 \t 60 \t 704 \t 261 ]\n",
      "8 \tObject: person \tConfidence = 0.8023 \tBbox: [ 538 \t 0 \t 590 \t 105 ]\n",
      "9 \tObject: person \tConfidence = 0.7748 \tBbox: [ 438 \t 5 \t 504 \t 205 ]\n",
      "10 \tObject: train \tConfidence = 0.7681 \tBbox: [ 3 \t 0 \t 446 \t 1069 ]\n",
      "11 \tObject: person \tConfidence = 0.7013 \tBbox: [ 395 \t 214 \t 470 \t 293 ]\n",
      "12 \tObject: person \tConfidence = 0.6708 \tBbox: [ 378 \t 150 \t 444 \t 262 ]\n",
      "13 \tObject: person \tConfidence = 0.6588 \tBbox: [ 492 \t 0 \t 532 \t 81 ]\n",
      "14 \tObject: person \tConfidence = 0.5514 \tBbox: [ 411 \t 7 \t 454 \t 181 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000466 / 1050\n",
      "Frames to be processed: 584  | To do: 55.62 % | Done: 44.38 %\n",
      "\n",
      "2022-04-20 13:14:05.961080\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000466.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 27.4ms pre-process, 169.4ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9049 \tBbox: [ 588 \t 556 \t 764 \t 970 ]\n",
      "2 \tObject: person \tConfidence = 0.8983 \tBbox: [ 112 \t 706 \t 358 \t 1079 ]\n",
      "3 \tObject: person \tConfidence = 0.8947 \tBbox: [ 264 \t 494 \t 391 \t 814 ]\n",
      "4 \tObject: person \tConfidence = 0.89 \tBbox: [ 546 \t 261 \t 700 \t 624 ]\n",
      "5 \tObject: person \tConfidence = 0.8717 \tBbox: [ 380 \t 266 \t 498 \t 570 ]\n",
      "6 \tObject: person \tConfidence = 0.868 \tBbox: [ 560 \t 95 \t 675 \t 316 ]\n",
      "7 \tObject: person \tConfidence = 0.8034 \tBbox: [ 538 \t 0 \t 587 \t 105 ]\n",
      "8 \tObject: person \tConfidence = 0.7989 \tBbox: [ 435 \t 6 \t 505 \t 205 ]\n",
      "9 \tObject: person \tConfidence = 0.7626 \tBbox: [ 636 \t 59 \t 700 \t 256 ]\n",
      "10 \tObject: person \tConfidence = 0.685 \tBbox: [ 492 \t 0 \t 532 \t 79 ]\n",
      "11 \tObject: train \tConfidence = 0.6837 \tBbox: [ 3 \t 0 \t 441 \t 1069 ]\n",
      "12 \tObject: person \tConfidence = 0.6108 \tBbox: [ 378 \t 149 \t 445 \t 262 ]\n",
      "13 \tObject: person \tConfidence = 0.5921 \tBbox: [ 404 \t 6 \t 450 \t 160 ]\n",
      "14 \tObject: person \tConfidence = 0.4436 \tBbox: [ 395 \t 212 \t 464 \t 297 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000467 / 1050\n",
      "Frames to be processed: 583  | To do: 55.52 % | Done: 44.48 %\n",
      "\n",
      "2022-04-20 13:14:06.516886\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000467.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 51.1ms pre-process, 166.8ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8829 \tBbox: [ 547 \t 265 \t 696 \t 621 ]\n",
      "2 \tObject: person \tConfidence = 0.8825 \tBbox: [ 110 \t 708 \t 355 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8758 \tBbox: [ 585 \t 560 \t 765 \t 1006 ]\n",
      "4 \tObject: person \tConfidence = 0.8661 \tBbox: [ 560 \t 95 \t 675 \t 321 ]\n",
      "5 \tObject: person \tConfidence = 0.8546 \tBbox: [ 263 \t 493 \t 390 \t 817 ]\n",
      "6 \tObject: person \tConfidence = 0.8496 \tBbox: [ 380 \t 266 \t 498 \t 570 ]\n",
      "7 \tObject: person \tConfidence = 0.8029 \tBbox: [ 536 \t 0 \t 588 \t 105 ]\n",
      "8 \tObject: person \tConfidence = 0.7898 \tBbox: [ 436 \t 4 \t 505 \t 205 ]\n",
      "9 \tObject: person \tConfidence = 0.7665 \tBbox: [ 634 \t 60 \t 700 \t 258 ]\n",
      "10 \tObject: person \tConfidence = 0.6857 \tBbox: [ 492 \t 0 \t 532 \t 80 ]\n",
      "11 \tObject: person \tConfidence = 0.6062 \tBbox: [ 405 \t 6 \t 450 \t 163 ]\n",
      "12 \tObject: train \tConfidence = 0.5829 \tBbox: [ 3 \t 0 \t 440 \t 1068 ]\n",
      "13 \tObject: person \tConfidence = 0.4489 \tBbox: [ 357 \t 183 \t 453 \t 383 ]\n",
      "14 \tObject: person \tConfidence = 0.396 \tBbox: [ 379 \t 150 \t 445 \t 260 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000468 / 1050\n",
      "Frames to be processed: 582  | To do: 55.43 % | Done: 44.57 %\n",
      "\n",
      "2022-04-20 13:14:07.006407\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000468.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 24.2ms pre-process, 179.9ms inference, 11.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9088 \tBbox: [ 549 \t 268 \t 695 \t 618 ]\n",
      "2 \tObject: person \tConfidence = 0.9045 \tBbox: [ 263 \t 496 \t 388 \t 816 ]\n",
      "3 \tObject: person \tConfidence = 0.889 \tBbox: [ 109 \t 714 \t 353 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.8804 \tBbox: [ 581 \t 568 \t 763 \t 1038 ]\n",
      "5 \tObject: person \tConfidence = 0.8606 \tBbox: [ 560 \t 94 \t 675 \t 319 ]\n",
      "6 \tObject: person \tConfidence = 0.8162 \tBbox: [ 379 \t 250 \t 499 \t 569 ]\n",
      "7 \tObject: person \tConfidence = 0.8081 \tBbox: [ 435 \t 4 \t 505 \t 204 ]\n",
      "8 \tObject: person \tConfidence = 0.8034 \tBbox: [ 633 \t 59 \t 699 \t 262 ]\n",
      "9 \tObject: person \tConfidence = 0.8025 \tBbox: [ 536 \t 0 \t 589 \t 106 ]\n",
      "10 \tObject: person \tConfidence = 0.726 \tBbox: [ 493 \t 0 \t 531 \t 80 ]\n",
      "11 \tObject: person \tConfidence = 0.6185 \tBbox: [ 352 \t 148 \t 446 \t 392 ]\n",
      "12 \tObject: person \tConfidence = 0.5968 \tBbox: [ 402 \t 5 \t 450 \t 170 ]\n",
      "13 \tObject: train \tConfidence = 0.4853 \tBbox: [ 1 \t 4 \t 428 \t 1071 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000469 / 1050\n",
      "Frames to be processed: 581  | To do: 55.33 % | Done: 44.67 %\n",
      "\n",
      "2022-04-20 13:14:07.540526\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000469.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 33.1ms pre-process, 175.8ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8977 \tBbox: [ 542 \t 269 \t 692 \t 652 ]\n",
      "2 \tObject: person \tConfidence = 0.8945 \tBbox: [ 578 \t 580 \t 765 \t 1073 ]\n",
      "3 \tObject: person \tConfidence = 0.8901 \tBbox: [ 108 \t 721 \t 348 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8674 \tBbox: [ 560 \t 94 \t 675 \t 321 ]\n",
      "5 \tObject: person \tConfidence = 0.8508 \tBbox: [ 379 \t 250 \t 500 \t 570 ]\n",
      "6 \tObject: person \tConfidence = 0.8228 \tBbox: [ 532 \t 0 \t 589 \t 105 ]\n",
      "7 \tObject: person \tConfidence = 0.8212 \tBbox: [ 262 \t 497 \t 387 \t 823 ]\n",
      "8 \tObject: person \tConfidence = 0.8199 \tBbox: [ 435 \t 4 \t 505 \t 204 ]\n",
      "9 \tObject: person \tConfidence = 0.7549 \tBbox: [ 631 \t 59 \t 698 \t 260 ]\n",
      "10 \tObject: person \tConfidence = 0.7163 \tBbox: [ 493 \t 0 \t 529 \t 80 ]\n",
      "11 \tObject: person \tConfidence = 0.661 \tBbox: [ 402 \t 5 \t 449 \t 175 ]\n",
      "12 \tObject: person \tConfidence = 0.6067 \tBbox: [ 352 \t 158 \t 446 \t 391 ]\n",
      "13 \tObject: train \tConfidence = 0.3009 \tBbox: [ 2 \t 7 \t 433 \t 1074 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000470 / 1050\n",
      "Frames to be processed: 580  | To do: 55.24 % | Done: 44.76 %\n",
      "\n",
      "2022-04-20 13:14:08.062173\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000470.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons\n",
      "Speed: 25.5ms pre-process, 180.1ms inference, 13.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9076 \tBbox: [ 538 \t 271 \t 688 \t 657 ]\n",
      "2 \tObject: person \tConfidence = 0.8949 \tBbox: [ 104 \t 726 \t 351 \t 1077 ]\n",
      "3 \tObject: person \tConfidence = 0.8933 \tBbox: [ 575 \t 588 \t 762 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.8679 \tBbox: [ 260 \t 498 \t 386 \t 825 ]\n",
      "5 \tObject: person \tConfidence = 0.8465 \tBbox: [ 380 \t 248 \t 503 \t 570 ]\n",
      "6 \tObject: person \tConfidence = 0.836 \tBbox: [ 561 \t 96 \t 675 \t 304 ]\n",
      "7 \tObject: person \tConfidence = 0.8251 \tBbox: [ 531 \t 0 \t 587 \t 105 ]\n",
      "8 \tObject: person \tConfidence = 0.7976 \tBbox: [ 435 \t 6 \t 505 \t 207 ]\n",
      "9 \tObject: person \tConfidence = 0.6771 \tBbox: [ 398 \t 6 \t 449 \t 187 ]\n",
      "10 \tObject: person \tConfidence = 0.6751 \tBbox: [ 626 \t 59 \t 696 \t 259 ]\n",
      "11 \tObject: person \tConfidence = 0.6731 \tBbox: [ 493 \t 0 \t 529 \t 79 ]\n",
      "12 \tObject: person \tConfidence = 0.6467 \tBbox: [ 352 \t 153 \t 442 \t 394 ]\n",
      "13 \tObject: person \tConfidence = 0.3018 \tBbox: [ 441 \t 0 \t 467 \t 42 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000471 / 1050\n",
      "Frames to be processed: 579  | To do: 55.14 % | Done: 44.86 %\n",
      "\n",
      "2022-04-20 13:14:08.519381\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000471.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons\n",
      "Speed: 25.3ms pre-process, 178.0ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9171 \tBbox: [ 536 \t 276 \t 679 \t 658 ]\n",
      "2 \tObject: person \tConfidence = 0.9064 \tBbox: [ 571 \t 613 \t 764 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8843 \tBbox: [ 377 \t 238 \t 505 \t 571 ]\n",
      "4 \tObject: person \tConfidence = 0.8782 \tBbox: [ 103 \t 728 \t 355 \t 1078 ]\n",
      "5 \tObject: person \tConfidence = 0.8587 \tBbox: [ 255 \t 499 \t 384 \t 836 ]\n",
      "6 \tObject: person \tConfidence = 0.8523 \tBbox: [ 562 \t 100 \t 677 \t 338 ]\n",
      "7 \tObject: person \tConfidence = 0.8325 \tBbox: [ 532 \t 0 \t 586 \t 105 ]\n",
      "8 \tObject: person \tConfidence = 0.82 \tBbox: [ 353 \t 152 \t 440 \t 395 ]\n",
      "9 \tObject: person \tConfidence = 0.8193 \tBbox: [ 438 \t 2 \t 506 \t 204 ]\n",
      "10 \tObject: person \tConfidence = 0.6511 \tBbox: [ 494 \t 0 \t 530 \t 79 ]\n",
      "11 \tObject: person \tConfidence = 0.6302 \tBbox: [ 396 \t 4 \t 449 \t 169 ]\n",
      "12 \tObject: person \tConfidence = 0.5488 \tBbox: [ 609 \t 59 \t 696 \t 248 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000472 / 1050\n",
      "Frames to be processed: 578  | To do: 55.05 % | Done: 44.95 %\n",
      "\n",
      "2022-04-20 13:14:09.027953\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000472.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons\n",
      "Speed: 30.1ms pre-process, 180.5ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9138 \tBbox: [ 568 \t 622 \t 764 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.904 \tBbox: [ 533 \t 278 \t 676 \t 658 ]\n",
      "3 \tObject: person \tConfidence = 0.8848 \tBbox: [ 375 \t 238 \t 506 \t 571 ]\n",
      "4 \tObject: person \tConfidence = 0.8843 \tBbox: [ 100 \t 728 \t 356 \t 1078 ]\n",
      "5 \tObject: person \tConfidence = 0.8753 \tBbox: [ 252 \t 498 \t 383 \t 845 ]\n",
      "6 \tObject: person \tConfidence = 0.8513 \tBbox: [ 563 \t 109 \t 678 \t 341 ]\n",
      "7 \tObject: person \tConfidence = 0.8166 \tBbox: [ 438 \t 2 \t 506 \t 203 ]\n",
      "8 \tObject: person \tConfidence = 0.7946 \tBbox: [ 531 \t 0 \t 582 \t 104 ]\n",
      "9 \tObject: person \tConfidence = 0.7427 \tBbox: [ 358 \t 154 \t 438 \t 396 ]\n",
      "10 \tObject: person \tConfidence = 0.6638 \tBbox: [ 397 \t 4 \t 449 \t 164 ]\n",
      "11 \tObject: person \tConfidence = 0.6058 \tBbox: [ 494 \t 0 \t 529 \t 78 ]\n",
      "12 \tObject: person \tConfidence = 0.4585 \tBbox: [ 599 \t 59 \t 693 \t 184 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000473 / 1050\n",
      "Frames to be processed: 577  | To do: 54.95 % | Done: 45.05 %\n",
      "\n",
      "2022-04-20 13:14:09.472743\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000473.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons\n",
      "Speed: 25.7ms pre-process, 181.0ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9194 \tBbox: [ 564 \t 629 \t 763 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8995 \tBbox: [ 529 \t 279 \t 674 \t 658 ]\n",
      "3 \tObject: person \tConfidence = 0.8909 \tBbox: [ 95 \t 730 \t 353 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8809 \tBbox: [ 372 \t 237 \t 508 \t 570 ]\n",
      "5 \tObject: person \tConfidence = 0.846 \tBbox: [ 564 \t 114 \t 679 \t 345 ]\n",
      "6 \tObject: person \tConfidence = 0.8331 \tBbox: [ 249 \t 498 \t 383 \t 845 ]\n",
      "7 \tObject: person \tConfidence = 0.8055 \tBbox: [ 438 \t 4 \t 506 \t 203 ]\n",
      "8 \tObject: person \tConfidence = 0.7949 \tBbox: [ 528 \t 0 \t 579 \t 105 ]\n",
      "9 \tObject: person \tConfidence = 0.6942 \tBbox: [ 394 \t 4 \t 449 \t 169 ]\n",
      "10 \tObject: person \tConfidence = 0.6408 \tBbox: [ 357 \t 155 \t 437 \t 396 ]\n",
      "11 \tObject: person \tConfidence = 0.5717 \tBbox: [ 493 \t 0 \t 528 \t 77 ]\n",
      "12 \tObject: person \tConfidence = 0.4287 \tBbox: [ 597 \t 58 \t 695 \t 236 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000474 / 1050\n",
      "Frames to be processed: 576  | To do: 54.86 % | Done: 45.14 %\n",
      "\n",
      "2022-04-20 13:14:09.962414\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000474.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons\n",
      "Speed: 28.5ms pre-process, 168.0ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9004 \tBbox: [ 563 \t 649 \t 762 \t 1077 ]\n",
      "2 \tObject: person \tConfidence = 0.8899 \tBbox: [ 522 \t 278 \t 672 \t 657 ]\n",
      "3 \tObject: person \tConfidence = 0.8853 \tBbox: [ 96 \t 732 \t 357 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8734 \tBbox: [ 248 \t 499 \t 383 \t 850 ]\n",
      "5 \tObject: person \tConfidence = 0.8641 \tBbox: [ 372 \t 237 \t 507 \t 570 ]\n",
      "6 \tObject: person \tConfidence = 0.8518 \tBbox: [ 567 \t 114 \t 681 \t 348 ]\n",
      "7 \tObject: person \tConfidence = 0.8147 \tBbox: [ 438 \t 3 \t 505 \t 202 ]\n",
      "8 \tObject: person \tConfidence = 0.793 \tBbox: [ 524 \t 0 \t 578 \t 106 ]\n",
      "9 \tObject: person \tConfidence = 0.7098 \tBbox: [ 393 \t 3 \t 451 \t 174 ]\n",
      "10 \tObject: person \tConfidence = 0.6685 \tBbox: [ 597 \t 58 \t 693 \t 178 ]\n",
      "11 \tObject: person \tConfidence = 0.6479 \tBbox: [ 359 \t 155 \t 436 \t 394 ]\n",
      "12 \tObject: person \tConfidence = 0.5602 \tBbox: [ 493 \t 0 \t 528 \t 76 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000475 / 1050\n",
      "Frames to be processed: 575  | To do: 54.76 % | Done: 45.24 %\n",
      "\n",
      "2022-04-20 13:14:10.375305\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000475.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons\n",
      "Speed: 27.1ms pre-process, 175.3ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9112 \tBbox: [ 560 \t 661 \t 763 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8963 \tBbox: [ 516 \t 280 \t 670 \t 657 ]\n",
      "3 \tObject: person \tConfidence = 0.8719 \tBbox: [ 246 \t 499 \t 382 \t 851 ]\n",
      "4 \tObject: person \tConfidence = 0.8699 \tBbox: [ 92 \t 732 \t 355 \t 1078 ]\n",
      "5 \tObject: person \tConfidence = 0.8628 \tBbox: [ 373 \t 236 \t 507 \t 570 ]\n",
      "6 \tObject: person \tConfidence = 0.8495 \tBbox: [ 566 \t 115 \t 683 \t 351 ]\n",
      "7 \tObject: person \tConfidence = 0.8323 \tBbox: [ 438 \t 5 \t 505 \t 203 ]\n",
      "8 \tObject: person \tConfidence = 0.7383 \tBbox: [ 393 \t 3 \t 451 \t 174 ]\n",
      "9 \tObject: person \tConfidence = 0.7294 \tBbox: [ 523 \t 0 \t 576 \t 106 ]\n",
      "10 \tObject: person \tConfidence = 0.6564 \tBbox: [ 596 \t 58 \t 692 \t 177 ]\n",
      "11 \tObject: person \tConfidence = 0.5271 \tBbox: [ 492 \t 0 \t 528 \t 77 ]\n",
      "12 \tObject: person \tConfidence = 0.5195 \tBbox: [ 359 \t 184 \t 433 \t 392 ]\n",
      "13 \tObject: person \tConfidence = 0.5009 \tBbox: [ 360 \t 152 \t 434 \t 268 ]\n",
      "14 \tObject: person \tConfidence = 0.322 \tBbox: [ 543 \t 441 \t 664 \t 539 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000476 / 1050\n",
      "Frames to be processed: 574  | To do: 54.67 % | Done: 45.33 %\n",
      "\n",
      "2022-04-20 13:14:10.868481\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000476.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 26.4ms pre-process, 177.8ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9073 \tBbox: [ 509 \t 281 \t 666 \t 658 ]\n",
      "2 \tObject: person \tConfidence = 0.8967 \tBbox: [ 242 \t 498 \t 381 \t 852 ]\n",
      "3 \tObject: person \tConfidence = 0.8854 \tBbox: [ 550 \t 677 \t 764 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.8691 \tBbox: [ 82 \t 735 \t 353 \t 1078 ]\n",
      "5 \tObject: person \tConfidence = 0.8471 \tBbox: [ 440 \t 4 \t 504 \t 201 ]\n",
      "6 \tObject: person \tConfidence = 0.8463 \tBbox: [ 571 \t 120 \t 687 \t 357 ]\n",
      "7 \tObject: person \tConfidence = 0.8293 \tBbox: [ 371 \t 233 \t 508 \t 569 ]\n",
      "8 \tObject: person \tConfidence = 0.7704 \tBbox: [ 393 \t 3 \t 447 \t 171 ]\n",
      "9 \tObject: person \tConfidence = 0.7263 \tBbox: [ 517 \t 0 \t 578 \t 105 ]\n",
      "10 \tObject: person \tConfidence = 0.7133 \tBbox: [ 594 \t 58 \t 691 \t 173 ]\n",
      "11 \tObject: person \tConfidence = 0.6411 \tBbox: [ 355 \t 194 \t 429 \t 389 ]\n",
      "12 \tObject: person \tConfidence = 0.6181 \tBbox: [ 491 \t 0 \t 525 \t 78 ]\n",
      "13 \tObject: train \tConfidence = 0.5734 \tBbox: [ 0 \t 2 \t 392 \t 1070 ]\n",
      "14 \tObject: person \tConfidence = 0.4244 \tBbox: [ 355 \t 151 \t 431 \t 270 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000477 / 1050\n",
      "Frames to be processed: 573  | To do: 54.57 % | Done: 45.43 %\n",
      "\n",
      "2022-04-20 13:14:11.389679\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000477.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons\n",
      "Speed: 27.2ms pre-process, 171.1ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9099 \tBbox: [ 507 \t 283 \t 664 \t 659 ]\n",
      "2 \tObject: person \tConfidence = 0.8764 \tBbox: [ 241 \t 498 \t 380 \t 853 ]\n",
      "3 \tObject: person \tConfidence = 0.8759 \tBbox: [ 72 \t 736 \t 348 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8558 \tBbox: [ 543 \t 683 \t 764 \t 1078 ]\n",
      "5 \tObject: person \tConfidence = 0.8536 \tBbox: [ 382 \t 233 \t 507 \t 570 ]\n",
      "6 \tObject: person \tConfidence = 0.8407 \tBbox: [ 569 \t 121 \t 689 \t 359 ]\n",
      "7 \tObject: person \tConfidence = 0.8218 \tBbox: [ 440 \t 5 \t 503 \t 197 ]\n",
      "8 \tObject: person \tConfidence = 0.7745 \tBbox: [ 392 \t 2 \t 447 \t 173 ]\n",
      "9 \tObject: person \tConfidence = 0.7433 \tBbox: [ 516 \t 0 \t 579 \t 105 ]\n",
      "10 \tObject: person \tConfidence = 0.7362 \tBbox: [ 593 \t 58 \t 691 \t 171 ]\n",
      "11 \tObject: person \tConfidence = 0.64 \tBbox: [ 354 \t 151 \t 431 \t 470 ]\n",
      "12 \tObject: person \tConfidence = 0.6042 \tBbox: [ 490 \t 0 \t 525 \t 78 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000478 / 1050\n",
      "Frames to be processed: 572  | To do: 54.48 % | Done: 45.52 %\n",
      "\n",
      "2022-04-20 13:14:11.834948\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000478.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons\n",
      "Speed: 29.7ms pre-process, 174.7ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9019 \tBbox: [ 503 \t 285 \t 663 \t 659 ]\n",
      "2 \tObject: person \tConfidence = 0.8812 \tBbox: [ 240 \t 498 \t 379 \t 853 ]\n",
      "3 \tObject: person \tConfidence = 0.8694 \tBbox: [ 85 \t 738 \t 341 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8616 \tBbox: [ 382 \t 234 \t 507 \t 569 ]\n",
      "5 \tObject: person \tConfidence = 0.8576 \tBbox: [ 541 \t 692 \t 765 \t 1078 ]\n",
      "6 \tObject: person \tConfidence = 0.8355 \tBbox: [ 566 \t 122 \t 695 \t 362 ]\n",
      "7 \tObject: person \tConfidence = 0.8085 \tBbox: [ 436 \t 3 \t 503 \t 197 ]\n",
      "8 \tObject: person \tConfidence = 0.7892 \tBbox: [ 391 \t 2 \t 440 \t 173 ]\n",
      "9 \tObject: person \tConfidence = 0.7579 \tBbox: [ 351 \t 150 \t 429 \t 476 ]\n",
      "10 \tObject: person \tConfidence = 0.6997 \tBbox: [ 516 \t 0 \t 576 \t 106 ]\n",
      "11 \tObject: person \tConfidence = 0.6202 \tBbox: [ 593 \t 59 \t 690 \t 175 ]\n",
      "12 \tObject: person \tConfidence = 0.5767 \tBbox: [ 490 \t 0 \t 524 \t 78 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000479 / 1050\n",
      "Frames to be processed: 571  | To do: 54.38 % | Done: 45.62 %\n",
      "\n",
      "2022-04-20 13:14:12.344050\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000479.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons\n",
      "Speed: 25.9ms pre-process, 173.2ms inference, 4.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9032 \tBbox: [ 502 \t 287 \t 659 \t 663 ]\n",
      "2 \tObject: person \tConfidence = 0.8908 \tBbox: [ 236 \t 498 \t 379 \t 856 ]\n",
      "3 \tObject: person \tConfidence = 0.8859 \tBbox: [ 87 \t 738 \t 335 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8747 \tBbox: [ 536 \t 699 \t 758 \t 1079 ]\n",
      "5 \tObject: person \tConfidence = 0.8675 \tBbox: [ 380 \t 233 \t 509 \t 570 ]\n",
      "6 \tObject: person \tConfidence = 0.838 \tBbox: [ 567 \t 122 \t 699 \t 366 ]\n",
      "7 \tObject: person \tConfidence = 0.7901 \tBbox: [ 349 \t 149 \t 427 \t 481 ]\n",
      "8 \tObject: person \tConfidence = 0.7899 \tBbox: [ 437 \t 6 \t 503 \t 194 ]\n",
      "9 \tObject: person \tConfidence = 0.7581 \tBbox: [ 392 \t 2 \t 441 \t 171 ]\n",
      "10 \tObject: person \tConfidence = 0.6158 \tBbox: [ 514 \t 0 \t 574 \t 106 ]\n",
      "11 \tObject: person \tConfidence = 0.5912 \tBbox: [ 592 \t 59 \t 690 \t 177 ]\n",
      "12 \tObject: person \tConfidence = 0.5693 \tBbox: [ 489 \t 0 \t 523 \t 79 ]\n",
      "13 \tObject: person \tConfidence = 0.3124 \tBbox: [ 511 \t 419 \t 654 \t 571 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000480 / 1050\n",
      "Frames to be processed: 570  | To do: 54.29 % | Done: 45.71 %\n",
      "\n",
      "2022-04-20 13:14:12.786620\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000480.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons\n",
      "Speed: 28.2ms pre-process, 171.5ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9 \tBbox: [ 501 \t 288 \t 657 \t 668 ]\n",
      "2 \tObject: person \tConfidence = 0.8914 \tBbox: [ 233 \t 497 \t 377 \t 857 ]\n",
      "3 \tObject: person \tConfidence = 0.8795 \tBbox: [ 87 \t 739 \t 336 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8781 \tBbox: [ 535 \t 715 \t 756 \t 1079 ]\n",
      "5 \tObject: person \tConfidence = 0.8708 \tBbox: [ 568 \t 124 \t 699 \t 371 ]\n",
      "6 \tObject: person \tConfidence = 0.859 \tBbox: [ 383 \t 233 \t 508 \t 570 ]\n",
      "7 \tObject: person \tConfidence = 0.8064 \tBbox: [ 437 \t 5 \t 503 \t 191 ]\n",
      "8 \tObject: person \tConfidence = 0.7934 \tBbox: [ 393 \t 3 \t 444 \t 171 ]\n",
      "9 \tObject: person \tConfidence = 0.7546 \tBbox: [ 347 \t 149 \t 426 \t 482 ]\n",
      "10 \tObject: person \tConfidence = 0.6581 \tBbox: [ 592 \t 59 \t 690 \t 169 ]\n",
      "11 \tObject: person \tConfidence = 0.6547 \tBbox: [ 515 \t 0 \t 575 \t 109 ]\n",
      "12 \tObject: person \tConfidence = 0.6143 \tBbox: [ 490 \t 0 \t 523 \t 79 ]\n",
      "13 \tObject: person \tConfidence = 0.3035 \tBbox: [ 447 \t 0 \t 485 \t 23 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000481 / 1050\n",
      "Frames to be processed: 569  | To do: 54.19 % | Done: 45.81 %\n",
      "\n",
      "2022-04-20 13:14:13.242672\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000481.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons\n",
      "Speed: 44.0ms pre-process, 177.8ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9078 \tBbox: [ 567 \t 128 \t 705 \t 382 ]\n",
      "2 \tObject: person \tConfidence = 0.9065 \tBbox: [ 498 \t 294 \t 652 \t 660 ]\n",
      "3 \tObject: person \tConfidence = 0.8854 \tBbox: [ 80 \t 742 \t 342 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8794 \tBbox: [ 231 \t 494 \t 375 \t 862 ]\n",
      "5 \tObject: person \tConfidence = 0.8679 \tBbox: [ 523 \t 738 \t 762 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.8652 \tBbox: [ 384 \t 231 \t 509 \t 570 ]\n",
      "7 \tObject: person \tConfidence = 0.8364 \tBbox: [ 437 \t 4 \t 503 \t 189 ]\n",
      "8 \tObject: person \tConfidence = 0.7848 \tBbox: [ 390 \t 3 \t 439 \t 171 ]\n",
      "9 \tObject: person \tConfidence = 0.7819 \tBbox: [ 346 \t 205 \t 421 \t 479 ]\n",
      "10 \tObject: person \tConfidence = 0.6651 \tBbox: [ 515 \t 0 \t 570 \t 106 ]\n",
      "11 \tObject: person \tConfidence = 0.6074 \tBbox: [ 590 \t 59 \t 690 \t 169 ]\n",
      "12 \tObject: person \tConfidence = 0.567 \tBbox: [ 488 \t 0 \t 522 \t 79 ]\n",
      "13 \tObject: person \tConfidence = 0.472 \tBbox: [ 348 \t 150 \t 423 \t 267 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000482 / 1050\n",
      "Frames to be processed: 568  | To do: 54.1 % | Done: 45.9 %\n",
      "\n",
      "2022-04-20 13:14:13.766364\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000482.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons\n",
      "Speed: 56.9ms pre-process, 179.7ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9163 \tBbox: [ 565 \t 131 \t 706 \t 383 ]\n",
      "2 \tObject: person \tConfidence = 0.8746 \tBbox: [ 81 \t 743 \t 329 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8714 \tBbox: [ 384 \t 230 \t 509 \t 570 ]\n",
      "4 \tObject: person \tConfidence = 0.8658 \tBbox: [ 498 \t 297 \t 651 \t 666 ]\n",
      "5 \tObject: person \tConfidence = 0.8613 \tBbox: [ 515 \t 752 \t 756 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.8306 \tBbox: [ 230 \t 492 \t 374 \t 864 ]\n",
      "7 \tObject: person \tConfidence = 0.8218 \tBbox: [ 437 \t 4 \t 503 \t 187 ]\n",
      "8 \tObject: person \tConfidence = 0.7916 \tBbox: [ 391 \t 2 \t 439 \t 171 ]\n",
      "9 \tObject: person \tConfidence = 0.6584 \tBbox: [ 515 \t 0 \t 565 \t 105 ]\n",
      "10 \tObject: person \tConfidence = 0.6546 \tBbox: [ 590 \t 59 \t 690 \t 172 ]\n",
      "11 \tObject: person \tConfidence = 0.6318 \tBbox: [ 344 \t 151 \t 422 \t 484 ]\n",
      "12 \tObject: person \tConfidence = 0.5275 \tBbox: [ 487 \t 0 \t 525 \t 80 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000483 / 1050\n",
      "Frames to be processed: 567  | To do: 54.0 % | Done: 46.0 %\n",
      "\n",
      "2022-04-20 13:14:14.320349\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000483.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons\n",
      "Speed: 40.9ms pre-process, 179.9ms inference, 3.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9281 \tBbox: [ 565 \t 133 \t 707 \t 389 ]\n",
      "2 \tObject: person \tConfidence = 0.8895 \tBbox: [ 78 \t 744 \t 338 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.885 \tBbox: [ 385 \t 230 \t 508 \t 570 ]\n",
      "4 \tObject: person \tConfidence = 0.8827 \tBbox: [ 497 \t 299 \t 647 \t 731 ]\n",
      "5 \tObject: person \tConfidence = 0.8826 \tBbox: [ 231 \t 490 \t 371 \t 864 ]\n",
      "6 \tObject: person \tConfidence = 0.8741 \tBbox: [ 510 \t 773 \t 750 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.8453 \tBbox: [ 437 \t 2 \t 503 \t 189 ]\n",
      "8 \tObject: person \tConfidence = 0.8183 \tBbox: [ 390 \t 2 \t 441 \t 173 ]\n",
      "9 \tObject: person \tConfidence = 0.7652 \tBbox: [ 345 \t 201 \t 418 \t 480 ]\n",
      "10 \tObject: person \tConfidence = 0.6887 \tBbox: [ 515 \t 0 \t 565 \t 106 ]\n",
      "11 \tObject: person \tConfidence = 0.6834 \tBbox: [ 589 \t 58 \t 689 \t 175 ]\n",
      "12 \tObject: person \tConfidence = 0.5582 \tBbox: [ 487 \t 0 \t 523 \t 78 ]\n",
      "13 \tObject: person \tConfidence = 0.4731 \tBbox: [ 525 \t 446 \t 628 \t 611 ]\n",
      "14 \tObject: person \tConfidence = 0.4515 \tBbox: [ 345 \t 150 \t 419 \t 265 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000484 / 1050\n",
      "Frames to be processed: 566  | To do: 53.9 % | Done: 46.1 %\n",
      "\n",
      "2022-04-20 13:14:14.830499\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000484.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons\n",
      "Speed: 27.5ms pre-process, 179.1ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.927 \tBbox: [ 565 \t 138 \t 708 \t 390 ]\n",
      "2 \tObject: person \tConfidence = 0.888 \tBbox: [ 75 \t 744 \t 328 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8857 \tBbox: [ 387 \t 230 \t 509 \t 570 ]\n",
      "4 \tObject: person \tConfidence = 0.87 \tBbox: [ 508 \t 788 \t 747 \t 1079 ]\n",
      "5 \tObject: person \tConfidence = 0.8661 \tBbox: [ 496 \t 303 \t 645 \t 732 ]\n",
      "6 \tObject: person \tConfidence = 0.8329 \tBbox: [ 438 \t 2 \t 504 \t 189 ]\n",
      "7 \tObject: person \tConfidence = 0.821 \tBbox: [ 344 \t 204 \t 416 \t 481 ]\n",
      "8 \tObject: person \tConfidence = 0.8146 \tBbox: [ 390 \t 2 \t 443 \t 173 ]\n",
      "9 \tObject: person \tConfidence = 0.7797 \tBbox: [ 231 \t 489 \t 370 \t 865 ]\n",
      "10 \tObject: person \tConfidence = 0.7377 \tBbox: [ 589 \t 58 \t 689 \t 179 ]\n",
      "11 \tObject: person \tConfidence = 0.7032 \tBbox: [ 514 \t 0 \t 565 \t 106 ]\n",
      "12 \tObject: person \tConfidence = 0.5994 \tBbox: [ 343 \t 150 \t 418 \t 264 ]\n",
      "13 \tObject: person \tConfidence = 0.5551 \tBbox: [ 487 \t 0 \t 521 \t 77 ]\n",
      "14 \tObject: person \tConfidence = 0.3374 \tBbox: [ 530 \t 444 \t 627 \t 612 ]\n",
      "15 \tObject: person \tConfidence = 0.3199 \tBbox: [ 539 \t 33 \t 571 \t 104 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000485 / 1050\n",
      "Frames to be processed: 565  | To do: 53.81 % | Done: 46.19 %\n",
      "\n",
      "2022-04-20 13:14:15.337012\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000485.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons\n",
      "Speed: 42.1ms pre-process, 179.6ms inference, 3.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9181 \tBbox: [ 565 \t 141 \t 708 \t 392 ]\n",
      "2 \tObject: person \tConfidence = 0.8827 \tBbox: [ 385 \t 231 \t 508 \t 569 ]\n",
      "3 \tObject: person \tConfidence = 0.8762 \tBbox: [ 494 \t 307 \t 642 \t 737 ]\n",
      "4 \tObject: person \tConfidence = 0.8725 \tBbox: [ 69 \t 744 \t 329 \t 1078 ]\n",
      "5 \tObject: person \tConfidence = 0.8614 \tBbox: [ 234 \t 488 \t 368 \t 863 ]\n",
      "6 \tObject: person \tConfidence = 0.852 \tBbox: [ 507 \t 807 \t 743 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.8379 \tBbox: [ 438 \t 2 \t 504 \t 188 ]\n",
      "8 \tObject: person \tConfidence = 0.8236 \tBbox: [ 391 \t 1 \t 443 \t 172 ]\n",
      "9 \tObject: person \tConfidence = 0.8218 \tBbox: [ 341 \t 204 \t 416 \t 481 ]\n",
      "10 \tObject: person \tConfidence = 0.6972 \tBbox: [ 513 \t 0 \t 563 \t 103 ]\n",
      "11 \tObject: person \tConfidence = 0.6832 \tBbox: [ 589 \t 57 \t 688 \t 182 ]\n",
      "12 \tObject: person \tConfidence = 0.6444 \tBbox: [ 344 \t 150 \t 416 \t 261 ]\n",
      "13 \tObject: person \tConfidence = 0.5251 \tBbox: [ 538 \t 33 \t 569 \t 102 ]\n",
      "14 \tObject: person \tConfidence = 0.5179 \tBbox: [ 487 \t 0 \t 520 \t 76 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000486 / 1050\n",
      "Frames to be processed: 564  | To do: 53.71 % | Done: 46.29 %\n",
      "\n",
      "2022-04-20 13:14:15.883539\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000486.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons\n",
      "Speed: 31.5ms pre-process, 181.1ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8953 \tBbox: [ 492 \t 314 \t 639 \t 748 ]\n",
      "2 \tObject: person \tConfidence = 0.8737 \tBbox: [ 387 \t 233 \t 509 \t 569 ]\n",
      "3 \tObject: person \tConfidence = 0.8725 \tBbox: [ 565 \t 149 \t 708 \t 410 ]\n",
      "4 \tObject: person \tConfidence = 0.8595 \tBbox: [ 495 \t 833 \t 731 \t 1079 ]\n",
      "5 \tObject: person \tConfidence = 0.8535 \tBbox: [ 238 \t 483 \t 364 \t 871 ]\n",
      "6 \tObject: person \tConfidence = 0.831 \tBbox: [ 438 \t 0 \t 506 \t 188 ]\n",
      "7 \tObject: person \tConfidence = 0.8254 \tBbox: [ 37 \t 754 \t 319 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.8046 \tBbox: [ 389 \t 2 \t 441 \t 173 ]\n",
      "9 \tObject: person \tConfidence = 0.7402 \tBbox: [ 336 \t 209 \t 411 \t 480 ]\n",
      "10 \tObject: person \tConfidence = 0.6969 \tBbox: [ 589 \t 56 \t 687 \t 190 ]\n",
      "11 \tObject: person \tConfidence = 0.6868 \tBbox: [ 512 \t 0 \t 560 \t 105 ]\n",
      "12 \tObject: person \tConfidence = 0.6143 \tBbox: [ 344 \t 149 \t 414 \t 255 ]\n",
      "13 \tObject: person \tConfidence = 0.4169 \tBbox: [ 538 \t 33 \t 569 \t 102 ]\n",
      "14 \tObject: person \tConfidence = 0.3657 \tBbox: [ 487 \t 0 \t 521 \t 76 ]\n",
      "15 \tObject: person \tConfidence = 0.3568 \tBbox: [ 507 \t 496 \t 622 \t 596 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000487 / 1050\n",
      "Frames to be processed: 563  | To do: 53.62 % | Done: 46.38 %\n",
      "\n",
      "2022-04-20 13:14:16.397856\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000487.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons\n",
      "Speed: 46.2ms pre-process, 176.6ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8889 \tBbox: [ 491 \t 317 \t 637 \t 751 ]\n",
      "2 \tObject: person \tConfidence = 0.8806 \tBbox: [ 385 \t 232 \t 509 \t 568 ]\n",
      "3 \tObject: person \tConfidence = 0.8773 \tBbox: [ 563 \t 152 \t 709 \t 410 ]\n",
      "4 \tObject: person \tConfidence = 0.8432 \tBbox: [ 489 \t 845 \t 729 \t 1079 ]\n",
      "5 \tObject: person \tConfidence = 0.8243 \tBbox: [ 33 \t 760 \t 318 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.8236 \tBbox: [ 438 \t 0 \t 509 \t 187 ]\n",
      "7 \tObject: person \tConfidence = 0.7975 \tBbox: [ 388 \t 1 \t 438 \t 173 ]\n",
      "8 \tObject: person \tConfidence = 0.7701 \tBbox: [ 589 \t 56 \t 687 \t 193 ]\n",
      "9 \tObject: person \tConfidence = 0.7582 \tBbox: [ 334 \t 206 \t 412 \t 479 ]\n",
      "10 \tObject: person \tConfidence = 0.7302 \tBbox: [ 238 \t 484 \t 362 \t 876 ]\n",
      "11 \tObject: person \tConfidence = 0.6672 \tBbox: [ 512 \t 0 \t 559 \t 105 ]\n",
      "12 \tObject: person \tConfidence = 0.4606 \tBbox: [ 342 \t 150 \t 413 \t 260 ]\n",
      "13 \tObject: person \tConfidence = 0.3757 \tBbox: [ 498 \t 484 \t 627 \t 609 ]\n",
      "14 \tObject: person \tConfidence = 0.3756 \tBbox: [ 536 \t 33 \t 566 \t 101 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000488 / 1050\n",
      "Frames to be processed: 562  | To do: 53.52 % | Done: 46.48 %\n",
      "\n",
      "2022-04-20 13:14:16.946491\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000488.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons\n",
      "Speed: 44.8ms pre-process, 170.4ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8915 \tBbox: [ 490 \t 319 \t 636 \t 751 ]\n",
      "2 \tObject: person \tConfidence = 0.8795 \tBbox: [ 384 \t 233 \t 509 \t 568 ]\n",
      "3 \tObject: person \tConfidence = 0.8596 \tBbox: [ 564 \t 156 \t 710 \t 402 ]\n",
      "4 \tObject: person \tConfidence = 0.8453 \tBbox: [ 481 \t 860 \t 725 \t 1078 ]\n",
      "5 \tObject: person \tConfidence = 0.8407 \tBbox: [ 24 \t 763 \t 322 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.8303 \tBbox: [ 442 \t 0 \t 510 \t 187 ]\n",
      "7 \tObject: person \tConfidence = 0.8188 \tBbox: [ 389 \t 1 \t 437 \t 173 ]\n",
      "8 \tObject: person \tConfidence = 0.7695 \tBbox: [ 333 \t 210 \t 411 \t 479 ]\n",
      "9 \tObject: person \tConfidence = 0.7683 \tBbox: [ 510 \t 0 \t 562 \t 107 ]\n",
      "10 \tObject: person \tConfidence = 0.7543 \tBbox: [ 589 \t 56 \t 687 \t 195 ]\n",
      "11 \tObject: person \tConfidence = 0.7069 \tBbox: [ 240 \t 480 \t 358 \t 844 ]\n",
      "12 \tObject: person \tConfidence = 0.5233 \tBbox: [ 339 \t 150 \t 412 \t 271 ]\n",
      "13 \tObject: person \tConfidence = 0.3895 \tBbox: [ 497 \t 495 \t 618 \t 608 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000489 / 1050\n",
      "Frames to be processed: 561  | To do: 53.43 % | Done: 46.57 %\n",
      "\n",
      "2022-04-20 13:14:17.507331\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000489.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons\n",
      "Speed: 69.5ms pre-process, 171.0ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8982 \tBbox: [ 488 \t 322 \t 634 \t 751 ]\n",
      "2 \tObject: person \tConfidence = 0.8856 \tBbox: [ 385 \t 233 \t 509 \t 568 ]\n",
      "3 \tObject: person \tConfidence = 0.8823 \tBbox: [ 565 \t 157 \t 710 \t 417 ]\n",
      "4 \tObject: person \tConfidence = 0.8609 \tBbox: [ 17 \t 764 \t 313 \t 1079 ]\n",
      "5 \tObject: person \tConfidence = 0.8356 \tBbox: [ 472 \t 872 \t 718 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.8278 \tBbox: [ 442 \t 0 \t 512 \t 186 ]\n",
      "7 \tObject: person \tConfidence = 0.8241 \tBbox: [ 506 \t 0 \t 560 \t 109 ]\n",
      "8 \tObject: person \tConfidence = 0.8112 \tBbox: [ 389 \t 1 \t 442 \t 173 ]\n",
      "9 \tObject: person \tConfidence = 0.7827 \tBbox: [ 232 \t 480 \t 358 \t 869 ]\n",
      "10 \tObject: person \tConfidence = 0.7771 \tBbox: [ 589 \t 55 \t 686 \t 197 ]\n",
      "11 \tObject: person \tConfidence = 0.7764 \tBbox: [ 331 \t 215 \t 412 \t 479 ]\n",
      "12 \tObject: person \tConfidence = 0.5424 \tBbox: [ 336 \t 150 \t 411 \t 275 ]\n",
      "13 \tObject: person \tConfidence = 0.5174 \tBbox: [ 583 \t 0 \t 607 \t 34 ]\n",
      "14 \tObject: person \tConfidence = 0.3775 \tBbox: [ 493 \t 477 \t 619 \t 621 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000490 / 1050\n",
      "Frames to be processed: 560  | To do: 53.33 % | Done: 46.67 %\n",
      "\n",
      "2022-04-20 13:14:18.085725\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000490.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons\n",
      "Speed: 57.3ms pre-process, 177.6ms inference, 9.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9002 \tBbox: [ 486 \t 324 \t 630 \t 751 ]\n",
      "2 \tObject: person \tConfidence = 0.8846 \tBbox: [ 384 \t 233 \t 509 \t 567 ]\n",
      "3 \tObject: person \tConfidence = 0.88 \tBbox: [ 563 \t 158 \t 708 \t 426 ]\n",
      "4 \tObject: person \tConfidence = 0.8691 \tBbox: [ 460 \t 878 \t 717 \t 1079 ]\n",
      "5 \tObject: person \tConfidence = 0.8685 \tBbox: [ 17 \t 766 \t 311 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.8369 \tBbox: [ 506 \t 0 \t 559 \t 109 ]\n",
      "7 \tObject: person \tConfidence = 0.8357 \tBbox: [ 442 \t 0 \t 513 \t 185 ]\n",
      "8 \tObject: person \tConfidence = 0.8198 \tBbox: [ 235 \t 481 \t 358 \t 880 ]\n",
      "9 \tObject: person \tConfidence = 0.8177 \tBbox: [ 389 \t 1 \t 443 \t 173 ]\n",
      "10 \tObject: person \tConfidence = 0.8055 \tBbox: [ 588 \t 55 \t 686 \t 198 ]\n",
      "11 \tObject: person \tConfidence = 0.7904 \tBbox: [ 331 \t 211 \t 411 \t 480 ]\n",
      "12 \tObject: person \tConfidence = 0.6519 \tBbox: [ 337 \t 151 \t 410 \t 273 ]\n",
      "13 \tObject: person \tConfidence = 0.5876 \tBbox: [ 584 \t 0 \t 607 \t 35 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000491 / 1050\n",
      "Frames to be processed: 559  | To do: 53.24 % | Done: 46.76 %\n",
      "\n",
      "2022-04-20 13:14:18.591450\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000491.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons\n",
      "Speed: 65.1ms pre-process, 170.2ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9064 \tBbox: [ 481 \t 328 \t 626 \t 750 ]\n",
      "2 \tObject: person \tConfidence = 0.8864 \tBbox: [ 560 \t 157 \t 708 \t 430 ]\n",
      "3 \tObject: person \tConfidence = 0.8833 \tBbox: [ 14 \t 769 \t 301 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.8823 \tBbox: [ 382 \t 233 \t 509 \t 567 ]\n",
      "5 \tObject: person \tConfidence = 0.8342 \tBbox: [ 444 \t 0 \t 514 \t 186 ]\n",
      "6 \tObject: person \tConfidence = 0.8333 \tBbox: [ 387 \t 1 \t 449 \t 174 ]\n",
      "7 \tObject: person \tConfidence = 0.8238 \tBbox: [ 447 \t 897 \t 704 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.7991 \tBbox: [ 588 \t 55 \t 685 \t 200 ]\n",
      "9 \tObject: person \tConfidence = 0.7984 \tBbox: [ 508 \t 0 \t 559 \t 112 ]\n",
      "10 \tObject: person \tConfidence = 0.795 \tBbox: [ 331 \t 210 \t 412 \t 480 ]\n",
      "11 \tObject: person \tConfidence = 0.7359 \tBbox: [ 220 \t 482 \t 355 \t 809 ]\n",
      "12 \tObject: person \tConfidence = 0.6373 \tBbox: [ 336 \t 150 \t 407 \t 276 ]\n",
      "13 \tObject: person \tConfidence = 0.5288 \tBbox: [ 584 \t 0 \t 604 \t 36 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000492 / 1050\n",
      "Frames to be processed: 558  | To do: 53.14 % | Done: 46.86 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons\n",
      "Speed: 26.4ms pre-process, 167.1ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:14:19.081406\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000492.jpg ------------------------------ \n",
      "\n",
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9031 \tBbox: [ 479 \t 330 \t 624 \t 749 ]\n",
      "2 \tObject: person \tConfidence = 0.8864 \tBbox: [ 385 \t 233 \t 509 \t 567 ]\n",
      "3 \tObject: person \tConfidence = 0.8798 \tBbox: [ 560 \t 157 \t 708 \t 433 ]\n",
      "4 \tObject: person \tConfidence = 0.8797 \tBbox: [ 15 \t 773 \t 297 \t 1079 ]\n",
      "5 \tObject: person \tConfidence = 0.8351 \tBbox: [ 388 \t 1 \t 449 \t 172 ]\n",
      "6 \tObject: person \tConfidence = 0.8175 \tBbox: [ 444 \t 0 \t 515 \t 186 ]\n",
      "7 \tObject: person \tConfidence = 0.7871 \tBbox: [ 332 \t 210 \t 411 \t 480 ]\n",
      "8 \tObject: person \tConfidence = 0.7662 \tBbox: [ 588 \t 54 \t 685 \t 202 ]\n",
      "9 \tObject: person \tConfidence = 0.7644 \tBbox: [ 448 \t 916 \t 699 \t 1079 ]\n",
      "10 \tObject: person \tConfidence = 0.7604 \tBbox: [ 507 \t 0 \t 559 \t 113 ]\n",
      "11 \tObject: person \tConfidence = 0.5926 \tBbox: [ 337 \t 149 \t 407 \t 272 ]\n",
      "12 \tObject: person \tConfidence = 0.5001 \tBbox: [ 212 \t 478 \t 355 \t 816 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000493 / 1050\n",
      "Frames to be processed: 557  | To do: 53.05 % | Done: 46.95 %\n",
      "\n",
      "2022-04-20 13:14:19.594886\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000493.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons\n",
      "Speed: 25.1ms pre-process, 177.2ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8868 \tBbox: [ 387 \t 233 \t 508 \t 567 ]\n",
      "2 \tObject: person \tConfidence = 0.8855 \tBbox: [ 560 \t 160 \t 707 \t 441 ]\n",
      "3 \tObject: person \tConfidence = 0.8821 \tBbox: [ 11 \t 776 \t 285 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8717 \tBbox: [ 476 \t 332 \t 622 \t 750 ]\n",
      "5 \tObject: person \tConfidence = 0.8479 \tBbox: [ 389 \t 0 \t 450 \t 172 ]\n",
      "6 \tObject: person \tConfidence = 0.8242 \tBbox: [ 445 \t 0 \t 516 \t 185 ]\n",
      "7 \tObject: person \tConfidence = 0.7768 \tBbox: [ 588 \t 53 \t 685 \t 204 ]\n",
      "8 \tObject: person \tConfidence = 0.7743 \tBbox: [ 330 \t 212 \t 410 \t 480 ]\n",
      "9 \tObject: person \tConfidence = 0.764 \tBbox: [ 447 \t 931 \t 686 \t 1079 ]\n",
      "10 \tObject: person \tConfidence = 0.7246 \tBbox: [ 505 \t 0 \t 557 \t 114 ]\n",
      "11 \tObject: person \tConfidence = 0.6536 \tBbox: [ 335 \t 149 \t 407 \t 265 ]\n",
      "12 \tObject: person \tConfidence = 0.3854 \tBbox: [ 210 \t 477 \t 360 \t 881 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000494 / 1050\n",
      "Frames to be processed: 556  | To do: 52.95 % | Done: 47.05 %\n",
      "\n",
      "2022-04-20 13:14:20.112366\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000494.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 28.8ms pre-process, 181.4ms inference, 10.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9195 \tBbox: [ 559 \t 161 \t 706 \t 451 ]\n",
      "2 \tObject: person \tConfidence = 0.8889 \tBbox: [ 6 \t 779 \t 279 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8704 \tBbox: [ 383 \t 232 \t 508 \t 566 ]\n",
      "4 \tObject: person \tConfidence = 0.8387 \tBbox: [ 388 \t 0 \t 449 \t 172 ]\n",
      "5 \tObject: person \tConfidence = 0.8246 \tBbox: [ 589 \t 54 \t 684 \t 204 ]\n",
      "6 \tObject: person \tConfidence = 0.8115 \tBbox: [ 445 \t 0 \t 516 \t 183 ]\n",
      "7 \tObject: person \tConfidence = 0.8085 \tBbox: [ 330 \t 209 \t 411 \t 479 ]\n",
      "8 \tObject: person \tConfidence = 0.7794 \tBbox: [ 448 \t 944 \t 651 \t 1079 ]\n",
      "9 \tObject: person \tConfidence = 0.7702 \tBbox: [ 471 \t 333 \t 620 \t 752 ]\n",
      "10 \tObject: person \tConfidence = 0.7219 \tBbox: [ 505 \t 0 \t 557 \t 114 ]\n",
      "11 \tObject: person \tConfidence = 0.6345 \tBbox: [ 338 \t 149 \t 406 \t 262 ]\n",
      "12 \tObject: person \tConfidence = 0.5285 \tBbox: [ 207 \t 474 \t 346 \t 872 ]\n",
      "13 \tObject: person \tConfidence = 0.4289 \tBbox: [ 656 \t 150 \t 711 \t 236 ]\n",
      "14 \tObject: train \tConfidence = 0.3126 \tBbox: [ 0 \t 3 \t 386 \t 1072 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000495 / 1050\n",
      "Frames to be processed: 555  | To do: 52.86 % | Done: 47.14 %\n",
      "\n",
      "2022-04-20 13:14:20.700731\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000495.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons\n",
      "Speed: 25.3ms pre-process, 175.4ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9262 \tBbox: [ 557 \t 165 \t 706 \t 466 ]\n",
      "2 \tObject: person \tConfidence = 0.8722 \tBbox: [ 384 \t 231 \t 507 \t 567 ]\n",
      "3 \tObject: person \tConfidence = 0.8417 \tBbox: [ 389 \t 1 \t 451 \t 172 ]\n",
      "4 \tObject: person \tConfidence = 0.8261 \tBbox: [ 466 \t 335 \t 618 \t 751 ]\n",
      "5 \tObject: person \tConfidence = 0.8194 \tBbox: [ 445 \t 0 \t 517 \t 185 ]\n",
      "6 \tObject: person \tConfidence = 0.8097 \tBbox: [ 328 \t 209 \t 412 \t 479 ]\n",
      "7 \tObject: person \tConfidence = 0.7983 \tBbox: [ 589 \t 54 \t 682 \t 211 ]\n",
      "8 \tObject: person \tConfidence = 0.7304 \tBbox: [ 506 \t 0 \t 557 \t 113 ]\n",
      "9 \tObject: person \tConfidence = 0.6887 \tBbox: [ 335 \t 149 \t 405 \t 263 ]\n",
      "10 \tObject: person \tConfidence = 0.6829 \tBbox: [ 2 \t 777 \t 651 \t 1079 ]\n",
      "11 \tObject: person \tConfidence = 0.4488 \tBbox: [ 202 \t 471 \t 339 \t 901 ]\n",
      "12 \tObject: person \tConfidence = 0.432 \tBbox: [ 2 \t 779 \t 270 \t 1078 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000496 / 1050\n",
      "Frames to be processed: 554  | To do: 52.76 % | Done: 47.24 %\n",
      "\n",
      "2022-04-20 13:14:21.274016\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000496.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons\n",
      "Speed: 26.1ms pre-process, 180.3ms inference, 3.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9191 \tBbox: [ 560 \t 174 \t 704 \t 485 ]\n",
      "2 \tObject: person \tConfidence = 0.8926 \tBbox: [ 455 \t 339 \t 614 \t 749 ]\n",
      "3 \tObject: person \tConfidence = 0.888 \tBbox: [ 387 \t 232 \t 506 \t 567 ]\n",
      "4 \tObject: person \tConfidence = 0.8539 \tBbox: [ 590 \t 54 \t 682 \t 219 ]\n",
      "5 \tObject: person \tConfidence = 0.8316 \tBbox: [ 446 \t 0 \t 519 \t 178 ]\n",
      "6 \tObject: person \tConfidence = 0.8256 \tBbox: [ 390 \t 0 \t 453 \t 170 ]\n",
      "7 \tObject: person \tConfidence = 0.8232 \tBbox: [ 328 \t 211 \t 413 \t 479 ]\n",
      "8 \tObject: person \tConfidence = 0.7318 \tBbox: [ 200 \t 464 \t 331 \t 956 ]\n",
      "9 \tObject: person \tConfidence = 0.6665 \tBbox: [ 1 \t 784 \t 261 \t 1078 ]\n",
      "10 \tObject: person \tConfidence = 0.6486 \tBbox: [ 342 \t 149 \t 405 \t 255 ]\n",
      "11 \tObject: person \tConfidence = 0.6359 \tBbox: [ 506 \t 0 \t 548 \t 112 ]\n",
      "12 \tObject: person \tConfidence = 0.6136 \tBbox: [ 4 \t 785 \t 627 \t 1079 ]\n",
      "13 \tObject: person \tConfidence = 0.3391 \tBbox: [ 536 \t 40 \t 561 \t 90 ]\n",
      "14 \tObject: person \tConfidence = 0.324 \tBbox: [ 660 \t 152 \t 710 \t 239 ]\n",
      "15 \tObject: person \tConfidence = 0.3231 \tBbox: [ 584 \t 0 \t 602 \t 41 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000497 / 1050\n",
      "Frames to be processed: 553  | To do: 52.67 % | Done: 47.33 %\n",
      "\n",
      "2022-04-20 13:14:21.814905\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000497.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons\n",
      "Speed: 29.5ms pre-process, 184.4ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9139 \tBbox: [ 559 \t 179 \t 707 \t 492 ]\n",
      "2 \tObject: person \tConfidence = 0.9106 \tBbox: [ 449 \t 340 \t 612 \t 750 ]\n",
      "3 \tObject: person \tConfidence = 0.8789 \tBbox: [ 385 \t 232 \t 503 \t 567 ]\n",
      "4 \tObject: person \tConfidence = 0.8656 \tBbox: [ 590 \t 54 \t 682 \t 224 ]\n",
      "5 \tObject: person \tConfidence = 0.858 \tBbox: [ 447 \t 0 \t 519 \t 176 ]\n",
      "6 \tObject: person \tConfidence = 0.848 \tBbox: [ 326 \t 210 \t 413 \t 478 ]\n",
      "7 \tObject: person \tConfidence = 0.8424 \tBbox: [ 391 \t 0 \t 455 \t 170 ]\n",
      "8 \tObject: person \tConfidence = 0.7395 \tBbox: [ 194 \t 462 \t 328 \t 970 ]\n",
      "9 \tObject: person \tConfidence = 0.7282 \tBbox: [ 1 \t 787 \t 254 \t 1077 ]\n",
      "10 \tObject: person \tConfidence = 0.7133 \tBbox: [ 351 \t 148 \t 406 \t 250 ]\n",
      "11 \tObject: person \tConfidence = 0.6838 \tBbox: [ 505 \t 0 \t 545 \t 114 ]\n",
      "12 \tObject: person \tConfidence = 0.5407 \tBbox: [ 535 \t 40 \t 560 \t 91 ]\n",
      "13 \tObject: person \tConfidence = 0.4402 \tBbox: [ 7 \t 791 \t 619 \t 1078 ]\n",
      "14 \tObject: person \tConfidence = 0.3823 \tBbox: [ 526 \t 18 \t 562 \t 104 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000498 / 1050\n",
      "Frames to be processed: 552  | To do: 52.57 % | Done: 47.43 %\n",
      "\n",
      "2022-04-20 13:14:22.307919\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000498.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons\n",
      "Speed: 30.3ms pre-process, 174.3ms inference, 4.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9111 \tBbox: [ 559 \t 185 \t 708 \t 499 ]\n",
      "2 \tObject: person \tConfidence = 0.9093 \tBbox: [ 440 \t 342 \t 609 \t 750 ]\n",
      "3 \tObject: person \tConfidence = 0.8751 \tBbox: [ 384 \t 231 \t 504 \t 568 ]\n",
      "4 \tObject: person \tConfidence = 0.8492 \tBbox: [ 590 \t 54 \t 681 \t 229 ]\n",
      "5 \tObject: person \tConfidence = 0.8472 \tBbox: [ 325 \t 206 \t 412 \t 481 ]\n",
      "6 \tObject: person \tConfidence = 0.8378 \tBbox: [ 448 \t 0 \t 519 \t 177 ]\n",
      "7 \tObject: person \tConfidence = 0.8192 \tBbox: [ 391 \t 0 \t 452 \t 168 ]\n",
      "8 \tObject: person \tConfidence = 0.7448 \tBbox: [ 352 \t 148 \t 407 \t 251 ]\n",
      "9 \tObject: person \tConfidence = 0.7413 \tBbox: [ 1 \t 789 \t 252 \t 1078 ]\n",
      "10 \tObject: person \tConfidence = 0.7114 \tBbox: [ 197 \t 461 \t 325 \t 962 ]\n",
      "11 \tObject: person \tConfidence = 0.6385 \tBbox: [ 505 \t 0 \t 547 \t 114 ]\n",
      "12 \tObject: person \tConfidence = 0.4395 \tBbox: [ 583 \t 0 \t 601 \t 42 ]\n",
      "13 \tObject: person \tConfidence = 0.4104 \tBbox: [ 657 \t 151 \t 709 \t 239 ]\n",
      "14 \tObject: person \tConfidence = 0.3496 \tBbox: [ 519 \t 13 \t 560 \t 106 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000499 / 1050\n",
      "Frames to be processed: 551  | To do: 52.48 % | Done: 47.52 %\n",
      "\n",
      "2022-04-20 13:14:22.761817\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000499.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 50.6ms pre-process, 175.9ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9078 \tBbox: [ 560 \t 190 \t 709 \t 500 ]\n",
      "2 \tObject: person \tConfidence = 0.8977 \tBbox: [ 435 \t 345 \t 606 \t 749 ]\n",
      "3 \tObject: person \tConfidence = 0.8762 \tBbox: [ 383 \t 231 \t 504 \t 567 ]\n",
      "4 \tObject: person \tConfidence = 0.8697 \tBbox: [ 589 \t 53 \t 681 \t 233 ]\n",
      "5 \tObject: person \tConfidence = 0.8562 \tBbox: [ 451 \t 0 \t 519 \t 178 ]\n",
      "6 \tObject: person \tConfidence = 0.8536 \tBbox: [ 324 \t 206 \t 412 \t 481 ]\n",
      "7 \tObject: person \tConfidence = 0.8479 \tBbox: [ 392 \t 0 \t 452 \t 166 ]\n",
      "8 \tObject: person \tConfidence = 0.7578 \tBbox: [ 1 \t 794 \t 246 \t 1079 ]\n",
      "9 \tObject: person \tConfidence = 0.7402 \tBbox: [ 352 \t 148 \t 407 \t 251 ]\n",
      "10 \tObject: person \tConfidence = 0.7106 \tBbox: [ 193 \t 461 \t 323 \t 974 ]\n",
      "11 \tObject: person \tConfidence = 0.668 \tBbox: [ 506 \t 0 \t 546 \t 113 ]\n",
      "12 \tObject: person \tConfidence = 0.6008 \tBbox: [ 582 \t 0 \t 601 \t 41 ]\n",
      "13 \tObject: train \tConfidence = 0.4634 \tBbox: [ 0 \t 0 \t 387 \t 944 ]\n",
      "14 \tObject: person \tConfidence = 0.3377 \tBbox: [ 524 \t 22 \t 558 \t 100 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000500 / 1050\n",
      "Frames to be processed: 550  | To do: 52.38 % | Done: 47.62 %\n",
      "\n",
      "2022-04-20 13:14:23.376696\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000500.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons\n",
      "Speed: 39.8ms pre-process, 180.6ms inference, 3.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9213 \tBbox: [ 561 \t 196 \t 712 \t 523 ]\n",
      "2 \tObject: person \tConfidence = 0.9012 \tBbox: [ 422 \t 346 \t 603 \t 758 ]\n",
      "3 \tObject: person \tConfidence = 0.8695 \tBbox: [ 382 \t 231 \t 504 \t 567 ]\n",
      "4 \tObject: person \tConfidence = 0.863 \tBbox: [ 590 \t 53 \t 680 \t 237 ]\n",
      "5 \tObject: person \tConfidence = 0.8609 \tBbox: [ 323 \t 206 \t 412 \t 481 ]\n",
      "6 \tObject: person \tConfidence = 0.8524 \tBbox: [ 392 \t 0 \t 453 \t 165 ]\n",
      "7 \tObject: person \tConfidence = 0.8449 \tBbox: [ 451 \t 0 \t 519 \t 176 ]\n",
      "8 \tObject: person \tConfidence = 0.8045 \tBbox: [ 0 \t 798 \t 247 \t 1079 ]\n",
      "9 \tObject: person \tConfidence = 0.7528 \tBbox: [ 351 \t 148 \t 408 \t 252 ]\n",
      "10 \tObject: person \tConfidence = 0.6509 \tBbox: [ 186 \t 462 \t 321 \t 1015 ]\n",
      "11 \tObject: person \tConfidence = 0.601 \tBbox: [ 507 \t 0 \t 545 \t 112 ]\n",
      "12 \tObject: person \tConfidence = 0.4947 \tBbox: [ 581 \t 0 \t 600 \t 42 ]\n",
      "13 \tObject: person \tConfidence = 0.3192 \tBbox: [ 533 \t 41 \t 559 \t 92 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000501 / 1050\n",
      "Frames to be processed: 549  | To do: 52.29 % | Done: 47.71 %\n",
      "\n",
      "2022-04-20 13:14:23.936791\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000501.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons\n",
      "Speed: 25.0ms pre-process, 179.9ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9191 \tBbox: [ 559 \t 202 \t 716 \t 524 ]\n",
      "2 \tObject: person \tConfidence = 0.9077 \tBbox: [ 410 \t 350 \t 597 \t 769 ]\n",
      "3 \tObject: person \tConfidence = 0.8748 \tBbox: [ 385 \t 232 \t 501 \t 566 ]\n",
      "4 \tObject: person \tConfidence = 0.872 \tBbox: [ 392 \t 0 \t 453 \t 163 ]\n",
      "5 \tObject: person \tConfidence = 0.8717 \tBbox: [ 589 \t 53 \t 678 \t 241 ]\n",
      "6 \tObject: person \tConfidence = 0.864 \tBbox: [ 323 \t 206 \t 411 \t 481 ]\n",
      "7 \tObject: person \tConfidence = 0.8626 \tBbox: [ 452 \t 0 \t 518 \t 173 ]\n",
      "8 \tObject: person \tConfidence = 0.8458 \tBbox: [ 1 \t 801 \t 239 \t 1079 ]\n",
      "9 \tObject: person \tConfidence = 0.7721 \tBbox: [ 352 \t 148 \t 409 \t 250 ]\n",
      "10 \tObject: person \tConfidence = 0.6245 \tBbox: [ 186 \t 461 \t 320 \t 806 ]\n",
      "11 \tObject: person \tConfidence = 0.5571 \tBbox: [ 506 \t 0 \t 542 \t 118 ]\n",
      "12 \tObject: person \tConfidence = 0.3214 \tBbox: [ 578 \t 0 \t 600 \t 43 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000502 / 1050\n",
      "Frames to be processed: 548  | To do: 52.19 % | Done: 47.81 %\n",
      "\n",
      "2022-04-20 13:14:24.426897\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000502.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 33.0ms pre-process, 180.4ms inference, 4.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.916 \tBbox: [ 559 \t 206 \t 719 \t 524 ]\n",
      "2 \tObject: person \tConfidence = 0.8986 \tBbox: [ 414 \t 352 \t 594 \t 767 ]\n",
      "3 \tObject: person \tConfidence = 0.8694 \tBbox: [ 385 \t 232 \t 502 \t 566 ]\n",
      "4 \tObject: person \tConfidence = 0.8637 \tBbox: [ 392 \t 0 \t 453 \t 163 ]\n",
      "5 \tObject: person \tConfidence = 0.8626 \tBbox: [ 323 \t 206 \t 412 \t 481 ]\n",
      "6 \tObject: person \tConfidence = 0.8556 \tBbox: [ 454 \t 0 \t 518 \t 173 ]\n",
      "7 \tObject: person \tConfidence = 0.8555 \tBbox: [ 590 \t 54 \t 671 \t 241 ]\n",
      "8 \tObject: person \tConfidence = 0.8145 \tBbox: [ 0 \t 804 \t 232 \t 1078 ]\n",
      "9 \tObject: person \tConfidence = 0.7321 \tBbox: [ 351 \t 149 \t 409 \t 252 ]\n",
      "10 \tObject: person \tConfidence = 0.638 \tBbox: [ 189 \t 458 \t 319 \t 834 ]\n",
      "11 \tObject: person \tConfidence = 0.6155 \tBbox: [ 643 \t 145 \t 702 \t 240 ]\n",
      "12 \tObject: person \tConfidence = 0.4812 \tBbox: [ 505 \t 0 \t 542 \t 119 ]\n",
      "13 \tObject: train \tConfidence = 0.3498 \tBbox: [ 0 \t 0 \t 388 \t 948 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000503 / 1050\n",
      "Frames to be processed: 547  | To do: 52.1 % | Done: 47.9 %\n",
      "\n",
      "2022-04-20 13:14:24.888768\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000503.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 27.0ms pre-process, 180.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9195 \tBbox: [ 555 \t 208 \t 721 \t 524 ]\n",
      "2 \tObject: person \tConfidence = 0.9073 \tBbox: [ 408 \t 353 \t 590 \t 772 ]\n",
      "3 \tObject: person \tConfidence = 0.8746 \tBbox: [ 392 \t 0 \t 453 \t 163 ]\n",
      "4 \tObject: person \tConfidence = 0.8682 \tBbox: [ 590 \t 54 \t 671 \t 242 ]\n",
      "5 \tObject: person \tConfidence = 0.8665 \tBbox: [ 323 \t 206 \t 411 \t 481 ]\n",
      "6 \tObject: person \tConfidence = 0.8632 \tBbox: [ 384 \t 233 \t 501 \t 565 ]\n",
      "7 \tObject: person \tConfidence = 0.8602 \tBbox: [ 454 \t 0 \t 518 \t 172 ]\n",
      "8 \tObject: person \tConfidence = 0.8307 \tBbox: [ 0 \t 805 \t 225 \t 1078 ]\n",
      "9 \tObject: person \tConfidence = 0.7524 \tBbox: [ 185 \t 457 \t 321 \t 843 ]\n",
      "10 \tObject: person \tConfidence = 0.6974 \tBbox: [ 346 \t 149 \t 410 \t 253 ]\n",
      "11 \tObject: person \tConfidence = 0.5723 \tBbox: [ 641 \t 145 \t 701 \t 241 ]\n",
      "12 \tObject: person \tConfidence = 0.4113 \tBbox: [ 505 \t 0 \t 541 \t 119 ]\n",
      "13 \tObject: train \tConfidence = 0.3459 \tBbox: [ 1 \t 4 \t 407 \t 910 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000504 / 1050\n",
      "Frames to be processed: 546  | To do: 52.0 % | Done: 48.0 %\n",
      "\n",
      "2022-04-20 13:14:25.450210\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000504.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons\n",
      "Speed: 35.9ms pre-process, 171.7ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9219 \tBbox: [ 412 \t 355 \t 587 \t 769 ]\n",
      "2 \tObject: person \tConfidence = 0.8891 \tBbox: [ 557 \t 204 \t 722 \t 523 ]\n",
      "3 \tObject: person \tConfidence = 0.877 \tBbox: [ 391 \t 0 \t 452 \t 163 ]\n",
      "4 \tObject: person \tConfidence = 0.8662 \tBbox: [ 453 \t 0 \t 519 \t 171 ]\n",
      "5 \tObject: person \tConfidence = 0.8625 \tBbox: [ 589 \t 54 \t 672 \t 245 ]\n",
      "6 \tObject: person \tConfidence = 0.8585 \tBbox: [ 323 \t 206 \t 412 \t 480 ]\n",
      "7 \tObject: person \tConfidence = 0.8502 \tBbox: [ 0 \t 807 \t 224 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.8426 \tBbox: [ 382 \t 233 \t 501 \t 564 ]\n",
      "9 \tObject: person \tConfidence = 0.8096 \tBbox: [ 185 \t 459 \t 327 \t 861 ]\n",
      "10 \tObject: person \tConfidence = 0.6785 \tBbox: [ 340 \t 149 \t 411 \t 256 ]\n",
      "11 \tObject: person \tConfidence = 0.3786 \tBbox: [ 506 \t 0 \t 545 \t 119 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000505 / 1050\n",
      "Frames to be processed: 545  | To do: 51.9 % | Done: 48.1 %\n",
      "\n",
      "2022-04-20 13:14:25.996164\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000505.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons\n",
      "Speed: 31.6ms pre-process, 175.9ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9159 \tBbox: [ 413 \t 356 \t 584 \t 768 ]\n",
      "2 \tObject: person \tConfidence = 0.9098 \tBbox: [ 555 \t 207 \t 721 \t 524 ]\n",
      "3 \tObject: person \tConfidence = 0.8823 \tBbox: [ 392 \t 0 \t 451 \t 162 ]\n",
      "4 \tObject: person \tConfidence = 0.8592 \tBbox: [ 452 \t 0 \t 516 \t 170 ]\n",
      "5 \tObject: person \tConfidence = 0.8583 \tBbox: [ 590 \t 53 \t 671 \t 246 ]\n",
      "6 \tObject: person \tConfidence = 0.8486 \tBbox: [ 323 \t 206 \t 412 \t 480 ]\n",
      "7 \tObject: person \tConfidence = 0.8405 \tBbox: [ 176 \t 459 \t 329 \t 865 ]\n",
      "8 \tObject: person \tConfidence = 0.8374 \tBbox: [ 1 \t 808 \t 230 \t 1079 ]\n",
      "9 \tObject: person \tConfidence = 0.8344 \tBbox: [ 380 \t 232 \t 499 \t 565 ]\n",
      "10 \tObject: person \tConfidence = 0.6992 \tBbox: [ 333 \t 149 \t 411 \t 261 ]\n",
      "11 \tObject: person \tConfidence = 0.4512 \tBbox: [ 506 \t 0 \t 544 \t 119 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000506 / 1050\n",
      "Frames to be processed: 544  | To do: 51.81 % | Done: 48.19 %\n",
      "\n",
      "2022-04-20 13:14:26.443931\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000506.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons\n",
      "Speed: 39.1ms pre-process, 175.6ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9169 \tBbox: [ 408 \t 356 \t 576 \t 771 ]\n",
      "2 \tObject: person \tConfidence = 0.9094 \tBbox: [ 552 \t 210 \t 723 \t 529 ]\n",
      "3 \tObject: person \tConfidence = 0.8704 \tBbox: [ 391 \t 0 \t 451 \t 162 ]\n",
      "4 \tObject: person \tConfidence = 0.8502 \tBbox: [ 590 \t 53 \t 668 \t 254 ]\n",
      "5 \tObject: person \tConfidence = 0.8444 \tBbox: [ 323 \t 206 \t 413 \t 480 ]\n",
      "6 \tObject: person \tConfidence = 0.8305 \tBbox: [ 451 \t 0 \t 523 \t 171 ]\n",
      "7 \tObject: person \tConfidence = 0.8304 \tBbox: [ 1 \t 811 \t 228 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.8206 \tBbox: [ 383 \t 231 \t 501 \t 565 ]\n",
      "9 \tObject: person \tConfidence = 0.82 \tBbox: [ 166 \t 458 \t 322 \t 864 ]\n",
      "10 \tObject: person \tConfidence = 0.6914 \tBbox: [ 336 \t 149 \t 411 \t 258 ]\n",
      "11 \tObject: person \tConfidence = 0.3754 \tBbox: [ 505 \t 0 \t 541 \t 118 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000507 / 1050\n",
      "Frames to be processed: 543  | To do: 51.71 % | Done: 48.29 %\n",
      "\n",
      "2022-04-20 13:14:26.984766\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000507.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons\n",
      "Speed: 29.5ms pre-process, 179.4ms inference, 3.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.904 \tBbox: [ 407 \t 357 \t 573 \t 771 ]\n",
      "2 \tObject: person \tConfidence = 0.9 \tBbox: [ 548 \t 214 \t 724 \t 549 ]\n",
      "3 \tObject: person \tConfidence = 0.8729 \tBbox: [ 391 \t 0 \t 451 \t 162 ]\n",
      "4 \tObject: person \tConfidence = 0.8498 \tBbox: [ 322 \t 206 \t 413 \t 480 ]\n",
      "5 \tObject: person \tConfidence = 0.8493 \tBbox: [ 451 \t 0 \t 525 \t 170 ]\n",
      "6 \tObject: person \tConfidence = 0.8466 \tBbox: [ 590 \t 54 \t 667 \t 257 ]\n",
      "7 \tObject: person \tConfidence = 0.8221 \tBbox: [ 382 \t 231 \t 501 \t 563 ]\n",
      "8 \tObject: person \tConfidence = 0.7947 \tBbox: [ 1 \t 811 \t 227 \t 1079 ]\n",
      "9 \tObject: person \tConfidence = 0.7835 \tBbox: [ 152 \t 458 \t 319 \t 864 ]\n",
      "10 \tObject: person \tConfidence = 0.7076 \tBbox: [ 339 \t 150 \t 412 \t 258 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000508 / 1050\n",
      "Frames to be processed: 542  | To do: 51.62 % | Done: 48.38 %\n",
      "\n",
      "2022-04-20 13:14:27.496818\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000508.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons\n",
      "Speed: 26.1ms pre-process, 180.7ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8975 \tBbox: [ 552 \t 215 \t 723 \t 560 ]\n",
      "2 \tObject: person \tConfidence = 0.8964 \tBbox: [ 403 \t 356 \t 569 \t 771 ]\n",
      "3 \tObject: person \tConfidence = 0.8848 \tBbox: [ 390 \t 0 \t 450 \t 162 ]\n",
      "4 \tObject: person \tConfidence = 0.8531 \tBbox: [ 322 \t 207 \t 413 \t 479 ]\n",
      "5 \tObject: person \tConfidence = 0.8427 \tBbox: [ 451 \t 0 \t 518 \t 170 ]\n",
      "6 \tObject: person \tConfidence = 0.8288 \tBbox: [ 156 \t 457 \t 313 \t 859 ]\n",
      "7 \tObject: person \tConfidence = 0.8247 \tBbox: [ 590 \t 54 \t 666 \t 258 ]\n",
      "8 \tObject: person \tConfidence = 0.8214 \tBbox: [ 1 \t 812 \t 224 \t 1078 ]\n",
      "9 \tObject: person \tConfidence = 0.8145 \tBbox: [ 382 \t 231 \t 501 \t 563 ]\n",
      "10 \tObject: person \tConfidence = 0.7185 \tBbox: [ 338 \t 151 \t 412 \t 259 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000509 / 1050\n",
      "Frames to be processed: 541  | To do: 51.52 % | Done: 48.48 %\n",
      "\n",
      "2022-04-20 13:14:27.993603\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000509.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons\n",
      "Speed: 27.5ms pre-process, 175.2ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9155 \tBbox: [ 549 \t 223 \t 722 \t 567 ]\n",
      "2 \tObject: person \tConfidence = 0.9014 \tBbox: [ 403 \t 356 \t 565 \t 769 ]\n",
      "3 \tObject: person \tConfidence = 0.8929 \tBbox: [ 389 \t 0 \t 449 \t 161 ]\n",
      "4 \tObject: person \tConfidence = 0.8564 \tBbox: [ 451 \t 0 \t 516 \t 168 ]\n",
      "5 \tObject: person \tConfidence = 0.8454 \tBbox: [ 321 \t 206 \t 415 \t 479 ]\n",
      "6 \tObject: person \tConfidence = 0.8093 \tBbox: [ 590 \t 52 \t 664 \t 257 ]\n",
      "7 \tObject: person \tConfidence = 0.809 \tBbox: [ 1 \t 811 \t 220 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.7841 \tBbox: [ 154 \t 456 \t 309 \t 852 ]\n",
      "9 \tObject: person \tConfidence = 0.7727 \tBbox: [ 383 \t 230 \t 498 \t 561 ]\n",
      "10 \tObject: person \tConfidence = 0.7473 \tBbox: [ 338 \t 152 \t 412 \t 259 ]\n",
      "11 \tObject: person \tConfidence = 0.3104 \tBbox: [ 621 \t 167 \t 685 \t 270 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000510 / 1050\n",
      "Frames to be processed: 540  | To do: 51.43 % | Done: 48.57 %\n",
      "\n",
      "2022-04-20 13:14:28.512406\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000510.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons\n",
      "Speed: 26.2ms pre-process, 178.3ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.92 \tBbox: [ 398 \t 357 \t 561 \t 769 ]\n",
      "2 \tObject: person \tConfidence = 0.8936 \tBbox: [ 546 \t 227 \t 722 \t 578 ]\n",
      "3 \tObject: person \tConfidence = 0.8876 \tBbox: [ 389 \t 0 \t 449 \t 161 ]\n",
      "4 \tObject: person \tConfidence = 0.8494 \tBbox: [ 321 \t 206 \t 413 \t 478 ]\n",
      "5 \tObject: person \tConfidence = 0.8425 \tBbox: [ 450 \t 0 \t 515 \t 169 ]\n",
      "6 \tObject: person \tConfidence = 0.7794 \tBbox: [ 1 \t 814 \t 209 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.7598 \tBbox: [ 152 \t 458 \t 307 \t 816 ]\n",
      "8 \tObject: person \tConfidence = 0.7582 \tBbox: [ 591 \t 53 \t 661 \t 256 ]\n",
      "9 \tObject: person \tConfidence = 0.7024 \tBbox: [ 341 \t 152 \t 413 \t 260 ]\n",
      "10 \tObject: person \tConfidence = 0.6389 \tBbox: [ 384 \t 229 \t 499 \t 559 ]\n",
      "11 \tObject: person \tConfidence = 0.4164 \tBbox: [ 619 \t 154 \t 682 \t 267 ]\n",
      "12 \tObject: person \tConfidence = 0.3756 \tBbox: [ 502 \t 0 \t 540 \t 113 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000511 / 1050\n",
      "Frames to be processed: 539  | To do: 51.33 % | Done: 48.67 %\n",
      "\n",
      "2022-04-20 13:14:28.997526\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000511.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons\n",
      "Speed: 28.6ms pre-process, 176.8ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9176 \tBbox: [ 545 \t 243 \t 722 \t 599 ]\n",
      "2 \tObject: person \tConfidence = 0.8973 \tBbox: [ 393 \t 363 \t 556 \t 772 ]\n",
      "3 \tObject: person \tConfidence = 0.8872 \tBbox: [ 388 \t 0 \t 449 \t 162 ]\n",
      "4 \tObject: person \tConfidence = 0.8459 \tBbox: [ 451 \t 0 \t 513 \t 167 ]\n",
      "5 \tObject: person \tConfidence = 0.845 \tBbox: [ 321 \t 206 \t 413 \t 478 ]\n",
      "6 \tObject: person \tConfidence = 0.7877 \tBbox: [ 1 \t 815 \t 207 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.78 \tBbox: [ 591 \t 53 \t 677 \t 260 ]\n",
      "8 \tObject: person \tConfidence = 0.6986 \tBbox: [ 146 \t 459 \t 307 \t 802 ]\n",
      "9 \tObject: person \tConfidence = 0.6846 \tBbox: [ 342 \t 153 \t 414 \t 264 ]\n",
      "10 \tObject: person \tConfidence = 0.625 \tBbox: [ 385 \t 232 \t 502 \t 474 ]\n",
      "11 \tObject: person \tConfidence = 0.4135 \tBbox: [ 566 \t 0 \t 596 \t 48 ]\n",
      "12 \tObject: person \tConfidence = 0.3698 \tBbox: [ 497 \t 0 \t 536 \t 115 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000512 / 1050\n",
      "Frames to be processed: 538  | To do: 51.24 % | Done: 48.76 %\n",
      "\n",
      "2022-04-20 13:14:29.483999\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000512.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons\n",
      "Speed: 35.7ms pre-process, 180.5ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9162 \tBbox: [ 545 \t 246 \t 722 \t 608 ]\n",
      "2 \tObject: person \tConfidence = 0.8919 \tBbox: [ 389 \t 361 \t 552 \t 771 ]\n",
      "3 \tObject: person \tConfidence = 0.8855 \tBbox: [ 388 \t 0 \t 447 \t 162 ]\n",
      "4 \tObject: person \tConfidence = 0.8355 \tBbox: [ 451 \t 0 \t 511 \t 165 ]\n",
      "5 \tObject: person \tConfidence = 0.8301 \tBbox: [ 321 \t 206 \t 413 \t 477 ]\n",
      "6 \tObject: person \tConfidence = 0.8079 \tBbox: [ 590 \t 53 \t 673 \t 259 ]\n",
      "7 \tObject: person \tConfidence = 0.7845 \tBbox: [ 1 \t 814 \t 219 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.6814 \tBbox: [ 348 \t 154 \t 415 \t 264 ]\n",
      "9 \tObject: person \tConfidence = 0.6739 \tBbox: [ 387 \t 232 \t 500 \t 470 ]\n",
      "10 \tObject: person \tConfidence = 0.6378 \tBbox: [ 146 \t 460 \t 307 \t 808 ]\n",
      "11 \tObject: person \tConfidence = 0.626 \tBbox: [ 564 \t 0 \t 597 \t 48 ]\n",
      "12 \tObject: person \tConfidence = 0.4621 \tBbox: [ 496 \t 0 \t 537 \t 114 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000513 / 1050\n",
      "Frames to be processed: 537  | To do: 51.14 % | Done: 48.86 %\n",
      "\n",
      "2022-04-20 13:14:29.966325\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000513.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons\n",
      "Speed: 57.8ms pre-process, 181.7ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9111 \tBbox: [ 547 \t 251 \t 722 \t 608 ]\n",
      "2 \tObject: person \tConfidence = 0.8883 \tBbox: [ 387 \t 0 \t 447 \t 163 ]\n",
      "3 \tObject: person \tConfidence = 0.885 \tBbox: [ 388 \t 362 \t 550 \t 769 ]\n",
      "4 \tObject: person \tConfidence = 0.85 \tBbox: [ 451 \t 0 \t 510 \t 163 ]\n",
      "5 \tObject: person \tConfidence = 0.8347 \tBbox: [ 321 \t 205 \t 414 \t 477 ]\n",
      "6 \tObject: person \tConfidence = 0.8114 \tBbox: [ 590 \t 53 \t 670 \t 261 ]\n",
      "7 \tObject: person \tConfidence = 0.774 \tBbox: [ 1 \t 816 \t 211 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.7003 \tBbox: [ 142 \t 460 \t 307 \t 803 ]\n",
      "9 \tObject: person \tConfidence = 0.6943 \tBbox: [ 349 \t 156 \t 415 \t 264 ]\n",
      "10 \tObject: person \tConfidence = 0.6709 \tBbox: [ 387 \t 231 \t 500 \t 472 ]\n",
      "11 \tObject: person \tConfidence = 0.4876 \tBbox: [ 564 \t 0 \t 596 \t 49 ]\n",
      "12 \tObject: person \tConfidence = 0.3848 \tBbox: [ 496 \t 0 \t 535 \t 114 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000514 / 1050\n",
      "Frames to be processed: 536  | To do: 51.05 % | Done: 48.95 %\n",
      "\n",
      "2022-04-20 13:14:30.543222\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000514.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 32.8ms pre-process, 180.3ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9126 \tBbox: [ 548 \t 254 \t 722 \t 608 ]\n",
      "2 \tObject: person \tConfidence = 0.8847 \tBbox: [ 387 \t 0 \t 446 \t 162 ]\n",
      "3 \tObject: person \tConfidence = 0.8605 \tBbox: [ 391 \t 365 \t 547 \t 772 ]\n",
      "4 \tObject: person \tConfidence = 0.8424 \tBbox: [ 320 \t 205 \t 414 \t 477 ]\n",
      "5 \tObject: person \tConfidence = 0.836 \tBbox: [ 452 \t 0 \t 510 \t 163 ]\n",
      "6 \tObject: person \tConfidence = 0.825 \tBbox: [ 1 \t 816 \t 240 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.8176 \tBbox: [ 590 \t 54 \t 668 \t 259 ]\n",
      "8 \tObject: person \tConfidence = 0.7061 \tBbox: [ 351 \t 155 \t 416 \t 264 ]\n",
      "9 \tObject: person \tConfidence = 0.7029 \tBbox: [ 387 \t 231 \t 504 \t 471 ]\n",
      "10 \tObject: person \tConfidence = 0.6426 \tBbox: [ 143 \t 459 \t 307 \t 810 ]\n",
      "11 \tObject: person \tConfidence = 0.3712 \tBbox: [ 565 \t 0 \t 595 \t 50 ]\n",
      "12 \tObject: person \tConfidence = 0.3605 \tBbox: [ 495 \t 0 \t 536 \t 113 ]\n",
      "13 \tObject: train \tConfidence = 0.3277 \tBbox: [ 0 \t 0 \t 393 \t 855 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000515 / 1050\n",
      "Frames to be processed: 535  | To do: 50.95 % | Done: 49.05 %\n",
      "\n",
      "2022-04-20 13:14:31.044317\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000515.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons\n",
      "Speed: 42.2ms pre-process, 181.0ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9113 \tBbox: [ 545 \t 257 \t 724 \t 608 ]\n",
      "2 \tObject: person \tConfidence = 0.8777 \tBbox: [ 387 \t 0 \t 446 \t 163 ]\n",
      "3 \tObject: person \tConfidence = 0.8581 \tBbox: [ 392 \t 368 \t 545 \t 772 ]\n",
      "4 \tObject: person \tConfidence = 0.8417 \tBbox: [ 320 \t 205 \t 414 \t 477 ]\n",
      "5 \tObject: person \tConfidence = 0.8199 \tBbox: [ 452 \t 0 \t 510 \t 163 ]\n",
      "6 \tObject: person \tConfidence = 0.7996 \tBbox: [ 587 \t 54 \t 664 \t 259 ]\n",
      "7 \tObject: person \tConfidence = 0.794 \tBbox: [ 1 \t 817 \t 236 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.7009 \tBbox: [ 386 \t 231 \t 501 \t 468 ]\n",
      "9 \tObject: person \tConfidence = 0.7006 \tBbox: [ 354 \t 156 \t 416 \t 265 ]\n",
      "10 \tObject: person \tConfidence = 0.6569 \tBbox: [ 146 \t 460 \t 306 \t 803 ]\n",
      "11 \tObject: person \tConfidence = 0.3552 \tBbox: [ 496 \t 0 \t 535 \t 112 ]\n",
      "12 \tObject: person \tConfidence = 0.3202 \tBbox: [ 565 \t 0 \t 595 \t 48 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000516 / 1050\n",
      "Frames to be processed: 534  | To do: 50.86 % | Done: 49.14 %\n",
      "\n",
      "2022-04-20 13:14:31.511750\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000516.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons\n",
      "Speed: 26.9ms pre-process, 181.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.909 \tBbox: [ 544 \t 262 \t 727 \t 609 ]\n",
      "2 \tObject: person \tConfidence = 0.8853 \tBbox: [ 389 \t 365 \t 542 \t 781 ]\n",
      "3 \tObject: person \tConfidence = 0.8818 \tBbox: [ 387 \t 0 \t 445 \t 163 ]\n",
      "4 \tObject: person \tConfidence = 0.8442 \tBbox: [ 575 \t 55 \t 657 \t 258 ]\n",
      "5 \tObject: person \tConfidence = 0.8439 \tBbox: [ 319 \t 204 \t 414 \t 477 ]\n",
      "6 \tObject: person \tConfidence = 0.8141 \tBbox: [ 452 \t 0 \t 510 \t 164 ]\n",
      "7 \tObject: person \tConfidence = 0.761 \tBbox: [ 1 \t 816 \t 230 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.7417 \tBbox: [ 353 \t 156 \t 416 \t 265 ]\n",
      "9 \tObject: person \tConfidence = 0.6877 \tBbox: [ 387 \t 232 \t 499 \t 467 ]\n",
      "10 \tObject: person \tConfidence = 0.5294 \tBbox: [ 144 \t 458 \t 306 \t 805 ]\n",
      "11 \tObject: person \tConfidence = 0.3726 \tBbox: [ 433 \t 0 \t 466 \t 119 ]\n",
      "12 \tObject: person \tConfidence = 0.3617 \tBbox: [ 495 \t 0 \t 533 \t 113 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000517 / 1050\n",
      "Frames to be processed: 533  | To do: 50.76 % | Done: 49.24 %\n",
      "\n",
      "2022-04-20 13:14:32.016212\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000517.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 34.1ms pre-process, 179.9ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9119 \tBbox: [ 545 \t 266 \t 728 \t 609 ]\n",
      "2 \tObject: person \tConfidence = 0.894 \tBbox: [ 388 \t 366 \t 540 \t 782 ]\n",
      "3 \tObject: person \tConfidence = 0.8809 \tBbox: [ 387 \t 0 \t 446 \t 163 ]\n",
      "4 \tObject: person \tConfidence = 0.854 \tBbox: [ 571 \t 54 \t 654 \t 258 ]\n",
      "5 \tObject: person \tConfidence = 0.8345 \tBbox: [ 318 \t 203 \t 414 \t 477 ]\n",
      "6 \tObject: person \tConfidence = 0.8067 \tBbox: [ 451 \t 0 \t 509 \t 164 ]\n",
      "7 \tObject: person \tConfidence = 0.7975 \tBbox: [ 1 \t 814 \t 234 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.7321 \tBbox: [ 352 \t 156 \t 416 \t 264 ]\n",
      "9 \tObject: person \tConfidence = 0.6875 \tBbox: [ 387 \t 232 \t 499 \t 466 ]\n",
      "10 \tObject: train \tConfidence = 0.6307 \tBbox: [ 0 \t 1 \t 388 \t 841 ]\n",
      "11 \tObject: person \tConfidence = 0.5269 \tBbox: [ 138 \t 460 \t 305 \t 849 ]\n",
      "12 \tObject: person \tConfidence = 0.4975 \tBbox: [ 565 \t 0 \t 591 \t 48 ]\n",
      "13 \tObject: person \tConfidence = 0.4105 \tBbox: [ 496 \t 0 \t 533 \t 113 ]\n",
      "14 \tObject: person \tConfidence = 0.375 \tBbox: [ 434 \t 0 \t 467 \t 120 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000518 / 1050\n",
      "Frames to be processed: 532  | To do: 50.67 % | Done: 49.33 %\n",
      "\n",
      "2022-04-20 13:14:32.471260\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000518.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons\n",
      "Speed: 25.1ms pre-process, 182.0ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9081 \tBbox: [ 544 \t 270 \t 730 \t 610 ]\n",
      "2 \tObject: person \tConfidence = 0.8905 \tBbox: [ 386 \t 366 \t 538 \t 780 ]\n",
      "3 \tObject: person \tConfidence = 0.8713 \tBbox: [ 387 \t 0 \t 446 \t 163 ]\n",
      "4 \tObject: person \tConfidence = 0.8262 \tBbox: [ 319 \t 203 \t 413 \t 477 ]\n",
      "5 \tObject: person \tConfidence = 0.8192 \tBbox: [ 1 \t 814 \t 237 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.8032 \tBbox: [ 568 \t 56 \t 653 \t 258 ]\n",
      "7 \tObject: person \tConfidence = 0.7859 \tBbox: [ 453 \t 0 \t 511 \t 165 ]\n",
      "8 \tObject: person \tConfidence = 0.7776 \tBbox: [ 355 \t 156 \t 416 \t 264 ]\n",
      "9 \tObject: person \tConfidence = 0.6906 \tBbox: [ 386 \t 232 \t 498 \t 467 ]\n",
      "10 \tObject: person \tConfidence = 0.6219 \tBbox: [ 144 \t 458 \t 307 \t 796 ]\n",
      "11 \tObject: person \tConfidence = 0.4896 \tBbox: [ 564 \t 0 \t 590 \t 49 ]\n",
      "12 \tObject: person \tConfidence = 0.3197 \tBbox: [ 496 \t 1 \t 532 \t 113 ]\n",
      "13 \tObject: person \tConfidence = 0.3194 \tBbox: [ 435 \t 0 \t 467 \t 121 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000519 / 1050\n",
      "Frames to be processed: 531  | To do: 50.57 % | Done: 49.43 %\n",
      "\n",
      "2022-04-20 13:14:32.937734\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000519.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 24.3ms pre-process, 172.6ms inference, 3.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9084 \tBbox: [ 545 \t 273 \t 730 \t 624 ]\n",
      "2 \tObject: person \tConfidence = 0.8689 \tBbox: [ 386 \t 369 \t 535 \t 793 ]\n",
      "3 \tObject: person \tConfidence = 0.8604 \tBbox: [ 387 \t 0 \t 445 \t 162 ]\n",
      "4 \tObject: person \tConfidence = 0.8234 \tBbox: [ 319 \t 203 \t 413 \t 477 ]\n",
      "5 \tObject: person \tConfidence = 0.8045 \tBbox: [ 0 \t 813 \t 235 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.7881 \tBbox: [ 566 \t 56 \t 651 \t 259 ]\n",
      "7 \tObject: person \tConfidence = 0.7724 \tBbox: [ 355 \t 156 \t 417 \t 263 ]\n",
      "8 \tObject: person \tConfidence = 0.7499 \tBbox: [ 454 \t 0 \t 516 \t 165 ]\n",
      "9 \tObject: person \tConfidence = 0.6855 \tBbox: [ 386 \t 232 \t 497 \t 467 ]\n",
      "10 \tObject: train \tConfidence = 0.6057 \tBbox: [ 0 \t 0 \t 386 \t 843 ]\n",
      "11 \tObject: person \tConfidence = 0.5781 \tBbox: [ 142 \t 456 \t 310 \t 803 ]\n",
      "12 \tObject: person \tConfidence = 0.5658 \tBbox: [ 562 \t 0 \t 588 \t 50 ]\n",
      "13 \tObject: person \tConfidence = 0.3406 \tBbox: [ 434 \t 0 \t 469 \t 121 ]\n",
      "14 \tObject: person \tConfidence = 0.3095 \tBbox: [ 496 \t 1 \t 532 \t 113 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000520 / 1050\n",
      "Frames to be processed: 530  | To do: 50.48 % | Done: 49.52 %\n",
      "\n",
      "2022-04-20 13:14:33.390030\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000520.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 28.3ms pre-process, 177.9ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9045 \tBbox: [ 545 \t 281 \t 730 \t 647 ]\n",
      "2 \tObject: person \tConfidence = 0.8643 \tBbox: [ 384 \t 370 \t 532 \t 845 ]\n",
      "3 \tObject: person \tConfidence = 0.8549 \tBbox: [ 387 \t 0 \t 445 \t 162 ]\n",
      "4 \tObject: person \tConfidence = 0.8103 \tBbox: [ 318 \t 203 \t 413 \t 477 ]\n",
      "5 \tObject: person \tConfidence = 0.7755 \tBbox: [ 1 \t 813 \t 220 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.7665 \tBbox: [ 354 \t 157 \t 418 \t 263 ]\n",
      "7 \tObject: person \tConfidence = 0.7425 \tBbox: [ 567 \t 56 \t 650 \t 260 ]\n",
      "8 \tObject: person \tConfidence = 0.7273 \tBbox: [ 454 \t 0 \t 514 \t 164 ]\n",
      "9 \tObject: person \tConfidence = 0.6758 \tBbox: [ 387 \t 232 \t 495 \t 471 ]\n",
      "10 \tObject: person \tConfidence = 0.6524 \tBbox: [ 147 \t 455 \t 308 \t 792 ]\n",
      "11 \tObject: train \tConfidence = 0.6109 \tBbox: [ 0 \t 0 \t 390 \t 847 ]\n",
      "12 \tObject: person \tConfidence = 0.4444 \tBbox: [ 558 \t 0 \t 592 \t 50 ]\n",
      "13 \tObject: person \tConfidence = 0.3169 \tBbox: [ 434 \t 0 \t 469 \t 120 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000521 / 1050\n",
      "Frames to be processed: 529  | To do: 50.38 % | Done: 49.62 %\n",
      "\n",
      "2022-04-20 13:14:33.967325\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000521.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 27.1ms pre-process, 180.2ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9221 \tBbox: [ 544 \t 300 \t 734 \t 680 ]\n",
      "2 \tObject: person \tConfidence = 0.85 \tBbox: [ 380 \t 373 \t 529 \t 849 ]\n",
      "3 \tObject: person \tConfidence = 0.8417 \tBbox: [ 387 \t 0 \t 446 \t 162 ]\n",
      "4 \tObject: person \tConfidence = 0.8031 \tBbox: [ 316 \t 203 \t 414 \t 476 ]\n",
      "5 \tObject: person \tConfidence = 0.7878 \tBbox: [ 1 \t 812 \t 195 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.7842 \tBbox: [ 356 \t 157 \t 419 \t 264 ]\n",
      "7 \tObject: person \tConfidence = 0.7184 \tBbox: [ 452 \t 0 \t 509 \t 164 ]\n",
      "8 \tObject: person \tConfidence = 0.7077 \tBbox: [ 565 \t 56 \t 642 \t 260 ]\n",
      "9 \tObject: person \tConfidence = 0.6899 \tBbox: [ 387 \t 232 \t 486 \t 475 ]\n",
      "10 \tObject: train \tConfidence = 0.6102 \tBbox: [ 3 \t 1 \t 369 \t 847 ]\n",
      "11 \tObject: person \tConfidence = 0.585 \tBbox: [ 152 \t 456 \t 311 \t 830 ]\n",
      "12 \tObject: person \tConfidence = 0.363 \tBbox: [ 495 \t 1 \t 531 \t 113 ]\n",
      "13 \tObject: person \tConfidence = 0.3604 \tBbox: [ 560 \t 0 \t 592 \t 52 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000522 / 1050\n",
      "Frames to be processed: 528  | To do: 50.29 % | Done: 49.71 %\n",
      "\n",
      "2022-04-20 13:14:34.490178\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000522.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 25.4ms pre-process, 184.5ms inference, 4.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9093 \tBbox: [ 546 \t 305 \t 736 \t 690 ]\n",
      "2 \tObject: person \tConfidence = 0.8467 \tBbox: [ 379 \t 375 \t 528 \t 849 ]\n",
      "3 \tObject: person \tConfidence = 0.8353 \tBbox: [ 387 \t 0 \t 447 \t 162 ]\n",
      "4 \tObject: person \tConfidence = 0.8023 \tBbox: [ 316 \t 203 \t 413 \t 476 ]\n",
      "5 \tObject: person \tConfidence = 0.79 \tBbox: [ 1 \t 812 \t 189 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.7745 \tBbox: [ 356 \t 157 \t 418 \t 264 ]\n",
      "7 \tObject: person \tConfidence = 0.7039 \tBbox: [ 453 \t 0 \t 511 \t 164 ]\n",
      "8 \tObject: person \tConfidence = 0.6643 \tBbox: [ 386 \t 231 \t 494 \t 473 ]\n",
      "9 \tObject: person \tConfidence = 0.6536 \tBbox: [ 566 \t 56 \t 640 \t 261 ]\n",
      "10 \tObject: train \tConfidence = 0.5975 \tBbox: [ 3 \t 1 \t 367 \t 845 ]\n",
      "11 \tObject: person \tConfidence = 0.5949 \tBbox: [ 154 \t 458 \t 312 \t 847 ]\n",
      "12 \tObject: person \tConfidence = 0.3809 \tBbox: [ 556 \t 0 \t 591 \t 53 ]\n",
      "13 \tObject: person \tConfidence = 0.3608 \tBbox: [ 494 \t 1 \t 530 \t 113 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000523 / 1050\n",
      "Frames to be processed: 527  | To do: 50.19 % | Done: 49.81 %\n",
      "\n",
      "2022-04-20 13:14:35.055050\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000523.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 25.7ms pre-process, 173.1ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9092 \tBbox: [ 547 \t 311 \t 738 \t 705 ]\n",
      "2 \tObject: person \tConfidence = 0.85 \tBbox: [ 387 \t 0 \t 446 \t 162 ]\n",
      "3 \tObject: person \tConfidence = 0.8381 \tBbox: [ 381 \t 376 \t 526 \t 850 ]\n",
      "4 \tObject: person \tConfidence = 0.811 \tBbox: [ 316 \t 203 \t 414 \t 475 ]\n",
      "5 \tObject: person \tConfidence = 0.7837 \tBbox: [ 1 \t 812 \t 189 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.7835 \tBbox: [ 356 \t 157 \t 418 \t 265 ]\n",
      "7 \tObject: person \tConfidence = 0.7437 \tBbox: [ 453 \t 0 \t 510 \t 163 ]\n",
      "8 \tObject: person \tConfidence = 0.6807 \tBbox: [ 161 \t 457 \t 313 \t 856 ]\n",
      "9 \tObject: train \tConfidence = 0.6698 \tBbox: [ 1 \t 2 \t 393 \t 851 ]\n",
      "10 \tObject: person \tConfidence = 0.6666 \tBbox: [ 568 \t 56 \t 639 \t 262 ]\n",
      "11 \tObject: person \tConfidence = 0.656 \tBbox: [ 387 \t 231 \t 493 \t 473 ]\n",
      "12 \tObject: person \tConfidence = 0.3936 \tBbox: [ 492 \t 0 \t 531 \t 113 ]\n",
      "13 \tObject: person \tConfidence = 0.3401 \tBbox: [ 552 \t 0 \t 588 \t 55 ]\n",
      "14 \tObject: person \tConfidence = 0.3348 \tBbox: [ 435 \t 1 \t 469 \t 119 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000524 / 1050\n",
      "Frames to be processed: 526  | To do: 50.1 % | Done: 49.9 %\n",
      "\n",
      "2022-04-20 13:14:35.606594\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000524.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 27.9ms pre-process, 168.0ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9152 \tBbox: [ 546 \t 322 \t 741 \t 725 ]\n",
      "2 \tObject: person \tConfidence = 0.8347 \tBbox: [ 386 \t 0 \t 446 \t 162 ]\n",
      "3 \tObject: person \tConfidence = 0.8282 \tBbox: [ 383 \t 377 \t 526 \t 849 ]\n",
      "4 \tObject: person \tConfidence = 0.8059 \tBbox: [ 316 \t 202 \t 413 \t 475 ]\n",
      "5 \tObject: person \tConfidence = 0.792 \tBbox: [ 356 \t 157 \t 418 \t 265 ]\n",
      "6 \tObject: person \tConfidence = 0.7678 \tBbox: [ 1 \t 812 \t 195 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.7227 \tBbox: [ 163 \t 458 \t 312 \t 864 ]\n",
      "8 \tObject: person \tConfidence = 0.6999 \tBbox: [ 453 \t 0 \t 511 \t 164 ]\n",
      "9 \tObject: train \tConfidence = 0.6839 \tBbox: [ 1 \t 2 \t 393 \t 845 ]\n",
      "10 \tObject: person \tConfidence = 0.6505 \tBbox: [ 566 \t 56 \t 635 \t 261 ]\n",
      "11 \tObject: person \tConfidence = 0.642 \tBbox: [ 386 \t 231 \t 499 \t 473 ]\n",
      "12 \tObject: person \tConfidence = 0.3347 \tBbox: [ 552 \t 0 \t 587 \t 56 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000525 / 1050\n",
      "Frames to be processed: 525  | To do: 50.0 % | Done: 50.0 %\n",
      "\n",
      "2022-04-20 13:14:36.061178\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000525.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 23.8ms pre-process, 173.8ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9068 \tBbox: [ 548 \t 328 \t 746 \t 736 ]\n",
      "2 \tObject: person \tConfidence = 0.8275 \tBbox: [ 386 \t 0 \t 446 \t 162 ]\n",
      "3 \tObject: person \tConfidence = 0.8263 \tBbox: [ 387 \t 379 \t 526 \t 849 ]\n",
      "4 \tObject: person \tConfidence = 0.8051 \tBbox: [ 316 \t 203 \t 412 \t 475 ]\n",
      "5 \tObject: person \tConfidence = 0.7949 \tBbox: [ 356 \t 157 \t 419 \t 266 ]\n",
      "6 \tObject: person \tConfidence = 0.7703 \tBbox: [ 165 \t 459 \t 311 \t 862 ]\n",
      "7 \tObject: person \tConfidence = 0.7552 \tBbox: [ 1 \t 813 \t 209 \t 1079 ]\n",
      "8 \tObject: train \tConfidence = 0.7184 \tBbox: [ 0 \t 2 \t 391 \t 850 ]\n",
      "9 \tObject: person \tConfidence = 0.7115 \tBbox: [ 454 \t 0 \t 511 \t 163 ]\n",
      "10 \tObject: person \tConfidence = 0.6482 \tBbox: [ 384 \t 231 \t 495 \t 474 ]\n",
      "11 \tObject: person \tConfidence = 0.5829 \tBbox: [ 566 \t 56 \t 634 \t 264 ]\n",
      "12 \tObject: person \tConfidence = 0.3157 \tBbox: [ 435 \t 0 \t 469 \t 119 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000526 / 1050\n",
      "Frames to be processed: 524  | To do: 49.9 % | Done: 50.1 %\n",
      "\n",
      "2022-04-20 13:14:36.572100\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000526.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 35.3ms pre-process, 168.9ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8233 \tBbox: [ 549 \t 335 \t 754 \t 738 ]\n",
      "2 \tObject: person \tConfidence = 0.817 \tBbox: [ 386 \t 382 \t 524 \t 851 ]\n",
      "3 \tObject: person \tConfidence = 0.8061 \tBbox: [ 2 \t 812 \t 242 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.7989 \tBbox: [ 387 \t 0 \t 446 \t 161 ]\n",
      "5 \tObject: person \tConfidence = 0.7978 \tBbox: [ 317 \t 202 \t 412 \t 475 ]\n",
      "6 \tObject: person \tConfidence = 0.757 \tBbox: [ 356 \t 157 \t 419 \t 268 ]\n",
      "7 \tObject: train \tConfidence = 0.7375 \tBbox: [ 1 \t 2 \t 388 \t 848 ]\n",
      "8 \tObject: person \tConfidence = 0.6836 \tBbox: [ 169 \t 461 \t 308 \t 853 ]\n",
      "9 \tObject: person \tConfidence = 0.6648 \tBbox: [ 385 \t 231 \t 495 \t 476 ]\n",
      "10 \tObject: person \tConfidence = 0.5964 \tBbox: [ 453 \t 0 \t 511 \t 163 ]\n",
      "11 \tObject: person \tConfidence = 0.4155 \tBbox: [ 566 \t 54 \t 632 \t 266 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000527 / 1050\n",
      "Frames to be processed: 523  | To do: 49.81 % | Done: 50.19 %\n",
      "\n",
      "2022-04-20 13:14:37.285402\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000527.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 30.3ms pre-process, 170.7ms inference, 10.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8327 \tBbox: [ 549 \t 339 \t 756 \t 737 ]\n",
      "2 \tObject: person \tConfidence = 0.8003 \tBbox: [ 386 \t 383 \t 525 \t 851 ]\n",
      "3 \tObject: person \tConfidence = 0.8 \tBbox: [ 318 \t 202 \t 411 \t 475 ]\n",
      "4 \tObject: person \tConfidence = 0.7993 \tBbox: [ 388 \t 0 \t 446 \t 161 ]\n",
      "5 \tObject: person \tConfidence = 0.794 \tBbox: [ 2 \t 812 \t 241 \t 1079 ]\n",
      "6 \tObject: train \tConfidence = 0.7897 \tBbox: [ 0 \t 2 \t 392 \t 847 ]\n",
      "7 \tObject: person \tConfidence = 0.729 \tBbox: [ 356 \t 156 \t 419 \t 269 ]\n",
      "8 \tObject: person \tConfidence = 0.7111 \tBbox: [ 168 \t 463 \t 307 \t 849 ]\n",
      "9 \tObject: person \tConfidence = 0.6668 \tBbox: [ 387 \t 230 \t 490 \t 481 ]\n",
      "10 \tObject: person \tConfidence = 0.5946 \tBbox: [ 453 \t 0 \t 509 \t 163 ]\n",
      "11 \tObject: person \tConfidence = 0.4025 \tBbox: [ 434 \t 0 \t 469 \t 119 ]\n",
      "12 \tObject: person \tConfidence = 0.3571 \tBbox: [ 354 \t 513 \t 512 \t 740 ]\n",
      "13 \tObject: person \tConfidence = 0.343 \tBbox: [ 567 \t 55 \t 631 \t 265 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000528 / 1050\n",
      "Frames to be processed: 522  | To do: 49.71 % | Done: 50.29 %\n",
      "\n",
      "2022-04-20 13:14:37.756323\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000528.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 23.1ms pre-process, 174.1ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9049 \tBbox: [ 551 \t 343 \t 763 \t 735 ]\n",
      "2 \tObject: person \tConfidence = 0.8376 \tBbox: [ 388 \t 0 \t 446 \t 159 ]\n",
      "3 \tObject: person \tConfidence = 0.81 \tBbox: [ 2 \t 812 \t 243 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.8085 \tBbox: [ 384 \t 384 \t 525 \t 851 ]\n",
      "5 \tObject: person \tConfidence = 0.7986 \tBbox: [ 316 \t 202 \t 411 \t 475 ]\n",
      "6 \tObject: person \tConfidence = 0.7373 \tBbox: [ 356 \t 156 \t 419 \t 270 ]\n",
      "7 \tObject: train \tConfidence = 0.7347 \tBbox: [ 0 \t 2 \t 394 \t 847 ]\n",
      "8 \tObject: person \tConfidence = 0.6929 \tBbox: [ 168 \t 465 \t 306 \t 843 ]\n",
      "9 \tObject: person \tConfidence = 0.6396 \tBbox: [ 386 \t 230 \t 493 \t 486 ]\n",
      "10 \tObject: person \tConfidence = 0.5502 \tBbox: [ 452 \t 0 \t 508 \t 163 ]\n",
      "11 \tObject: person \tConfidence = 0.3404 \tBbox: [ 434 \t 0 \t 468 \t 119 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000529 / 1050\n",
      "Frames to be processed: 521  | To do: 49.62 % | Done: 50.38 %\n",
      "\n",
      "2022-04-20 13:14:38.245104\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000529.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 24.8ms pre-process, 173.0ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9171 \tBbox: [ 551 \t 349 \t 765 \t 735 ]\n",
      "2 \tObject: person \tConfidence = 0.8302 \tBbox: [ 387 \t 0 \t 445 \t 159 ]\n",
      "3 \tObject: person \tConfidence = 0.8138 \tBbox: [ 1 \t 813 \t 242 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.809 \tBbox: [ 384 \t 386 \t 526 \t 851 ]\n",
      "5 \tObject: person \tConfidence = 0.8034 \tBbox: [ 316 \t 201 \t 411 \t 475 ]\n",
      "6 \tObject: person \tConfidence = 0.8004 \tBbox: [ 168 \t 467 \t 308 \t 859 ]\n",
      "7 \tObject: train \tConfidence = 0.756 \tBbox: [ 2 \t 1 \t 371 \t 845 ]\n",
      "8 \tObject: person \tConfidence = 0.7521 \tBbox: [ 356 \t 156 \t 419 \t 269 ]\n",
      "9 \tObject: person \tConfidence = 0.6624 \tBbox: [ 386 \t 229 \t 497 \t 489 ]\n",
      "10 \tObject: person \tConfidence = 0.4495 \tBbox: [ 563 \t 54 \t 629 \t 272 ]\n",
      "11 \tObject: person \tConfidence = 0.3832 \tBbox: [ 455 \t 0 \t 510 \t 162 ]\n",
      "12 \tObject: person \tConfidence = 0.3593 \tBbox: [ 434 \t 0 \t 468 \t 119 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000530 / 1050\n",
      "Frames to be processed: 520  | To do: 49.52 % | Done: 50.48 %\n",
      "\n",
      "2022-04-20 13:14:38.720545\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000530.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 32.3ms pre-process, 170.0ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9083 \tBbox: [ 550 \t 351 \t 766 \t 736 ]\n",
      "2 \tObject: person \tConfidence = 0.823 \tBbox: [ 387 \t 0 \t 445 \t 159 ]\n",
      "3 \tObject: person \tConfidence = 0.8078 \tBbox: [ 381 \t 388 \t 526 \t 852 ]\n",
      "4 \tObject: person \tConfidence = 0.7959 \tBbox: [ 316 \t 201 \t 411 \t 475 ]\n",
      "5 \tObject: person \tConfidence = 0.7659 \tBbox: [ 0 \t 813 \t 230 \t 1079 ]\n",
      "6 \tObject: train \tConfidence = 0.7514 \tBbox: [ 2 \t 1 \t 366 \t 843 ]\n",
      "7 \tObject: person \tConfidence = 0.7374 \tBbox: [ 356 \t 155 \t 419 \t 270 ]\n",
      "8 \tObject: person \tConfidence = 0.7255 \tBbox: [ 169 \t 467 \t 308 \t 855 ]\n",
      "9 \tObject: person \tConfidence = 0.6575 \tBbox: [ 386 \t 229 \t 497 \t 494 ]\n",
      "10 \tObject: person \tConfidence = 0.5436 \tBbox: [ 454 \t 0 \t 510 \t 164 ]\n",
      "11 \tObject: person \tConfidence = 0.4666 \tBbox: [ 562 \t 53 \t 628 \t 272 ]\n",
      "12 \tObject: person \tConfidence = 0.3381 \tBbox: [ 433 \t 0 \t 468 \t 118 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000531 / 1050\n",
      "Frames to be processed: 519  | To do: 49.43 % | Done: 50.57 %\n",
      "\n",
      "2022-04-20 13:14:39.235296\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000531.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 26.7ms pre-process, 172.1ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8995 \tBbox: [ 551 \t 360 \t 765 \t 751 ]\n",
      "2 \tObject: person \tConfidence = 0.8307 \tBbox: [ 368 \t 391 \t 527 \t 851 ]\n",
      "3 \tObject: person \tConfidence = 0.8215 \tBbox: [ 387 \t 0 \t 445 \t 159 ]\n",
      "4 \tObject: person \tConfidence = 0.8153 \tBbox: [ 170 \t 470 \t 309 \t 859 ]\n",
      "5 \tObject: person \tConfidence = 0.8053 \tBbox: [ 314 \t 200 \t 411 \t 475 ]\n",
      "6 \tObject: train \tConfidence = 0.7818 \tBbox: [ 0 \t 1 \t 397 \t 844 ]\n",
      "7 \tObject: person \tConfidence = 0.7283 \tBbox: [ 1 \t 812 \t 196 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.7079 \tBbox: [ 354 \t 155 \t 419 \t 270 ]\n",
      "9 \tObject: person \tConfidence = 0.6663 \tBbox: [ 454 \t 0 \t 510 \t 162 ]\n",
      "10 \tObject: person \tConfidence = 0.6368 \tBbox: [ 386 \t 228 \t 497 \t 496 ]\n",
      "11 \tObject: person \tConfidence = 0.6241 \tBbox: [ 559 \t 54 \t 627 \t 269 ]\n",
      "12 \tObject: person \tConfidence = 0.3845 \tBbox: [ 554 \t 0 \t 581 \t 56 ]\n",
      "13 \tObject: person \tConfidence = 0.3397 \tBbox: [ 433 \t 0 \t 468 \t 118 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000532 / 1050\n",
      "Frames to be processed: 518  | To do: 49.33 % | Done: 50.67 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:14:39.683256\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000532.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 26.0ms pre-process, 168.1ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.904 \tBbox: [ 552 \t 366 \t 765 \t 792 ]\n",
      "2 \tObject: person \tConfidence = 0.8506 \tBbox: [ 365 \t 392 \t 528 \t 851 ]\n",
      "3 \tObject: person \tConfidence = 0.8172 \tBbox: [ 313 \t 200 \t 410 \t 475 ]\n",
      "4 \tObject: person \tConfidence = 0.811 \tBbox: [ 169 \t 471 \t 310 \t 864 ]\n",
      "5 \tObject: person \tConfidence = 0.8034 \tBbox: [ 387 \t 0 \t 447 \t 159 ]\n",
      "6 \tObject: train \tConfidence = 0.7829 \tBbox: [ 0 \t 1 \t 397 \t 844 ]\n",
      "7 \tObject: person \tConfidence = 0.7509 \tBbox: [ 1 \t 812 \t 203 \t 1078 ]\n",
      "8 \tObject: person \tConfidence = 0.7015 \tBbox: [ 352 \t 154 \t 419 \t 270 ]\n",
      "9 \tObject: person \tConfidence = 0.6852 \tBbox: [ 386 \t 230 \t 489 \t 502 ]\n",
      "10 \tObject: person \tConfidence = 0.6831 \tBbox: [ 452 \t 0 \t 508 \t 162 ]\n",
      "11 \tObject: person \tConfidence = 0.5788 \tBbox: [ 552 \t 0 \t 581 \t 55 ]\n",
      "12 \tObject: person \tConfidence = 0.4965 \tBbox: [ 560 \t 54 \t 627 \t 266 ]\n",
      "13 \tObject: person \tConfidence = 0.3238 \tBbox: [ 433 \t 0 \t 468 \t 118 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000533 / 1050\n",
      "Frames to be processed: 517  | To do: 49.24 % | Done: 50.76 %\n",
      "\n",
      "2022-04-20 13:14:40.119743\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000533.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 25.7ms pre-process, 174.7ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.899 \tBbox: [ 555 \t 376 \t 765 \t 820 ]\n",
      "2 \tObject: train \tConfidence = 0.8452 \tBbox: [ 0 \t 1 \t 395 \t 845 ]\n",
      "3 \tObject: person \tConfidence = 0.8424 \tBbox: [ 363 \t 394 \t 529 \t 852 ]\n",
      "4 \tObject: person \tConfidence = 0.8103 \tBbox: [ 313 \t 200 \t 411 \t 475 ]\n",
      "5 \tObject: person \tConfidence = 0.7728 \tBbox: [ 387 \t 0 \t 447 \t 160 ]\n",
      "6 \tObject: person \tConfidence = 0.7351 \tBbox: [ 1 \t 812 \t 198 \t 1078 ]\n",
      "7 \tObject: person \tConfidence = 0.7049 \tBbox: [ 353 \t 154 \t 419 \t 270 ]\n",
      "8 \tObject: person \tConfidence = 0.6902 \tBbox: [ 168 \t 471 \t 310 \t 860 ]\n",
      "9 \tObject: person \tConfidence = 0.6737 \tBbox: [ 385 \t 229 \t 500 \t 506 ]\n",
      "10 \tObject: person \tConfidence = 0.6255 \tBbox: [ 451 \t 0 \t 509 \t 162 ]\n",
      "11 \tObject: person \tConfidence = 0.5026 \tBbox: [ 550 \t 0 \t 581 \t 56 ]\n",
      "12 \tObject: person \tConfidence = 0.4236 \tBbox: [ 560 \t 53 \t 626 \t 220 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000534 / 1050\n",
      "Frames to be processed: 516  | To do: 49.14 % | Done: 50.86 %\n",
      "\n",
      "2022-04-20 13:14:40.617322\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000534.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 59.3ms pre-process, 171.0ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8872 \tBbox: [ 556 \t 386 \t 765 \t 845 ]\n",
      "2 \tObject: person \tConfidence = 0.8515 \tBbox: [ 359 \t 398 \t 525 \t 852 ]\n",
      "3 \tObject: train \tConfidence = 0.8507 \tBbox: [ 0 \t 1 \t 397 \t 844 ]\n",
      "4 \tObject: person \tConfidence = 0.8217 \tBbox: [ 313 \t 200 \t 411 \t 474 ]\n",
      "5 \tObject: person \tConfidence = 0.7939 \tBbox: [ 387 \t 0 \t 447 \t 159 ]\n",
      "6 \tObject: person \tConfidence = 0.7705 \tBbox: [ 167 \t 470 \t 311 \t 859 ]\n",
      "7 \tObject: person \tConfidence = 0.7464 \tBbox: [ 0 \t 809 \t 224 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.7038 \tBbox: [ 352 \t 154 \t 419 \t 269 ]\n",
      "9 \tObject: person \tConfidence = 0.6797 \tBbox: [ 385 \t 229 \t 491 \t 504 ]\n",
      "10 \tObject: person \tConfidence = 0.65 \tBbox: [ 452 \t 0 \t 509 \t 162 ]\n",
      "11 \tObject: person \tConfidence = 0.611 \tBbox: [ 549 \t 0 \t 583 \t 57 ]\n",
      "12 \tObject: person \tConfidence = 0.4593 \tBbox: [ 562 \t 54 \t 626 \t 252 ]\n",
      "13 \tObject: person \tConfidence = 0.3215 \tBbox: [ 434 \t 1 \t 470 \t 118 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000535 / 1050\n",
      "Frames to be processed: 515  | To do: 49.05 % | Done: 50.95 %\n",
      "\n",
      "2022-04-20 13:14:41.166222\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000535.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 45.2ms pre-process, 175.4ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9064 \tBbox: [ 553 \t 396 \t 766 \t 848 ]\n",
      "2 \tObject: person \tConfidence = 0.8474 \tBbox: [ 358 \t 401 \t 525 \t 851 ]\n",
      "3 \tObject: person \tConfidence = 0.8194 \tBbox: [ 168 \t 471 \t 310 \t 861 ]\n",
      "4 \tObject: person \tConfidence = 0.8106 \tBbox: [ 313 \t 200 \t 411 \t 474 ]\n",
      "5 \tObject: train \tConfidence = 0.7989 \tBbox: [ 0 \t 1 \t 397 \t 843 ]\n",
      "6 \tObject: person \tConfidence = 0.7733 \tBbox: [ 0 \t 811 \t 240 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.7689 \tBbox: [ 387 \t 0 \t 447 \t 159 ]\n",
      "8 \tObject: person \tConfidence = 0.7066 \tBbox: [ 353 \t 154 \t 419 \t 270 ]\n",
      "9 \tObject: person \tConfidence = 0.6278 \tBbox: [ 387 \t 229 \t 490 \t 504 ]\n",
      "10 \tObject: person \tConfidence = 0.6153 \tBbox: [ 548 \t 0 \t 583 \t 58 ]\n",
      "11 \tObject: person \tConfidence = 0.5978 \tBbox: [ 453 \t 0 \t 510 \t 161 ]\n",
      "12 \tObject: person \tConfidence = 0.5256 \tBbox: [ 562 \t 53 \t 627 \t 190 ]\n",
      "13 \tObject: person \tConfidence = 0.4786 \tBbox: [ 0 \t 530 \t 104 \t 832 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000536 / 1050\n",
      "Frames to be processed: 514  | To do: 48.95 % | Done: 51.05 %\n",
      "\n",
      "2022-04-20 13:14:41.677797\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000536.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 88.8ms pre-process, 180.5ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.885 \tBbox: [ 552 \t 418 \t 766 \t 889 ]\n",
      "2 \tObject: person \tConfidence = 0.8471 \tBbox: [ 164 \t 469 \t 310 \t 863 ]\n",
      "3 \tObject: train \tConfidence = 0.8214 \tBbox: [ 1 \t 2 \t 398 \t 840 ]\n",
      "4 \tObject: person \tConfidence = 0.8054 \tBbox: [ 312 \t 200 \t 411 \t 474 ]\n",
      "5 \tObject: person \tConfidence = 0.8022 \tBbox: [ 379 \t 403 \t 529 \t 852 ]\n",
      "6 \tObject: person \tConfidence = 0.7974 \tBbox: [ 387 \t 0 \t 446 \t 158 ]\n",
      "7 \tObject: person \tConfidence = 0.7647 \tBbox: [ 0 \t 815 \t 237 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.7544 \tBbox: [ 0 \t 537 \t 129 \t 846 ]\n",
      "9 \tObject: person \tConfidence = 0.6946 \tBbox: [ 449 \t 0 \t 510 \t 160 ]\n",
      "10 \tObject: person \tConfidence = 0.683 \tBbox: [ 351 \t 154 \t 419 \t 269 ]\n",
      "11 \tObject: person \tConfidence = 0.6453 \tBbox: [ 560 \t 53 \t 624 \t 190 ]\n",
      "12 \tObject: person \tConfidence = 0.615 \tBbox: [ 546 \t 0 \t 592 \t 59 ]\n",
      "13 \tObject: person \tConfidence = 0.5858 \tBbox: [ 386 \t 229 \t 491 \t 502 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000537 / 1050\n",
      "Frames to be processed: 513  | To do: 48.86 % | Done: 51.14 %\n",
      "\n",
      "2022-04-20 13:14:42.187611\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000537.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 36.0ms pre-process, 181.9ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9169 \tBbox: [ 550 \t 427 \t 765 \t 899 ]\n",
      "2 \tObject: person \tConfidence = 0.8556 \tBbox: [ 163 \t 469 \t 310 \t 860 ]\n",
      "3 \tObject: train \tConfidence = 0.8121 \tBbox: [ 0 \t 1 \t 402 \t 837 ]\n",
      "4 \tObject: person \tConfidence = 0.7998 \tBbox: [ 381 \t 405 \t 529 \t 852 ]\n",
      "5 \tObject: person \tConfidence = 0.7974 \tBbox: [ 313 \t 200 \t 411 \t 474 ]\n",
      "6 \tObject: person \tConfidence = 0.7916 \tBbox: [ 0 \t 541 \t 151 \t 860 ]\n",
      "7 \tObject: person \tConfidence = 0.782 \tBbox: [ 387 \t 0 \t 446 \t 158 ]\n",
      "8 \tObject: person \tConfidence = 0.7661 \tBbox: [ 0 \t 818 \t 227 \t 1079 ]\n",
      "9 \tObject: person \tConfidence = 0.6876 \tBbox: [ 352 \t 153 \t 418 \t 269 ]\n",
      "10 \tObject: person \tConfidence = 0.6681 \tBbox: [ 447 \t 0 \t 510 \t 161 ]\n",
      "11 \tObject: person \tConfidence = 0.6557 \tBbox: [ 560 \t 54 \t 624 \t 191 ]\n",
      "12 \tObject: person \tConfidence = 0.6479 \tBbox: [ 545 \t 0 \t 581 \t 59 ]\n",
      "13 \tObject: person \tConfidence = 0.5467 \tBbox: [ 386 \t 228 \t 490 \t 503 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000538 / 1050\n",
      "Frames to be processed: 512  | To do: 48.76 % | Done: 51.24 %\n",
      "\n",
      "2022-04-20 13:14:42.703222\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000538.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 26.3ms pre-process, 182.7ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9158 \tBbox: [ 549 \t 433 \t 765 \t 905 ]\n",
      "2 \tObject: person \tConfidence = 0.8102 \tBbox: [ 311 \t 199 \t 410 \t 473 ]\n",
      "3 \tObject: person \tConfidence = 0.7964 \tBbox: [ 165 \t 468 \t 307 \t 859 ]\n",
      "4 \tObject: person \tConfidence = 0.7914 \tBbox: [ 385 \t 405 \t 529 \t 854 ]\n",
      "5 \tObject: train \tConfidence = 0.7825 \tBbox: [ 0 \t 0 \t 399 \t 823 ]\n",
      "6 \tObject: person \tConfidence = 0.7645 \tBbox: [ 0 \t 815 \t 223 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.7643 \tBbox: [ 0 \t 546 \t 171 \t 860 ]\n",
      "8 \tObject: person \tConfidence = 0.7634 \tBbox: [ 387 \t 0 \t 445 \t 158 ]\n",
      "9 \tObject: person \tConfidence = 0.709 \tBbox: [ 353 \t 153 \t 418 \t 269 ]\n",
      "10 \tObject: person \tConfidence = 0.6842 \tBbox: [ 449 \t 0 \t 510 \t 161 ]\n",
      "11 \tObject: person \tConfidence = 0.5912 \tBbox: [ 559 \t 53 \t 622 \t 192 ]\n",
      "12 \tObject: person \tConfidence = 0.5831 \tBbox: [ 544 \t 0 \t 580 \t 62 ]\n",
      "13 \tObject: person \tConfidence = 0.5824 \tBbox: [ 386 \t 229 \t 488 \t 506 ]\n",
      "14 \tObject: person \tConfidence = 0.3722 \tBbox: [ 359 \t 538 \t 502 \t 741 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000539 / 1050\n",
      "Frames to be processed: 511  | To do: 48.67 % | Done: 51.33 %\n",
      "\n",
      "2022-04-20 13:14:43.224371\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000539.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 40.4ms pre-process, 180.0ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8944 \tBbox: [ 550 \t 441 \t 763 \t 905 ]\n",
      "2 \tObject: person \tConfidence = 0.8326 \tBbox: [ 161 \t 467 \t 307 \t 860 ]\n",
      "3 \tObject: person \tConfidence = 0.7849 \tBbox: [ 389 \t 406 \t 530 \t 854 ]\n",
      "4 \tObject: train \tConfidence = 0.7824 \tBbox: [ 0 \t 0 \t 397 \t 817 ]\n",
      "5 \tObject: person \tConfidence = 0.7776 \tBbox: [ 309 \t 197 \t 411 \t 475 ]\n",
      "6 \tObject: person \tConfidence = 0.7659 \tBbox: [ 0 \t 815 \t 235 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.7284 \tBbox: [ 387 \t 0 \t 443 \t 159 ]\n",
      "8 \tObject: person \tConfidence = 0.6796 \tBbox: [ 353 \t 153 \t 418 \t 269 ]\n",
      "9 \tObject: person \tConfidence = 0.6122 \tBbox: [ 449 \t 0 \t 510 \t 161 ]\n",
      "10 \tObject: person \tConfidence = 0.5634 \tBbox: [ 0 \t 548 \t 182 \t 860 ]\n",
      "11 \tObject: person \tConfidence = 0.5354 \tBbox: [ 542 \t 0 \t 581 \t 63 ]\n",
      "12 \tObject: person \tConfidence = 0.5042 \tBbox: [ 387 \t 230 \t 503 \t 497 ]\n",
      "13 \tObject: person \tConfidence = 0.3904 \tBbox: [ 558 \t 53 \t 622 \t 192 ]\n",
      "14 \tObject: person \tConfidence = 0.356 \tBbox: [ 360 \t 554 \t 502 \t 734 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000540 / 1050\n",
      "Frames to be processed: 510  | To do: 48.57 % | Done: 51.43 %\n",
      "\n",
      "2022-04-20 13:14:43.707281\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000540.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 27.0ms pre-process, 180.0ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9053 \tBbox: [ 552 \t 446 \t 763 \t 905 ]\n",
      "2 \tObject: person \tConfidence = 0.8727 \tBbox: [ 158 \t 466 \t 306 \t 861 ]\n",
      "3 \tObject: person \tConfidence = 0.8061 \tBbox: [ 0 \t 554 \t 195 \t 854 ]\n",
      "4 \tObject: train \tConfidence = 0.7984 \tBbox: [ 0 \t 1 \t 395 \t 827 ]\n",
      "5 \tObject: person \tConfidence = 0.7865 \tBbox: [ 311 \t 199 \t 411 \t 473 ]\n",
      "6 \tObject: person \tConfidence = 0.7825 \tBbox: [ 394 \t 405 \t 531 \t 853 ]\n",
      "7 \tObject: person \tConfidence = 0.7545 \tBbox: [ 0 \t 816 \t 220 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.7325 \tBbox: [ 388 \t 0 \t 443 \t 158 ]\n",
      "9 \tObject: person \tConfidence = 0.6889 \tBbox: [ 353 \t 153 \t 417 \t 270 ]\n",
      "10 \tObject: person \tConfidence = 0.6375 \tBbox: [ 451 \t 0 \t 510 \t 161 ]\n",
      "11 \tObject: person \tConfidence = 0.5596 \tBbox: [ 387 \t 229 \t 502 \t 522 ]\n",
      "12 \tObject: person \tConfidence = 0.5203 \tBbox: [ 542 \t 0 \t 585 \t 63 ]\n",
      "13 \tObject: person \tConfidence = 0.489 \tBbox: [ 557 \t 52 \t 621 \t 192 ]\n",
      "14 \tObject: person \tConfidence = 0.3455 \tBbox: [ 290 \t 93 \t 333 \t 304 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000541 / 1050\n",
      "Frames to be processed: 509  | To do: 48.48 % | Done: 51.52 %\n",
      "\n",
      "2022-04-20 13:14:44.318325\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000541.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 35.9ms pre-process, 181.3ms inference, 10.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9009 \tBbox: [ 551 \t 459 \t 761 \t 906 ]\n",
      "2 \tObject: person \tConfidence = 0.7768 \tBbox: [ 313 \t 200 \t 411 \t 474 ]\n",
      "3 \tObject: person \tConfidence = 0.7768 \tBbox: [ 129 \t 464 \t 289 \t 845 ]\n",
      "4 \tObject: train \tConfidence = 0.772 \tBbox: [ 0 \t 2 \t 393 \t 670 ]\n",
      "5 \tObject: person \tConfidence = 0.77 \tBbox: [ 397 \t 407 \t 531 \t 851 ]\n",
      "6 \tObject: person \tConfidence = 0.7691 \tBbox: [ 1 \t 816 \t 217 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.7475 \tBbox: [ 388 \t 0 \t 444 \t 157 ]\n",
      "8 \tObject: person \tConfidence = 0.7286 \tBbox: [ 0 \t 563 \t 235 \t 854 ]\n",
      "9 \tObject: person \tConfidence = 0.6689 \tBbox: [ 353 \t 153 \t 417 \t 272 ]\n",
      "10 \tObject: person \tConfidence = 0.6291 \tBbox: [ 454 \t 0 \t 511 \t 159 ]\n",
      "11 \tObject: person \tConfidence = 0.5884 \tBbox: [ 289 \t 93 \t 341 \t 256 ]\n",
      "12 \tObject: person \tConfidence = 0.5822 \tBbox: [ 540 \t 0 \t 594 \t 64 ]\n",
      "13 \tObject: person \tConfidence = 0.5259 \tBbox: [ 385 \t 223 \t 504 \t 546 ]\n",
      "14 \tObject: person \tConfidence = 0.4577 \tBbox: [ 555 \t 52 \t 618 \t 205 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000542 / 1050\n",
      "Frames to be processed: 508  | To do: 48.38 % | Done: 51.62 %\n",
      "\n",
      "2022-04-20 13:14:44.838450\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000542.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 28.5ms pre-process, 172.6ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9017 \tBbox: [ 550 \t 467 \t 760 \t 905 ]\n",
      "2 \tObject: train \tConfidence = 0.823 \tBbox: [ 0 \t 1 \t 393 \t 661 ]\n",
      "3 \tObject: person \tConfidence = 0.8104 \tBbox: [ 387 \t 0 \t 444 \t 158 ]\n",
      "4 \tObject: person \tConfidence = 0.7923 \tBbox: [ 0 \t 818 \t 189 \t 1079 ]\n",
      "5 \tObject: person \tConfidence = 0.7913 \tBbox: [ 1 \t 568 \t 238 \t 854 ]\n",
      "6 \tObject: person \tConfidence = 0.7864 \tBbox: [ 315 \t 200 \t 411 \t 474 ]\n",
      "7 \tObject: person \tConfidence = 0.7676 \tBbox: [ 150 \t 461 \t 295 \t 858 ]\n",
      "8 \tObject: person \tConfidence = 0.7544 \tBbox: [ 397 \t 408 \t 530 \t 851 ]\n",
      "9 \tObject: person \tConfidence = 0.7138 \tBbox: [ 453 \t 0 \t 510 \t 157 ]\n",
      "10 \tObject: person \tConfidence = 0.6842 \tBbox: [ 351 \t 152 \t 417 \t 270 ]\n",
      "11 \tObject: person \tConfidence = 0.6739 \tBbox: [ 554 \t 51 \t 616 \t 221 ]\n",
      "12 \tObject: person \tConfidence = 0.6031 \tBbox: [ 539 \t 0 \t 593 \t 64 ]\n",
      "13 \tObject: person \tConfidence = 0.5848 \tBbox: [ 289 \t 95 \t 343 \t 282 ]\n",
      "14 \tObject: person \tConfidence = 0.5477 \tBbox: [ 385 \t 223 \t 506 \t 547 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000543 / 1050\n",
      "Frames to be processed: 507  | To do: 48.29 % | Done: 51.71 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:14:45.317079\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000543.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 25.9ms pre-process, 167.9ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.87 \tBbox: [ 552 \t 473 \t 762 \t 908 ]\n",
      "2 \tObject: train \tConfidence = 0.832 \tBbox: [ 0 \t 1 \t 393 \t 662 ]\n",
      "3 \tObject: person \tConfidence = 0.7963 \tBbox: [ 387 \t 0 \t 443 \t 159 ]\n",
      "4 \tObject: person \tConfidence = 0.7717 \tBbox: [ 314 \t 199 \t 411 \t 473 ]\n",
      "5 \tObject: person \tConfidence = 0.7716 \tBbox: [ 152 \t 461 \t 288 \t 859 ]\n",
      "6 \tObject: person \tConfidence = 0.7676 \tBbox: [ 1 \t 568 \t 252 \t 883 ]\n",
      "7 \tObject: person \tConfidence = 0.7649 \tBbox: [ 396 \t 408 \t 530 \t 851 ]\n",
      "8 \tObject: person \tConfidence = 0.7508 \tBbox: [ 1 \t 818 \t 202 \t 1079 ]\n",
      "9 \tObject: person \tConfidence = 0.7067 \tBbox: [ 552 \t 51 \t 610 \t 228 ]\n",
      "10 \tObject: person \tConfidence = 0.702 \tBbox: [ 453 \t 0 \t 511 \t 155 ]\n",
      "11 \tObject: person \tConfidence = 0.6638 \tBbox: [ 350 \t 152 \t 417 \t 270 ]\n",
      "12 \tObject: person \tConfidence = 0.6471 \tBbox: [ 539 \t 0 \t 591 \t 63 ]\n",
      "13 \tObject: person \tConfidence = 0.5133 \tBbox: [ 287 \t 95 \t 344 \t 295 ]\n",
      "14 \tObject: person \tConfidence = 0.4995 \tBbox: [ 385 \t 226 \t 499 \t 551 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000544 / 1050\n",
      "Frames to be processed: 506  | To do: 48.19 % | Done: 51.81 %\n",
      "\n",
      "2022-04-20 13:14:45.753897\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000544.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 26.9ms pre-process, 172.2ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8426 \tBbox: [ 548 \t 482 \t 761 \t 938 ]\n",
      "2 \tObject: train \tConfidence = 0.8311 \tBbox: [ 0 \t 2 \t 398 \t 690 ]\n",
      "3 \tObject: person \tConfidence = 0.7916 \tBbox: [ 387 \t 0 \t 443 \t 158 ]\n",
      "4 \tObject: person \tConfidence = 0.7697 \tBbox: [ 314 \t 200 \t 411 \t 472 ]\n",
      "5 \tObject: person \tConfidence = 0.7616 \tBbox: [ 2 \t 567 \t 253 \t 898 ]\n",
      "6 \tObject: person \tConfidence = 0.7511 \tBbox: [ 0 \t 817 \t 192 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.7467 \tBbox: [ 396 \t 410 \t 529 \t 848 ]\n",
      "8 \tObject: person \tConfidence = 0.7356 \tBbox: [ 550 \t 50 \t 608 \t 242 ]\n",
      "9 \tObject: person \tConfidence = 0.7199 \tBbox: [ 350 \t 152 \t 417 \t 268 ]\n",
      "10 \tObject: person \tConfidence = 0.7122 \tBbox: [ 453 \t 0 \t 511 \t 154 ]\n",
      "11 \tObject: person \tConfidence = 0.6909 \tBbox: [ 537 \t 0 \t 591 \t 62 ]\n",
      "12 \tObject: person \tConfidence = 0.6628 \tBbox: [ 151 \t 460 \t 281 \t 801 ]\n",
      "13 \tObject: person \tConfidence = 0.6098 \tBbox: [ 272 \t 95 \t 349 \t 317 ]\n",
      "14 \tObject: person \tConfidence = 0.5159 \tBbox: [ 386 \t 226 \t 493 \t 546 ]\n",
      "15 \tObject: person \tConfidence = 0.3135 \tBbox: [ 361 \t 535 \t 504 \t 756 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000545 / 1050\n",
      "Frames to be processed: 505  | To do: 48.1 % | Done: 51.9 %\n",
      "\n",
      "2022-04-20 13:14:46.205838\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000545.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 26.2ms pre-process, 175.0ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8494 \tBbox: [ 546 \t 494 \t 763 \t 970 ]\n",
      "2 \tObject: train \tConfidence = 0.8452 \tBbox: [ 0 \t 2 \t 403 \t 705 ]\n",
      "3 \tObject: person \tConfidence = 0.8113 \tBbox: [ 3 \t 565 \t 251 \t 917 ]\n",
      "4 \tObject: person \tConfidence = 0.7874 \tBbox: [ 314 \t 199 \t 411 \t 473 ]\n",
      "5 \tObject: person \tConfidence = 0.7625 \tBbox: [ 395 \t 411 \t 530 \t 848 ]\n",
      "6 \tObject: person \tConfidence = 0.7576 \tBbox: [ 1 \t 816 \t 200 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.755 \tBbox: [ 387 \t 0 \t 445 \t 160 ]\n",
      "8 \tObject: person \tConfidence = 0.7451 \tBbox: [ 548 \t 50 \t 610 \t 253 ]\n",
      "9 \tObject: person \tConfidence = 0.7402 \tBbox: [ 353 \t 152 \t 417 \t 268 ]\n",
      "10 \tObject: person \tConfidence = 0.6915 \tBbox: [ 276 \t 95 \t 354 \t 316 ]\n",
      "11 \tObject: person \tConfidence = 0.6869 \tBbox: [ 537 \t 0 \t 589 \t 63 ]\n",
      "12 \tObject: person \tConfidence = 0.6806 \tBbox: [ 452 \t 0 \t 511 \t 159 ]\n",
      "13 \tObject: person \tConfidence = 0.6416 \tBbox: [ 151 \t 459 \t 279 \t 769 ]\n",
      "14 \tObject: person \tConfidence = 0.5221 \tBbox: [ 386 \t 228 \t 499 \t 536 ]\n",
      "15 \tObject: person \tConfidence = 0.3105 \tBbox: [ 360 \t 548 \t 502 \t 747 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000546 / 1050\n",
      "Frames to be processed: 504  | To do: 48.0 % | Done: 52.0 %\n",
      "\n",
      "2022-04-20 13:14:46.687087\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000546.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 52.5ms pre-process, 172.9ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8941 \tBbox: [ 544 \t 509 \t 762 \t 1035 ]\n",
      "2 \tObject: train \tConfidence = 0.8313 \tBbox: [ 0 \t 2 \t 399 \t 711 ]\n",
      "3 \tObject: person \tConfidence = 0.8141 \tBbox: [ 315 \t 199 \t 411 \t 474 ]\n",
      "4 \tObject: person \tConfidence = 0.8103 \tBbox: [ 148 \t 458 \t 275 \t 756 ]\n",
      "5 \tObject: person \tConfidence = 0.7803 \tBbox: [ 399 \t 411 \t 530 \t 846 ]\n",
      "6 \tObject: person \tConfidence = 0.7794 \tBbox: [ 387 \t 0 \t 444 \t 160 ]\n",
      "7 \tObject: person \tConfidence = 0.7699 \tBbox: [ 9 \t 566 \t 251 \t 919 ]\n",
      "8 \tObject: person \tConfidence = 0.7645 \tBbox: [ 545 \t 50 \t 609 \t 255 ]\n",
      "9 \tObject: person \tConfidence = 0.7522 \tBbox: [ 0 \t 817 \t 226 \t 1079 ]\n",
      "10 \tObject: person \tConfidence = 0.7482 \tBbox: [ 274 \t 97 \t 358 \t 326 ]\n",
      "11 \tObject: person \tConfidence = 0.7209 \tBbox: [ 452 \t 0 \t 511 \t 159 ]\n",
      "12 \tObject: person \tConfidence = 0.7022 \tBbox: [ 354 \t 153 \t 417 \t 268 ]\n",
      "13 \tObject: person \tConfidence = 0.6778 \tBbox: [ 386 \t 228 \t 497 \t 542 ]\n",
      "14 \tObject: person \tConfidence = 0.6416 \tBbox: [ 537 \t 0 \t 589 \t 63 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000547 / 1050\n",
      "Frames to be processed: 503  | To do: 47.9 % | Done: 52.1 %\n",
      "\n",
      "2022-04-20 13:14:47.160076\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000547.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 24.3ms pre-process, 172.6ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8563 \tBbox: [ 547 \t 537 \t 762 \t 1076 ]\n",
      "2 \tObject: person \tConfidence = 0.8313 \tBbox: [ 312 \t 200 \t 412 \t 473 ]\n",
      "3 \tObject: person \tConfidence = 0.8297 \tBbox: [ 387 \t 0 \t 443 \t 159 ]\n",
      "4 \tObject: person \tConfidence = 0.8255 \tBbox: [ 541 \t 46 \t 611 \t 254 ]\n",
      "5 \tObject: person \tConfidence = 0.8208 \tBbox: [ 397 \t 417 \t 530 \t 846 ]\n",
      "6 \tObject: train \tConfidence = 0.8113 \tBbox: [ 0 \t 1 \t 397 \t 813 ]\n",
      "7 \tObject: person \tConfidence = 0.7739 \tBbox: [ 450 \t 0 \t 512 \t 159 ]\n",
      "8 \tObject: person \tConfidence = 0.7583 \tBbox: [ 0 \t 816 \t 227 \t 1079 ]\n",
      "9 \tObject: person \tConfidence = 0.7405 \tBbox: [ 352 \t 151 \t 417 \t 266 ]\n",
      "10 \tObject: person \tConfidence = 0.6588 \tBbox: [ 281 \t 95 \t 365 \t 342 ]\n",
      "11 \tObject: person \tConfidence = 0.5362 \tBbox: [ 383 \t 227 \t 501 \t 542 ]\n",
      "12 \tObject: person \tConfidence = 0.5131 \tBbox: [ 428 \t 0 \t 469 \t 130 ]\n",
      "13 \tObject: person \tConfidence = 0.3742 \tBbox: [ 68 \t 467 \t 291 \t 922 ]\n",
      "14 \tObject: person \tConfidence = 0.3718 \tBbox: [ 134 \t 455 \t 270 \t 745 ]\n",
      "15 \tObject: person \tConfidence = 0.3667 \tBbox: [ 541 \t 0 \t 588 \t 51 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000548 / 1050\n",
      "Frames to be processed: 502  | To do: 47.81 % | Done: 52.19 %\n",
      "\n",
      "2022-04-20 13:14:47.617457\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000548.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 31.2ms pre-process, 176.0ms inference, 3.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8778 \tBbox: [ 548 \t 553 \t 759 \t 1080 ]\n",
      "2 \tObject: person \tConfidence = 0.8336 \tBbox: [ 538 \t 46 \t 609 \t 254 ]\n",
      "3 \tObject: person \tConfidence = 0.8318 \tBbox: [ 314 \t 199 \t 413 \t 472 ]\n",
      "4 \tObject: person \tConfidence = 0.8315 \tBbox: [ 397 \t 418 \t 530 \t 845 ]\n",
      "5 \tObject: train \tConfidence = 0.8266 \tBbox: [ 0 \t 0 \t 404 \t 817 ]\n",
      "6 \tObject: person \tConfidence = 0.8028 \tBbox: [ 452 \t 0 \t 511 \t 159 ]\n",
      "7 \tObject: person \tConfidence = 0.7863 \tBbox: [ 0 \t 816 \t 246 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.7625 \tBbox: [ 353 \t 152 \t 417 \t 265 ]\n",
      "9 \tObject: person \tConfidence = 0.7529 \tBbox: [ 387 \t 0 \t 457 \t 158 ]\n",
      "10 \tObject: person \tConfidence = 0.7075 \tBbox: [ 289 \t 95 \t 366 \t 311 ]\n",
      "11 \tObject: person \tConfidence = 0.564 \tBbox: [ 381 \t 226 \t 504 \t 541 ]\n",
      "12 \tObject: person \tConfidence = 0.5192 \tBbox: [ 538 \t 0 \t 587 \t 56 ]\n",
      "13 \tObject: person \tConfidence = 0.507 \tBbox: [ 130 \t 456 \t 270 \t 732 ]\n",
      "14 \tObject: person \tConfidence = 0.4834 \tBbox: [ 87 \t 555 \t 309 \t 920 ]\n",
      "15 \tObject: person \tConfidence = 0.4632 \tBbox: [ 425 \t 0 \t 468 \t 132 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000549 / 1050\n",
      "Frames to be processed: 501  | To do: 47.71 % | Done: 52.29 %\n",
      "\n",
      "2022-04-20 13:14:48.131468\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000549.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 53.8ms pre-process, 175.8ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8935 \tBbox: [ 547 \t 569 \t 755 \t 1080 ]\n",
      "2 \tObject: person \tConfidence = 0.8279 \tBbox: [ 535 \t 45 \t 608 \t 251 ]\n",
      "3 \tObject: person \tConfidence = 0.8176 \tBbox: [ 397 \t 418 \t 530 \t 844 ]\n",
      "4 \tObject: train \tConfidence = 0.8024 \tBbox: [ 1 \t 3 \t 406 \t 819 ]\n",
      "5 \tObject: person \tConfidence = 0.795 \tBbox: [ 315 \t 200 \t 413 \t 472 ]\n",
      "6 \tObject: person \tConfidence = 0.7863 \tBbox: [ 0 \t 814 \t 247 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.785 \tBbox: [ 453 \t 0 \t 511 \t 154 ]\n",
      "8 \tObject: person \tConfidence = 0.7795 \tBbox: [ 132 \t 456 \t 268 \t 729 ]\n",
      "9 \tObject: person \tConfidence = 0.7338 \tBbox: [ 354 \t 152 \t 417 \t 263 ]\n",
      "10 \tObject: person \tConfidence = 0.7096 \tBbox: [ 387 \t 0 \t 453 \t 157 ]\n",
      "11 \tObject: person \tConfidence = 0.6943 \tBbox: [ 292 \t 96 \t 374 \t 291 ]\n",
      "12 \tObject: person \tConfidence = 0.6253 \tBbox: [ 74 \t 558 \t 322 \t 997 ]\n",
      "13 \tObject: person \tConfidence = 0.5142 \tBbox: [ 536 \t 0 \t 586 \t 57 ]\n",
      "14 \tObject: person \tConfidence = 0.4985 \tBbox: [ 380 \t 226 \t 505 \t 544 ]\n",
      "15 \tObject: person \tConfidence = 0.3747 \tBbox: [ 426 \t 0 \t 467 \t 130 ]\n",
      "16 \tObject: person \tConfidence = 0.3289 \tBbox: [ 355 \t 577 \t 504 \t 732 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000550 / 1050\n",
      "Frames to be processed: 500  | To do: 47.62 % | Done: 52.38 %\n",
      "\n",
      "2022-04-20 13:14:48.684107\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000550.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 92.0ms pre-process, 181.0ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9104 \tBbox: [ 546 \t 582 \t 760 \t 1080 ]\n",
      "2 \tObject: train \tConfidence = 0.8513 \tBbox: [ 1 \t 2 \t 407 \t 821 ]\n",
      "3 \tObject: person \tConfidence = 0.8357 \tBbox: [ 398 \t 419 \t 529 \t 846 ]\n",
      "4 \tObject: person \tConfidence = 0.8164 \tBbox: [ 534 \t 45 \t 605 \t 252 ]\n",
      "5 \tObject: person \tConfidence = 0.8145 \tBbox: [ 1 \t 814 \t 246 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.804 \tBbox: [ 456 \t 0 \t 510 \t 154 ]\n",
      "7 \tObject: person \tConfidence = 0.7919 \tBbox: [ 316 \t 199 \t 413 \t 472 ]\n",
      "8 \tObject: person \tConfidence = 0.7838 \tBbox: [ 131 \t 454 \t 252 \t 641 ]\n",
      "9 \tObject: person \tConfidence = 0.7794 \tBbox: [ 292 \t 96 \t 377 \t 290 ]\n",
      "10 \tObject: person \tConfidence = 0.7365 \tBbox: [ 386 \t 0 \t 453 \t 158 ]\n",
      "11 \tObject: person \tConfidence = 0.7261 \tBbox: [ 100 \t 559 \t 335 \t 970 ]\n",
      "12 \tObject: person \tConfidence = 0.7239 \tBbox: [ 352 \t 151 \t 417 \t 262 ]\n",
      "13 \tObject: person \tConfidence = 0.4877 \tBbox: [ 426 \t 0 \t 465 \t 130 ]\n",
      "14 \tObject: person \tConfidence = 0.4663 \tBbox: [ 381 \t 226 \t 504 \t 543 ]\n",
      "15 \tObject: person \tConfidence = 0.4245 \tBbox: [ 539 \t 0 \t 582 \t 51 ]\n",
      "16 \tObject: person \tConfidence = 0.3039 \tBbox: [ 360 \t 573 \t 505 \t 732 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000551 / 1050\n",
      "Frames to be processed: 499  | To do: 47.52 % | Done: 52.48 %\n",
      "\n",
      "2022-04-20 13:14:49.307491\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000551.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 26.0ms pre-process, 173.0ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.911 \tBbox: [ 544 \t 595 \t 762 \t 1079 ]\n",
      "2 \tObject: train \tConfidence = 0.8498 \tBbox: [ 1 \t 1 \t 406 \t 815 ]\n",
      "3 \tObject: person \tConfidence = 0.8424 \tBbox: [ 137 \t 454 \t 249 \t 647 ]\n",
      "4 \tObject: person \tConfidence = 0.8363 \tBbox: [ 398 \t 419 \t 530 \t 846 ]\n",
      "5 \tObject: person \tConfidence = 0.813 \tBbox: [ 1 \t 814 \t 248 \t 1080 ]\n",
      "6 \tObject: person \tConfidence = 0.7969 \tBbox: [ 532 \t 44 \t 604 \t 254 ]\n",
      "7 \tObject: person \tConfidence = 0.7946 \tBbox: [ 318 \t 197 \t 414 \t 472 ]\n",
      "8 \tObject: person \tConfidence = 0.7647 \tBbox: [ 385 \t 2 \t 447 \t 157 ]\n",
      "9 \tObject: person \tConfidence = 0.7647 \tBbox: [ 109 \t 560 \t 374 \t 1011 ]\n",
      "10 \tObject: person \tConfidence = 0.7603 \tBbox: [ 353 \t 151 \t 417 \t 258 ]\n",
      "11 \tObject: person \tConfidence = 0.7562 \tBbox: [ 456 \t 0 \t 509 \t 159 ]\n",
      "12 \tObject: person \tConfidence = 0.7505 \tBbox: [ 292 \t 95 \t 385 \t 285 ]\n",
      "13 \tObject: person \tConfidence = 0.5584 \tBbox: [ 426 \t 0 \t 466 \t 128 ]\n",
      "14 \tObject: person \tConfidence = 0.4024 \tBbox: [ 382 \t 222 \t 506 \t 536 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000552 / 1050\n",
      "Frames to be processed: 498  | To do: 47.43 % | Done: 52.57 %\n",
      "\n",
      "2022-04-20 13:14:49.782207\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000552.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 36.2ms pre-process, 179.9ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9035 \tBbox: [ 541 \t 616 \t 764 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8628 \tBbox: [ 132 \t 454 \t 250 \t 669 ]\n",
      "3 \tObject: train \tConfidence = 0.8531 \tBbox: [ 0 \t 3 \t 402 \t 811 ]\n",
      "4 \tObject: person \tConfidence = 0.7982 \tBbox: [ 318 \t 196 \t 414 \t 471 ]\n",
      "5 \tObject: person \tConfidence = 0.7863 \tBbox: [ 119 \t 567 \t 435 \t 1021 ]\n",
      "6 \tObject: person \tConfidence = 0.7825 \tBbox: [ 397 \t 417 \t 529 \t 846 ]\n",
      "7 \tObject: person \tConfidence = 0.768 \tBbox: [ 528 \t 43 \t 600 \t 247 ]\n",
      "8 \tObject: person \tConfidence = 0.7593 \tBbox: [ 1 \t 816 \t 246 \t 1080 ]\n",
      "9 \tObject: person \tConfidence = 0.7443 \tBbox: [ 303 \t 95 \t 409 \t 264 ]\n",
      "10 \tObject: person \tConfidence = 0.7333 \tBbox: [ 351 \t 151 \t 417 \t 256 ]\n",
      "11 \tObject: person \tConfidence = 0.7145 \tBbox: [ 387 \t 0 \t 446 \t 155 ]\n",
      "12 \tObject: person \tConfidence = 0.5043 \tBbox: [ 455 \t 0 \t 508 \t 151 ]\n",
      "13 \tObject: person \tConfidence = 0.4209 \tBbox: [ 383 \t 225 \t 498 \t 551 ]\n",
      "14 \tObject: person \tConfidence = 0.3416 \tBbox: [ 541 \t 0 \t 584 \t 47 ]\n",
      "15 \tObject: person \tConfidence = 0.3122 \tBbox: [ 361 \t 573 \t 505 \t 736 ]\n",
      "16 \tObject: person \tConfidence = 0.3037 \tBbox: [ 345 \t 274 \t 407 \t 368 ]\n",
      "17 \tObject: person \tConfidence = 0.3001 \tBbox: [ 437 \t 0 \t 471 \t 129 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000553 / 1050\n",
      "Frames to be processed: 497  | To do: 47.33 % | Done: 52.67 %\n",
      "\n",
      "2022-04-20 13:14:50.349721\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000553.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 27.4ms pre-process, 178.0ms inference, 10.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9161 \tBbox: [ 541 \t 627 \t 765 \t 1079 ]\n",
      "2 \tObject: train \tConfidence = 0.8563 \tBbox: [ 0 \t 3 \t 406 \t 816 ]\n",
      "3 \tObject: person \tConfidence = 0.8527 \tBbox: [ 133 \t 454 \t 253 \t 675 ]\n",
      "4 \tObject: person \tConfidence = 0.8018 \tBbox: [ 128 \t 569 \t 444 \t 1026 ]\n",
      "5 \tObject: person \tConfidence = 0.7884 \tBbox: [ 317 \t 196 \t 415 \t 471 ]\n",
      "6 \tObject: person \tConfidence = 0.7595 \tBbox: [ 527 \t 43 \t 598 \t 244 ]\n",
      "7 \tObject: person \tConfidence = 0.7424 \tBbox: [ 308 \t 95 \t 413 \t 261 ]\n",
      "8 \tObject: person \tConfidence = 0.7394 \tBbox: [ 398 \t 418 \t 530 \t 849 ]\n",
      "9 \tObject: person \tConfidence = 0.7344 \tBbox: [ 0 \t 816 \t 242 \t 1079 ]\n",
      "10 \tObject: person \tConfidence = 0.7009 \tBbox: [ 347 \t 149 \t 417 \t 257 ]\n",
      "11 \tObject: person \tConfidence = 0.6769 \tBbox: [ 388 \t 1 \t 446 \t 155 ]\n",
      "12 \tObject: person \tConfidence = 0.6098 \tBbox: [ 446 \t 0 \t 509 \t 158 ]\n",
      "13 \tObject: person \tConfidence = 0.4047 \tBbox: [ 384 \t 221 \t 504 \t 521 ]\n",
      "14 \tObject: person \tConfidence = 0.3376 \tBbox: [ 534 \t 0 \t 586 \t 62 ]\n",
      "15 \tObject: person \tConfidence = 0.3138 \tBbox: [ 345 \t 273 \t 407 \t 368 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000554 / 1050\n",
      "Frames to be processed: 496  | To do: 47.24 % | Done: 52.76 %\n",
      "\n",
      "2022-04-20 13:14:50.880018\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000554.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 34.7ms pre-process, 180.0ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9031 \tBbox: [ 537 \t 637 \t 765 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8791 \tBbox: [ 134 \t 453 \t 254 \t 715 ]\n",
      "3 \tObject: train \tConfidence = 0.8345 \tBbox: [ 1 \t 3 \t 407 \t 824 ]\n",
      "4 \tObject: person \tConfidence = 0.8146 \tBbox: [ 526 \t 42 \t 598 \t 241 ]\n",
      "5 \tObject: person \tConfidence = 0.8117 \tBbox: [ 318 \t 196 \t 414 \t 471 ]\n",
      "6 \tObject: person \tConfidence = 0.7837 \tBbox: [ 0 \t 816 \t 247 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.7827 \tBbox: [ 312 \t 95 \t 414 \t 261 ]\n",
      "8 \tObject: person \tConfidence = 0.7688 \tBbox: [ 155 \t 569 \t 461 \t 1014 ]\n",
      "9 \tObject: person \tConfidence = 0.7634 \tBbox: [ 388 \t 0 \t 444 \t 156 ]\n",
      "10 \tObject: person \tConfidence = 0.7145 \tBbox: [ 398 \t 419 \t 530 \t 850 ]\n",
      "11 \tObject: person \tConfidence = 0.6705 \tBbox: [ 446 \t 0 \t 507 \t 159 ]\n",
      "12 \tObject: person \tConfidence = 0.6703 \tBbox: [ 343 \t 148 \t 416 \t 257 ]\n",
      "13 \tObject: person \tConfidence = 0.4444 \tBbox: [ 385 \t 225 \t 496 \t 549 ]\n",
      "14 \tObject: person \tConfidence = 0.3127 \tBbox: [ 536 \t 0 \t 584 \t 47 ]\n",
      "15 \tObject: person \tConfidence = 0.3065 \tBbox: [ 345 \t 272 \t 409 \t 368 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000555 / 1050\n",
      "Frames to be processed: 495  | To do: 47.14 % | Done: 52.86 %\n",
      "\n",
      "2022-04-20 13:14:51.357221\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000555.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 59.0ms pre-process, 176.1ms inference, 11.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8837 \tBbox: [ 535 \t 649 \t 765 \t 1079 ]\n",
      "2 \tObject: train \tConfidence = 0.837 \tBbox: [ 0 \t 0 \t 403 \t 832 ]\n",
      "3 \tObject: person \tConfidence = 0.7937 \tBbox: [ 178 \t 568 \t 462 \t 1024 ]\n",
      "4 \tObject: person \tConfidence = 0.7788 \tBbox: [ 319 \t 194 \t 413 \t 471 ]\n",
      "5 \tObject: person \tConfidence = 0.7706 \tBbox: [ 1 \t 816 \t 246 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.7557 \tBbox: [ 525 \t 42 \t 600 \t 242 ]\n",
      "7 \tObject: person \tConfidence = 0.7482 \tBbox: [ 133 \t 451 \t 256 \t 773 ]\n",
      "8 \tObject: person \tConfidence = 0.74 \tBbox: [ 319 \t 96 \t 418 \t 252 ]\n",
      "9 \tObject: person \tConfidence = 0.6783 \tBbox: [ 389 \t 0 \t 444 \t 154 ]\n",
      "10 \tObject: person \tConfidence = 0.6711 \tBbox: [ 449 \t 0 \t 507 \t 159 ]\n",
      "11 \tObject: person \tConfidence = 0.54 \tBbox: [ 385 \t 224 \t 500 \t 546 ]\n",
      "12 \tObject: person \tConfidence = 0.4415 \tBbox: [ 400 \t 421 \t 529 \t 846 ]\n",
      "13 \tObject: person \tConfidence = 0.3191 \tBbox: [ 346 \t 269 \t 408 \t 372 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000556 / 1050\n",
      "Frames to be processed: 494  | To do: 47.05 % | Done: 52.95 %\n",
      "\n",
      "2022-04-20 13:14:51.887541\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000556.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 55.8ms pre-process, 180.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8954 \tBbox: [ 532 \t 660 \t 766 \t 1079 ]\n",
      "2 \tObject: train \tConfidence = 0.8352 \tBbox: [ 0 \t 0 \t 402 \t 818 ]\n",
      "3 \tObject: person \tConfidence = 0.8194 \tBbox: [ 197 \t 562 \t 468 \t 1024 ]\n",
      "4 \tObject: person \tConfidence = 0.8125 \tBbox: [ 319 \t 194 \t 411 \t 471 ]\n",
      "5 \tObject: person \tConfidence = 0.7984 \tBbox: [ 525 \t 40 \t 601 \t 243 ]\n",
      "6 \tObject: person \tConfidence = 0.7502 \tBbox: [ 1 \t 816 \t 244 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.7383 \tBbox: [ 325 \t 94 \t 424 \t 252 ]\n",
      "8 \tObject: person \tConfidence = 0.7345 \tBbox: [ 448 \t 0 \t 506 \t 158 ]\n",
      "9 \tObject: person \tConfidence = 0.7326 \tBbox: [ 125 \t 455 \t 259 \t 901 ]\n",
      "10 \tObject: person \tConfidence = 0.7076 \tBbox: [ 389 \t 0 \t 444 \t 155 ]\n",
      "11 \tObject: person \tConfidence = 0.5096 \tBbox: [ 386 \t 224 \t 503 \t 550 ]\n",
      "12 \tObject: person \tConfidence = 0.4013 \tBbox: [ 535 \t 0 \t 583 \t 46 ]\n",
      "13 \tObject: person \tConfidence = 0.3756 \tBbox: [ 389 \t 426 \t 530 \t 1073 ]\n",
      "14 \tObject: person \tConfidence = 0.3265 \tBbox: [ 343 \t 257 \t 410 \t 387 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000557 / 1050\n",
      "Frames to be processed: 493  | To do: 46.95 % | Done: 53.05 %\n",
      "\n",
      "2022-04-20 13:14:52.458604\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000557.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 34.1ms pre-process, 173.5ms inference, 10.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.887 \tBbox: [ 527 \t 691 \t 765 \t 1079 ]\n",
      "2 \tObject: train \tConfidence = 0.8688 \tBbox: [ 0 \t 2 \t 399 \t 809 ]\n",
      "3 \tObject: person \tConfidence = 0.8617 \tBbox: [ 111 \t 454 \t 261 \t 858 ]\n",
      "4 \tObject: person \tConfidence = 0.7759 \tBbox: [ 521 \t 40 \t 601 \t 241 ]\n",
      "5 \tObject: person \tConfidence = 0.7639 \tBbox: [ 261 \t 554 \t 469 \t 997 ]\n",
      "6 \tObject: person \tConfidence = 0.762 \tBbox: [ 335 \t 150 \t 415 \t 251 ]\n",
      "7 \tObject: person \tConfidence = 0.7547 \tBbox: [ 322 \t 194 \t 413 \t 471 ]\n",
      "8 \tObject: person \tConfidence = 0.7444 \tBbox: [ 340 \t 98 \t 436 \t 231 ]\n",
      "9 \tObject: person \tConfidence = 0.7306 \tBbox: [ 1 \t 816 \t 246 \t 1079 ]\n",
      "10 \tObject: person \tConfidence = 0.6707 \tBbox: [ 403 \t 428 \t 530 \t 847 ]\n",
      "11 \tObject: person \tConfidence = 0.5829 \tBbox: [ 443 \t 1 \t 504 \t 153 ]\n",
      "12 \tObject: person \tConfidence = 0.5774 \tBbox: [ 387 \t 226 \t 500 \t 549 ]\n",
      "13 \tObject: person \tConfidence = 0.5064 \tBbox: [ 389 \t 0 \t 442 \t 151 ]\n",
      "14 \tObject: person \tConfidence = 0.3355 \tBbox: [ 343 \t 249 \t 410 \t 397 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000558 / 1050\n",
      "Frames to be processed: 492  | To do: 46.86 % | Done: 53.14 %\n",
      "\n",
      "2022-04-20 13:14:52.927685\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000558.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 30.6ms pre-process, 170.2ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8779 \tBbox: [ 524 \t 708 \t 765 \t 1078 ]\n",
      "2 \tObject: train \tConfidence = 0.8569 \tBbox: [ 0 \t 1 \t 398 \t 819 ]\n",
      "3 \tObject: person \tConfidence = 0.8552 \tBbox: [ 112 \t 454 \t 262 \t 858 ]\n",
      "4 \tObject: person \tConfidence = 0.8195 \tBbox: [ 368 \t 100 \t 441 \t 237 ]\n",
      "5 \tObject: person \tConfidence = 0.8021 \tBbox: [ 322 \t 192 \t 411 \t 472 ]\n",
      "6 \tObject: person \tConfidence = 0.7883 \tBbox: [ 519 \t 39 \t 601 \t 240 ]\n",
      "7 \tObject: person \tConfidence = 0.7783 \tBbox: [ 1 \t 816 \t 242 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.7655 \tBbox: [ 414 \t 428 \t 531 \t 849 ]\n",
      "9 \tObject: person \tConfidence = 0.7545 \tBbox: [ 441 \t 2 \t 498 \t 151 ]\n",
      "10 \tObject: person \tConfidence = 0.7179 \tBbox: [ 278 \t 553 \t 469 \t 993 ]\n",
      "11 \tObject: person \tConfidence = 0.7109 \tBbox: [ 333 \t 150 \t 416 \t 256 ]\n",
      "12 \tObject: person \tConfidence = 0.621 \tBbox: [ 387 \t 228 \t 500 \t 547 ]\n",
      "13 \tObject: person \tConfidence = 0.561 \tBbox: [ 483 \t 0 \t 526 \t 120 ]\n",
      "14 \tObject: person \tConfidence = 0.5303 \tBbox: [ 389 \t 1 \t 443 \t 147 ]\n",
      "15 \tObject: person \tConfidence = 0.3309 \tBbox: [ 532 \t 0 \t 583 \t 51 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000559 / 1050\n",
      "Frames to be processed: 491  | To do: 46.76 % | Done: 53.24 %\n",
      "\n",
      "2022-04-20 13:14:53.438527\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000559.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 29.9ms pre-process, 169.0ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8649 \tBbox: [ 1 \t 3 \t 399 \t 809 ]\n",
      "2 \tObject: person \tConfidence = 0.8646 \tBbox: [ 522 \t 728 \t 765 \t 1079 ]\n",
      "3 \tObject: person \tConfidence = 0.846 \tBbox: [ 109 \t 453 \t 265 \t 861 ]\n",
      "4 \tObject: person \tConfidence = 0.7685 \tBbox: [ 372 \t 103 \t 447 \t 241 ]\n",
      "5 \tObject: person \tConfidence = 0.7651 \tBbox: [ 322 \t 193 \t 412 \t 471 ]\n",
      "6 \tObject: person \tConfidence = 0.7638 \tBbox: [ 518 \t 39 \t 600 \t 240 ]\n",
      "7 \tObject: person \tConfidence = 0.741 \tBbox: [ 240 \t 548 \t 479 \t 1070 ]\n",
      "8 \tObject: person \tConfidence = 0.7192 \tBbox: [ 0 \t 817 \t 225 \t 1079 ]\n",
      "9 \tObject: person \tConfidence = 0.6841 \tBbox: [ 332 \t 148 \t 416 \t 258 ]\n",
      "10 \tObject: person \tConfidence = 0.6714 \tBbox: [ 415 \t 429 \t 530 \t 847 ]\n",
      "11 \tObject: person \tConfidence = 0.6678 \tBbox: [ 442 \t 1 \t 500 \t 152 ]\n",
      "12 \tObject: person \tConfidence = 0.6552 \tBbox: [ 386 \t 224 \t 501 \t 544 ]\n",
      "13 \tObject: person \tConfidence = 0.4087 \tBbox: [ 389 \t 0 \t 444 \t 142 ]\n",
      "14 \tObject: person \tConfidence = 0.3178 \tBbox: [ 346 \t 251 \t 410 \t 391 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000560 / 1050\n",
      "Frames to be processed: 490  | To do: 46.67 % | Done: 53.33 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 28.1ms pre-process, 165.0ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:14:53.992950\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000560.jpg ------------------------------ \n",
      "\n",
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8581 \tBbox: [ 519 \t 750 \t 764 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8505 \tBbox: [ 106 \t 453 \t 265 \t 864 ]\n",
      "3 \tObject: train \tConfidence = 0.8395 \tBbox: [ 1 \t 3 \t 403 \t 808 ]\n",
      "4 \tObject: person \tConfidence = 0.786 \tBbox: [ 322 \t 193 \t 413 \t 471 ]\n",
      "5 \tObject: person \tConfidence = 0.7732 \tBbox: [ 517 \t 39 \t 597 \t 240 ]\n",
      "6 \tObject: person \tConfidence = 0.7731 \tBbox: [ 382 \t 104 \t 451 \t 242 ]\n",
      "7 \tObject: person \tConfidence = 0.7612 \tBbox: [ 0 \t 816 \t 239 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.7448 \tBbox: [ 331 \t 148 \t 415 \t 260 ]\n",
      "9 \tObject: person \tConfidence = 0.7193 \tBbox: [ 282 \t 544 \t 490 \t 1044 ]\n",
      "10 \tObject: person \tConfidence = 0.6258 \tBbox: [ 416 \t 430 \t 530 \t 837 ]\n",
      "11 \tObject: person \tConfidence = 0.6093 \tBbox: [ 386 \t 222 \t 503 \t 541 ]\n",
      "12 \tObject: person \tConfidence = 0.5756 \tBbox: [ 443 \t 0 \t 498 \t 154 ]\n",
      "13 \tObject: person \tConfidence = 0.3241 \tBbox: [ 347 \t 249 \t 411 \t 391 ]\n",
      "14 \tObject: person \tConfidence = 0.304 \tBbox: [ 390 \t 0 \t 447 \t 116 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000561 / 1050\n",
      "Frames to be processed: 489  | To do: 46.57 % | Done: 53.43 %\n",
      "\n",
      "2022-04-20 13:14:54.538215\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000561.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 26.8ms pre-process, 168.6ms inference, 10.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8418 \tBbox: [ 104 \t 453 \t 264 \t 863 ]\n",
      "2 \tObject: train \tConfidence = 0.8287 \tBbox: [ 0 \t 2 \t 400 \t 811 ]\n",
      "3 \tObject: person \tConfidence = 0.8207 \tBbox: [ 515 \t 774 \t 763 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.8135 \tBbox: [ 292 \t 545 \t 510 \t 1050 ]\n",
      "5 \tObject: person \tConfidence = 0.7882 \tBbox: [ 0 \t 817 \t 239 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.781 \tBbox: [ 516 \t 38 \t 594 \t 239 ]\n",
      "7 \tObject: person \tConfidence = 0.7801 \tBbox: [ 322 \t 192 \t 414 \t 472 ]\n",
      "8 \tObject: person \tConfidence = 0.7656 \tBbox: [ 383 \t 105 \t 458 \t 243 ]\n",
      "9 \tObject: person \tConfidence = 0.7228 \tBbox: [ 382 \t 223 \t 500 \t 550 ]\n",
      "10 \tObject: person \tConfidence = 0.6817 \tBbox: [ 449 \t 0 \t 498 \t 152 ]\n",
      "11 \tObject: person \tConfidence = 0.6562 \tBbox: [ 329 \t 147 \t 415 \t 267 ]\n",
      "12 \tObject: person \tConfidence = 0.5489 \tBbox: [ 390 \t 0 \t 446 \t 115 ]\n",
      "13 \tObject: person \tConfidence = 0.3992 \tBbox: [ 489 \t 1 \t 534 \t 118 ]\n",
      "14 \tObject: person \tConfidence = 0.3514 \tBbox: [ 415 \t 433 \t 529 \t 794 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000562 / 1050\n",
      "Frames to be processed: 488  | To do: 46.48 % | Done: 53.52 %\n",
      "\n",
      "2022-04-20 13:14:55.050993\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000562.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 50.1ms pre-process, 172.7ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8569 \tBbox: [ 98 \t 453 \t 263 \t 857 ]\n",
      "2 \tObject: train \tConfidence = 0.8495 \tBbox: [ 0 \t 3 \t 405 \t 806 ]\n",
      "3 \tObject: person \tConfidence = 0.8385 \tBbox: [ 503 \t 817 \t 763 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.8251 \tBbox: [ 512 \t 37 \t 598 \t 240 ]\n",
      "5 \tObject: person \tConfidence = 0.7836 \tBbox: [ 322 \t 191 \t 414 \t 471 ]\n",
      "6 \tObject: person \tConfidence = 0.7546 \tBbox: [ 1 \t 819 \t 217 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.7386 \tBbox: [ 386 \t 225 \t 501 \t 552 ]\n",
      "8 \tObject: person \tConfidence = 0.7144 \tBbox: [ 337 \t 545 \t 543 \t 1053 ]\n",
      "9 \tObject: person \tConfidence = 0.7105 \tBbox: [ 451 \t 0 \t 499 \t 151 ]\n",
      "10 \tObject: person \tConfidence = 0.7078 \tBbox: [ 373 \t 433 \t 528 \t 629 ]\n",
      "11 \tObject: person \tConfidence = 0.7011 \tBbox: [ 389 \t 0 \t 447 \t 130 ]\n",
      "12 \tObject: person \tConfidence = 0.6605 \tBbox: [ 389 \t 107 \t 477 \t 248 ]\n",
      "13 \tObject: person \tConfidence = 0.6236 \tBbox: [ 329 \t 147 \t 414 \t 265 ]\n",
      "14 \tObject: person \tConfidence = 0.4371 \tBbox: [ 494 \t 0 \t 534 \t 113 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000563 / 1050\n",
      "Frames to be processed: 487  | To do: 46.38 % | Done: 53.62 %\n",
      "\n",
      "2022-04-20 13:14:55.606096\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000563.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 29.1ms pre-process, 181.7ms inference, 10.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8775 \tBbox: [ 504 \t 835 \t 763 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8537 \tBbox: [ 103 \t 453 \t 264 \t 860 ]\n",
      "3 \tObject: person \tConfidence = 0.8418 \tBbox: [ 347 \t 545 \t 561 \t 1038 ]\n",
      "4 \tObject: person \tConfidence = 0.8111 \tBbox: [ 511 \t 34 \t 597 \t 240 ]\n",
      "5 \tObject: train \tConfidence = 0.8019 \tBbox: [ 1 \t 3 \t 401 \t 812 ]\n",
      "6 \tObject: person \tConfidence = 0.7739 \tBbox: [ 324 \t 191 \t 414 \t 472 ]\n",
      "7 \tObject: person \tConfidence = 0.7613 \tBbox: [ 0 \t 819 \t 227 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.7568 \tBbox: [ 387 \t 225 \t 504 \t 551 ]\n",
      "9 \tObject: person \tConfidence = 0.7199 \tBbox: [ 377 \t 435 \t 523 \t 624 ]\n",
      "10 \tObject: person \tConfidence = 0.6903 \tBbox: [ 450 \t 0 \t 498 \t 151 ]\n",
      "11 \tObject: person \tConfidence = 0.6701 \tBbox: [ 387 \t 0 \t 446 \t 164 ]\n",
      "12 \tObject: person \tConfidence = 0.6631 \tBbox: [ 389 \t 107 \t 479 \t 245 ]\n",
      "13 \tObject: person \tConfidence = 0.6202 \tBbox: [ 330 \t 147 \t 414 \t 265 ]\n",
      "14 \tObject: person \tConfidence = 0.451 \tBbox: [ 490 \t 0 \t 539 \t 108 ]\n",
      "15 \tObject: person \tConfidence = 0.3901 \tBbox: [ 0 \t 544 \t 104 \t 835 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000564 / 1050\n",
      "Frames to be processed: 486  | To do: 46.29 % | Done: 53.71 %\n",
      "\n",
      "2022-04-20 13:14:56.151566\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000564.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 29.8ms pre-process, 182.8ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8694 \tBbox: [ 108 \t 454 \t 263 \t 859 ]\n",
      "2 \tObject: person \tConfidence = 0.8658 \tBbox: [ 361 \t 547 \t 579 \t 1024 ]\n",
      "3 \tObject: person \tConfidence = 0.8203 \tBbox: [ 509 \t 34 \t 598 \t 240 ]\n",
      "4 \tObject: train \tConfidence = 0.8095 \tBbox: [ 0 \t 3 \t 406 \t 818 ]\n",
      "5 \tObject: person \tConfidence = 0.7961 \tBbox: [ 323 \t 191 \t 416 \t 471 ]\n",
      "6 \tObject: person \tConfidence = 0.7698 \tBbox: [ 1 \t 819 \t 218 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.7213 \tBbox: [ 386 \t 225 \t 504 \t 552 ]\n",
      "8 \tObject: person \tConfidence = 0.7193 \tBbox: [ 392 \t 106 \t 491 \t 252 ]\n",
      "9 \tObject: person \tConfidence = 0.7123 \tBbox: [ 387 \t 0 \t 448 \t 167 ]\n",
      "10 \tObject: person \tConfidence = 0.712 \tBbox: [ 450 \t 0 \t 498 \t 151 ]\n",
      "11 \tObject: person \tConfidence = 0.6974 \tBbox: [ 497 \t 859 \t 762 \t 1079 ]\n",
      "12 \tObject: person \tConfidence = 0.6706 \tBbox: [ 0 \t 543 \t 110 \t 844 ]\n",
      "13 \tObject: person \tConfidence = 0.6613 \tBbox: [ 331 \t 147 \t 414 \t 265 ]\n",
      "14 \tObject: person \tConfidence = 0.5338 \tBbox: [ 354 \t 437 \t 521 \t 686 ]\n",
      "15 \tObject: person \tConfidence = 0.3085 \tBbox: [ 504 \t 0 \t 545 \t 98 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000565 / 1050\n",
      "Frames to be processed: 485  | To do: 46.19 % | Done: 53.81 %\n",
      "\n",
      "2022-04-20 13:14:56.737902\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000565.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 35.7ms pre-process, 173.6ms inference, 10.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8682 \tBbox: [ 375 \t 552 \t 605 \t 996 ]\n",
      "2 \tObject: person \tConfidence = 0.868 \tBbox: [ 111 \t 454 \t 263 \t 858 ]\n",
      "3 \tObject: person \tConfidence = 0.8321 \tBbox: [ 507 \t 34 \t 594 \t 239 ]\n",
      "4 \tObject: train \tConfidence = 0.8026 \tBbox: [ 0 \t 4 \t 406 \t 810 ]\n",
      "5 \tObject: person \tConfidence = 0.7977 \tBbox: [ 323 \t 190 \t 419 \t 471 ]\n",
      "6 \tObject: person \tConfidence = 0.7636 \tBbox: [ 1 \t 820 \t 214 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.7421 \tBbox: [ 400 \t 105 \t 488 \t 258 ]\n",
      "8 \tObject: person \tConfidence = 0.7407 \tBbox: [ 0 \t 543 \t 115 \t 836 ]\n",
      "9 \tObject: person \tConfidence = 0.7406 \tBbox: [ 449 \t 0 \t 498 \t 150 ]\n",
      "10 \tObject: person \tConfidence = 0.731 \tBbox: [ 505 \t 872 \t 763 \t 1079 ]\n",
      "11 \tObject: person \tConfidence = 0.6579 \tBbox: [ 352 \t 435 \t 520 \t 702 ]\n",
      "12 \tObject: person \tConfidence = 0.6451 \tBbox: [ 387 \t 0 \t 447 \t 161 ]\n",
      "13 \tObject: person \tConfidence = 0.6371 \tBbox: [ 334 \t 146 \t 415 \t 260 ]\n",
      "14 \tObject: person \tConfidence = 0.6269 \tBbox: [ 384 \t 221 \t 510 \t 550 ]\n",
      "15 \tObject: person \tConfidence = 0.3216 \tBbox: [ 494 \t 0 \t 527 \t 106 ]\n",
      "16 \tObject: person \tConfidence = 0.3116 \tBbox: [ 512 \t 0 \t 555 \t 94 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000566 / 1050\n",
      "Frames to be processed: 484  | To do: 46.1 % | Done: 53.9 %\n",
      "\n",
      "2022-04-20 13:14:57.222182\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000566.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 29.2ms pre-process, 179.3ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8533 \tBbox: [ 118 \t 455 \t 267 \t 855 ]\n",
      "2 \tObject: person \tConfidence = 0.8396 \tBbox: [ 377 \t 559 \t 637 \t 989 ]\n",
      "3 \tObject: person \tConfidence = 0.8194 \tBbox: [ 506 \t 34 \t 592 \t 239 ]\n",
      "4 \tObject: person \tConfidence = 0.7959 \tBbox: [ 509 \t 887 \t 748 \t 1079 ]\n",
      "5 \tObject: person \tConfidence = 0.773 \tBbox: [ 323 \t 189 \t 417 \t 470 ]\n",
      "6 \tObject: person \tConfidence = 0.7623 \tBbox: [ 404 \t 106 \t 496 \t 269 ]\n",
      "7 \tObject: train \tConfidence = 0.7605 \tBbox: [ 0 \t 2 \t 415 \t 810 ]\n",
      "8 \tObject: person \tConfidence = 0.7599 \tBbox: [ 0 \t 545 \t 124 \t 840 ]\n",
      "9 \tObject: person \tConfidence = 0.7544 \tBbox: [ 1 \t 820 \t 210 \t 1079 ]\n",
      "10 \tObject: person \tConfidence = 0.6999 \tBbox: [ 448 \t 0 \t 498 \t 148 ]\n",
      "11 \tObject: person \tConfidence = 0.6778 \tBbox: [ 386 \t 0 \t 446 \t 164 ]\n",
      "12 \tObject: person \tConfidence = 0.6481 \tBbox: [ 378 \t 434 \t 521 \t 677 ]\n",
      "13 \tObject: person \tConfidence = 0.609 \tBbox: [ 334 \t 146 \t 414 \t 261 ]\n",
      "14 \tObject: person \tConfidence = 0.5882 \tBbox: [ 385 \t 220 \t 510 \t 544 ]\n",
      "15 \tObject: person \tConfidence = 0.3944 \tBbox: [ 280 \t 94 \t 347 \t 318 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000567 / 1050\n",
      "Frames to be processed: 483  | To do: 46.0 % | Done: 54.0 %\n",
      "\n",
      "2022-04-20 13:14:57.721961\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000567.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 36.2ms pre-process, 180.2ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.868 \tBbox: [ 379 \t 568 \t 689 \t 989 ]\n",
      "2 \tObject: person \tConfidence = 0.8479 \tBbox: [ 127 \t 454 \t 272 \t 851 ]\n",
      "3 \tObject: person \tConfidence = 0.8039 \tBbox: [ 413 \t 105 \t 493 \t 279 ]\n",
      "4 \tObject: person \tConfidence = 0.796 \tBbox: [ 354 \t 433 \t 518 \t 801 ]\n",
      "5 \tObject: person \tConfidence = 0.7955 \tBbox: [ 506 \t 35 \t 583 \t 240 ]\n",
      "6 \tObject: person \tConfidence = 0.791 \tBbox: [ 321 \t 190 \t 420 \t 473 ]\n",
      "7 \tObject: person \tConfidence = 0.7387 \tBbox: [ 388 \t 0 \t 446 \t 155 ]\n",
      "8 \tObject: person \tConfidence = 0.7339 \tBbox: [ 1 \t 820 \t 206 \t 1079 ]\n",
      "9 \tObject: train \tConfidence = 0.6846 \tBbox: [ 0 \t 5 \t 398 \t 823 ]\n",
      "10 \tObject: person \tConfidence = 0.6695 \tBbox: [ 0 \t 555 \t 135 \t 852 ]\n",
      "11 \tObject: person \tConfidence = 0.6621 \tBbox: [ 328 \t 147 \t 414 \t 268 ]\n",
      "12 \tObject: person \tConfidence = 0.5841 \tBbox: [ 448 \t 0 \t 497 \t 146 ]\n",
      "13 \tObject: person \tConfidence = 0.5819 \tBbox: [ 386 \t 224 \t 511 \t 513 ]\n",
      "14 \tObject: person \tConfidence = 0.473 \tBbox: [ 284 \t 99 \t 349 \t 326 ]\n",
      "15 \tObject: person \tConfidence = 0.4698 \tBbox: [ 565 \t 933 \t 751 \t 1080 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000568 / 1050\n",
      "Frames to be processed: 482  | To do: 45.9 % | Done: 54.1 %\n",
      "\n",
      "2022-04-20 13:14:58.255655\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000568.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 55.1ms pre-process, 178.7ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8772 \tBbox: [ 381 \t 575 \t 708 \t 1019 ]\n",
      "2 \tObject: person \tConfidence = 0.8429 \tBbox: [ 129 \t 454 \t 274 \t 851 ]\n",
      "3 \tObject: person \tConfidence = 0.8039 \tBbox: [ 359 \t 432 \t 516 \t 806 ]\n",
      "4 \tObject: person \tConfidence = 0.7991 \tBbox: [ 503 \t 34 \t 582 \t 238 ]\n",
      "5 \tObject: person \tConfidence = 0.7942 \tBbox: [ 416 \t 105 \t 503 \t 290 ]\n",
      "6 \tObject: person \tConfidence = 0.7926 \tBbox: [ 327 \t 188 \t 420 \t 472 ]\n",
      "7 \tObject: person \tConfidence = 0.7503 \tBbox: [ 389 \t 1 \t 445 \t 153 ]\n",
      "8 \tObject: person \tConfidence = 0.7362 \tBbox: [ 0 \t 559 \t 144 \t 846 ]\n",
      "9 \tObject: person \tConfidence = 0.7242 \tBbox: [ 1 \t 821 \t 192 \t 1079 ]\n",
      "10 \tObject: person \tConfidence = 0.6419 \tBbox: [ 388 \t 227 \t 511 \t 502 ]\n",
      "11 \tObject: train \tConfidence = 0.6073 \tBbox: [ 0 \t 2 \t 404 \t 772 ]\n",
      "12 \tObject: person \tConfidence = 0.4954 \tBbox: [ 285 \t 97 \t 350 \t 318 ]\n",
      "13 \tObject: person \tConfidence = 0.4876 \tBbox: [ 329 \t 147 \t 412 \t 268 ]\n",
      "14 \tObject: person \tConfidence = 0.4517 \tBbox: [ 621 \t 957 \t 746 \t 1079 ]\n",
      "15 \tObject: person \tConfidence = 0.3314 \tBbox: [ 449 \t 0 \t 495 \t 113 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000569 / 1050\n",
      "Frames to be processed: 481  | To do: 45.81 % | Done: 54.19 %\n",
      "\n",
      "2022-04-20 13:14:58.783910\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000569.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 68.6ms pre-process, 175.5ms inference, 10.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8276 \tBbox: [ 396 \t 580 \t 724 \t 1036 ]\n",
      "2 \tObject: person \tConfidence = 0.8249 \tBbox: [ 131 \t 454 \t 275 \t 845 ]\n",
      "3 \tObject: person \tConfidence = 0.8021 \tBbox: [ 354 \t 432 \t 514 \t 810 ]\n",
      "4 \tObject: person \tConfidence = 0.7995 \tBbox: [ 503 \t 34 \t 578 \t 238 ]\n",
      "5 \tObject: person \tConfidence = 0.7932 \tBbox: [ 419 \t 106 \t 506 \t 291 ]\n",
      "6 \tObject: person \tConfidence = 0.7925 \tBbox: [ 328 \t 187 \t 424 \t 472 ]\n",
      "7 \tObject: person \tConfidence = 0.7677 \tBbox: [ 389 \t 0 \t 444 \t 153 ]\n",
      "8 \tObject: person \tConfidence = 0.7353 \tBbox: [ 1 \t 820 \t 220 \t 1079 ]\n",
      "9 \tObject: person \tConfidence = 0.7063 \tBbox: [ 389 \t 226 \t 512 \t 501 ]\n",
      "10 \tObject: person \tConfidence = 0.6649 \tBbox: [ 1 \t 562 \t 174 \t 884 ]\n",
      "11 \tObject: train \tConfidence = 0.5816 \tBbox: [ 0 \t 2 \t 402 \t 673 ]\n",
      "12 \tObject: person \tConfidence = 0.5238 \tBbox: [ 331 \t 147 \t 399 \t 265 ]\n",
      "13 \tObject: person \tConfidence = 0.4482 \tBbox: [ 285 \t 99 \t 350 \t 318 ]\n",
      "14 \tObject: person \tConfidence = 0.3651 \tBbox: [ 619 \t 985 \t 746 \t 1079 ]\n",
      "15 \tObject: person \tConfidence = 0.3584 \tBbox: [ 542 \t 0 \t 581 \t 62 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000570 / 1050\n",
      "Frames to be processed: 480  | To do: 45.71 % | Done: 54.29 %\n",
      "\n",
      "2022-04-20 13:14:59.278200\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000570.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 26.8ms pre-process, 179.2ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8512 \tBbox: [ 408 \t 582 \t 740 \t 1047 ]\n",
      "2 \tObject: person \tConfidence = 0.8361 \tBbox: [ 131 \t 454 \t 275 \t 846 ]\n",
      "3 \tObject: person \tConfidence = 0.7988 \tBbox: [ 500 \t 33 \t 579 \t 237 ]\n",
      "4 \tObject: person \tConfidence = 0.786 \tBbox: [ 419 \t 107 \t 510 \t 298 ]\n",
      "5 \tObject: person \tConfidence = 0.779 \tBbox: [ 332 \t 185 \t 423 \t 470 ]\n",
      "6 \tObject: person \tConfidence = 0.7652 \tBbox: [ 2 \t 559 \t 194 \t 918 ]\n",
      "7 \tObject: person \tConfidence = 0.7456 \tBbox: [ 1 \t 821 \t 219 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.7233 \tBbox: [ 392 \t 226 \t 514 \t 507 ]\n",
      "9 \tObject: person \tConfidence = 0.7038 \tBbox: [ 389 \t 0 \t 445 \t 154 ]\n",
      "10 \tObject: person \tConfidence = 0.5672 \tBbox: [ 353 \t 432 \t 512 \t 851 ]\n",
      "11 \tObject: train \tConfidence = 0.4358 \tBbox: [ 1 \t 2 \t 400 \t 643 ]\n",
      "12 \tObject: person \tConfidence = 0.394 \tBbox: [ 330 \t 148 \t 411 \t 269 ]\n",
      "13 \tObject: person \tConfidence = 0.3612 \tBbox: [ 538 \t 0 \t 583 \t 72 ]\n",
      "14 \tObject: person \tConfidence = 0.3201 \tBbox: [ 286 \t 95 \t 351 \t 318 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000571 / 1050\n",
      "Frames to be processed: 479  | To do: 45.62 % | Done: 54.38 %\n",
      "\n",
      "2022-04-20 13:14:59.721531\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000571.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 24.3ms pre-process, 179.8ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8592 \tBbox: [ 436 \t 580 \t 764 \t 1076 ]\n",
      "2 \tObject: person \tConfidence = 0.8035 \tBbox: [ 1 \t 821 \t 245 \t 1079 ]\n",
      "3 \tObject: person \tConfidence = 0.7969 \tBbox: [ 132 \t 452 \t 273 \t 836 ]\n",
      "4 \tObject: person \tConfidence = 0.7852 \tBbox: [ 505 \t 33 \t 583 \t 239 ]\n",
      "5 \tObject: person \tConfidence = 0.7814 \tBbox: [ 327 \t 186 \t 427 \t 469 ]\n",
      "6 \tObject: person \tConfidence = 0.7688 \tBbox: [ 358 \t 431 \t 510 \t 847 ]\n",
      "7 \tObject: person \tConfidence = 0.7641 \tBbox: [ 394 \t 225 \t 516 \t 506 ]\n",
      "8 \tObject: person \tConfidence = 0.7577 \tBbox: [ 5 \t 571 \t 205 \t 926 ]\n",
      "9 \tObject: person \tConfidence = 0.7223 \tBbox: [ 388 \t 0 \t 449 \t 155 ]\n",
      "10 \tObject: person \tConfidence = 0.643 \tBbox: [ 426 \t 107 \t 527 \t 325 ]\n",
      "11 \tObject: person \tConfidence = 0.4795 \tBbox: [ 328 \t 148 \t 394 \t 275 ]\n",
      "12 \tObject: train \tConfidence = 0.4402 \tBbox: [ 0 \t 3 \t 399 \t 712 ]\n",
      "13 \tObject: person \tConfidence = 0.4052 \tBbox: [ 286 \t 99 \t 351 \t 315 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000572 / 1050\n",
      "Frames to be processed: 478  | To do: 45.52 % | Done: 54.48 %\n",
      "\n",
      "2022-04-20 13:15:00.154976\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000572.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 31.4ms pre-process, 172.9ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8593 \tBbox: [ 446 \t 112 \t 563 \t 370 ]\n",
      "2 \tObject: person \tConfidence = 0.8304 \tBbox: [ 49 \t 570 \t 222 \t 935 ]\n",
      "3 \tObject: person \tConfidence = 0.8301 \tBbox: [ 369 \t 429 \t 505 \t 845 ]\n",
      "4 \tObject: person \tConfidence = 0.822 \tBbox: [ 396 \t 222 \t 516 \t 512 ]\n",
      "5 \tObject: person \tConfidence = 0.8146 \tBbox: [ 131 \t 452 \t 270 \t 762 ]\n",
      "6 \tObject: person \tConfidence = 0.8134 \tBbox: [ 527 \t 581 \t 766 \t 1074 ]\n",
      "7 \tObject: person \tConfidence = 0.7912 \tBbox: [ 554 \t 0 \t 624 \t 129 ]\n",
      "8 \tObject: person \tConfidence = 0.7886 \tBbox: [ 329 \t 189 \t 430 \t 469 ]\n",
      "9 \tObject: person \tConfidence = 0.7646 \tBbox: [ 0 \t 822 \t 238 \t 1079 ]\n",
      "10 \tObject: person \tConfidence = 0.7278 \tBbox: [ 506 \t 32 \t 584 \t 237 ]\n",
      "11 \tObject: person \tConfidence = 0.6621 \tBbox: [ 389 \t 2 \t 446 \t 155 ]\n",
      "12 \tObject: train \tConfidence = 0.6459 \tBbox: [ 0 \t 1 \t 401 \t 802 ]\n",
      "13 \tObject: person \tConfidence = 0.5786 \tBbox: [ 328 \t 149 \t 393 \t 273 ]\n",
      "14 \tObject: person \tConfidence = 0.403 \tBbox: [ 442 \t 0 \t 495 \t 138 ]\n",
      "15 \tObject: person \tConfidence = 0.3753 \tBbox: [ 291 \t 98 \t 354 \t 313 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000573 / 1050\n",
      "Frames to be processed: 477  | To do: 45.43 % | Done: 54.57 %\n",
      "\n",
      "2022-04-20 13:15:00.599561\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000573.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 28.3ms pre-process, 175.8ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8886 \tBbox: [ 454 \t 114 \t 570 \t 379 ]\n",
      "2 \tObject: person \tConfidence = 0.8639 \tBbox: [ 131 \t 452 \t 269 \t 755 ]\n",
      "3 \tObject: person \tConfidence = 0.8458 \tBbox: [ 559 \t 593 \t 765 \t 1074 ]\n",
      "4 \tObject: person \tConfidence = 0.8449 \tBbox: [ 366 \t 426 \t 503 \t 847 ]\n",
      "5 \tObject: person \tConfidence = 0.8421 \tBbox: [ 397 \t 222 \t 517 \t 517 ]\n",
      "6 \tObject: person \tConfidence = 0.8135 \tBbox: [ 63 \t 572 \t 231 \t 932 ]\n",
      "7 \tObject: person \tConfidence = 0.8075 \tBbox: [ 559 \t 0 \t 624 \t 130 ]\n",
      "8 \tObject: person \tConfidence = 0.789 \tBbox: [ 331 \t 188 \t 431 \t 468 ]\n",
      "9 \tObject: person \tConfidence = 0.7838 \tBbox: [ 0 \t 822 \t 236 \t 1079 ]\n",
      "10 \tObject: person \tConfidence = 0.7421 \tBbox: [ 506 \t 32 \t 575 \t 234 ]\n",
      "11 \tObject: person \tConfidence = 0.686 \tBbox: [ 390 \t 1 \t 447 \t 152 ]\n",
      "12 \tObject: train \tConfidence = 0.6824 \tBbox: [ 0 \t 1 \t 402 \t 789 ]\n",
      "13 \tObject: person \tConfidence = 0.6174 \tBbox: [ 328 \t 153 \t 391 \t 275 ]\n",
      "14 \tObject: person \tConfidence = 0.5962 \tBbox: [ 449 \t 0 \t 495 \t 145 ]\n",
      "15 \tObject: person \tConfidence = 0.3607 \tBbox: [ 292 \t 94 \t 361 \t 316 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000574 / 1050\n",
      "Frames to be processed: 476  | To do: 45.33 % | Done: 54.67 %\n",
      "\n",
      "2022-04-20 13:15:01.185808\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000574.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 25.6ms pre-process, 180.4ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8907 \tBbox: [ 461 \t 117 \t 568 \t 379 ]\n",
      "2 \tObject: person \tConfidence = 0.8445 \tBbox: [ 363 \t 425 \t 502 \t 847 ]\n",
      "3 \tObject: person \tConfidence = 0.8302 \tBbox: [ 400 \t 220 \t 517 \t 523 ]\n",
      "4 \tObject: person \tConfidence = 0.8204 \tBbox: [ 130 \t 452 \t 268 \t 749 ]\n",
      "5 \tObject: person \tConfidence = 0.8081 \tBbox: [ 1 \t 822 \t 246 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.8068 \tBbox: [ 586 \t 576 \t 765 \t 1072 ]\n",
      "7 \tObject: person \tConfidence = 0.7724 \tBbox: [ 327 \t 188 \t 432 \t 468 ]\n",
      "8 \tObject: train \tConfidence = 0.7615 \tBbox: [ 1 \t 3 \t 395 \t 779 ]\n",
      "9 \tObject: person \tConfidence = 0.752 \tBbox: [ 569 \t 0 \t 623 \t 132 ]\n",
      "10 \tObject: person \tConfidence = 0.7287 \tBbox: [ 78 \t 570 \t 247 \t 934 ]\n",
      "11 \tObject: person \tConfidence = 0.7046 \tBbox: [ 507 \t 32 \t 580 \t 235 ]\n",
      "12 \tObject: person \tConfidence = 0.6204 \tBbox: [ 328 \t 150 \t 392 \t 275 ]\n",
      "13 \tObject: person \tConfidence = 0.5896 \tBbox: [ 442 \t 0 \t 494 \t 147 ]\n",
      "14 \tObject: person \tConfidence = 0.5739 \tBbox: [ 390 \t 0 \t 445 \t 153 ]\n",
      "15 \tObject: person \tConfidence = 0.3432 \tBbox: [ 309 \t 114 \t 379 \t 295 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000575 / 1050\n",
      "Frames to be processed: 475  | To do: 45.24 % | Done: 54.76 %\n",
      "\n",
      "2022-04-20 13:15:01.786793\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000575.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 45.1ms pre-process, 180.8ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8948 \tBbox: [ 469 \t 118 \t 569 \t 384 ]\n",
      "2 \tObject: person \tConfidence = 0.8217 \tBbox: [ 360 \t 423 \t 500 \t 845 ]\n",
      "3 \tObject: person \tConfidence = 0.8203 \tBbox: [ 401 \t 219 \t 519 \t 528 ]\n",
      "4 \tObject: train \tConfidence = 0.7999 \tBbox: [ 1 \t 2 \t 397 \t 804 ]\n",
      "5 \tObject: person \tConfidence = 0.7977 \tBbox: [ 130 \t 452 \t 266 \t 743 ]\n",
      "6 \tObject: person \tConfidence = 0.7783 \tBbox: [ 326 \t 187 \t 434 \t 467 ]\n",
      "7 \tObject: person \tConfidence = 0.7778 \tBbox: [ 0 \t 823 \t 242 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.7771 \tBbox: [ 91 \t 571 \t 256 \t 953 ]\n",
      "9 \tObject: person \tConfidence = 0.7719 \tBbox: [ 573 \t 0 \t 623 \t 132 ]\n",
      "10 \tObject: person \tConfidence = 0.723 \tBbox: [ 390 \t 0 \t 444 \t 152 ]\n",
      "11 \tObject: person \tConfidence = 0.6785 \tBbox: [ 447 \t 0 \t 495 \t 147 ]\n",
      "12 \tObject: person \tConfidence = 0.5925 \tBbox: [ 609 \t 606 \t 766 \t 1073 ]\n",
      "13 \tObject: person \tConfidence = 0.588 \tBbox: [ 327 \t 149 \t 392 \t 279 ]\n",
      "14 \tObject: person \tConfidence = 0.5747 \tBbox: [ 503 \t 30 \t 577 \t 245 ]\n",
      "15 \tObject: person \tConfidence = 0.3127 \tBbox: [ 311 \t 99 \t 368 \t 248 ]\n",
      "16 \tObject: person \tConfidence = 0.311 \tBbox: [ 290 \t 95 \t 361 \t 317 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000576 / 1050\n",
      "Frames to be processed: 474  | To do: 45.14 % | Done: 54.86 %\n",
      "\n",
      "2022-04-20 13:15:02.315284\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000576.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 57.4ms pre-process, 179.1ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8841 \tBbox: [ 475 \t 119 \t 570 \t 385 ]\n",
      "2 \tObject: person \tConfidence = 0.8285 \tBbox: [ 102 \t 575 \t 282 \t 972 ]\n",
      "3 \tObject: person \tConfidence = 0.8191 \tBbox: [ 402 \t 216 \t 518 \t 533 ]\n",
      "4 \tObject: person \tConfidence = 0.8046 \tBbox: [ 390 \t 0 \t 442 \t 152 ]\n",
      "5 \tObject: person \tConfidence = 0.8026 \tBbox: [ 576 \t 0 \t 625 \t 133 ]\n",
      "6 \tObject: person \tConfidence = 0.7928 \tBbox: [ 1 \t 823 \t 247 \t 1079 ]\n",
      "7 \tObject: train \tConfidence = 0.7733 \tBbox: [ 1 \t 2 \t 390 \t 806 ]\n",
      "8 \tObject: person \tConfidence = 0.7335 \tBbox: [ 617 \t 612 \t 765 \t 1072 ]\n",
      "9 \tObject: person \tConfidence = 0.732 \tBbox: [ 336 \t 188 \t 433 \t 467 ]\n",
      "10 \tObject: person \tConfidence = 0.7017 \tBbox: [ 452 \t 0 \t 495 \t 147 ]\n",
      "11 \tObject: person \tConfidence = 0.6815 \tBbox: [ 130 \t 451 \t 259 \t 639 ]\n",
      "12 \tObject: person \tConfidence = 0.643 \tBbox: [ 357 \t 420 \t 499 \t 845 ]\n",
      "13 \tObject: person \tConfidence = 0.547 \tBbox: [ 497 \t 29 \t 569 \t 201 ]\n",
      "14 \tObject: person \tConfidence = 0.5251 \tBbox: [ 295 \t 78 \t 380 \t 251 ]\n",
      "15 \tObject: person \tConfidence = 0.4549 \tBbox: [ 327 \t 146 \t 392 \t 293 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000577 / 1050\n",
      "Frames to be processed: 473  | To do: 45.05 % | Done: 54.95 %\n",
      "\n",
      "2022-04-20 13:15:02.822189\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000577.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 25.2ms pre-process, 179.6ms inference, 8.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8886 \tBbox: [ 484 \t 119 \t 584 \t 387 ]\n",
      "2 \tObject: person \tConfidence = 0.8608 \tBbox: [ 129 \t 450 \t 248 \t 660 ]\n",
      "3 \tObject: person \tConfidence = 0.8396 \tBbox: [ 405 \t 215 \t 518 \t 533 ]\n",
      "4 \tObject: person \tConfidence = 0.8383 \tBbox: [ 618 \t 628 \t 765 \t 1073 ]\n",
      "5 \tObject: person \tConfidence = 0.7914 \tBbox: [ 1 \t 824 \t 248 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.7777 \tBbox: [ 389 \t 0 \t 440 \t 155 ]\n",
      "7 \tObject: person \tConfidence = 0.7744 \tBbox: [ 588 \t 0 \t 635 \t 130 ]\n",
      "8 \tObject: train \tConfidence = 0.7652 \tBbox: [ 1 \t 3 \t 391 \t 803 ]\n",
      "9 \tObject: person \tConfidence = 0.7348 \tBbox: [ 123 \t 580 \t 291 \t 1039 ]\n",
      "10 \tObject: person \tConfidence = 0.7008 \tBbox: [ 358 \t 418 \t 489 \t 711 ]\n",
      "11 \tObject: person \tConfidence = 0.6806 \tBbox: [ 335 \t 185 \t 433 \t 460 ]\n",
      "12 \tObject: person \tConfidence = 0.6776 \tBbox: [ 450 \t 0 \t 496 \t 147 ]\n",
      "13 \tObject: person \tConfidence = 0.61 \tBbox: [ 498 \t 28 \t 567 \t 140 ]\n",
      "14 \tObject: person \tConfidence = 0.4897 \tBbox: [ 327 \t 149 \t 392 \t 283 ]\n",
      "15 \tObject: person \tConfidence = 0.4886 \tBbox: [ 313 \t 76 \t 389 \t 227 ]\n",
      "16 \tObject: person \tConfidence = 0.3507 \tBbox: [ 105 \t 442 \t 149 \t 566 ]\n",
      "17 \tObject: person \tConfidence = 0.342 \tBbox: [ 365 \t 193 \t 487 \t 483 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000578 / 1050\n",
      "Frames to be processed: 472  | To do: 44.95 % | Done: 55.05 %\n",
      "\n",
      "2022-04-20 13:15:03.279706\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000578.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 33.6ms pre-process, 180.7ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8919 \tBbox: [ 487 \t 119 \t 592 \t 387 ]\n",
      "2 \tObject: person \tConfidence = 0.8531 \tBbox: [ 406 \t 216 \t 519 \t 533 ]\n",
      "3 \tObject: person \tConfidence = 0.8472 \tBbox: [ 356 \t 417 \t 486 \t 712 ]\n",
      "4 \tObject: person \tConfidence = 0.8329 \tBbox: [ 130 \t 450 \t 245 \t 670 ]\n",
      "5 \tObject: person \tConfidence = 0.8319 \tBbox: [ 1 \t 824 \t 246 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.8317 \tBbox: [ 139 \t 580 \t 317 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.7982 \tBbox: [ 392 \t 0 \t 439 \t 154 ]\n",
      "8 \tObject: person \tConfidence = 0.779 \tBbox: [ 593 \t 1 \t 641 \t 132 ]\n",
      "9 \tObject: train \tConfidence = 0.7756 \tBbox: [ 1 \t 3 \t 392 \t 810 ]\n",
      "10 \tObject: person \tConfidence = 0.7569 \tBbox: [ 619 \t 647 \t 765 \t 1073 ]\n",
      "11 \tObject: person \tConfidence = 0.6434 \tBbox: [ 501 \t 29 \t 565 \t 151 ]\n",
      "12 \tObject: person \tConfidence = 0.6239 \tBbox: [ 451 \t 0 \t 500 \t 145 ]\n",
      "13 \tObject: person \tConfidence = 0.6217 \tBbox: [ 329 \t 186 \t 434 \t 476 ]\n",
      "14 \tObject: person \tConfidence = 0.4831 \tBbox: [ 327 \t 149 \t 394 \t 283 ]\n",
      "15 \tObject: person \tConfidence = 0.4105 \tBbox: [ 326 \t 82 \t 403 \t 211 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000579 / 1050\n",
      "Frames to be processed: 471  | To do: 44.86 % | Done: 55.14 %\n",
      "\n",
      "2022-04-20 13:15:03.754870\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000579.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 24.4ms pre-process, 175.3ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8918 \tBbox: [ 491 \t 118 \t 597 \t 386 ]\n",
      "2 \tObject: person \tConfidence = 0.878 \tBbox: [ 158 \t 585 \t 350 \t 1079 ]\n",
      "3 \tObject: person \tConfidence = 0.8528 \tBbox: [ 407 \t 216 \t 522 \t 533 ]\n",
      "4 \tObject: person \tConfidence = 0.8464 \tBbox: [ 598 \t 0 \t 648 \t 131 ]\n",
      "5 \tObject: person \tConfidence = 0.8263 \tBbox: [ 1 \t 825 \t 247 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.8151 \tBbox: [ 391 \t 0 \t 440 \t 154 ]\n",
      "7 \tObject: person \tConfidence = 0.8145 \tBbox: [ 350 \t 417 \t 485 \t 715 ]\n",
      "8 \tObject: train \tConfidence = 0.7712 \tBbox: [ 1 \t 3 \t 392 \t 815 ]\n",
      "9 \tObject: person \tConfidence = 0.7155 \tBbox: [ 497 \t 28 \t 564 \t 171 ]\n",
      "10 \tObject: person \tConfidence = 0.6984 \tBbox: [ 333 \t 185 \t 435 \t 439 ]\n",
      "11 \tObject: person \tConfidence = 0.6967 \tBbox: [ 128 \t 447 \t 246 \t 783 ]\n",
      "12 \tObject: person \tConfidence = 0.6636 \tBbox: [ 450 \t 0 \t 499 \t 143 ]\n",
      "13 \tObject: person \tConfidence = 0.5056 \tBbox: [ 620 \t 665 \t 765 \t 1073 ]\n",
      "14 \tObject: person \tConfidence = 0.3841 \tBbox: [ 368 \t 263 \t 426 \t 351 ]\n",
      "15 \tObject: person \tConfidence = 0.3616 \tBbox: [ 332 \t 93 \t 410 \t 204 ]\n",
      "16 \tObject: person \tConfidence = 0.3367 \tBbox: [ 327 \t 146 \t 401 \t 293 ]\n",
      "17 \tObject: person \tConfidence = 0.3338 \tBbox: [ 105 \t 442 \t 149 \t 567 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000580 / 1050\n",
      "Frames to be processed: 470  | To do: 44.76 % | Done: 55.24 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 24.3ms pre-process, 169.2ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:15:04.232081\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000580.jpg ------------------------------ \n",
      "\n",
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8991 \tBbox: [ 496 \t 119 \t 605 \t 385 ]\n",
      "2 \tObject: person \tConfidence = 0.8952 \tBbox: [ 172 \t 591 \t 389 \t 1080 ]\n",
      "3 \tObject: person \tConfidence = 0.8699 \tBbox: [ 599 \t 0 \t 661 \t 132 ]\n",
      "4 \tObject: person \tConfidence = 0.8674 \tBbox: [ 407 \t 216 \t 533 \t 533 ]\n",
      "5 \tObject: person \tConfidence = 0.8326 \tBbox: [ 392 \t 0 \t 441 \t 153 ]\n",
      "6 \tObject: person \tConfidence = 0.8165 \tBbox: [ 107 \t 449 \t 247 \t 868 ]\n",
      "7 \tObject: person \tConfidence = 0.8152 \tBbox: [ 1 \t 825 \t 251 \t 1079 ]\n",
      "8 \tObject: train \tConfidence = 0.7928 \tBbox: [ 1 \t 2 \t 399 \t 815 ]\n",
      "9 \tObject: person \tConfidence = 0.7343 \tBbox: [ 345 \t 415 \t 484 \t 718 ]\n",
      "10 \tObject: person \tConfidence = 0.7011 \tBbox: [ 451 \t 1 \t 496 \t 144 ]\n",
      "11 \tObject: person \tConfidence = 0.6936 \tBbox: [ 499 \t 28 \t 565 \t 173 ]\n",
      "12 \tObject: person \tConfidence = 0.6606 \tBbox: [ 332 \t 184 \t 435 \t 443 ]\n",
      "13 \tObject: person \tConfidence = 0.5621 \tBbox: [ 622 \t 691 \t 764 \t 1073 ]\n",
      "14 \tObject: person \tConfidence = 0.4884 \tBbox: [ 354 \t 97 \t 417 \t 201 ]\n",
      "15 \tObject: person \tConfidence = 0.4013 \tBbox: [ 327 \t 148 \t 397 \t 278 ]\n",
      "16 \tObject: person \tConfidence = 0.3655 \tBbox: [ 369 \t 263 \t 427 \t 350 ]\n",
      "17 \tObject: person \tConfidence = 0.3067 \tBbox: [ 105 \t 442 \t 148 \t 567 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000581 / 1050\n",
      "Frames to be processed: 469  | To do: 44.67 % | Done: 55.33 %\n",
      "\n",
      "2022-04-20 13:15:04.718657\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000581.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 26.6ms pre-process, 175.7ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8964 \tBbox: [ 499 \t 119 \t 610 \t 386 ]\n",
      "2 \tObject: person \tConfidence = 0.8853 \tBbox: [ 408 \t 215 \t 540 \t 532 ]\n",
      "3 \tObject: person \tConfidence = 0.8761 \tBbox: [ 600 \t 0 \t 673 \t 132 ]\n",
      "4 \tObject: person \tConfidence = 0.8677 \tBbox: [ 181 \t 600 \t 435 \t 1080 ]\n",
      "5 \tObject: person \tConfidence = 0.8296 \tBbox: [ 109 \t 448 \t 250 \t 864 ]\n",
      "6 \tObject: person \tConfidence = 0.8178 \tBbox: [ 392 \t 0 \t 441 \t 150 ]\n",
      "7 \tObject: train \tConfidence = 0.8157 \tBbox: [ 0 \t 1 \t 406 \t 811 ]\n",
      "8 \tObject: person \tConfidence = 0.805 \tBbox: [ 1 \t 825 \t 250 \t 1079 ]\n",
      "9 \tObject: person \tConfidence = 0.7234 \tBbox: [ 333 \t 184 \t 436 \t 428 ]\n",
      "10 \tObject: person \tConfidence = 0.7076 \tBbox: [ 452 \t 0 \t 496 \t 142 ]\n",
      "11 \tObject: person \tConfidence = 0.6499 \tBbox: [ 500 \t 27 \t 569 \t 176 ]\n",
      "12 \tObject: person \tConfidence = 0.5487 \tBbox: [ 338 \t 413 \t 482 \t 724 ]\n",
      "13 \tObject: person \tConfidence = 0.5406 \tBbox: [ 631 \t 722 \t 765 \t 1072 ]\n",
      "14 \tObject: person \tConfidence = 0.5262 \tBbox: [ 357 \t 99 \t 428 \t 225 ]\n",
      "15 \tObject: person \tConfidence = 0.3401 \tBbox: [ 105 \t 442 \t 148 \t 567 ]\n",
      "16 \tObject: person \tConfidence = 0.333 \tBbox: [ 324 \t 147 \t 401 \t 326 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000582 / 1050\n",
      "Frames to be processed: 468  | To do: 44.57 % | Done: 55.43 %\n",
      "\n",
      "2022-04-20 13:15:05.274985\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000582.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 29.9ms pre-process, 177.9ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9068 \tBbox: [ 511 \t 122 \t 621 \t 410 ]\n",
      "2 \tObject: person \tConfidence = 0.8772 \tBbox: [ 599 \t 0 \t 682 \t 132 ]\n",
      "3 \tObject: person \tConfidence = 0.8584 \tBbox: [ 409 \t 216 \t 525 \t 532 ]\n",
      "4 \tObject: person \tConfidence = 0.8125 \tBbox: [ 1 \t 827 \t 252 \t 1079 ]\n",
      "5 \tObject: person \tConfidence = 0.8095 \tBbox: [ 113 \t 447 \t 259 \t 869 ]\n",
      "6 \tObject: person \tConfidence = 0.8008 \tBbox: [ 189 \t 616 \t 446 \t 1080 ]\n",
      "7 \tObject: train \tConfidence = 0.8005 \tBbox: [ 0 \t 1 \t 420 \t 817 ]\n",
      "8 \tObject: person \tConfidence = 0.772 \tBbox: [ 327 \t 415 \t 474 \t 733 ]\n",
      "9 \tObject: person \tConfidence = 0.7457 \tBbox: [ 497 \t 24 \t 571 \t 209 ]\n",
      "10 \tObject: person \tConfidence = 0.7373 \tBbox: [ 332 \t 183 \t 436 \t 429 ]\n",
      "11 \tObject: person \tConfidence = 0.7271 \tBbox: [ 391 \t 0 \t 444 \t 149 ]\n",
      "12 \tObject: person \tConfidence = 0.5873 \tBbox: [ 371 \t 100 \t 445 \t 237 ]\n",
      "13 \tObject: person \tConfidence = 0.5129 \tBbox: [ 450 \t 0 \t 505 \t 143 ]\n",
      "14 \tObject: person \tConfidence = 0.3015 \tBbox: [ 105 \t 442 \t 149 \t 565 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000583 / 1050\n",
      "Frames to be processed: 467  | To do: 44.48 % | Done: 55.52 %\n",
      "\n",
      "2022-04-20 13:15:05.788415\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000583.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 53.1ms pre-process, 172.5ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8971 \tBbox: [ 514 \t 123 \t 625 \t 413 ]\n",
      "2 \tObject: person \tConfidence = 0.8885 \tBbox: [ 599 \t 0 \t 682 \t 132 ]\n",
      "3 \tObject: person \tConfidence = 0.8658 \tBbox: [ 410 \t 215 \t 526 \t 532 ]\n",
      "4 \tObject: train \tConfidence = 0.8196 \tBbox: [ 0 \t 1 \t 413 \t 811 ]\n",
      "5 \tObject: person \tConfidence = 0.814 \tBbox: [ 119 \t 448 \t 261 \t 858 ]\n",
      "6 \tObject: person \tConfidence = 0.8056 \tBbox: [ 1 \t 827 \t 252 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.7679 \tBbox: [ 205 \t 622 \t 432 \t 1080 ]\n",
      "8 \tObject: person \tConfidence = 0.7459 \tBbox: [ 495 \t 23 \t 572 \t 218 ]\n",
      "9 \tObject: person \tConfidence = 0.7272 \tBbox: [ 390 \t 0 \t 446 \t 149 ]\n",
      "10 \tObject: person \tConfidence = 0.7119 \tBbox: [ 323 \t 415 \t 474 \t 728 ]\n",
      "11 \tObject: person \tConfidence = 0.7043 \tBbox: [ 332 \t 181 \t 436 \t 430 ]\n",
      "12 \tObject: person \tConfidence = 0.5888 \tBbox: [ 450 \t 0 \t 506 \t 142 ]\n",
      "13 \tObject: person \tConfidence = 0.5113 \tBbox: [ 364 \t 100 \t 453 \t 243 ]\n",
      "14 \tObject: person \tConfidence = 0.3278 \tBbox: [ 368 \t 207 \t 427 \t 401 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000584 / 1050\n",
      "Frames to be processed: 466  | To do: 44.38 % | Done: 55.62 %\n",
      "\n",
      "2022-04-20 13:15:06.354646\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000584.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 38.3ms pre-process, 168.8ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8935 \tBbox: [ 518 \t 126 \t 628 \t 420 ]\n",
      "2 \tObject: person \tConfidence = 0.8688 \tBbox: [ 605 \t 0 \t 681 \t 131 ]\n",
      "3 \tObject: person \tConfidence = 0.8615 \tBbox: [ 409 \t 215 \t 524 \t 531 ]\n",
      "4 \tObject: person \tConfidence = 0.8004 \tBbox: [ 120 \t 448 \t 262 \t 859 ]\n",
      "5 \tObject: train \tConfidence = 0.7933 \tBbox: [ 1 \t 2 \t 403 \t 811 ]\n",
      "6 \tObject: person \tConfidence = 0.7795 \tBbox: [ 494 \t 24 \t 570 \t 219 ]\n",
      "7 \tObject: person \tConfidence = 0.7598 \tBbox: [ 323 \t 415 \t 471 \t 704 ]\n",
      "8 \tObject: person \tConfidence = 0.7518 \tBbox: [ 1 \t 828 \t 248 \t 1079 ]\n",
      "9 \tObject: person \tConfidence = 0.7281 \tBbox: [ 223 \t 625 \t 439 \t 1080 ]\n",
      "10 \tObject: person \tConfidence = 0.6829 \tBbox: [ 331 \t 178 \t 436 \t 431 ]\n",
      "11 \tObject: person \tConfidence = 0.6639 \tBbox: [ 390 \t 0 \t 446 \t 125 ]\n",
      "12 \tObject: person \tConfidence = 0.5974 \tBbox: [ 453 \t 0 \t 499 \t 142 ]\n",
      "13 \tObject: person \tConfidence = 0.5559 \tBbox: [ 377 \t 103 \t 462 \t 238 ]\n",
      "14 \tObject: person \tConfidence = 0.4886 \tBbox: [ 350 \t 72 \t 428 \t 159 ]\n",
      "15 \tObject: person \tConfidence = 0.3342 \tBbox: [ 368 \t 207 \t 427 \t 401 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000585 / 1050\n",
      "Frames to be processed: 465  | To do: 44.29 % | Done: 55.71 %\n",
      "\n",
      "2022-04-20 13:15:06.940871\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000585.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 25.3ms pre-process, 176.7ms inference, 14.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8991 \tBbox: [ 524 \t 130 \t 634 \t 423 ]\n",
      "2 \tObject: person \tConfidence = 0.8794 \tBbox: [ 409 \t 214 \t 523 \t 531 ]\n",
      "3 \tObject: person \tConfidence = 0.8519 \tBbox: [ 608 \t 0 \t 686 \t 131 ]\n",
      "4 \tObject: person \tConfidence = 0.8168 \tBbox: [ 1 \t 828 \t 258 \t 1079 ]\n",
      "5 \tObject: train \tConfidence = 0.8144 \tBbox: [ 0 \t 2 \t 396 \t 811 ]\n",
      "6 \tObject: person \tConfidence = 0.8041 \tBbox: [ 121 \t 449 \t 264 \t 856 ]\n",
      "7 \tObject: person \tConfidence = 0.7734 \tBbox: [ 494 \t 22 \t 569 \t 219 ]\n",
      "8 \tObject: person \tConfidence = 0.7576 \tBbox: [ 320 \t 414 \t 469 \t 700 ]\n",
      "9 \tObject: person \tConfidence = 0.746 \tBbox: [ 332 \t 183 \t 434 \t 433 ]\n",
      "10 \tObject: person \tConfidence = 0.6605 \tBbox: [ 378 \t 105 \t 466 \t 268 ]\n",
      "11 \tObject: person \tConfidence = 0.654 \tBbox: [ 391 \t 0 \t 447 \t 114 ]\n",
      "12 \tObject: person \tConfidence = 0.6513 \tBbox: [ 240 \t 629 \t 435 \t 1080 ]\n",
      "13 \tObject: person \tConfidence = 0.5755 \tBbox: [ 452 \t 0 \t 503 \t 142 ]\n",
      "14 \tObject: person \tConfidence = 0.5486 \tBbox: [ 363 \t 234 \t 428 \t 377 ]\n",
      "15 \tObject: person \tConfidence = 0.442 \tBbox: [ 354 \t 72 \t 422 \t 153 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000586 / 1050\n",
      "Frames to be processed: 464  | To do: 44.19 % | Done: 55.81 %\n",
      "\n",
      "2022-04-20 13:15:07.526679\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000586.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 25.1ms pre-process, 180.5ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8862 \tBbox: [ 409 \t 215 \t 524 \t 531 ]\n",
      "2 \tObject: person \tConfidence = 0.8781 \tBbox: [ 526 \t 133 \t 640 \t 427 ]\n",
      "3 \tObject: person \tConfidence = 0.8388 \tBbox: [ 319 \t 414 \t 469 \t 684 ]\n",
      "4 \tObject: person \tConfidence = 0.8259 \tBbox: [ 120 \t 449 \t 264 \t 856 ]\n",
      "5 \tObject: person \tConfidence = 0.8215 \tBbox: [ 1 \t 828 \t 259 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.7887 \tBbox: [ 498 \t 24 \t 567 \t 219 ]\n",
      "7 \tObject: person \tConfidence = 0.7826 \tBbox: [ 615 \t 0 \t 691 \t 132 ]\n",
      "8 \tObject: train \tConfidence = 0.7741 \tBbox: [ 1 \t 3 \t 386 \t 810 ]\n",
      "9 \tObject: person \tConfidence = 0.75 \tBbox: [ 241 \t 630 \t 451 \t 1080 ]\n",
      "10 \tObject: person \tConfidence = 0.7156 \tBbox: [ 331 \t 176 \t 434 \t 437 ]\n",
      "11 \tObject: person \tConfidence = 0.701 \tBbox: [ 390 \t 0 \t 449 \t 112 ]\n",
      "12 \tObject: person \tConfidence = 0.6467 \tBbox: [ 376 \t 105 \t 472 \t 268 ]\n",
      "13 \tObject: person \tConfidence = 0.5275 \tBbox: [ 365 \t 71 \t 431 \t 150 ]\n",
      "14 \tObject: person \tConfidence = 0.5256 \tBbox: [ 451 \t 1 \t 498 \t 142 ]\n",
      "15 \tObject: person \tConfidence = 0.5053 \tBbox: [ 366 \t 258 \t 426 \t 354 ]\n",
      "16 \tObject: person \tConfidence = 0.3252 \tBbox: [ 106 \t 441 \t 148 \t 567 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000587 / 1050\n",
      "Frames to be processed: 463  | To do: 44.1 % | Done: 55.9 %\n",
      "\n",
      "2022-04-20 13:15:08.082861\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000587.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 24.5ms pre-process, 178.9ms inference, 11.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8947 \tBbox: [ 318 \t 414 \t 467 \t 651 ]\n",
      "2 \tObject: person \tConfidence = 0.8649 \tBbox: [ 409 \t 217 \t 524 \t 531 ]\n",
      "3 \tObject: person \tConfidence = 0.8592 \tBbox: [ 287 \t 620 \t 528 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.8518 \tBbox: [ 541 \t 137 \t 649 \t 439 ]\n",
      "5 \tObject: person \tConfidence = 0.8471 \tBbox: [ 1 \t 831 \t 261 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.7878 \tBbox: [ 501 \t 25 \t 568 \t 220 ]\n",
      "7 \tObject: train \tConfidence = 0.7845 \tBbox: [ 0 \t 1 \t 388 \t 820 ]\n",
      "8 \tObject: person \tConfidence = 0.7405 \tBbox: [ 335 \t 180 \t 435 \t 445 ]\n",
      "9 \tObject: person \tConfidence = 0.6743 \tBbox: [ 379 \t 108 \t 488 \t 260 ]\n",
      "10 \tObject: person \tConfidence = 0.6596 \tBbox: [ 125 \t 447 \t 268 \t 879 ]\n",
      "11 \tObject: person \tConfidence = 0.4717 \tBbox: [ 371 \t 72 \t 451 \t 172 ]\n",
      "12 \tObject: person \tConfidence = 0.4691 \tBbox: [ 367 \t 266 \t 426 \t 347 ]\n",
      "13 \tObject: person \tConfidence = 0.4679 \tBbox: [ 392 \t 0 \t 449 \t 106 ]\n",
      "14 \tObject: person \tConfidence = 0.4581 \tBbox: [ 453 \t 0 \t 506 \t 141 ]\n",
      "15 \tObject: person \tConfidence = 0.4384 \tBbox: [ 642 \t 0 \t 696 \t 127 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000588 / 1050\n",
      "Frames to be processed: 462  | To do: 44.0 % | Done: 56.0 %\n",
      "\n",
      "2022-04-20 13:15:08.560293\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000588.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 23.8ms pre-process, 181.1ms inference, 3.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8674 \tBbox: [ 302 \t 621 \t 521 \t 1080 ]\n",
      "2 \tObject: person \tConfidence = 0.8659 \tBbox: [ 408 \t 213 \t 524 \t 531 ]\n",
      "3 \tObject: person \tConfidence = 0.8561 \tBbox: [ 1 \t 829 \t 261 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.8364 \tBbox: [ 545 \t 139 \t 656 \t 440 ]\n",
      "5 \tObject: person \tConfidence = 0.8237 \tBbox: [ 316 \t 413 \t 467 \t 653 ]\n",
      "6 \tObject: person \tConfidence = 0.7633 \tBbox: [ 499 \t 25 \t 570 \t 219 ]\n",
      "7 \tObject: train \tConfidence = 0.7564 \tBbox: [ 0 \t 3 \t 387 \t 852 ]\n",
      "8 \tObject: person \tConfidence = 0.7461 \tBbox: [ 335 \t 180 \t 435 \t 451 ]\n",
      "9 \tObject: person \tConfidence = 0.6026 \tBbox: [ 122 \t 448 \t 270 \t 894 ]\n",
      "10 \tObject: person \tConfidence = 0.595 \tBbox: [ 386 \t 110 \t 481 \t 258 ]\n",
      "11 \tObject: person \tConfidence = 0.3996 \tBbox: [ 455 \t 0 \t 503 \t 141 ]\n",
      "12 \tObject: person \tConfidence = 0.3943 \tBbox: [ 368 \t 268 \t 427 \t 344 ]\n",
      "13 \tObject: person \tConfidence = 0.3166 \tBbox: [ 392 \t 0 \t 437 \t 95 ]\n",
      "14 \tObject: person \tConfidence = 0.3002 \tBbox: [ 655 \t 0 \t 693 \t 126 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000589 / 1050\n",
      "Frames to be processed: 461  | To do: 43.9 % | Done: 56.1 %\n",
      "\n",
      "2022-04-20 13:15:09.058757\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000589.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 27.3ms pre-process, 181.4ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8817 \tBbox: [ 311 \t 623 \t 519 \t 1080 ]\n",
      "2 \tObject: person \tConfidence = 0.8767 \tBbox: [ 409 \t 210 \t 523 \t 531 ]\n",
      "3 \tObject: person \tConfidence = 0.8558 \tBbox: [ 556 \t 140 \t 665 \t 440 ]\n",
      "4 \tObject: person \tConfidence = 0.8421 \tBbox: [ 314 \t 413 \t 466 \t 652 ]\n",
      "5 \tObject: person \tConfidence = 0.8255 \tBbox: [ 1 \t 828 \t 260 \t 1079 ]\n",
      "6 \tObject: train \tConfidence = 0.7858 \tBbox: [ 0 \t 2 \t 394 \t 817 ]\n",
      "7 \tObject: person \tConfidence = 0.7641 \tBbox: [ 336 \t 182 \t 434 \t 453 ]\n",
      "8 \tObject: person \tConfidence = 0.7139 \tBbox: [ 499 \t 24 \t 568 \t 219 ]\n",
      "9 \tObject: person \tConfidence = 0.7121 \tBbox: [ 109 \t 447 \t 268 \t 862 ]\n",
      "10 \tObject: person \tConfidence = 0.617 \tBbox: [ 395 \t 111 \t 475 \t 257 ]\n",
      "11 \tObject: person \tConfidence = 0.4724 \tBbox: [ 0 \t 609 \t 114 \t 859 ]\n",
      "12 \tObject: person \tConfidence = 0.3891 \tBbox: [ 328 \t 146 \t 389 \t 283 ]\n",
      "13 \tObject: person \tConfidence = 0.383 \tBbox: [ 454 \t 0 \t 510 \t 141 ]\n",
      "14 \tObject: person \tConfidence = 0.3451 \tBbox: [ 391 \t 0 \t 438 \t 96 ]\n",
      "15 \tObject: person \tConfidence = 0.3028 \tBbox: [ 369 \t 268 \t 425 \t 344 ]\n",
      "16 \tObject: person \tConfidence = 0.3017 \tBbox: [ 552 \t 0 \t 584 \t 57 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000590 / 1050\n",
      "Frames to be processed: 460  | To do: 43.81 % | Done: 56.19 %\n",
      "\n",
      "2022-04-20 13:15:09.527020\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000590.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 30.3ms pre-process, 178.8ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8878 \tBbox: [ 408 \t 207 \t 522 \t 531 ]\n",
      "2 \tObject: person \tConfidence = 0.8658 \tBbox: [ 563 \t 141 \t 670 \t 439 ]\n",
      "3 \tObject: person \tConfidence = 0.8567 \tBbox: [ 327 \t 620 \t 533 \t 1080 ]\n",
      "4 \tObject: person \tConfidence = 0.8231 \tBbox: [ 114 \t 447 \t 268 \t 856 ]\n",
      "5 \tObject: person \tConfidence = 0.8086 \tBbox: [ 1 \t 829 \t 258 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.7884 \tBbox: [ 315 \t 411 \t 467 \t 677 ]\n",
      "7 \tObject: person \tConfidence = 0.7766 \tBbox: [ 336 \t 183 \t 434 \t 452 ]\n",
      "8 \tObject: person \tConfidence = 0.7629 \tBbox: [ 503 \t 23 \t 570 \t 218 ]\n",
      "9 \tObject: train \tConfidence = 0.7474 \tBbox: [ 0 \t 2 \t 391 \t 809 ]\n",
      "10 \tObject: person \tConfidence = 0.6445 \tBbox: [ 403 \t 111 \t 472 \t 256 ]\n",
      "11 \tObject: person \tConfidence = 0.516 \tBbox: [ 0 \t 600 \t 128 \t 857 ]\n",
      "12 \tObject: person \tConfidence = 0.5114 \tBbox: [ 328 \t 147 \t 390 \t 281 ]\n",
      "13 \tObject: person \tConfidence = 0.4499 \tBbox: [ 455 \t 0 \t 503 \t 141 ]\n",
      "14 \tObject: person \tConfidence = 0.3744 \tBbox: [ 391 \t 0 \t 439 \t 97 ]\n",
      "15 \tObject: person \tConfidence = 0.3537 \tBbox: [ 105 \t 442 \t 148 \t 565 ]\n",
      "16 \tObject: person \tConfidence = 0.3031 \tBbox: [ 556 \t 0 \t 581 \t 57 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000591 / 1050\n",
      "Frames to be processed: 459  | To do: 43.71 % | Done: 56.29 %\n",
      "\n",
      "2022-04-20 13:15:09.989054\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000591.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 24.9ms pre-process, 170.2ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8733 \tBbox: [ 335 \t 622 \t 553 \t 1080 ]\n",
      "2 \tObject: person \tConfidence = 0.8723 \tBbox: [ 408 \t 209 \t 522 \t 531 ]\n",
      "3 \tObject: person \tConfidence = 0.8602 \tBbox: [ 568 \t 141 \t 675 \t 440 ]\n",
      "4 \tObject: person \tConfidence = 0.8582 \tBbox: [ 314 \t 412 \t 466 \t 706 ]\n",
      "5 \tObject: person \tConfidence = 0.8093 \tBbox: [ 0 \t 627 \t 145 \t 855 ]\n",
      "6 \tObject: person \tConfidence = 0.8071 \tBbox: [ 125 \t 447 \t 270 \t 855 ]\n",
      "7 \tObject: person \tConfidence = 0.7786 \tBbox: [ 337 \t 182 \t 433 \t 453 ]\n",
      "8 \tObject: person \tConfidence = 0.7763 \tBbox: [ 0 \t 831 \t 254 \t 1079 ]\n",
      "9 \tObject: person \tConfidence = 0.7696 \tBbox: [ 500 \t 22 \t 572 \t 217 ]\n",
      "10 \tObject: train \tConfidence = 0.7688 \tBbox: [ 0 \t 2 \t 393 \t 730 ]\n",
      "11 \tObject: person \tConfidence = 0.6216 \tBbox: [ 406 \t 110 \t 489 \t 256 ]\n",
      "12 \tObject: person \tConfidence = 0.5322 \tBbox: [ 329 \t 146 \t 390 \t 281 ]\n",
      "13 \tObject: person \tConfidence = 0.4323 \tBbox: [ 455 \t 0 \t 515 \t 138 ]\n",
      "14 \tObject: person \tConfidence = 0.3746 \tBbox: [ 106 \t 442 \t 148 \t 565 ]\n",
      "15 \tObject: person \tConfidence = 0.3716 \tBbox: [ 391 \t 0 \t 439 \t 101 ]\n",
      "16 \tObject: person \tConfidence = 0.3634 \tBbox: [ 385 \t 80 \t 455 \t 201 ]\n",
      "17 \tObject: person \tConfidence = 0.3246 \tBbox: [ 285 \t 111 \t 329 \t 306 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000592 / 1050\n",
      "Frames to be processed: 458  | To do: 43.62 % | Done: 56.38 %\n",
      "\n",
      "2022-04-20 13:15:10.458813\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000592.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 37.8ms pre-process, 175.6ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9032 \tBbox: [ 353 \t 625 \t 608 \t 1080 ]\n",
      "2 \tObject: person \tConfidence = 0.8875 \tBbox: [ 411 \t 209 \t 521 \t 531 ]\n",
      "3 \tObject: person \tConfidence = 0.8571 \tBbox: [ 579 \t 141 \t 690 \t 440 ]\n",
      "4 \tObject: person \tConfidence = 0.8098 \tBbox: [ 503 \t 18 \t 574 \t 214 ]\n",
      "5 \tObject: person \tConfidence = 0.7938 \tBbox: [ 314 \t 412 \t 463 \t 795 ]\n",
      "6 \tObject: person \tConfidence = 0.7918 \tBbox: [ 0 \t 625 \t 171 \t 859 ]\n",
      "7 \tObject: person \tConfidence = 0.7914 \tBbox: [ 129 \t 447 \t 272 \t 854 ]\n",
      "8 \tObject: person \tConfidence = 0.77 \tBbox: [ 337 \t 182 \t 432 \t 453 ]\n",
      "9 \tObject: person \tConfidence = 0.7299 \tBbox: [ 413 \t 111 \t 518 \t 256 ]\n",
      "10 \tObject: train \tConfidence = 0.7292 \tBbox: [ 0 \t 2 \t 399 \t 700 ]\n",
      "11 \tObject: person \tConfidence = 0.7137 \tBbox: [ 1 \t 831 \t 253 \t 1079 ]\n",
      "12 \tObject: person \tConfidence = 0.5698 \tBbox: [ 329 \t 146 \t 392 \t 282 ]\n",
      "13 \tObject: person \tConfidence = 0.5319 \tBbox: [ 284 \t 96 \t 335 \t 328 ]\n",
      "14 \tObject: person \tConfidence = 0.4864 \tBbox: [ 391 \t 82 \t 466 \t 203 ]\n",
      "15 \tObject: person \tConfidence = 0.3927 \tBbox: [ 536 \t 0 \t 585 \t 56 ]\n",
      "16 \tObject: person \tConfidence = 0.387 \tBbox: [ 107 \t 441 \t 148 \t 565 ]\n",
      "17 \tObject: person \tConfidence = 0.3265 \tBbox: [ 391 \t 2 \t 438 \t 112 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000593 / 1050\n",
      "Frames to be processed: 457  | To do: 43.52 % | Done: 56.48 %\n",
      "\n",
      "2022-04-20 13:15:10.997751\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000593.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 35.5ms pre-process, 179.9ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8733 \tBbox: [ 410 \t 208 \t 519 \t 532 ]\n",
      "2 \tObject: person \tConfidence = 0.873 \tBbox: [ 353 \t 625 \t 630 \t 1080 ]\n",
      "3 \tObject: person \tConfidence = 0.8689 \tBbox: [ 583 \t 141 \t 696 \t 439 ]\n",
      "4 \tObject: person \tConfidence = 0.8397 \tBbox: [ 129 \t 447 \t 272 \t 854 ]\n",
      "5 \tObject: person \tConfidence = 0.815 \tBbox: [ 1 \t 624 \t 191 \t 912 ]\n",
      "6 \tObject: person \tConfidence = 0.8053 \tBbox: [ 503 \t 16 \t 575 \t 208 ]\n",
      "7 \tObject: person \tConfidence = 0.8015 \tBbox: [ 314 \t 412 \t 461 \t 791 ]\n",
      "8 \tObject: person \tConfidence = 0.7659 \tBbox: [ 339 \t 184 \t 430 \t 452 ]\n",
      "9 \tObject: person \tConfidence = 0.7462 \tBbox: [ 419 \t 113 \t 520 \t 256 ]\n",
      "10 \tObject: train \tConfidence = 0.7286 \tBbox: [ 0 \t 2 \t 395 \t 691 ]\n",
      "11 \tObject: person \tConfidence = 0.6816 \tBbox: [ 0 \t 833 \t 237 \t 1079 ]\n",
      "12 \tObject: person \tConfidence = 0.5911 \tBbox: [ 284 \t 93 \t 337 \t 332 ]\n",
      "13 \tObject: person \tConfidence = 0.5527 \tBbox: [ 539 \t 0 \t 586 \t 57 ]\n",
      "14 \tObject: person \tConfidence = 0.5441 \tBbox: [ 328 \t 146 \t 392 \t 287 ]\n",
      "15 \tObject: person \tConfidence = 0.4536 \tBbox: [ 394 \t 89 \t 466 \t 220 ]\n",
      "16 \tObject: person \tConfidence = 0.3983 \tBbox: [ 391 \t 1 \t 448 \t 114 ]\n",
      "17 \tObject: person \tConfidence = 0.3525 \tBbox: [ 107 \t 441 \t 148 \t 563 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000594 / 1050\n",
      "Frames to be processed: 456  | To do: 43.43 % | Done: 56.57 %\n",
      "\n",
      "2022-04-20 13:15:11.470208\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000594.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 32.4ms pre-process, 176.9ms inference, 3.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8936 \tBbox: [ 353 \t 628 \t 650 \t 1080 ]\n",
      "2 \tObject: person \tConfidence = 0.8885 \tBbox: [ 406 \t 208 \t 519 \t 529 ]\n",
      "3 \tObject: person \tConfidence = 0.8578 \tBbox: [ 315 \t 414 \t 459 \t 797 ]\n",
      "4 \tObject: person \tConfidence = 0.8417 \tBbox: [ 584 \t 141 \t 703 \t 438 ]\n",
      "5 \tObject: person \tConfidence = 0.7799 \tBbox: [ 501 \t 16 \t 574 \t 206 ]\n",
      "6 \tObject: person \tConfidence = 0.7679 \tBbox: [ 339 \t 184 \t 430 \t 451 ]\n",
      "7 \tObject: person \tConfidence = 0.7567 \tBbox: [ 426 \t 113 \t 527 \t 258 ]\n",
      "8 \tObject: person \tConfidence = 0.7317 \tBbox: [ 2 \t 621 \t 205 \t 933 ]\n",
      "9 \tObject: person \tConfidence = 0.7284 \tBbox: [ 128 \t 446 \t 271 \t 847 ]\n",
      "10 \tObject: person \tConfidence = 0.7149 \tBbox: [ 1 \t 833 \t 256 \t 1079 ]\n",
      "11 \tObject: train \tConfidence = 0.6951 \tBbox: [ 0 \t 2 \t 398 \t 673 ]\n",
      "12 \tObject: person \tConfidence = 0.6262 \tBbox: [ 285 \t 95 \t 339 \t 330 ]\n",
      "13 \tObject: person \tConfidence = 0.5638 \tBbox: [ 541 \t 0 \t 593 \t 57 ]\n",
      "14 \tObject: person \tConfidence = 0.4663 \tBbox: [ 329 \t 146 \t 392 \t 301 ]\n",
      "15 \tObject: person \tConfidence = 0.449 \tBbox: [ 389 \t 0 \t 447 \t 166 ]\n",
      "16 \tObject: person \tConfidence = 0.3358 \tBbox: [ 107 \t 441 \t 148 \t 561 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000595 / 1050\n",
      "Frames to be processed: 455  | To do: 43.33 % | Done: 56.67 %\n",
      "\n",
      "2022-04-20 13:15:12.005795\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000595.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 29.4ms pre-process, 178.5ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8884 \tBbox: [ 404 \t 206 \t 519 \t 528 ]\n",
      "2 \tObject: person \tConfidence = 0.8844 \tBbox: [ 355 \t 630 \t 665 \t 1080 ]\n",
      "3 \tObject: person \tConfidence = 0.8288 \tBbox: [ 589 \t 143 \t 708 \t 429 ]\n",
      "4 \tObject: person \tConfidence = 0.8232 \tBbox: [ 314 \t 414 \t 458 \t 828 ]\n",
      "5 \tObject: person \tConfidence = 0.7738 \tBbox: [ 4 \t 616 \t 216 \t 946 ]\n",
      "6 \tObject: person \tConfidence = 0.773 \tBbox: [ 505 \t 16 \t 571 \t 205 ]\n",
      "7 \tObject: person \tConfidence = 0.754 \tBbox: [ 338 \t 184 \t 432 \t 451 ]\n",
      "8 \tObject: person \tConfidence = 0.7324 \tBbox: [ 430 \t 114 \t 531 \t 261 ]\n",
      "9 \tObject: person \tConfidence = 0.686 \tBbox: [ 11 \t 836 \t 252 \t 1078 ]\n",
      "10 \tObject: train \tConfidence = 0.6408 \tBbox: [ 0 \t 3 \t 397 \t 676 ]\n",
      "11 \tObject: person \tConfidence = 0.6233 \tBbox: [ 128 \t 445 \t 271 \t 801 ]\n",
      "12 \tObject: person \tConfidence = 0.5378 \tBbox: [ 287 \t 127 \t 342 \t 323 ]\n",
      "13 \tObject: person \tConfidence = 0.5088 \tBbox: [ 545 \t 0 \t 597 \t 58 ]\n",
      "14 \tObject: person \tConfidence = 0.5024 \tBbox: [ 327 \t 147 \t 393 \t 286 ]\n",
      "15 \tObject: person \tConfidence = 0.4659 \tBbox: [ 389 \t 1 \t 448 \t 173 ]\n",
      "16 \tObject: person \tConfidence = 0.3355 \tBbox: [ 410 \t 101 \t 470 \t 239 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000596 / 1050\n",
      "Frames to be processed: 454  | To do: 43.24 % | Done: 56.76 %\n",
      "\n",
      "2022-04-20 13:15:12.511262\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000596.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 29.2ms pre-process, 178.5ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9121 \tBbox: [ 392 \t 2 \t 448 \t 146 ]\n",
      "2 \tObject: person \tConfidence = 0.8805 \tBbox: [ 401 \t 204 \t 519 \t 528 ]\n",
      "3 \tObject: person \tConfidence = 0.8619 \tBbox: [ 364 \t 630 \t 670 \t 1080 ]\n",
      "4 \tObject: person \tConfidence = 0.8407 \tBbox: [ 595 \t 144 \t 714 \t 436 ]\n",
      "5 \tObject: person \tConfidence = 0.8395 \tBbox: [ 315 \t 414 \t 459 \t 874 ]\n",
      "6 \tObject: person \tConfidence = 0.8105 \tBbox: [ 2 \t 613 \t 231 \t 952 ]\n",
      "7 \tObject: person \tConfidence = 0.7775 \tBbox: [ 129 \t 446 \t 270 \t 727 ]\n",
      "8 \tObject: person \tConfidence = 0.7296 \tBbox: [ 504 \t 14 \t 573 \t 204 ]\n",
      "9 \tObject: person \tConfidence = 0.716 \tBbox: [ 5 \t 836 \t 251 \t 1078 ]\n",
      "10 \tObject: person \tConfidence = 0.7111 \tBbox: [ 341 \t 184 \t 431 \t 452 ]\n",
      "11 \tObject: person \tConfidence = 0.7049 \tBbox: [ 430 \t 116 \t 538 \t 264 ]\n",
      "12 \tObject: train \tConfidence = 0.6241 \tBbox: [ 0 \t 3 \t 418 \t 668 ]\n",
      "13 \tObject: person \tConfidence = 0.5698 \tBbox: [ 549 \t 0 \t 601 \t 59 ]\n",
      "14 \tObject: person \tConfidence = 0.4235 \tBbox: [ 329 \t 147 \t 393 \t 277 ]\n",
      "15 \tObject: person \tConfidence = 0.4181 \tBbox: [ 415 \t 86 \t 483 \t 239 ]\n",
      "16 \tObject: person \tConfidence = 0.3437 \tBbox: [ 288 \t 127 \t 347 \t 318 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000597 / 1050\n",
      "Frames to be processed: 453  | To do: 43.14 % | Done: 56.86 %\n",
      "\n",
      "2022-04-20 13:15:13.016341\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000597.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 26.8ms pre-process, 181.6ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8612 \tBbox: [ 393 \t 622 \t 694 \t 1080 ]\n",
      "2 \tObject: person \tConfidence = 0.8611 \tBbox: [ 603 \t 150 \t 727 \t 450 ]\n",
      "3 \tObject: person \tConfidence = 0.8604 \tBbox: [ 391 \t 2 \t 449 \t 156 ]\n",
      "4 \tObject: person \tConfidence = 0.8406 \tBbox: [ 400 \t 201 \t 522 \t 529 ]\n",
      "5 \tObject: person \tConfidence = 0.8367 \tBbox: [ 317 \t 416 \t 463 \t 878 ]\n",
      "6 \tObject: person \tConfidence = 0.8344 \tBbox: [ 129 \t 446 \t 272 \t 721 ]\n",
      "7 \tObject: person \tConfidence = 0.8342 \tBbox: [ 12 \t 606 \t 250 \t 959 ]\n",
      "8 \tObject: person \tConfidence = 0.728 \tBbox: [ 502 \t 7 \t 575 \t 210 ]\n",
      "9 \tObject: person \tConfidence = 0.7109 \tBbox: [ 0 \t 837 \t 232 \t 1079 ]\n",
      "10 \tObject: person \tConfidence = 0.6868 \tBbox: [ 340 \t 180 \t 429 \t 454 ]\n",
      "11 \tObject: train \tConfidence = 0.6048 \tBbox: [ 0 \t 4 \t 396 \t 682 ]\n",
      "12 \tObject: person \tConfidence = 0.6032 \tBbox: [ 454 \t 119 \t 555 \t 383 ]\n",
      "13 \tObject: person \tConfidence = 0.5853 \tBbox: [ 290 \t 118 \t 352 \t 334 ]\n",
      "14 \tObject: person \tConfidence = 0.4866 \tBbox: [ 556 \t 0 \t 607 \t 64 ]\n",
      "15 \tObject: person \tConfidence = 0.4812 \tBbox: [ 427 \t 87 \t 492 \t 217 ]\n",
      "16 \tObject: person \tConfidence = 0.4806 \tBbox: [ 329 \t 147 \t 392 \t 272 ]\n",
      "17 \tObject: person \tConfidence = 0.3208 \tBbox: [ 0 \t 492 \t 76 \t 824 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000598 / 1050\n",
      "Frames to be processed: 452  | To do: 43.05 % | Done: 56.95 %\n",
      "\n",
      "2022-04-20 13:15:13.496380\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000598.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 29.9ms pre-process, 180.5ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8723 \tBbox: [ 607 \t 154 \t 739 \t 458 ]\n",
      "2 \tObject: person \tConfidence = 0.8606 \tBbox: [ 128 \t 446 \t 272 \t 714 ]\n",
      "3 \tObject: person \tConfidence = 0.842 \tBbox: [ 398 \t 200 \t 521 \t 528 ]\n",
      "4 \tObject: person \tConfidence = 0.8384 \tBbox: [ 318 \t 417 \t 465 \t 878 ]\n",
      "5 \tObject: person \tConfidence = 0.8376 \tBbox: [ 432 \t 620 \t 697 \t 1080 ]\n",
      "6 \tObject: person \tConfidence = 0.8148 \tBbox: [ 12 \t 606 \t 258 \t 962 ]\n",
      "7 \tObject: person \tConfidence = 0.7319 \tBbox: [ 458 \t 119 \t 564 \t 390 ]\n",
      "8 \tObject: person \tConfidence = 0.7159 \tBbox: [ 505 \t 8 \t 574 \t 211 ]\n",
      "9 \tObject: train \tConfidence = 0.686 \tBbox: [ 0 \t 3 \t 388 \t 704 ]\n",
      "10 \tObject: person \tConfidence = 0.678 \tBbox: [ 339 \t 181 \t 427 \t 453 ]\n",
      "11 \tObject: person \tConfidence = 0.6544 \tBbox: [ 392 \t 2 \t 447 \t 155 ]\n",
      "12 \tObject: person \tConfidence = 0.6539 \tBbox: [ 0 \t 837 \t 224 \t 1079 ]\n",
      "13 \tObject: person \tConfidence = 0.5776 \tBbox: [ 329 \t 147 \t 392 \t 275 ]\n",
      "14 \tObject: person \tConfidence = 0.5634 \tBbox: [ 429 \t 84 \t 499 \t 210 ]\n",
      "15 \tObject: person \tConfidence = 0.5603 \tBbox: [ 293 \t 110 \t 353 \t 348 ]\n",
      "16 \tObject: person \tConfidence = 0.4017 \tBbox: [ 556 \t 0 \t 608 \t 77 ]\n",
      "17 \tObject: person \tConfidence = 0.3648 \tBbox: [ 0 \t 514 \t 84 \t 825 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000599 / 1050\n",
      "Frames to be processed: 451  | To do: 42.95 % | Done: 57.05 %\n",
      "\n",
      "2022-04-20 13:15:14.011487\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000599.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 23.6ms pre-process, 177.9ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8899 \tBbox: [ 611 \t 156 \t 749 \t 465 ]\n",
      "2 \tObject: person \tConfidence = 0.871 \tBbox: [ 127 \t 446 \t 270 \t 704 ]\n",
      "3 \tObject: person \tConfidence = 0.8582 \tBbox: [ 395 \t 201 \t 518 \t 528 ]\n",
      "4 \tObject: person \tConfidence = 0.8178 \tBbox: [ 318 \t 418 \t 468 \t 880 ]\n",
      "5 \tObject: person \tConfidence = 0.8024 \tBbox: [ 467 \t 120 \t 568 \t 398 ]\n",
      "6 \tObject: person \tConfidence = 0.7721 \tBbox: [ 459 \t 616 \t 707 \t 1080 ]\n",
      "7 \tObject: person \tConfidence = 0.7478 \tBbox: [ 32 \t 607 \t 265 \t 967 ]\n",
      "8 \tObject: person \tConfidence = 0.688 \tBbox: [ 0 \t 838 \t 225 \t 1079 ]\n",
      "9 \tObject: person \tConfidence = 0.6675 \tBbox: [ 392 \t 2 \t 447 \t 154 ]\n",
      "10 \tObject: train \tConfidence = 0.6639 \tBbox: [ 0 \t 3 \t 386 \t 693 ]\n",
      "11 \tObject: person \tConfidence = 0.6325 \tBbox: [ 339 \t 180 \t 424 \t 453 ]\n",
      "12 \tObject: person \tConfidence = 0.5756 \tBbox: [ 293 \t 103 \t 354 \t 338 ]\n",
      "13 \tObject: person \tConfidence = 0.5658 \tBbox: [ 500 \t 4 \t 575 \t 211 ]\n",
      "14 \tObject: person \tConfidence = 0.4234 \tBbox: [ 432 \t 86 \t 505 \t 213 ]\n",
      "15 \tObject: person \tConfidence = 0.4188 \tBbox: [ 327 \t 146 \t 393 \t 290 ]\n",
      "16 \tObject: person \tConfidence = 0.4004 \tBbox: [ 0 \t 514 \t 91 \t 827 ]\n",
      "17 \tObject: person \tConfidence = 0.3291 \tBbox: [ 558 \t 0 \t 608 \t 81 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000600 / 1050\n",
      "Frames to be processed: 450  | To do: 42.86 % | Done: 57.14 %\n",
      "\n",
      "2022-04-20 13:15:14.496866\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000600.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 17 persons, 1 train\n",
      "Speed: 27.0ms pre-process, 180.6ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 18 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8909 \tBbox: [ 127 \t 447 \t 275 \t 693 ]\n",
      "2 \tObject: person \tConfidence = 0.8853 \tBbox: [ 614 \t 159 \t 752 \t 467 ]\n",
      "3 \tObject: person \tConfidence = 0.8747 \tBbox: [ 395 \t 204 \t 516 \t 524 ]\n",
      "4 \tObject: person \tConfidence = 0.8257 \tBbox: [ 473 \t 121 \t 568 \t 400 ]\n",
      "5 \tObject: person \tConfidence = 0.8247 \tBbox: [ 319 \t 420 \t 468 \t 875 ]\n",
      "6 \tObject: person \tConfidence = 0.8146 \tBbox: [ 496 \t 616 \t 725 \t 1080 ]\n",
      "7 \tObject: person \tConfidence = 0.7724 \tBbox: [ 48 \t 609 \t 279 \t 1009 ]\n",
      "8 \tObject: person \tConfidence = 0.6568 \tBbox: [ 392 \t 2 \t 447 \t 153 ]\n",
      "9 \tObject: train \tConfidence = 0.6542 \tBbox: [ 0 \t 3 \t 385 \t 718 ]\n",
      "10 \tObject: person \tConfidence = 0.6439 \tBbox: [ 1 \t 837 \t 216 \t 1079 ]\n",
      "11 \tObject: person \tConfidence = 0.6171 \tBbox: [ 337 \t 179 \t 424 \t 453 ]\n",
      "12 \tObject: person \tConfidence = 0.5228 \tBbox: [ 436 \t 85 \t 510 \t 212 ]\n",
      "13 \tObject: person \tConfidence = 0.493 \tBbox: [ 506 \t 13 \t 579 \t 197 ]\n",
      "14 \tObject: person \tConfidence = 0.4087 \tBbox: [ 0 \t 509 \t 98 \t 836 ]\n",
      "15 \tObject: person \tConfidence = 0.3729 \tBbox: [ 563 \t 0 \t 611 \t 86 ]\n",
      "16 \tObject: person \tConfidence = 0.3418 \tBbox: [ 292 \t 97 \t 355 \t 322 ]\n",
      "17 \tObject: person \tConfidence = 0.3282 \tBbox: [ 319 \t 141 \t 392 \t 350 ]\n",
      "18 \tObject: person \tConfidence = 0.3006 \tBbox: [ 448 \t 0 \t 506 \t 97 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    17\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000601 / 1050\n",
      "Frames to be processed: 449  | To do: 42.76 % | Done: 57.24 %\n",
      "\n",
      "2022-04-20 13:15:15.013874\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000601.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 45.0ms pre-process, 179.4ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8741 \tBbox: [ 394 \t 205 \t 517 \t 522 ]\n",
      "2 \tObject: person \tConfidence = 0.8723 \tBbox: [ 126 \t 447 \t 272 \t 681 ]\n",
      "3 \tObject: person \tConfidence = 0.8439 \tBbox: [ 319 \t 420 \t 468 \t 876 ]\n",
      "4 \tObject: person \tConfidence = 0.8353 \tBbox: [ 616 \t 162 \t 754 \t 480 ]\n",
      "5 \tObject: person \tConfidence = 0.8097 \tBbox: [ 521 \t 615 \t 743 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.7792 \tBbox: [ 57 \t 612 \t 287 \t 1014 ]\n",
      "7 \tObject: person \tConfidence = 0.7639 \tBbox: [ 477 \t 120 \t 570 \t 403 ]\n",
      "8 \tObject: train \tConfidence = 0.7148 \tBbox: [ 0 \t 3 \t 379 \t 704 ]\n",
      "9 \tObject: person \tConfidence = 0.6484 \tBbox: [ 0 \t 843 \t 227 \t 1079 ]\n",
      "10 \tObject: person \tConfidence = 0.6027 \tBbox: [ 392 \t 3 \t 447 \t 153 ]\n",
      "11 \tObject: person \tConfidence = 0.5998 \tBbox: [ 509 \t 14 \t 586 \t 188 ]\n",
      "12 \tObject: person \tConfidence = 0.5922 \tBbox: [ 337 \t 178 \t 422 \t 453 ]\n",
      "13 \tObject: person \tConfidence = 0.468 \tBbox: [ 321 \t 142 \t 394 \t 344 ]\n",
      "14 \tObject: person \tConfidence = 0.4561 \tBbox: [ 0 \t 507 \t 110 \t 844 ]\n",
      "15 \tObject: person \tConfidence = 0.4105 \tBbox: [ 444 \t 88 \t 516 \t 215 ]\n",
      "16 \tObject: person \tConfidence = 0.3758 \tBbox: [ 565 \t 0 \t 618 \t 89 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000602 / 1050\n",
      "Frames to be processed: 448  | To do: 42.67 % | Done: 57.33 %\n",
      "\n",
      "2022-04-20 13:15:15.551573\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000602.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 18 persons, 1 train\n",
      "Speed: 24.5ms pre-process, 175.6ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 19 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8995 \tBbox: [ 318 \t 423 \t 468 \t 878 ]\n",
      "2 \tObject: person \tConfidence = 0.8918 \tBbox: [ 125 \t 447 \t 261 \t 660 ]\n",
      "3 \tObject: person \tConfidence = 0.8683 \tBbox: [ 393 \t 204 \t 518 \t 521 ]\n",
      "4 \tObject: person \tConfidence = 0.8258 \tBbox: [ 490 \t 127 \t 576 \t 404 ]\n",
      "5 \tObject: person \tConfidence = 0.8178 \tBbox: [ 552 \t 619 \t 766 \t 1080 ]\n",
      "6 \tObject: person \tConfidence = 0.8177 \tBbox: [ 92 \t 622 \t 305 \t 1077 ]\n",
      "7 \tObject: person \tConfidence = 0.7816 \tBbox: [ 636 \t 168 \t 764 \t 483 ]\n",
      "8 \tObject: person \tConfidence = 0.7528 \tBbox: [ 0 \t 509 \t 132 \t 855 ]\n",
      "9 \tObject: train \tConfidence = 0.7081 \tBbox: [ 0 \t 3 \t 391 \t 687 ]\n",
      "10 \tObject: person \tConfidence = 0.6648 \tBbox: [ 347 \t 187 \t 425 \t 462 ]\n",
      "11 \tObject: person \tConfidence = 0.6341 \tBbox: [ 0 \t 843 \t 220 \t 1079 ]\n",
      "12 \tObject: person \tConfidence = 0.606 \tBbox: [ 454 \t 86 \t 523 \t 260 ]\n",
      "13 \tObject: person \tConfidence = 0.5817 \tBbox: [ 391 \t 1 \t 451 \t 152 ]\n",
      "14 \tObject: person \tConfidence = 0.4707 \tBbox: [ 326 \t 146 \t 395 \t 287 ]\n",
      "15 \tObject: person \tConfidence = 0.4608 \tBbox: [ 570 \t 0 \t 623 \t 110 ]\n",
      "16 \tObject: person \tConfidence = 0.3733 \tBbox: [ 451 \t 0 \t 516 \t 101 ]\n",
      "17 \tObject: person \tConfidence = 0.3184 \tBbox: [ 395 \t 255 \t 502 \t 395 ]\n",
      "18 \tObject: person \tConfidence = 0.3146 \tBbox: [ 319 \t 111 \t 360 \t 225 ]\n",
      "19 \tObject: person \tConfidence = 0.314 \tBbox: [ 513 \t 14 \t 581 \t 140 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    18\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000603 / 1050\n",
      "Frames to be processed: 447  | To do: 42.57 % | Done: 57.43 %\n",
      "\n",
      "2022-04-20 13:15:16.027639\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000603.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 17 persons, 1 train\n",
      "Speed: 30.7ms pre-process, 176.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 18 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8925 \tBbox: [ 318 \t 424 \t 467 \t 877 ]\n",
      "2 \tObject: person \tConfidence = 0.8701 \tBbox: [ 126 \t 449 \t 261 \t 666 ]\n",
      "3 \tObject: person \tConfidence = 0.8618 \tBbox: [ 392 \t 205 \t 514 \t 521 ]\n",
      "4 \tObject: person \tConfidence = 0.8011 \tBbox: [ 104 \t 626 \t 319 \t 1080 ]\n",
      "5 \tObject: person \tConfidence = 0.7938 \tBbox: [ 491 \t 127 \t 582 \t 405 ]\n",
      "6 \tObject: person \tConfidence = 0.7687 \tBbox: [ 555 \t 621 \t 766 \t 1080 ]\n",
      "7 \tObject: person \tConfidence = 0.7069 \tBbox: [ 650 \t 169 \t 765 \t 484 ]\n",
      "8 \tObject: person \tConfidence = 0.6504 \tBbox: [ 0 \t 512 \t 145 \t 859 ]\n",
      "9 \tObject: train \tConfidence = 0.6379 \tBbox: [ 0 \t 3 \t 392 \t 685 ]\n",
      "10 \tObject: person \tConfidence = 0.6323 \tBbox: [ 347 \t 187 \t 424 \t 462 ]\n",
      "11 \tObject: person \tConfidence = 0.6277 \tBbox: [ 458 \t 93 \t 526 \t 260 ]\n",
      "12 \tObject: person \tConfidence = 0.5895 \tBbox: [ 1 \t 846 \t 176 \t 1079 ]\n",
      "13 \tObject: person \tConfidence = 0.5337 \tBbox: [ 391 \t 1 \t 452 \t 153 ]\n",
      "14 \tObject: person \tConfidence = 0.454 \tBbox: [ 572 \t 0 \t 629 \t 111 ]\n",
      "15 \tObject: person \tConfidence = 0.3905 \tBbox: [ 326 \t 146 \t 396 \t 280 ]\n",
      "16 \tObject: person \tConfidence = 0.3838 \tBbox: [ 452 \t 0 \t 519 \t 105 ]\n",
      "17 \tObject: person \tConfidence = 0.3519 \tBbox: [ 500 \t 13 \t 573 \t 135 ]\n",
      "18 \tObject: person \tConfidence = 0.3046 \tBbox: [ 292 \t 104 \t 343 \t 329 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    17\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000604 / 1050\n",
      "Frames to be processed: 446  | To do: 42.48 % | Done: 57.52 %\n",
      "\n",
      "2022-04-20 13:15:16.551584\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000604.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 17 persons, 1 train\n",
      "Speed: 29.2ms pre-process, 178.3ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 18 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.877 \tBbox: [ 318 \t 425 \t 467 \t 873 ]\n",
      "2 \tObject: person \tConfidence = 0.8512 \tBbox: [ 391 \t 205 \t 512 \t 520 ]\n",
      "3 \tObject: person \tConfidence = 0.8469 \tBbox: [ 126 \t 450 \t 260 \t 687 ]\n",
      "4 \tObject: person \tConfidence = 0.833 \tBbox: [ 664 \t 170 \t 765 \t 484 ]\n",
      "5 \tObject: person \tConfidence = 0.8087 \tBbox: [ 494 \t 129 \t 586 \t 405 ]\n",
      "6 \tObject: person \tConfidence = 0.8007 \tBbox: [ 117 \t 633 \t 341 \t 1080 ]\n",
      "7 \tObject: person \tConfidence = 0.7849 \tBbox: [ 0 \t 519 \t 159 \t 864 ]\n",
      "8 \tObject: person \tConfidence = 0.6822 \tBbox: [ 461 \t 95 \t 532 \t 261 ]\n",
      "9 \tObject: train \tConfidence = 0.6274 \tBbox: [ 0 \t 3 \t 395 \t 682 ]\n",
      "10 \tObject: person \tConfidence = 0.5797 \tBbox: [ 577 \t 0 \t 630 \t 108 ]\n",
      "11 \tObject: person \tConfidence = 0.5621 \tBbox: [ 336 \t 173 \t 421 \t 461 ]\n",
      "12 \tObject: person \tConfidence = 0.5063 \tBbox: [ 392 \t 1 \t 452 \t 153 ]\n",
      "13 \tObject: person \tConfidence = 0.4957 \tBbox: [ 1 \t 846 \t 148 \t 1079 ]\n",
      "14 \tObject: person \tConfidence = 0.4951 \tBbox: [ 504 \t 14 \t 581 \t 132 ]\n",
      "15 \tObject: person \tConfidence = 0.4802 \tBbox: [ 556 \t 626 \t 766 \t 1080 ]\n",
      "16 \tObject: person \tConfidence = 0.3925 \tBbox: [ 451 \t 0 \t 518 \t 107 ]\n",
      "17 \tObject: person \tConfidence = 0.3508 \tBbox: [ 293 \t 102 \t 349 \t 324 ]\n",
      "18 \tObject: person \tConfidence = 0.3245 \tBbox: [ 74 \t 866 \t 223 \t 1079 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    17\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000605 / 1050\n",
      "Frames to be processed: 445  | To do: 42.38 % | Done: 57.62 %\n",
      "\n",
      "2022-04-20 13:15:17.059734\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000605.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 25.9ms pre-process, 174.9ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8717 \tBbox: [ 319 \t 426 \t 468 \t 877 ]\n",
      "2 \tObject: person \tConfidence = 0.8625 \tBbox: [ 123 \t 450 \t 263 \t 692 ]\n",
      "3 \tObject: person \tConfidence = 0.8396 \tBbox: [ 389 \t 203 \t 513 \t 521 ]\n",
      "4 \tObject: person \tConfidence = 0.7915 \tBbox: [ 494 \t 131 \t 588 \t 405 ]\n",
      "5 \tObject: person \tConfidence = 0.7706 \tBbox: [ 0 \t 523 \t 170 \t 888 ]\n",
      "6 \tObject: person \tConfidence = 0.7634 \tBbox: [ 670 \t 171 \t 765 \t 486 ]\n",
      "7 \tObject: person \tConfidence = 0.7568 \tBbox: [ 130 \t 636 \t 361 \t 1080 ]\n",
      "8 \tObject: train \tConfidence = 0.7126 \tBbox: [ 1 \t 2 \t 396 \t 659 ]\n",
      "9 \tObject: person \tConfidence = 0.5861 \tBbox: [ 334 \t 178 \t 421 \t 457 ]\n",
      "10 \tObject: person \tConfidence = 0.5244 \tBbox: [ 1 \t 847 \t 146 \t 1079 ]\n",
      "11 \tObject: person \tConfidence = 0.4829 \tBbox: [ 578 \t 0 \t 637 \t 108 ]\n",
      "12 \tObject: person \tConfidence = 0.478 \tBbox: [ 465 \t 98 \t 535 \t 264 ]\n",
      "13 \tObject: person \tConfidence = 0.4291 \tBbox: [ 391 \t 1 \t 450 \t 153 ]\n",
      "14 \tObject: person \tConfidence = 0.3773 \tBbox: [ 499 \t 15 \t 573 \t 134 ]\n",
      "15 \tObject: person \tConfidence = 0.349 \tBbox: [ 294 \t 101 \t 355 \t 319 ]\n",
      "16 \tObject: person \tConfidence = 0.3394 \tBbox: [ 557 \t 630 \t 766 \t 1080 ]\n",
      "17 \tObject: person \tConfidence = 0.3347 \tBbox: [ 321 \t 140 \t 395 \t 346 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000606 / 1050\n",
      "Frames to be processed: 444  | To do: 42.29 % | Done: 57.71 %\n",
      "\n",
      "2022-04-20 13:15:17.600757\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000606.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 17 persons, 1 train\n",
      "Speed: 40.7ms pre-process, 177.2ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 18 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.861 \tBbox: [ 318 \t 427 \t 465 \t 876 ]\n",
      "2 \tObject: person \tConfidence = 0.8533 \tBbox: [ 148 \t 641 \t 363 \t 1080 ]\n",
      "3 \tObject: person \tConfidence = 0.8469 \tBbox: [ 122 \t 451 \t 255 \t 698 ]\n",
      "4 \tObject: person \tConfidence = 0.839 \tBbox: [ 389 \t 203 \t 513 \t 520 ]\n",
      "5 \tObject: person \tConfidence = 0.8088 \tBbox: [ 0 \t 526 \t 179 \t 929 ]\n",
      "6 \tObject: person \tConfidence = 0.7388 \tBbox: [ 676 \t 172 \t 765 \t 488 ]\n",
      "7 \tObject: person \tConfidence = 0.7384 \tBbox: [ 499 \t 129 \t 592 \t 405 ]\n",
      "8 \tObject: train \tConfidence = 0.6756 \tBbox: [ 1 \t 2 \t 394 \t 627 ]\n",
      "9 \tObject: person \tConfidence = 0.5957 \tBbox: [ 470 \t 98 \t 542 \t 267 ]\n",
      "10 \tObject: person \tConfidence = 0.5675 \tBbox: [ 340 \t 186 \t 421 \t 463 ]\n",
      "11 \tObject: person \tConfidence = 0.5215 \tBbox: [ 577 \t 0 \t 642 \t 108 ]\n",
      "12 \tObject: person \tConfidence = 0.4577 \tBbox: [ 294 \t 99 \t 357 \t 315 ]\n",
      "13 \tObject: person \tConfidence = 0.4467 \tBbox: [ 325 \t 144 \t 391 \t 300 ]\n",
      "14 \tObject: person \tConfidence = 0.4313 \tBbox: [ 392 \t 2 \t 449 \t 153 ]\n",
      "15 \tObject: person \tConfidence = 0.4085 \tBbox: [ 349 \t 95 \t 404 \t 187 ]\n",
      "16 \tObject: person \tConfidence = 0.3402 \tBbox: [ 496 \t 15 \t 569 \t 137 ]\n",
      "17 \tObject: person \tConfidence = 0.3325 \tBbox: [ 1 \t 849 \t 142 \t 1079 ]\n",
      "18 \tObject: person \tConfidence = 0.3312 \tBbox: [ 561 \t 641 \t 765 \t 1079 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    17\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000607 / 1050\n",
      "Frames to be processed: 443  | To do: 42.19 % | Done: 57.81 %\n",
      "\n",
      "2022-04-20 13:15:18.126498\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000607.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 24.7ms pre-process, 170.0ms inference, 14.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8361 \tBbox: [ 1 \t 530 \t 197 \t 956 ]\n",
      "2 \tObject: person \tConfidence = 0.8307 \tBbox: [ 388 \t 203 \t 509 \t 519 ]\n",
      "3 \tObject: person \tConfidence = 0.7618 \tBbox: [ 121 \t 454 \t 256 \t 725 ]\n",
      "4 \tObject: person \tConfidence = 0.734 \tBbox: [ 318 \t 429 \t 463 \t 816 ]\n",
      "5 \tObject: person \tConfidence = 0.7188 \tBbox: [ 178 \t 643 \t 377 \t 1080 ]\n",
      "6 \tObject: person \tConfidence = 0.7173 \tBbox: [ 515 \t 132 \t 601 \t 408 ]\n",
      "7 \tObject: train \tConfidence = 0.6435 \tBbox: [ 0 \t 3 \t 400 \t 602 ]\n",
      "8 \tObject: person \tConfidence = 0.6157 \tBbox: [ 360 \t 93 \t 424 \t 221 ]\n",
      "9 \tObject: person \tConfidence = 0.5982 \tBbox: [ 302 \t 97 \t 367 \t 298 ]\n",
      "10 \tObject: person \tConfidence = 0.5684 \tBbox: [ 686 \t 170 \t 766 \t 521 ]\n",
      "11 \tObject: person \tConfidence = 0.5469 \tBbox: [ 0 \t 854 \t 207 \t 1078 ]\n",
      "12 \tObject: person \tConfidence = 0.5454 \tBbox: [ 481 \t 111 \t 559 \t 405 ]\n",
      "13 \tObject: person \tConfidence = 0.5121 \tBbox: [ 345 \t 187 \t 418 \t 462 ]\n",
      "14 \tObject: person \tConfidence = 0.4845 \tBbox: [ 578 \t 1 \t 646 \t 109 ]\n",
      "15 \tObject: person \tConfidence = 0.431 \tBbox: [ 393 \t 1 \t 450 \t 152 ]\n",
      "16 \tObject: person \tConfidence = 0.3086 \tBbox: [ 324 \t 145 \t 402 \t 322 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000608 / 1050\n",
      "Frames to be processed: 442  | To do: 42.1 % | Done: 57.9 %\n",
      "\n",
      "2022-04-20 13:15:18.725692\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000608.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 17 persons, 1 train\n",
      "Speed: 32.8ms pre-process, 167.2ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 18 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8943 \tBbox: [ 394 \t 0 \t 451 \t 152 ]\n",
      "2 \tObject: person \tConfidence = 0.8429 \tBbox: [ 122 \t 456 \t 258 \t 704 ]\n",
      "3 \tObject: person \tConfidence = 0.8369 \tBbox: [ 386 \t 203 \t 513 \t 516 ]\n",
      "4 \tObject: person \tConfidence = 0.7846 \tBbox: [ 0 \t 532 \t 208 \t 962 ]\n",
      "5 \tObject: person \tConfidence = 0.7609 \tBbox: [ 317 \t 430 \t 461 \t 783 ]\n",
      "6 \tObject: person \tConfidence = 0.7539 \tBbox: [ 190 \t 646 \t 396 \t 1080 ]\n",
      "7 \tObject: person \tConfidence = 0.7152 \tBbox: [ 521 \t 130 \t 607 \t 415 ]\n",
      "8 \tObject: person \tConfidence = 0.6974 \tBbox: [ 366 \t 92 \t 426 \t 220 ]\n",
      "9 \tObject: train \tConfidence = 0.6417 \tBbox: [ 0 \t 3 \t 407 \t 630 ]\n",
      "10 \tObject: person \tConfidence = 0.5643 \tBbox: [ 694 \t 177 \t 765 \t 515 ]\n",
      "11 \tObject: person \tConfidence = 0.5612 \tBbox: [ 485 \t 107 \t 565 \t 410 ]\n",
      "12 \tObject: person \tConfidence = 0.5599 \tBbox: [ 340 \t 187 \t 419 \t 461 ]\n",
      "13 \tObject: person \tConfidence = 0.5595 \tBbox: [ 304 \t 97 \t 371 \t 277 ]\n",
      "14 \tObject: person \tConfidence = 0.5394 \tBbox: [ 580 \t 0 \t 648 \t 111 ]\n",
      "15 \tObject: person \tConfidence = 0.5191 \tBbox: [ 1 \t 858 \t 201 \t 1078 ]\n",
      "16 \tObject: person \tConfidence = 0.4749 \tBbox: [ 326 \t 145 \t 393 \t 296 ]\n",
      "17 \tObject: person \tConfidence = 0.4652 \tBbox: [ 447 \t 0 \t 505 \t 152 ]\n",
      "18 \tObject: person \tConfidence = 0.3549 \tBbox: [ 566 \t 665 \t 765 \t 1076 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    17\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000609 / 1050\n",
      "Frames to be processed: 441  | To do: 42.0 % | Done: 58.0 %\n",
      "\n",
      "2022-04-20 13:15:19.225879\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000609.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 18 persons, 1 train\n",
      "Speed: 52.6ms pre-process, 181.0ms inference, 10.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 19 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8537 \tBbox: [ 317 \t 429 \t 461 \t 773 ]\n",
      "2 \tObject: person \tConfidence = 0.8436 \tBbox: [ 193 \t 648 \t 408 \t 1079 ]\n",
      "3 \tObject: person \tConfidence = 0.8423 \tBbox: [ 122 \t 456 \t 263 \t 720 ]\n",
      "4 \tObject: person \tConfidence = 0.824 \tBbox: [ 382 \t 201 \t 516 \t 516 ]\n",
      "5 \tObject: person \tConfidence = 0.8018 \tBbox: [ 517 \t 133 \t 613 \t 439 ]\n",
      "6 \tObject: person \tConfidence = 0.8004 \tBbox: [ 2 \t 532 \t 216 \t 965 ]\n",
      "7 \tObject: person \tConfidence = 0.7168 \tBbox: [ 369 \t 93 \t 429 \t 219 ]\n",
      "8 \tObject: train \tConfidence = 0.6913 \tBbox: [ 0 \t 3 \t 396 \t 741 ]\n",
      "9 \tObject: person \tConfidence = 0.6772 \tBbox: [ 696 \t 198 \t 765 \t 540 ]\n",
      "10 \tObject: person \tConfidence = 0.6132 \tBbox: [ 311 \t 96 \t 378 \t 252 ]\n",
      "11 \tObject: person \tConfidence = 0.594 \tBbox: [ 582 \t 0 \t 650 \t 108 ]\n",
      "12 \tObject: person \tConfidence = 0.5888 \tBbox: [ 394 \t 0 \t 451 \t 152 ]\n",
      "13 \tObject: person \tConfidence = 0.5641 \tBbox: [ 344 \t 187 \t 418 \t 462 ]\n",
      "14 \tObject: person \tConfidence = 0.5311 \tBbox: [ 491 \t 106 \t 566 \t 279 ]\n",
      "15 \tObject: person \tConfidence = 0.5263 \tBbox: [ 578 \t 671 \t 766 \t 1071 ]\n",
      "16 \tObject: person \tConfidence = 0.4679 \tBbox: [ 318 \t 142 \t 388 \t 341 ]\n",
      "17 \tObject: person \tConfidence = 0.344 \tBbox: [ 1 \t 858 \t 196 \t 1078 ]\n",
      "18 \tObject: person \tConfidence = 0.3418 \tBbox: [ 445 \t 0 \t 511 \t 151 ]\n",
      "19 \tObject: person \tConfidence = 0.3139 \tBbox: [ 286 \t 98 \t 327 \t 314 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    18\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000610 / 1050\n",
      "Frames to be processed: 440  | To do: 41.9 % | Done: 58.1 %\n",
      "\n",
      "2022-04-20 13:15:19.734391\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000610.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 19 persons, 1 train\n",
      "Speed: 27.8ms pre-process, 180.9ms inference, 2.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 20 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.854 \tBbox: [ 379 \t 203 \t 527 \t 513 ]\n",
      "2 \tObject: person \tConfidence = 0.8483 \tBbox: [ 120 \t 459 \t 273 \t 712 ]\n",
      "3 \tObject: person \tConfidence = 0.8375 \tBbox: [ 3 \t 531 \t 225 \t 964 ]\n",
      "4 \tObject: person \tConfidence = 0.8274 \tBbox: [ 317 \t 430 \t 460 \t 768 ]\n",
      "5 \tObject: person \tConfidence = 0.7877 \tBbox: [ 522 \t 134 \t 618 \t 443 ]\n",
      "6 \tObject: person \tConfidence = 0.7751 \tBbox: [ 216 \t 649 \t 414 \t 1078 ]\n",
      "7 \tObject: person \tConfidence = 0.7545 \tBbox: [ 375 \t 94 \t 433 \t 218 ]\n",
      "8 \tObject: person \tConfidence = 0.7518 \tBbox: [ 395 \t 0 \t 452 \t 147 ]\n",
      "9 \tObject: train \tConfidence = 0.7423 \tBbox: [ 0 \t 2 \t 404 \t 829 ]\n",
      "10 \tObject: person \tConfidence = 0.6569 \tBbox: [ 705 \t 204 \t 766 \t 539 ]\n",
      "11 \tObject: person \tConfidence = 0.6251 \tBbox: [ 589 \t 0 \t 652 \t 108 ]\n",
      "12 \tObject: person \tConfidence = 0.573 \tBbox: [ 341 \t 186 \t 418 \t 461 ]\n",
      "13 \tObject: person \tConfidence = 0.5645 \tBbox: [ 311 \t 95 \t 380 \t 243 ]\n",
      "14 \tObject: person \tConfidence = 0.4548 \tBbox: [ 495 \t 108 \t 570 \t 271 ]\n",
      "15 \tObject: person \tConfidence = 0.4378 \tBbox: [ 594 \t 674 \t 765 \t 1075 ]\n",
      "16 \tObject: person \tConfidence = 0.4187 \tBbox: [ 318 \t 146 \t 388 \t 345 ]\n",
      "17 \tObject: person \tConfidence = 0.3982 \tBbox: [ 512 \t 11 \t 574 \t 127 ]\n",
      "18 \tObject: person \tConfidence = 0.3952 \tBbox: [ 445 \t 0 \t 508 \t 150 ]\n",
      "19 \tObject: person \tConfidence = 0.3942 \tBbox: [ 1 \t 860 \t 196 \t 1079 ]\n",
      "20 \tObject: person \tConfidence = 0.3567 \tBbox: [ 32 \t 640 \t 229 \t 865 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    19\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000611 / 1050\n",
      "Frames to be processed: 439  | To do: 41.81 % | Done: 58.19 %\n",
      "\n",
      "2022-04-20 13:15:20.241153\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000611.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 18 persons, 1 train\n",
      "Speed: 25.4ms pre-process, 184.6ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 19 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.84 \tBbox: [ 376 \t 202 \t 507 \t 511 ]\n",
      "2 \tObject: person \tConfidence = 0.8399 \tBbox: [ 118 \t 461 \t 276 \t 711 ]\n",
      "3 \tObject: person \tConfidence = 0.8295 \tBbox: [ 9 \t 531 \t 235 \t 964 ]\n",
      "4 \tObject: person \tConfidence = 0.8066 \tBbox: [ 317 \t 431 \t 459 \t 745 ]\n",
      "5 \tObject: train \tConfidence = 0.7409 \tBbox: [ 0 \t 2 \t 401 \t 843 ]\n",
      "6 \tObject: person \tConfidence = 0.7233 \tBbox: [ 519 \t 136 \t 623 \t 446 ]\n",
      "7 \tObject: person \tConfidence = 0.6775 \tBbox: [ 380 \t 94 \t 437 \t 216 ]\n",
      "8 \tObject: person \tConfidence = 0.6407 \tBbox: [ 238 \t 650 \t 424 \t 1079 ]\n",
      "9 \tObject: person \tConfidence = 0.5602 \tBbox: [ 1 \t 859 \t 194 \t 1079 ]\n",
      "10 \tObject: person \tConfidence = 0.5401 \tBbox: [ 345 \t 187 \t 417 \t 461 ]\n",
      "11 \tObject: person \tConfidence = 0.5085 \tBbox: [ 396 \t 0 \t 451 \t 148 ]\n",
      "12 \tObject: person \tConfidence = 0.4794 \tBbox: [ 315 \t 99 \t 386 \t 241 ]\n",
      "13 \tObject: person \tConfidence = 0.4503 \tBbox: [ 598 \t 1 \t 655 \t 107 ]\n",
      "14 \tObject: person \tConfidence = 0.4203 \tBbox: [ 616 \t 685 \t 765 \t 1069 ]\n",
      "15 \tObject: person \tConfidence = 0.3944 \tBbox: [ 511 \t 11 \t 577 \t 127 ]\n",
      "16 \tObject: person \tConfidence = 0.3685 \tBbox: [ 447 \t 1 \t 515 \t 146 ]\n",
      "17 \tObject: person \tConfidence = 0.3656 \tBbox: [ 492 \t 106 \t 582 \t 422 ]\n",
      "18 \tObject: person \tConfidence = 0.3607 \tBbox: [ 711 \t 211 \t 765 \t 536 ]\n",
      "19 \tObject: person \tConfidence = 0.333 \tBbox: [ 324 \t 147 \t 391 \t 283 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    18\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000612 / 1050\n",
      "Frames to be processed: 438  | To do: 41.71 % | Done: 58.29 %\n",
      "\n",
      "2022-04-20 13:15:20.903921\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000612.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 24.3ms pre-process, 185.0ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8571 \tBbox: [ 23 \t 533 \t 246 \t 964 ]\n",
      "2 \tObject: person \tConfidence = 0.8488 \tBbox: [ 116 \t 461 \t 276 \t 707 ]\n",
      "3 \tObject: person \tConfidence = 0.8344 \tBbox: [ 379 \t 201 \t 506 \t 510 ]\n",
      "4 \tObject: person \tConfidence = 0.7979 \tBbox: [ 526 \t 144 \t 633 \t 449 ]\n",
      "5 \tObject: person \tConfidence = 0.7922 \tBbox: [ 202 \t 645 \t 457 \t 1077 ]\n",
      "6 \tObject: person \tConfidence = 0.7884 \tBbox: [ 317 \t 431 \t 457 \t 727 ]\n",
      "7 \tObject: train \tConfidence = 0.7646 \tBbox: [ 0 \t 2 \t 402 \t 814 ]\n",
      "8 \tObject: person \tConfidence = 0.7535 \tBbox: [ 387 \t 94 \t 443 \t 212 ]\n",
      "9 \tObject: person \tConfidence = 0.7037 \tBbox: [ 1 \t 863 \t 193 \t 1079 ]\n",
      "10 \tObject: person \tConfidence = 0.6152 \tBbox: [ 342 \t 188 \t 418 \t 462 ]\n",
      "11 \tObject: person \tConfidence = 0.5728 \tBbox: [ 507 \t 103 \t 595 \t 272 ]\n",
      "12 \tObject: person \tConfidence = 0.5469 \tBbox: [ 322 \t 97 \t 395 \t 231 ]\n",
      "13 \tObject: person \tConfidence = 0.5239 \tBbox: [ 288 \t 99 \t 343 \t 309 ]\n",
      "14 \tObject: person \tConfidence = 0.3777 \tBbox: [ 395 \t 0 \t 448 \t 110 ]\n",
      "15 \tObject: person \tConfidence = 0.3666 \tBbox: [ 319 \t 146 \t 390 \t 347 ]\n",
      "16 \tObject: person \tConfidence = 0.3633 \tBbox: [ 606 \t 0 \t 666 \t 107 ]\n",
      "17 \tObject: person \tConfidence = 0.307 \tBbox: [ 447 \t 0 \t 507 \t 147 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000613 / 1050\n",
      "Frames to be processed: 437  | To do: 41.62 % | Done: 58.38 %\n",
      "\n",
      "2022-04-20 13:15:21.411524\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000613.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 17 persons, 1 train\n",
      "Speed: 26.4ms pre-process, 182.3ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 18 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8643 \tBbox: [ 317 \t 430 \t 457 \t 708 ]\n",
      "2 \tObject: person \tConfidence = 0.8613 \tBbox: [ 115 \t 463 \t 276 \t 704 ]\n",
      "3 \tObject: person \tConfidence = 0.8253 \tBbox: [ 379 \t 200 \t 507 \t 508 ]\n",
      "4 \tObject: person \tConfidence = 0.8202 \tBbox: [ 31 \t 533 \t 253 \t 961 ]\n",
      "5 \tObject: person \tConfidence = 0.8041 \tBbox: [ 528 \t 147 \t 638 \t 458 ]\n",
      "6 \tObject: train \tConfidence = 0.7639 \tBbox: [ 0 \t 2 \t 399 \t 795 ]\n",
      "7 \tObject: person \tConfidence = 0.7423 \tBbox: [ 388 \t 94 \t 450 \t 209 ]\n",
      "8 \tObject: person \tConfidence = 0.7322 \tBbox: [ 258 \t 646 \t 465 \t 1032 ]\n",
      "9 \tObject: person \tConfidence = 0.6222 \tBbox: [ 289 \t 99 \t 345 \t 316 ]\n",
      "10 \tObject: person \tConfidence = 0.5868 \tBbox: [ 332 \t 183 \t 417 \t 455 ]\n",
      "11 \tObject: person \tConfidence = 0.5598 \tBbox: [ 0 \t 865 \t 193 \t 1079 ]\n",
      "12 \tObject: person \tConfidence = 0.5068 \tBbox: [ 510 \t 102 \t 601 \t 272 ]\n",
      "13 \tObject: person \tConfidence = 0.4744 \tBbox: [ 606 \t 0 \t 672 \t 106 ]\n",
      "14 \tObject: person \tConfidence = 0.4117 \tBbox: [ 397 \t 1 \t 450 \t 109 ]\n",
      "15 \tObject: person \tConfidence = 0.3708 \tBbox: [ 332 \t 98 \t 401 \t 211 ]\n",
      "16 \tObject: person \tConfidence = 0.3548 \tBbox: [ 446 \t 0 \t 504 \t 148 ]\n",
      "17 \tObject: person \tConfidence = 0.3339 \tBbox: [ 503 \t 6 \t 568 \t 141 ]\n",
      "18 \tObject: person \tConfidence = 0.3272 \tBbox: [ 319 \t 137 \t 395 \t 344 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    17\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000614 / 1050\n",
      "Frames to be processed: 436  | To do: 41.52 % | Done: 58.48 %\n",
      "\n",
      "2022-04-20 13:15:22.048738\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000614.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 17 persons, 1 train\n",
      "Speed: 28.6ms pre-process, 185.2ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 18 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8764 \tBbox: [ 115 \t 465 \t 276 \t 697 ]\n",
      "2 \tObject: person \tConfidence = 0.8706 \tBbox: [ 318 \t 431 \t 457 \t 689 ]\n",
      "3 \tObject: person \tConfidence = 0.832 \tBbox: [ 380 \t 200 \t 507 \t 506 ]\n",
      "4 \tObject: person \tConfidence = 0.8169 \tBbox: [ 44 \t 534 \t 262 \t 957 ]\n",
      "5 \tObject: train \tConfidence = 0.7865 \tBbox: [ 0 \t 2 \t 402 \t 772 ]\n",
      "6 \tObject: person \tConfidence = 0.741 \tBbox: [ 520 \t 149 \t 644 \t 461 ]\n",
      "7 \tObject: person \tConfidence = 0.7282 \tBbox: [ 391 \t 100 \t 455 \t 211 ]\n",
      "8 \tObject: person \tConfidence = 0.7247 \tBbox: [ 262 \t 645 \t 474 \t 1041 ]\n",
      "9 \tObject: person \tConfidence = 0.645 \tBbox: [ 516 \t 99 \t 607 \t 272 ]\n",
      "10 \tObject: person \tConfidence = 0.6317 \tBbox: [ 288 \t 97 \t 351 \t 316 ]\n",
      "11 \tObject: person \tConfidence = 0.5996 \tBbox: [ 0 \t 865 \t 195 \t 1079 ]\n",
      "12 \tObject: person \tConfidence = 0.5541 \tBbox: [ 617 \t 1 \t 677 \t 106 ]\n",
      "13 \tObject: person \tConfidence = 0.5274 \tBbox: [ 340 \t 189 \t 419 \t 460 ]\n",
      "14 \tObject: person \tConfidence = 0.3861 \tBbox: [ 397 \t 0 \t 452 \t 147 ]\n",
      "15 \tObject: person \tConfidence = 0.3658 \tBbox: [ 346 \t 97 \t 407 \t 193 ]\n",
      "16 \tObject: person \tConfidence = 0.363 \tBbox: [ 318 \t 145 \t 389 \t 353 ]\n",
      "17 \tObject: person \tConfidence = 0.3406 \tBbox: [ 447 \t 0 \t 507 \t 149 ]\n",
      "18 \tObject: person \tConfidence = 0.3001 \tBbox: [ 503 \t 6 \t 570 \t 144 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    17\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000615 / 1050\n",
      "Frames to be processed: 435  | To do: 41.43 % | Done: 58.57 %\n",
      "\n",
      "2022-04-20 13:15:22.585217\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000615.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 26.1ms pre-process, 180.1ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8662 \tBbox: [ 49 \t 536 \t 269 \t 958 ]\n",
      "2 \tObject: person \tConfidence = 0.8501 \tBbox: [ 113 \t 467 \t 274 \t 692 ]\n",
      "3 \tObject: person \tConfidence = 0.8489 \tBbox: [ 317 \t 432 \t 457 \t 679 ]\n",
      "4 \tObject: person \tConfidence = 0.8165 \tBbox: [ 381 \t 197 \t 506 \t 505 ]\n",
      "5 \tObject: person \tConfidence = 0.795 \tBbox: [ 540 \t 153 \t 648 \t 462 ]\n",
      "6 \tObject: train \tConfidence = 0.7633 \tBbox: [ 0 \t 2 \t 401 \t 777 ]\n",
      "7 \tObject: person \tConfidence = 0.7446 \tBbox: [ 305 \t 644 \t 488 \t 1072 ]\n",
      "8 \tObject: person \tConfidence = 0.6973 \tBbox: [ 398 \t 101 \t 461 \t 221 ]\n",
      "9 \tObject: person \tConfidence = 0.6846 \tBbox: [ 289 \t 97 \t 357 \t 317 ]\n",
      "10 \tObject: person \tConfidence = 0.6428 \tBbox: [ 355 \t 99 \t 412 \t 185 ]\n",
      "11 \tObject: person \tConfidence = 0.5282 \tBbox: [ 329 \t 174 \t 414 \t 454 ]\n",
      "12 \tObject: person \tConfidence = 0.5163 \tBbox: [ 621 \t 1 \t 682 \t 106 ]\n",
      "13 \tObject: person \tConfidence = 0.4535 \tBbox: [ 520 \t 118 \t 597 \t 366 ]\n",
      "14 \tObject: person \tConfidence = 0.4286 \tBbox: [ 563 \t 99 \t 613 \t 181 ]\n",
      "15 \tObject: person \tConfidence = 0.4003 \tBbox: [ 0 \t 864 \t 184 \t 1079 ]\n",
      "16 \tObject: person \tConfidence = 0.3153 \tBbox: [ 316 \t 143 \t 390 \t 360 ]\n",
      "17 \tObject: person \tConfidence = 0.3026 \tBbox: [ 503 \t 3 \t 566 \t 161 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000616 / 1050\n",
      "Frames to be processed: 434  | To do: 41.33 % | Done: 58.67 %\n",
      "\n",
      "2022-04-20 13:15:23.117433\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000616.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 26.3ms pre-process, 180.9ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8243 \tBbox: [ 317 \t 431 \t 457 \t 678 ]\n",
      "2 \tObject: person \tConfidence = 0.8197 \tBbox: [ 380 \t 198 \t 507 \t 504 ]\n",
      "3 \tObject: person \tConfidence = 0.819 \tBbox: [ 62 \t 537 \t 294 \t 960 ]\n",
      "4 \tObject: person \tConfidence = 0.8188 \tBbox: [ 112 \t 467 \t 273 \t 687 ]\n",
      "5 \tObject: person \tConfidence = 0.8176 \tBbox: [ 556 \t 154 \t 653 \t 462 ]\n",
      "6 \tObject: train \tConfidence = 0.7973 \tBbox: [ 0 \t 0 \t 402 \t 840 ]\n",
      "7 \tObject: person \tConfidence = 0.7848 \tBbox: [ 319 \t 643 \t 531 \t 1075 ]\n",
      "8 \tObject: person \tConfidence = 0.6814 \tBbox: [ 404 \t 99 \t 468 \t 232 ]\n",
      "9 \tObject: person \tConfidence = 0.64 \tBbox: [ 624 \t 1 \t 686 \t 106 ]\n",
      "10 \tObject: person \tConfidence = 0.638 \tBbox: [ 291 \t 96 \t 356 \t 318 ]\n",
      "11 \tObject: person \tConfidence = 0.6115 \tBbox: [ 524 \t 103 \t 616 \t 400 ]\n",
      "12 \tObject: person \tConfidence = 0.5606 \tBbox: [ 323 \t 169 \t 414 \t 455 ]\n",
      "13 \tObject: person \tConfidence = 0.5284 \tBbox: [ 368 \t 100 \t 417 \t 188 ]\n",
      "14 \tObject: person \tConfidence = 0.4402 \tBbox: [ 0 \t 865 \t 195 \t 1079 ]\n",
      "15 \tObject: person \tConfidence = 0.395 \tBbox: [ 299 \t 941 \t 456 \t 1079 ]\n",
      "16 \tObject: person \tConfidence = 0.3804 \tBbox: [ 399 \t 0 \t 457 \t 158 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000617 / 1050\n",
      "Frames to be processed: 433  | To do: 41.24 % | Done: 58.76 %\n",
      "\n",
      "2022-04-20 13:15:23.845065\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000617.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 40.3ms pre-process, 180.9ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.883 \tBbox: [ 328 \t 641 \t 595 \t 1052 ]\n",
      "2 \tObject: person \tConfidence = 0.877 \tBbox: [ 78 \t 543 \t 336 \t 981 ]\n",
      "3 \tObject: person \tConfidence = 0.8452 \tBbox: [ 378 \t 196 \t 507 \t 502 ]\n",
      "4 \tObject: person \tConfidence = 0.839 \tBbox: [ 557 \t 155 \t 665 \t 464 ]\n",
      "5 \tObject: person \tConfidence = 0.8032 \tBbox: [ 318 \t 429 \t 456 \t 690 ]\n",
      "6 \tObject: train \tConfidence = 0.7529 \tBbox: [ 0 \t 1 \t 398 \t 795 ]\n",
      "7 \tObject: person \tConfidence = 0.7434 \tBbox: [ 95 \t 469 \t 205 \t 628 ]\n",
      "8 \tObject: person \tConfidence = 0.6598 \tBbox: [ 532 \t 105 \t 628 \t 275 ]\n",
      "9 \tObject: person \tConfidence = 0.6441 \tBbox: [ 411 \t 97 \t 479 \t 244 ]\n",
      "10 \tObject: person \tConfidence = 0.5982 \tBbox: [ 626 \t 0 \t 695 \t 105 ]\n",
      "11 \tObject: person \tConfidence = 0.5965 \tBbox: [ 503 \t 4 \t 568 \t 186 ]\n",
      "12 \tObject: person \tConfidence = 0.571 \tBbox: [ 373 \t 99 \t 427 \t 202 ]\n",
      "13 \tObject: person \tConfidence = 0.5679 \tBbox: [ 0 \t 862 \t 201 \t 1079 ]\n",
      "14 \tObject: person \tConfidence = 0.536 \tBbox: [ 326 \t 177 \t 415 \t 453 ]\n",
      "15 \tObject: person \tConfidence = 0.4071 \tBbox: [ 567 \t 0 \t 596 \t 65 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000618 / 1050\n",
      "Frames to be processed: 432  | To do: 41.14 % | Done: 58.86 %\n",
      "\n",
      "2022-04-20 13:15:24.368438\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000618.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 17 persons, 1 train\n",
      "Speed: 33.9ms pre-process, 176.5ms inference, 15.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 18 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8766 \tBbox: [ 82 \t 548 \t 348 \t 989 ]\n",
      "2 \tObject: person \tConfidence = 0.8495 \tBbox: [ 558 \t 157 \t 670 \t 465 ]\n",
      "3 \tObject: person \tConfidence = 0.843 \tBbox: [ 388 \t 196 \t 508 \t 501 ]\n",
      "4 \tObject: person \tConfidence = 0.8397 \tBbox: [ 340 \t 640 \t 605 \t 1053 ]\n",
      "5 \tObject: person \tConfidence = 0.787 \tBbox: [ 317 \t 428 \t 455 \t 728 ]\n",
      "6 \tObject: train \tConfidence = 0.7333 \tBbox: [ 0 \t 2 \t 398 \t 762 ]\n",
      "7 \tObject: person \tConfidence = 0.7279 \tBbox: [ 536 \t 107 \t 633 \t 275 ]\n",
      "8 \tObject: person \tConfidence = 0.7195 \tBbox: [ 420 \t 97 \t 483 \t 244 ]\n",
      "9 \tObject: person \tConfidence = 0.6805 \tBbox: [ 82 \t 469 \t 204 \t 705 ]\n",
      "10 \tObject: person \tConfidence = 0.6622 \tBbox: [ 375 \t 100 \t 433 \t 207 ]\n",
      "11 \tObject: person \tConfidence = 0.6617 \tBbox: [ 502 \t 4 \t 580 \t 187 ]\n",
      "12 \tObject: person \tConfidence = 0.5708 \tBbox: [ 623 \t 0 \t 696 \t 104 ]\n",
      "13 \tObject: person \tConfidence = 0.5142 \tBbox: [ 331 \t 175 \t 415 \t 453 ]\n",
      "14 \tObject: person \tConfidence = 0.4369 \tBbox: [ 569 \t 0 \t 600 \t 69 ]\n",
      "15 \tObject: person \tConfidence = 0.4164 \tBbox: [ 0 \t 864 \t 194 \t 1079 ]\n",
      "16 \tObject: person \tConfidence = 0.4036 \tBbox: [ 456 \t 0 \t 508 \t 131 ]\n",
      "17 \tObject: person \tConfidence = 0.3314 \tBbox: [ 300 \t 104 \t 366 \t 251 ]\n",
      "18 \tObject: person \tConfidence = 0.3213 \tBbox: [ 399 \t 0 \t 458 \t 114 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    17\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000619 / 1050\n",
      "Frames to be processed: 431  | To do: 41.05 % | Done: 58.95 %\n",
      "\n",
      "2022-04-20 13:15:24.865086\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000619.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 19 persons, 1 train\n",
      "Speed: 33.7ms pre-process, 169.6ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 20 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8416 \tBbox: [ 387 \t 194 \t 508 \t 501 ]\n",
      "2 \tObject: person \tConfidence = 0.8362 \tBbox: [ 362 \t 638 \t 607 \t 1056 ]\n",
      "3 \tObject: person \tConfidence = 0.8328 \tBbox: [ 576 \t 157 \t 677 \t 462 ]\n",
      "4 \tObject: person \tConfidence = 0.8225 \tBbox: [ 94 \t 549 \t 350 \t 994 ]\n",
      "5 \tObject: person \tConfidence = 0.8203 \tBbox: [ 318 \t 429 \t 454 \t 734 ]\n",
      "6 \tObject: person \tConfidence = 0.8034 \tBbox: [ 538 \t 109 \t 636 \t 367 ]\n",
      "7 \tObject: train \tConfidence = 0.7608 \tBbox: [ 0 \t 3 \t 397 \t 728 ]\n",
      "8 \tObject: person \tConfidence = 0.718 \tBbox: [ 423 \t 94 \t 495 \t 259 ]\n",
      "9 \tObject: person \tConfidence = 0.649 \tBbox: [ 502 \t 4 \t 577 \t 184 ]\n",
      "10 \tObject: person \tConfidence = 0.6153 \tBbox: [ 79 \t 469 \t 201 \t 729 ]\n",
      "11 \tObject: person \tConfidence = 0.6109 \tBbox: [ 333 \t 180 \t 417 \t 454 ]\n",
      "12 \tObject: person \tConfidence = 0.6083 \tBbox: [ 382 \t 99 \t 436 \t 210 ]\n",
      "13 \tObject: person \tConfidence = 0.5984 \tBbox: [ 632 \t 0 \t 696 \t 104 ]\n",
      "14 \tObject: person \tConfidence = 0.4461 \tBbox: [ 456 \t 0 \t 507 \t 113 ]\n",
      "15 \tObject: person \tConfidence = 0.3769 \tBbox: [ 0 \t 631 \t 89 \t 903 ]\n",
      "16 \tObject: person \tConfidence = 0.367 \tBbox: [ 304 \t 95 \t 375 \t 237 ]\n",
      "17 \tObject: person \tConfidence = 0.3606 \tBbox: [ 0 \t 863 \t 166 \t 1078 ]\n",
      "18 \tObject: person \tConfidence = 0.3537 \tBbox: [ 399 \t 0 \t 458 \t 105 ]\n",
      "19 \tObject: person \tConfidence = 0.335 \tBbox: [ 323 \t 148 \t 386 \t 267 ]\n",
      "20 \tObject: person \tConfidence = 0.3175 \tBbox: [ 611 \t 0 \t 660 \t 68 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    19\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000620 / 1050\n",
      "Frames to be processed: 430  | To do: 40.95 % | Done: 59.05 %\n",
      "\n",
      "2022-04-20 13:15:25.374087\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000620.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 28.9ms pre-process, 174.2ms inference, 7.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8682 \tBbox: [ 584 \t 159 \t 681 \t 462 ]\n",
      "2 \tObject: person \tConfidence = 0.8511 \tBbox: [ 318 \t 427 \t 455 \t 743 ]\n",
      "3 \tObject: person \tConfidence = 0.8419 \tBbox: [ 543 \t 112 \t 638 \t 366 ]\n",
      "4 \tObject: person \tConfidence = 0.8294 \tBbox: [ 391 \t 196 \t 508 \t 499 ]\n",
      "5 \tObject: person \tConfidence = 0.8283 \tBbox: [ 388 \t 634 \t 610 \t 1058 ]\n",
      "6 \tObject: train \tConfidence = 0.7935 \tBbox: [ 0 \t 3 \t 404 \t 719 ]\n",
      "7 \tObject: person \tConfidence = 0.7628 \tBbox: [ 109 \t 549 \t 352 \t 996 ]\n",
      "8 \tObject: person \tConfidence = 0.7376 \tBbox: [ 428 \t 95 \t 500 \t 261 ]\n",
      "9 \tObject: person \tConfidence = 0.6633 \tBbox: [ 385 \t 100 \t 440 \t 209 ]\n",
      "10 \tObject: person \tConfidence = 0.6574 \tBbox: [ 639 \t 0 \t 697 \t 102 ]\n",
      "11 \tObject: person \tConfidence = 0.6347 \tBbox: [ 77 \t 470 \t 204 \t 796 ]\n",
      "12 \tObject: person \tConfidence = 0.6027 \tBbox: [ 335 \t 182 \t 420 \t 453 ]\n",
      "13 \tObject: person \tConfidence = 0.5977 \tBbox: [ 503 \t 3 \t 579 \t 184 ]\n",
      "14 \tObject: person \tConfidence = 0.3771 \tBbox: [ 306 \t 147 \t 385 \t 344 ]\n",
      "15 \tObject: person \tConfidence = 0.3686 \tBbox: [ 307 \t 97 \t 377 \t 231 ]\n",
      "16 \tObject: person \tConfidence = 0.3336 \tBbox: [ 1 \t 863 \t 139 \t 1078 ]\n",
      "17 \tObject: person \tConfidence = 0.3123 \tBbox: [ 616 \t 0 \t 662 \t 70 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000621 / 1050\n",
      "Frames to be processed: 429  | To do: 40.86 % | Done: 59.14 %\n",
      "\n",
      "2022-04-20 13:15:25.915735\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000621.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 19 persons, 1 train\n",
      "Speed: 38.0ms pre-process, 177.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 20 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8731 \tBbox: [ 584 \t 161 \t 688 \t 464 ]\n",
      "2 \tObject: person \tConfidence = 0.8469 \tBbox: [ 546 \t 112 \t 644 \t 367 ]\n",
      "3 \tObject: person \tConfidence = 0.8306 \tBbox: [ 317 \t 428 \t 458 \t 744 ]\n",
      "4 \tObject: person \tConfidence = 0.8095 \tBbox: [ 391 \t 194 \t 509 \t 499 ]\n",
      "5 \tObject: train \tConfidence = 0.7981 \tBbox: [ 0 \t 2 \t 401 \t 693 ]\n",
      "6 \tObject: person \tConfidence = 0.7729 \tBbox: [ 407 \t 631 \t 609 \t 1056 ]\n",
      "7 \tObject: person \tConfidence = 0.7587 \tBbox: [ 124 \t 552 \t 352 \t 996 ]\n",
      "8 \tObject: person \tConfidence = 0.6825 \tBbox: [ 646 \t 0 \t 699 \t 98 ]\n",
      "9 \tObject: person \tConfidence = 0.68 \tBbox: [ 502 \t 3 \t 584 \t 184 ]\n",
      "10 \tObject: person \tConfidence = 0.6065 \tBbox: [ 433 \t 97 \t 503 \t 263 ]\n",
      "11 \tObject: person \tConfidence = 0.6023 \tBbox: [ 337 \t 185 \t 419 \t 455 ]\n",
      "12 \tObject: person \tConfidence = 0.5709 \tBbox: [ 389 \t 100 \t 445 \t 213 ]\n",
      "13 \tObject: person \tConfidence = 0.5709 \tBbox: [ 77 \t 474 \t 204 \t 955 ]\n",
      "14 \tObject: person \tConfidence = 0.4531 \tBbox: [ 619 \t 0 \t 663 \t 68 ]\n",
      "15 \tObject: person \tConfidence = 0.4405 \tBbox: [ 317 \t 147 \t 386 \t 342 ]\n",
      "16 \tObject: person \tConfidence = 0.4076 \tBbox: [ 0 \t 622 \t 109 \t 937 ]\n",
      "17 \tObject: person \tConfidence = 0.4024 \tBbox: [ 309 \t 97 \t 379 \t 230 ]\n",
      "18 \tObject: person \tConfidence = 0.39 \tBbox: [ 456 \t 0 \t 506 \t 120 ]\n",
      "19 \tObject: person \tConfidence = 0.3428 \tBbox: [ 1 \t 864 \t 177 \t 1079 ]\n",
      "20 \tObject: person \tConfidence = 0.3354 \tBbox: [ 401 \t 0 \t 457 \t 113 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    19\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000622 / 1050\n",
      "Frames to be processed: 428  | To do: 40.76 % | Done: 59.24 %\n",
      "\n",
      "2022-04-20 13:15:26.442802\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000622.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 19 persons, 1 train\n",
      "Speed: 25.2ms pre-process, 170.1ms inference, 11.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 20 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8937 \tBbox: [ 585 \t 165 \t 704 \t 475 ]\n",
      "2 \tObject: person \tConfidence = 0.8468 \tBbox: [ 554 \t 118 \t 655 \t 368 ]\n",
      "3 \tObject: person \tConfidence = 0.846 \tBbox: [ 392 \t 195 \t 510 \t 499 ]\n",
      "4 \tObject: person \tConfidence = 0.723 \tBbox: [ 436 \t 618 \t 621 \t 962 ]\n",
      "5 \tObject: train \tConfidence = 0.7047 \tBbox: [ 1 \t 1 \t 403 \t 683 ]\n",
      "6 \tObject: person \tConfidence = 0.6983 \tBbox: [ 138 \t 551 \t 359 \t 994 ]\n",
      "7 \tObject: person \tConfidence = 0.6646 \tBbox: [ 370 \t 927 \t 589 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.6645 \tBbox: [ 336 \t 184 \t 422 \t 455 ]\n",
      "9 \tObject: person \tConfidence = 0.6407 \tBbox: [ 506 \t 2 \t 581 \t 183 ]\n",
      "10 \tObject: person \tConfidence = 0.6347 \tBbox: [ 85 \t 474 \t 217 \t 907 ]\n",
      "11 \tObject: person \tConfidence = 0.5868 \tBbox: [ 444 \t 94 \t 511 \t 269 ]\n",
      "12 \tObject: person \tConfidence = 0.5681 \tBbox: [ 394 \t 100 \t 455 \t 223 ]\n",
      "13 \tObject: person \tConfidence = 0.4781 \tBbox: [ 667 \t 0 \t 700 \t 95 ]\n",
      "14 \tObject: person \tConfidence = 0.4447 \tBbox: [ 322 \t 148 \t 387 \t 274 ]\n",
      "15 \tObject: person \tConfidence = 0.4406 \tBbox: [ 317 \t 425 \t 458 \t 863 ]\n",
      "16 \tObject: person \tConfidence = 0.4309 \tBbox: [ 400 \t 0 \t 456 \t 115 ]\n",
      "17 \tObject: person \tConfidence = 0.3693 \tBbox: [ 316 \t 96 \t 385 \t 223 ]\n",
      "18 \tObject: person \tConfidence = 0.3683 \tBbox: [ 449 \t 0 \t 506 \t 99 ]\n",
      "19 \tObject: person \tConfidence = 0.3073 \tBbox: [ 643 \t 0 \t 674 \t 73 ]\n",
      "20 \tObject: person \tConfidence = 0.3057 \tBbox: [ 567 \t 0 \t 605 \t 140 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    19\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000623 / 1050\n",
      "Frames to be processed: 427  | To do: 40.67 % | Done: 59.33 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 17 persons, 1 train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:15:26.917474\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000623.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 26.1ms pre-process, 168.3ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 18 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8555 \tBbox: [ 396 \t 195 \t 510 \t 499 ]\n",
      "2 \tObject: person \tConfidence = 0.8501 \tBbox: [ 557 \t 121 \t 661 \t 369 ]\n",
      "3 \tObject: person \tConfidence = 0.7639 \tBbox: [ 585 \t 167 \t 721 \t 478 ]\n",
      "4 \tObject: train \tConfidence = 0.7633 \tBbox: [ 1 \t 1 \t 405 \t 669 ]\n",
      "5 \tObject: person \tConfidence = 0.6579 \tBbox: [ 394 \t 98 \t 459 \t 229 ]\n",
      "6 \tObject: person \tConfidence = 0.6561 \tBbox: [ 316 \t 425 \t 457 \t 784 ]\n",
      "7 \tObject: person \tConfidence = 0.6502 \tBbox: [ 342 \t 184 \t 422 \t 457 ]\n",
      "8 \tObject: person \tConfidence = 0.5785 \tBbox: [ 510 \t 2 \t 582 \t 183 ]\n",
      "9 \tObject: person \tConfidence = 0.5597 \tBbox: [ 448 \t 97 \t 516 \t 270 ]\n",
      "10 \tObject: person \tConfidence = 0.544 \tBbox: [ 86 \t 476 \t 218 \t 910 ]\n",
      "11 \tObject: person \tConfidence = 0.5419 \tBbox: [ 448 \t 613 \t 640 \t 1075 ]\n",
      "12 \tObject: person \tConfidence = 0.5132 \tBbox: [ 156 \t 560 \t 368 \t 1021 ]\n",
      "13 \tObject: person \tConfidence = 0.3834 \tBbox: [ 320 \t 147 \t 386 \t 339 ]\n",
      "14 \tObject: person \tConfidence = 0.379 \tBbox: [ 565 \t 0 \t 607 \t 143 ]\n",
      "15 \tObject: person \tConfidence = 0.3732 \tBbox: [ 451 \t 0 \t 505 \t 95 ]\n",
      "16 \tObject: person \tConfidence = 0.3649 \tBbox: [ 323 \t 91 \t 393 \t 211 ]\n",
      "17 \tObject: person \tConfidence = 0.3642 \tBbox: [ 400 \t 1 \t 456 \t 120 ]\n",
      "18 \tObject: person \tConfidence = 0.302 \tBbox: [ 643 \t 0 \t 677 \t 69 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    17\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000624 / 1050\n",
      "Frames to be processed: 426  | To do: 40.57 % | Done: 59.43 %\n",
      "\n",
      "2022-04-20 13:15:27.552513\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000624.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 25.1ms pre-process, 167.9ms inference, 11.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8881 \tBbox: [ 586 \t 172 \t 735 \t 484 ]\n",
      "2 \tObject: person \tConfidence = 0.8198 \tBbox: [ 405 \t 194 \t 511 \t 498 ]\n",
      "3 \tObject: person \tConfidence = 0.8098 \tBbox: [ 560 \t 124 \t 666 \t 369 ]\n",
      "4 \tObject: person \tConfidence = 0.7062 \tBbox: [ 394 \t 98 \t 464 \t 227 ]\n",
      "5 \tObject: person \tConfidence = 0.7044 \tBbox: [ 452 \t 94 \t 521 \t 317 ]\n",
      "6 \tObject: person \tConfidence = 0.6972 \tBbox: [ 343 \t 183 \t 425 \t 458 ]\n",
      "7 \tObject: train \tConfidence = 0.6934 \tBbox: [ 2 \t 4 \t 401 \t 663 ]\n",
      "8 \tObject: person \tConfidence = 0.6856 \tBbox: [ 316 \t 427 \t 457 \t 743 ]\n",
      "9 \tObject: person \tConfidence = 0.6069 \tBbox: [ 509 \t 2 \t 582 \t 183 ]\n",
      "10 \tObject: person \tConfidence = 0.5428 \tBbox: [ 87 \t 473 \t 217 \t 873 ]\n",
      "11 \tObject: person \tConfidence = 0.5015 \tBbox: [ 464 \t 606 \t 653 \t 951 ]\n",
      "12 \tObject: person \tConfidence = 0.4758 \tBbox: [ 168 \t 559 \t 379 \t 986 ]\n",
      "13 \tObject: person \tConfidence = 0.4323 \tBbox: [ 453 \t 0 \t 506 \t 96 ]\n",
      "14 \tObject: person \tConfidence = 0.3895 \tBbox: [ 649 \t 1 \t 698 \t 93 ]\n",
      "15 \tObject: person \tConfidence = 0.3612 \tBbox: [ 321 \t 146 \t 387 \t 342 ]\n",
      "16 \tObject: person \tConfidence = 0.3377 \tBbox: [ 401 \t 0 \t 458 \t 117 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000625 / 1050\n",
      "Frames to be processed: 425  | To do: 40.48 % | Done: 59.52 %\n",
      "\n",
      "2022-04-20 13:15:28.069669\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000625.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 18 persons, 1 train\n",
      "Speed: 29.6ms pre-process, 174.6ms inference, 3.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 19 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8933 \tBbox: [ 587 \t 175 \t 736 \t 488 ]\n",
      "2 \tObject: person \tConfidence = 0.8564 \tBbox: [ 563 \t 125 \t 670 \t 369 ]\n",
      "3 \tObject: person \tConfidence = 0.8366 \tBbox: [ 402 \t 194 \t 512 \t 498 ]\n",
      "4 \tObject: person \tConfidence = 0.7614 \tBbox: [ 456 \t 97 \t 537 \t 328 ]\n",
      "5 \tObject: train \tConfidence = 0.7164 \tBbox: [ 1 \t 2 \t 405 \t 666 ]\n",
      "6 \tObject: person \tConfidence = 0.7097 \tBbox: [ 316 \t 426 \t 457 \t 747 ]\n",
      "7 \tObject: person \tConfidence = 0.7017 \tBbox: [ 83 \t 476 \t 217 \t 835 ]\n",
      "8 \tObject: person \tConfidence = 0.6821 \tBbox: [ 472 \t 602 \t 673 \t 1061 ]\n",
      "9 \tObject: person \tConfidence = 0.6745 \tBbox: [ 397 \t 98 \t 468 \t 227 ]\n",
      "10 \tObject: person \tConfidence = 0.6551 \tBbox: [ 173 \t 553 \t 388 \t 986 ]\n",
      "11 \tObject: person \tConfidence = 0.6442 \tBbox: [ 344 \t 181 \t 423 \t 459 ]\n",
      "12 \tObject: person \tConfidence = 0.6229 \tBbox: [ 510 \t 2 \t 582 \t 183 ]\n",
      "13 \tObject: person \tConfidence = 0.4574 \tBbox: [ 565 \t 0 \t 611 \t 148 ]\n",
      "14 \tObject: person \tConfidence = 0.4474 \tBbox: [ 324 \t 90 \t 400 \t 221 ]\n",
      "15 \tObject: person \tConfidence = 0.4201 \tBbox: [ 651 \t 0 \t 685 \t 73 ]\n",
      "16 \tObject: person \tConfidence = 0.415 \tBbox: [ 1 \t 861 \t 177 \t 1078 ]\n",
      "17 \tObject: person \tConfidence = 0.3675 \tBbox: [ 456 \t 0 \t 506 \t 95 ]\n",
      "18 \tObject: person \tConfidence = 0.3645 \tBbox: [ 397 \t 0 \t 460 \t 161 ]\n",
      "19 \tObject: person \tConfidence = 0.3216 \tBbox: [ 669 \t 0 \t 699 \t 96 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    18\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000626 / 1050\n",
      "Frames to be processed: 424  | To do: 40.38 % | Done: 59.62 %\n",
      "\n",
      "2022-04-20 13:15:28.565983\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000626.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 17 persons, 1 train\n",
      "Speed: 29.9ms pre-process, 178.1ms inference, 11.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 18 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8839 \tBbox: [ 590 \t 177 \t 737 \t 495 ]\n",
      "2 \tObject: person \tConfidence = 0.8682 \tBbox: [ 567 \t 126 \t 672 \t 369 ]\n",
      "3 \tObject: person \tConfidence = 0.831 \tBbox: [ 405 \t 192 \t 514 \t 498 ]\n",
      "4 \tObject: person \tConfidence = 0.7758 \tBbox: [ 462 \t 97 \t 550 \t 334 ]\n",
      "5 \tObject: person \tConfidence = 0.749 \tBbox: [ 81 \t 479 \t 218 \t 810 ]\n",
      "6 \tObject: train \tConfidence = 0.7425 \tBbox: [ 0 \t 3 \t 406 \t 704 ]\n",
      "7 \tObject: person \tConfidence = 0.7334 \tBbox: [ 487 \t 604 \t 685 \t 1077 ]\n",
      "8 \tObject: person \tConfidence = 0.7263 \tBbox: [ 188 \t 550 \t 395 \t 1080 ]\n",
      "9 \tObject: person \tConfidence = 0.7219 \tBbox: [ 316 \t 425 \t 456 \t 754 ]\n",
      "10 \tObject: person \tConfidence = 0.7011 \tBbox: [ 1 \t 628 \t 184 \t 977 ]\n",
      "11 \tObject: person \tConfidence = 0.6967 \tBbox: [ 402 \t 100 \t 474 \t 232 ]\n",
      "12 \tObject: person \tConfidence = 0.6814 \tBbox: [ 344 \t 180 \t 425 \t 460 ]\n",
      "13 \tObject: person \tConfidence = 0.6126 \tBbox: [ 508 \t 2 \t 582 \t 184 ]\n",
      "14 \tObject: person \tConfidence = 0.5136 \tBbox: [ 652 \t 0 \t 689 \t 72 ]\n",
      "15 \tObject: person \tConfidence = 0.4898 \tBbox: [ 564 \t 0 \t 614 \t 147 ]\n",
      "16 \tObject: person \tConfidence = 0.3943 \tBbox: [ 1 \t 859 \t 192 \t 1078 ]\n",
      "17 \tObject: person \tConfidence = 0.3373 \tBbox: [ 333 \t 87 \t 402 \t 195 ]\n",
      "18 \tObject: person \tConfidence = 0.3055 \tBbox: [ 322 \t 149 \t 381 \t 345 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    17\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000627 / 1050\n",
      "Frames to be processed: 423  | To do: 40.29 % | Done: 59.71 %\n",
      "\n",
      "2022-04-20 13:15:29.050232\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000627.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 18 persons, 1 train\n",
      "Speed: 29.5ms pre-process, 179.5ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 19 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8711 \tBbox: [ 403 \t 192 \t 514 \t 498 ]\n",
      "2 \tObject: person \tConfidence = 0.8261 \tBbox: [ 510 \t 600 \t 712 \t 1065 ]\n",
      "3 \tObject: person \tConfidence = 0.7949 \tBbox: [ 470 \t 99 \t 564 \t 341 ]\n",
      "4 \tObject: person \tConfidence = 0.789 \tBbox: [ 576 \t 126 \t 679 \t 399 ]\n",
      "5 \tObject: person \tConfidence = 0.7786 \tBbox: [ 592 \t 181 \t 747 \t 507 ]\n",
      "6 \tObject: person \tConfidence = 0.7555 \tBbox: [ 202 \t 555 \t 413 \t 1077 ]\n",
      "7 \tObject: person \tConfidence = 0.697 \tBbox: [ 1 \t 626 \t 207 \t 1007 ]\n",
      "8 \tObject: person \tConfidence = 0.6962 \tBbox: [ 347 \t 184 \t 423 \t 459 ]\n",
      "9 \tObject: person \tConfidence = 0.6813 \tBbox: [ 314 \t 424 \t 456 \t 749 ]\n",
      "10 \tObject: train \tConfidence = 0.6609 \tBbox: [ 0 \t 2 \t 399 \t 782 ]\n",
      "11 \tObject: person \tConfidence = 0.64 \tBbox: [ 69 \t 481 \t 233 \t 804 ]\n",
      "12 \tObject: person \tConfidence = 0.6333 \tBbox: [ 414 \t 100 \t 484 \t 248 ]\n",
      "13 \tObject: person \tConfidence = 0.5636 \tBbox: [ 510 \t 1 \t 579 \t 184 ]\n",
      "14 \tObject: person \tConfidence = 0.5486 \tBbox: [ 1 \t 859 \t 200 \t 1078 ]\n",
      "15 \tObject: person \tConfidence = 0.4763 \tBbox: [ 564 \t 0 \t 622 \t 150 ]\n",
      "16 \tObject: person \tConfidence = 0.4218 \tBbox: [ 398 \t 0 \t 458 \t 152 ]\n",
      "17 \tObject: person \tConfidence = 0.4121 \tBbox: [ 651 \t 0 \t 693 \t 74 ]\n",
      "18 \tObject: person \tConfidence = 0.3538 \tBbox: [ 361 \t 88 \t 408 \t 189 ]\n",
      "19 \tObject: person \tConfidence = 0.3357 \tBbox: [ 321 \t 150 \t 382 \t 345 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    18\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000628 / 1050\n",
      "Frames to be processed: 422  | To do: 40.19 % | Done: 59.81 %\n",
      "\n",
      "2022-04-20 13:15:29.592723\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000628.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 19 persons, 1 train\n",
      "Speed: 29.5ms pre-process, 181.2ms inference, 13.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 20 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.861 \tBbox: [ 406 \t 192 \t 517 \t 497 ]\n",
      "2 \tObject: person \tConfidence = 0.8444 \tBbox: [ 579 \t 126 \t 689 \t 418 ]\n",
      "3 \tObject: person \tConfidence = 0.8266 \tBbox: [ 517 \t 599 \t 723 \t 1066 ]\n",
      "4 \tObject: person \tConfidence = 0.8141 \tBbox: [ 475 \t 99 \t 566 \t 342 ]\n",
      "5 \tObject: person \tConfidence = 0.7842 \tBbox: [ 59 \t 482 \t 235 \t 755 ]\n",
      "6 \tObject: person \tConfidence = 0.7668 \tBbox: [ 596 \t 183 \t 751 \t 507 ]\n",
      "7 \tObject: person \tConfidence = 0.7657 \tBbox: [ 2 \t 623 \t 225 \t 1015 ]\n",
      "8 \tObject: person \tConfidence = 0.7033 \tBbox: [ 419 \t 98 \t 489 \t 241 ]\n",
      "9 \tObject: person \tConfidence = 0.6709 \tBbox: [ 348 \t 183 \t 423 \t 461 ]\n",
      "10 \tObject: person \tConfidence = 0.6529 \tBbox: [ 212 \t 557 \t 421 \t 1074 ]\n",
      "11 \tObject: person \tConfidence = 0.645 \tBbox: [ 511 \t 1 \t 578 \t 180 ]\n",
      "12 \tObject: person \tConfidence = 0.6442 \tBbox: [ 314 \t 424 \t 456 \t 755 ]\n",
      "13 \tObject: train \tConfidence = 0.6041 \tBbox: [ 1 \t 4 \t 401 \t 797 ]\n",
      "14 \tObject: person \tConfidence = 0.5605 \tBbox: [ 652 \t 0 \t 696 \t 71 ]\n",
      "15 \tObject: person \tConfidence = 0.5517 \tBbox: [ 569 \t 0 \t 627 \t 149 ]\n",
      "16 \tObject: person \tConfidence = 0.4628 \tBbox: [ 361 \t 87 \t 412 \t 194 ]\n",
      "17 \tObject: person \tConfidence = 0.4372 \tBbox: [ 399 \t 0 \t 458 \t 146 ]\n",
      "18 \tObject: person \tConfidence = 0.429 \tBbox: [ 1 \t 863 \t 202 \t 1079 ]\n",
      "19 \tObject: person \tConfidence = 0.3613 \tBbox: [ 319 \t 144 \t 387 \t 343 ]\n",
      "20 \tObject: person \tConfidence = 0.33 \tBbox: [ 455 \t 0 \t 506 \t 99 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    19\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000629 / 1050\n",
      "Frames to be processed: 421  | To do: 40.1 % | Done: 59.9 %\n",
      "\n",
      "2022-04-20 13:15:30.119321\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000629.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 18 persons, 1 train\n",
      "Speed: 27.3ms pre-process, 182.3ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 19 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8723 \tBbox: [ 479 \t 99 \t 567 \t 343 ]\n",
      "2 \tObject: person \tConfidence = 0.8684 \tBbox: [ 518 \t 599 \t 733 \t 1063 ]\n",
      "3 \tObject: person \tConfidence = 0.8625 \tBbox: [ 583 \t 127 \t 696 \t 415 ]\n",
      "4 \tObject: person \tConfidence = 0.8349 \tBbox: [ 409 \t 193 \t 518 \t 499 ]\n",
      "5 \tObject: person \tConfidence = 0.8302 \tBbox: [ 600 \t 185 \t 759 \t 507 ]\n",
      "6 \tObject: person \tConfidence = 0.8301 \tBbox: [ 2 \t 623 \t 241 \t 1015 ]\n",
      "7 \tObject: person \tConfidence = 0.7879 \tBbox: [ 37 \t 483 \t 233 \t 756 ]\n",
      "8 \tObject: person \tConfidence = 0.7305 \tBbox: [ 346 \t 181 \t 429 \t 459 ]\n",
      "9 \tObject: person \tConfidence = 0.7103 \tBbox: [ 423 \t 96 \t 494 \t 244 ]\n",
      "10 \tObject: person \tConfidence = 0.7031 \tBbox: [ 314 \t 423 \t 456 \t 745 ]\n",
      "11 \tObject: person \tConfidence = 0.644 \tBbox: [ 511 \t 1 \t 582 \t 179 ]\n",
      "12 \tObject: person \tConfidence = 0.6076 \tBbox: [ 576 \t 0 \t 633 \t 153 ]\n",
      "13 \tObject: person \tConfidence = 0.5696 \tBbox: [ 232 \t 557 \t 430 \t 1053 ]\n",
      "14 \tObject: person \tConfidence = 0.5584 \tBbox: [ 399 \t 0 \t 458 \t 145 ]\n",
      "15 \tObject: person \tConfidence = 0.5568 \tBbox: [ 652 \t 0 \t 697 \t 71 ]\n",
      "16 \tObject: train \tConfidence = 0.5478 \tBbox: [ 0 \t 2 \t 395 \t 804 ]\n",
      "17 \tObject: person \tConfidence = 0.4681 \tBbox: [ 365 \t 88 \t 417 \t 199 ]\n",
      "18 \tObject: person \tConfidence = 0.4366 \tBbox: [ 453 \t 0 \t 504 \t 101 ]\n",
      "19 \tObject: person \tConfidence = 0.4033 \tBbox: [ 1 \t 859 \t 176 \t 1079 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    18\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000630 / 1050\n",
      "Frames to be processed: 420  | To do: 40.0 % | Done: 60.0 %\n",
      "\n",
      "2022-04-20 13:15:30.621180\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000630.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 19 persons, 1 train\n",
      "Speed: 27.5ms pre-process, 170.0ms inference, 10.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 20 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8709 \tBbox: [ 587 \t 127 \t 699 \t 419 ]\n",
      "2 \tObject: person \tConfidence = 0.8546 \tBbox: [ 517 \t 601 \t 742 \t 1061 ]\n",
      "3 \tObject: person \tConfidence = 0.8446 \tBbox: [ 484 \t 101 \t 569 \t 341 ]\n",
      "4 \tObject: person \tConfidence = 0.829 \tBbox: [ 615 \t 186 \t 765 \t 508 ]\n",
      "5 \tObject: person \tConfidence = 0.8262 \tBbox: [ 409 \t 193 \t 518 \t 498 ]\n",
      "6 \tObject: person \tConfidence = 0.79 \tBbox: [ 7 \t 627 \t 256 \t 1055 ]\n",
      "7 \tObject: person \tConfidence = 0.7325 \tBbox: [ 344 \t 182 \t 430 \t 458 ]\n",
      "8 \tObject: person \tConfidence = 0.7293 \tBbox: [ 33 \t 485 \t 221 \t 749 ]\n",
      "9 \tObject: person \tConfidence = 0.711 \tBbox: [ 312 \t 421 \t 455 \t 733 ]\n",
      "10 \tObject: person \tConfidence = 0.6789 \tBbox: [ 653 \t 0 \t 700 \t 70 ]\n",
      "11 \tObject: train \tConfidence = 0.6261 \tBbox: [ 1 \t 3 \t 398 \t 825 ]\n",
      "12 \tObject: person \tConfidence = 0.6175 \tBbox: [ 513 \t 0 \t 584 \t 176 ]\n",
      "13 \tObject: person \tConfidence = 0.6032 \tBbox: [ 425 \t 106 \t 496 \t 247 ]\n",
      "14 \tObject: person \tConfidence = 0.5539 \tBbox: [ 239 \t 559 \t 438 \t 1070 ]\n",
      "15 \tObject: person \tConfidence = 0.521 \tBbox: [ 579 \t 0 \t 637 \t 154 ]\n",
      "16 \tObject: person \tConfidence = 0.458 \tBbox: [ 368 \t 88 \t 422 \t 208 ]\n",
      "17 \tObject: person \tConfidence = 0.4472 \tBbox: [ 400 \t 0 \t 459 \t 145 ]\n",
      "18 \tObject: person \tConfidence = 0.394 \tBbox: [ 255 \t 693 \t 438 \t 942 ]\n",
      "19 \tObject: person \tConfidence = 0.382 \tBbox: [ 1 \t 860 \t 191 \t 1079 ]\n",
      "20 \tObject: person \tConfidence = 0.3635 \tBbox: [ 452 \t 0 \t 502 \t 119 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    19\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000631 / 1050\n",
      "Frames to be processed: 419  | To do: 39.9 % | Done: 60.1 %\n",
      "\n",
      "2022-04-20 13:15:31.104199\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000631.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 19 persons, 1 train\n",
      "Speed: 28.7ms pre-process, 174.1ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 20 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8802 \tBbox: [ 590 \t 127 \t 702 \t 422 ]\n",
      "2 \tObject: person \tConfidence = 0.8479 \tBbox: [ 16 \t 625 \t 274 \t 1076 ]\n",
      "3 \tObject: person \tConfidence = 0.8363 \tBbox: [ 408 \t 194 \t 520 \t 497 ]\n",
      "4 \tObject: person \tConfidence = 0.8358 \tBbox: [ 312 \t 421 \t 454 \t 716 ]\n",
      "5 \tObject: person \tConfidence = 0.8277 \tBbox: [ 628 \t 187 \t 765 \t 507 ]\n",
      "6 \tObject: person \tConfidence = 0.8113 \tBbox: [ 517 \t 603 \t 755 \t 1061 ]\n",
      "7 \tObject: person \tConfidence = 0.7862 \tBbox: [ 487 \t 104 \t 572 \t 341 ]\n",
      "8 \tObject: person \tConfidence = 0.7475 \tBbox: [ 30 \t 487 \t 204 \t 754 ]\n",
      "9 \tObject: person \tConfidence = 0.7127 \tBbox: [ 345 \t 185 \t 429 \t 457 ]\n",
      "10 \tObject: person \tConfidence = 0.6993 \tBbox: [ 255 \t 568 \t 444 \t 1063 ]\n",
      "11 \tObject: person \tConfidence = 0.6773 \tBbox: [ 654 \t 0 \t 700 \t 71 ]\n",
      "12 \tObject: person \tConfidence = 0.5866 \tBbox: [ 512 \t 0 \t 583 \t 180 ]\n",
      "13 \tObject: train \tConfidence = 0.5282 \tBbox: [ 0 \t 2 \t 397 \t 837 ]\n",
      "14 \tObject: person \tConfidence = 0.4322 \tBbox: [ 580 \t 0 \t 644 \t 161 ]\n",
      "15 \tObject: person \tConfidence = 0.427 \tBbox: [ 400 \t 0 \t 457 \t 148 ]\n",
      "16 \tObject: person \tConfidence = 0.4098 \tBbox: [ 441 \t 0 \t 502 \t 149 ]\n",
      "17 \tObject: person \tConfidence = 0.4027 \tBbox: [ 321 \t 149 \t 419 \t 271 ]\n",
      "18 \tObject: person \tConfidence = 0.3789 \tBbox: [ 426 \t 103 \t 503 \t 242 ]\n",
      "19 \tObject: person \tConfidence = 0.3718 \tBbox: [ 1 \t 861 \t 200 \t 1079 ]\n",
      "20 \tObject: person \tConfidence = 0.341 \tBbox: [ 368 \t 89 \t 425 \t 211 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    19\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000632 / 1050\n",
      "Frames to be processed: 418  | To do: 39.81 % | Done: 60.19 %\n",
      "\n",
      "2022-04-20 13:15:31.694452\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000632.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 19 persons, 1 train\n",
      "Speed: 23.9ms pre-process, 178.1ms inference, 11.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 20 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9096 \tBbox: [ 597 \t 129 \t 709 \t 422 ]\n",
      "2 \tObject: person \tConfidence = 0.8492 \tBbox: [ 412 \t 193 \t 522 \t 496 ]\n",
      "3 \tObject: person \tConfidence = 0.8324 \tBbox: [ 20 \t 624 \t 319 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8269 \tBbox: [ 275 \t 575 \t 464 \t 1067 ]\n",
      "5 \tObject: person \tConfidence = 0.8019 \tBbox: [ 310 \t 421 \t 453 \t 687 ]\n",
      "6 \tObject: person \tConfidence = 0.7467 \tBbox: [ 495 \t 105 \t 575 \t 350 ]\n",
      "7 \tObject: person \tConfidence = 0.738 \tBbox: [ 658 \t 186 \t 766 \t 508 ]\n",
      "8 \tObject: person \tConfidence = 0.7177 \tBbox: [ 519 \t 605 \t 766 \t 1058 ]\n",
      "9 \tObject: person \tConfidence = 0.6568 \tBbox: [ 344 \t 183 \t 423 \t 453 ]\n",
      "10 \tObject: person \tConfidence = 0.5254 \tBbox: [ 22 \t 493 \t 172 \t 731 ]\n",
      "11 \tObject: person \tConfidence = 0.523 \tBbox: [ 659 \t 0 \t 698 \t 71 ]\n",
      "12 \tObject: person \tConfidence = 0.5169 \tBbox: [ 375 \t 89 \t 433 \t 239 ]\n",
      "13 \tObject: person \tConfidence = 0.5001 \tBbox: [ 1 \t 858 \t 172 \t 1078 ]\n",
      "14 \tObject: person \tConfidence = 0.4889 \tBbox: [ 584 \t 0 \t 651 \t 153 ]\n",
      "15 \tObject: train \tConfidence = 0.4531 \tBbox: [ 0 \t 2 \t 399 \t 828 ]\n",
      "16 \tObject: person \tConfidence = 0.3813 \tBbox: [ 321 \t 150 \t 423 \t 262 ]\n",
      "17 \tObject: person \tConfidence = 0.3577 \tBbox: [ 509 \t 0 \t 578 \t 162 ]\n",
      "18 \tObject: person \tConfidence = 0.3465 \tBbox: [ 447 \t 104 \t 515 \t 238 ]\n",
      "19 \tObject: person \tConfidence = 0.3216 \tBbox: [ 399 \t 0 \t 453 \t 142 ]\n",
      "20 \tObject: person \tConfidence = 0.3216 \tBbox: [ 444 \t 0 \t 498 \t 126 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    19\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000633 / 1050\n",
      "Frames to be processed: 417  | To do: 39.71 % | Done: 60.29 %\n",
      "\n",
      "2022-04-20 13:15:32.241923\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000633.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 17 persons, 1 train\n",
      "Speed: 24.5ms pre-process, 173.0ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 18 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9196 \tBbox: [ 600 \t 129 \t 713 \t 424 ]\n",
      "2 \tObject: person \tConfidence = 0.8578 \tBbox: [ 310 \t 419 \t 452 \t 678 ]\n",
      "3 \tObject: person \tConfidence = 0.8333 \tBbox: [ 414 \t 192 \t 522 \t 496 ]\n",
      "4 \tObject: person \tConfidence = 0.7855 \tBbox: [ 674 \t 189 \t 766 \t 513 ]\n",
      "5 \tObject: person \tConfidence = 0.7823 \tBbox: [ 13 \t 491 \t 163 \t 736 ]\n",
      "6 \tObject: person \tConfidence = 0.7635 \tBbox: [ 500 \t 104 \t 576 \t 343 ]\n",
      "7 \tObject: person \tConfidence = 0.7562 \tBbox: [ 22 \t 626 \t 305 \t 1077 ]\n",
      "8 \tObject: person \tConfidence = 0.7525 \tBbox: [ 288 \t 578 \t 479 \t 1067 ]\n",
      "9 \tObject: person \tConfidence = 0.7238 \tBbox: [ 521 \t 604 \t 766 \t 1059 ]\n",
      "10 \tObject: person \tConfidence = 0.647 \tBbox: [ 342 \t 184 \t 425 \t 453 ]\n",
      "11 \tObject: train \tConfidence = 0.6372 \tBbox: [ 0 \t 2 \t 403 \t 848 ]\n",
      "12 \tObject: person \tConfidence = 0.5605 \tBbox: [ 379 \t 90 \t 437 \t 244 ]\n",
      "13 \tObject: person \tConfidence = 0.5192 \tBbox: [ 1 \t 856 \t 137 \t 1079 ]\n",
      "14 \tObject: person \tConfidence = 0.4232 \tBbox: [ 513 \t 0 \t 581 \t 157 ]\n",
      "15 \tObject: person \tConfidence = 0.4137 \tBbox: [ 585 \t 0 \t 653 \t 153 ]\n",
      "16 \tObject: person \tConfidence = 0.4069 \tBbox: [ 664 \t 0 \t 698 \t 71 ]\n",
      "17 \tObject: person \tConfidence = 0.3722 \tBbox: [ 324 \t 149 \t 422 \t 264 ]\n",
      "18 \tObject: person \tConfidence = 0.3334 \tBbox: [ 443 \t 0 \t 498 \t 127 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    17\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000634 / 1050\n",
      "Frames to be processed: 416  | To do: 39.62 % | Done: 60.38 %\n",
      "\n",
      "2022-04-20 13:15:32.865761\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000634.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 28.2ms pre-process, 176.1ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9197 \tBbox: [ 603 \t 132 \t 717 \t 425 ]\n",
      "2 \tObject: person \tConfidence = 0.8367 \tBbox: [ 418 \t 192 \t 529 \t 495 ]\n",
      "3 \tObject: person \tConfidence = 0.8123 \tBbox: [ 295 \t 579 \t 486 \t 1067 ]\n",
      "4 \tObject: person \tConfidence = 0.7763 \tBbox: [ 308 \t 420 \t 453 \t 673 ]\n",
      "5 \tObject: person \tConfidence = 0.7287 \tBbox: [ 39 \t 627 \t 353 \t 1077 ]\n",
      "6 \tObject: person \tConfidence = 0.6918 \tBbox: [ 504 \t 100 \t 579 \t 344 ]\n",
      "7 \tObject: person \tConfidence = 0.6553 \tBbox: [ 342 \t 184 \t 427 \t 454 ]\n",
      "8 \tObject: person \tConfidence = 0.6511 \tBbox: [ 3 \t 492 \t 156 \t 778 ]\n",
      "9 \tObject: person \tConfidence = 0.6006 \tBbox: [ 685 \t 191 \t 766 \t 537 ]\n",
      "10 \tObject: person \tConfidence = 0.5503 \tBbox: [ 1 \t 857 \t 147 \t 1079 ]\n",
      "11 \tObject: person \tConfidence = 0.5225 \tBbox: [ 527 \t 604 \t 765 \t 1059 ]\n",
      "12 \tObject: person \tConfidence = 0.4764 \tBbox: [ 322 \t 149 \t 424 \t 263 ]\n",
      "13 \tObject: person \tConfidence = 0.4642 \tBbox: [ 384 \t 89 \t 444 \t 245 ]\n",
      "14 \tObject: person \tConfidence = 0.4402 \tBbox: [ 516 \t 0 \t 580 \t 159 ]\n",
      "15 \tObject: train \tConfidence = 0.4245 \tBbox: [ 0 \t 2 \t 398 \t 756 ]\n",
      "16 \tObject: person \tConfidence = 0.3494 \tBbox: [ 586 \t 1 \t 656 \t 156 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000635 / 1050\n",
      "Frames to be processed: 415  | To do: 39.52 % | Done: 60.48 %\n",
      "\n",
      "2022-04-20 13:15:33.392801\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000635.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 17 persons, 1 train\n",
      "Speed: 24.3ms pre-process, 172.2ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 18 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9072 \tBbox: [ 606 \t 134 \t 721 \t 434 ]\n",
      "2 \tObject: person \tConfidence = 0.8631 \tBbox: [ 416 \t 192 \t 535 \t 497 ]\n",
      "3 \tObject: person \tConfidence = 0.8346 \tBbox: [ 299 \t 580 \t 495 \t 1064 ]\n",
      "4 \tObject: person \tConfidence = 0.7879 \tBbox: [ 0 \t 490 \t 159 \t 867 ]\n",
      "5 \tObject: person \tConfidence = 0.7246 \tBbox: [ 306 \t 418 \t 445 \t 625 ]\n",
      "6 \tObject: person \tConfidence = 0.7183 \tBbox: [ 514 \t 112 \t 583 \t 340 ]\n",
      "7 \tObject: person \tConfidence = 0.6916 \tBbox: [ 62 \t 628 \t 409 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.6853 \tBbox: [ 339 \t 185 \t 430 \t 456 ]\n",
      "9 \tObject: person \tConfidence = 0.6153 \tBbox: [ 534 \t 606 \t 765 \t 1056 ]\n",
      "10 \tObject: person \tConfidence = 0.5705 \tBbox: [ 1 \t 857 \t 185 \t 1078 ]\n",
      "11 \tObject: person \tConfidence = 0.5704 \tBbox: [ 320 \t 149 \t 425 \t 261 ]\n",
      "12 \tObject: person \tConfidence = 0.5499 \tBbox: [ 687 \t 201 \t 765 \t 543 ]\n",
      "13 \tObject: train \tConfidence = 0.4605 \tBbox: [ 0 \t 3 \t 395 \t 656 ]\n",
      "14 \tObject: person \tConfidence = 0.4528 \tBbox: [ 521 \t 0 \t 580 \t 161 ]\n",
      "15 \tObject: person \tConfidence = 0.3945 \tBbox: [ 387 \t 88 \t 449 \t 245 ]\n",
      "16 \tObject: person \tConfidence = 0.3794 \tBbox: [ 461 \t 101 \t 533 \t 263 ]\n",
      "17 \tObject: person \tConfidence = 0.3282 \tBbox: [ 589 \t 0 \t 659 \t 157 ]\n",
      "18 \tObject: person \tConfidence = 0.3171 \tBbox: [ 292 \t 106 \t 340 \t 302 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    17\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000636 / 1050\n",
      "Frames to be processed: 414  | To do: 39.43 % | Done: 60.57 %\n",
      "\n",
      "2022-04-20 13:15:33.879743\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000636.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 18 persons\n",
      "Speed: 27.7ms pre-process, 174.9ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 18 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8963 \tBbox: [ 609 \t 140 \t 725 \t 437 ]\n",
      "2 \tObject: person \tConfidence = 0.8591 \tBbox: [ 418 \t 191 \t 537 \t 496 ]\n",
      "3 \tObject: person \tConfidence = 0.8394 \tBbox: [ 73 \t 627 \t 363 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.8082 \tBbox: [ 305 \t 583 \t 494 \t 1069 ]\n",
      "5 \tObject: person \tConfidence = 0.7363 \tBbox: [ 0 \t 488 \t 153 \t 871 ]\n",
      "6 \tObject: person \tConfidence = 0.7343 \tBbox: [ 321 \t 147 \t 424 \t 265 ]\n",
      "7 \tObject: person \tConfidence = 0.7255 \tBbox: [ 306 \t 419 \t 442 \t 628 ]\n",
      "8 \tObject: person \tConfidence = 0.7148 \tBbox: [ 328 \t 184 \t 427 \t 456 ]\n",
      "9 \tObject: person \tConfidence = 0.642 \tBbox: [ 521 \t 123 \t 586 \t 339 ]\n",
      "10 \tObject: person \tConfidence = 0.6378 \tBbox: [ 556 \t 604 \t 766 \t 1049 ]\n",
      "11 \tObject: person \tConfidence = 0.5522 \tBbox: [ 0 \t 857 \t 205 \t 1078 ]\n",
      "12 \tObject: person \tConfidence = 0.5049 \tBbox: [ 470 \t 100 \t 542 \t 310 ]\n",
      "13 \tObject: person \tConfidence = 0.4368 \tBbox: [ 292 \t 106 \t 341 \t 303 ]\n",
      "14 \tObject: person \tConfidence = 0.4261 \tBbox: [ 390 \t 89 \t 452 \t 248 ]\n",
      "15 \tObject: person \tConfidence = 0.4187 \tBbox: [ 591 \t 0 \t 664 \t 165 ]\n",
      "16 \tObject: person \tConfidence = 0.366 \tBbox: [ 523 \t 0 \t 580 \t 157 ]\n",
      "17 \tObject: person \tConfidence = 0.3655 \tBbox: [ 438 \t 0 \t 496 \t 142 ]\n",
      "18 \tObject: person \tConfidence = 0.3024 \tBbox: [ 695 \t 210 \t 766 \t 553 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    18\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000637 / 1050\n",
      "Frames to be processed: 413  | To do: 39.33 % | Done: 60.67 %\n",
      "\n",
      "2022-04-20 13:15:34.368609\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000637.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 18 persons, 1 train\n",
      "Speed: 37.6ms pre-process, 172.4ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 19 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8453 \tBbox: [ 615 \t 142 \t 733 \t 451 ]\n",
      "2 \tObject: person \tConfidence = 0.8186 \tBbox: [ 421 \t 187 \t 539 \t 495 ]\n",
      "3 \tObject: person \tConfidence = 0.8179 \tBbox: [ 89 \t 626 \t 365 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.7547 \tBbox: [ 326 \t 183 \t 425 \t 453 ]\n",
      "5 \tObject: person \tConfidence = 0.742 \tBbox: [ 326 \t 582 \t 524 \t 1068 ]\n",
      "6 \tObject: person \tConfidence = 0.7267 \tBbox: [ 320 \t 147 \t 424 \t 265 ]\n",
      "7 \tObject: person \tConfidence = 0.7104 \tBbox: [ 529 \t 102 \t 593 \t 338 ]\n",
      "8 \tObject: person \tConfidence = 0.6534 \tBbox: [ 303 \t 416 \t 439 \t 634 ]\n",
      "9 \tObject: person \tConfidence = 0.5683 \tBbox: [ 301 \t 113 \t 352 \t 290 ]\n",
      "10 \tObject: person \tConfidence = 0.4865 \tBbox: [ 0 \t 487 \t 156 \t 870 ]\n",
      "11 \tObject: person \tConfidence = 0.4861 \tBbox: [ 594 \t 0 \t 665 \t 176 ]\n",
      "12 \tObject: person \tConfidence = 0.4711 \tBbox: [ 599 \t 599 \t 766 \t 1038 ]\n",
      "13 \tObject: person \tConfidence = 0.4523 \tBbox: [ 482 \t 96 \t 554 \t 335 ]\n",
      "14 \tObject: person \tConfidence = 0.4404 \tBbox: [ 395 \t 87 \t 464 \t 265 ]\n",
      "15 \tObject: train \tConfidence = 0.3397 \tBbox: [ 2 \t 2 \t 395 \t 684 ]\n",
      "16 \tObject: person \tConfidence = 0.3293 \tBbox: [ 518 \t 0 \t 583 \t 144 ]\n",
      "17 \tObject: person \tConfidence = 0.3225 \tBbox: [ 440 \t 0 \t 496 \t 148 ]\n",
      "18 \tObject: person \tConfidence = 0.3189 \tBbox: [ 1 \t 857 \t 202 \t 1078 ]\n",
      "19 \tObject: person \tConfidence = 0.3056 \tBbox: [ 715 \t 223 \t 765 \t 562 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    18\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000638 / 1050\n",
      "Frames to be processed: 412  | To do: 39.24 % | Done: 60.76 %\n",
      "\n",
      "2022-04-20 13:15:34.923707\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000638.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 17 persons, 1 train\n",
      "Speed: 26.0ms pre-process, 169.2ms inference, 4.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 18 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8441 \tBbox: [ 619 \t 142 \t 738 \t 452 ]\n",
      "2 \tObject: person \tConfidence = 0.8416 \tBbox: [ 419 \t 187 \t 549 \t 497 ]\n",
      "3 \tObject: person \tConfidence = 0.8383 \tBbox: [ 100 \t 624 \t 357 \t 1075 ]\n",
      "4 \tObject: person \tConfidence = 0.7742 \tBbox: [ 337 \t 583 \t 528 \t 1064 ]\n",
      "5 \tObject: person \tConfidence = 0.7593 \tBbox: [ 325 \t 182 \t 426 \t 454 ]\n",
      "6 \tObject: person \tConfidence = 0.7422 \tBbox: [ 536 \t 92 \t 599 \t 337 ]\n",
      "7 \tObject: person \tConfidence = 0.7063 \tBbox: [ 323 \t 148 \t 425 \t 266 ]\n",
      "8 \tObject: person \tConfidence = 0.704 \tBbox: [ 622 \t 635 \t 765 \t 1027 ]\n",
      "9 \tObject: person \tConfidence = 0.6727 \tBbox: [ 302 \t 414 \t 439 \t 652 ]\n",
      "10 \tObject: person \tConfidence = 0.6451 \tBbox: [ 596 \t 0 \t 666 \t 176 ]\n",
      "11 \tObject: person \tConfidence = 0.6435 \tBbox: [ 486 \t 96 \t 566 \t 345 ]\n",
      "12 \tObject: train \tConfidence = 0.489 \tBbox: [ 0 \t 2 \t 402 \t 826 ]\n",
      "13 \tObject: person \tConfidence = 0.4479 \tBbox: [ 0 \t 487 \t 165 \t 872 ]\n",
      "14 \tObject: person \tConfidence = 0.4367 \tBbox: [ 398 \t 84 \t 468 \t 263 ]\n",
      "15 \tObject: person \tConfidence = 0.4217 \tBbox: [ 520 \t 0 \t 587 \t 100 ]\n",
      "16 \tObject: person \tConfidence = 0.3885 \tBbox: [ 308 \t 111 \t 357 \t 281 ]\n",
      "17 \tObject: person \tConfidence = 0.3728 \tBbox: [ 447 \t 0 \t 498 \t 150 ]\n",
      "18 \tObject: person \tConfidence = 0.3089 \tBbox: [ 1 \t 856 \t 191 \t 1078 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    17\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000639 / 1050\n",
      "Frames to be processed: 411  | To do: 39.14 % | Done: 60.86 %\n",
      "\n",
      "2022-04-20 13:15:35.403572\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000639.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 17 persons\n",
      "Speed: 36.1ms pre-process, 175.5ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8526 \tBbox: [ 125 \t 623 \t 363 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8521 \tBbox: [ 421 \t 187 \t 544 \t 496 ]\n",
      "3 \tObject: person \tConfidence = 0.8397 \tBbox: [ 621 \t 148 \t 742 \t 463 ]\n",
      "4 \tObject: person \tConfidence = 0.8029 \tBbox: [ 344 \t 581 \t 536 \t 1069 ]\n",
      "5 \tObject: person \tConfidence = 0.7772 \tBbox: [ 536 \t 94 \t 602 \t 345 ]\n",
      "6 \tObject: person \tConfidence = 0.7641 \tBbox: [ 324 \t 182 \t 425 \t 455 ]\n",
      "7 \tObject: person \tConfidence = 0.6326 \tBbox: [ 322 \t 146 \t 425 \t 267 ]\n",
      "8 \tObject: person \tConfidence = 0.5733 \tBbox: [ 297 \t 415 \t 437 \t 707 ]\n",
      "9 \tObject: person \tConfidence = 0.5598 \tBbox: [ 599 \t 0 \t 664 \t 175 ]\n",
      "10 \tObject: person \tConfidence = 0.5212 \tBbox: [ 487 \t 95 \t 559 \t 320 ]\n",
      "11 \tObject: person \tConfidence = 0.4932 \tBbox: [ 647 \t 630 \t 765 \t 1038 ]\n",
      "12 \tObject: person \tConfidence = 0.4036 \tBbox: [ 314 \t 109 \t 359 \t 247 ]\n",
      "13 \tObject: person \tConfidence = 0.3935 \tBbox: [ 398 \t 82 \t 474 \t 259 ]\n",
      "14 \tObject: person \tConfidence = 0.3502 \tBbox: [ 0 \t 491 \t 158 \t 879 ]\n",
      "15 \tObject: person \tConfidence = 0.3459 \tBbox: [ 520 \t 0 \t 588 \t 107 ]\n",
      "16 \tObject: person \tConfidence = 0.336 \tBbox: [ 443 \t 0 \t 498 \t 151 ]\n",
      "17 \tObject: person \tConfidence = 0.3032 \tBbox: [ 1 \t 856 \t 172 \t 1078 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    17\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000640 / 1050\n",
      "Frames to be processed: 410  | To do: 39.05 % | Done: 60.95 %\n",
      "\n",
      "2022-04-20 13:15:35.868525\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000640.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 43.2ms pre-process, 174.3ms inference, 4.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8736 \tBbox: [ 131 \t 621 \t 367 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8719 \tBbox: [ 621 \t 148 \t 748 \t 483 ]\n",
      "3 \tObject: person \tConfidence = 0.8643 \tBbox: [ 421 \t 186 \t 545 \t 498 ]\n",
      "4 \tObject: person \tConfidence = 0.8074 \tBbox: [ 346 \t 582 \t 541 \t 1071 ]\n",
      "5 \tObject: person \tConfidence = 0.7867 \tBbox: [ 325 \t 181 \t 426 \t 452 ]\n",
      "6 \tObject: person \tConfidence = 0.7332 \tBbox: [ 549 \t 94 \t 612 \t 343 ]\n",
      "7 \tObject: person \tConfidence = 0.7208 \tBbox: [ 601 \t 0 \t 666 \t 176 ]\n",
      "8 \tObject: person \tConfidence = 0.6741 \tBbox: [ 497 \t 96 \t 567 \t 353 ]\n",
      "9 \tObject: person \tConfidence = 0.6306 \tBbox: [ 297 \t 414 \t 438 \t 758 ]\n",
      "10 \tObject: person \tConfidence = 0.5625 \tBbox: [ 398 \t 85 \t 479 \t 259 ]\n",
      "11 \tObject: person \tConfidence = 0.5492 \tBbox: [ 319 \t 148 \t 426 \t 269 ]\n",
      "12 \tObject: person \tConfidence = 0.5018 \tBbox: [ 442 \t 0 \t 497 \t 152 ]\n",
      "13 \tObject: person \tConfidence = 0.4729 \tBbox: [ 516 \t 0 \t 590 \t 106 ]\n",
      "14 \tObject: train \tConfidence = 0.4596 \tBbox: [ 0 \t 3 \t 443 \t 868 ]\n",
      "15 \tObject: person \tConfidence = 0.4159 \tBbox: [ 0 \t 490 \t 155 \t 876 ]\n",
      "16 \tObject: person \tConfidence = 0.374 \tBbox: [ 1 \t 855 \t 165 \t 1078 ]\n",
      "17 \tObject: person \tConfidence = 0.3247 \tBbox: [ 511 \t 0 \t 546 \t 64 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000641 / 1050\n",
      "Frames to be processed: 409  | To do: 38.95 % | Done: 61.05 %\n",
      "\n",
      "2022-04-20 13:15:36.352782\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000641.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 17 persons, 1 train\n",
      "Speed: 30.6ms pre-process, 167.4ms inference, 2.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 18 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8653 \tBbox: [ 622 \t 151 \t 753 \t 463 ]\n",
      "2 \tObject: person \tConfidence = 0.8643 \tBbox: [ 423 \t 186 \t 545 \t 497 ]\n",
      "3 \tObject: person \tConfidence = 0.8606 \tBbox: [ 132 \t 619 \t 374 \t 1077 ]\n",
      "4 \tObject: person \tConfidence = 0.8223 \tBbox: [ 323 \t 180 \t 427 \t 452 ]\n",
      "5 \tObject: person \tConfidence = 0.8175 \tBbox: [ 358 \t 585 \t 557 \t 1069 ]\n",
      "6 \tObject: person \tConfidence = 0.7543 \tBbox: [ 602 \t 0 \t 666 \t 176 ]\n",
      "7 \tObject: person \tConfidence = 0.7412 \tBbox: [ 554 \t 95 \t 627 \t 340 ]\n",
      "8 \tObject: person \tConfidence = 0.7407 \tBbox: [ 502 \t 96 \t 574 \t 341 ]\n",
      "9 \tObject: person \tConfidence = 0.7396 \tBbox: [ 294 \t 414 \t 438 \t 746 ]\n",
      "10 \tObject: person \tConfidence = 0.6353 \tBbox: [ 324 \t 146 \t 424 \t 268 ]\n",
      "11 \tObject: person \tConfidence = 0.5788 \tBbox: [ 441 \t 0 \t 495 \t 150 ]\n",
      "12 \tObject: person \tConfidence = 0.4781 \tBbox: [ 518 \t 0 \t 590 \t 119 ]\n",
      "13 \tObject: person \tConfidence = 0.418 \tBbox: [ 1 \t 855 \t 202 \t 1078 ]\n",
      "14 \tObject: person \tConfidence = 0.41 \tBbox: [ 404 \t 84 \t 482 \t 251 ]\n",
      "15 \tObject: person \tConfidence = 0.3781 \tBbox: [ 0 \t 504 \t 145 \t 896 ]\n",
      "16 \tObject: train \tConfidence = 0.3557 \tBbox: [ 2 \t 1 \t 448 \t 891 ]\n",
      "17 \tObject: person \tConfidence = 0.3427 \tBbox: [ 321 \t 107 \t 369 \t 221 ]\n",
      "18 \tObject: person \tConfidence = 0.3004 \tBbox: [ 512 \t 0 \t 547 \t 63 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    17\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000642 / 1050\n",
      "Frames to be processed: 408  | To do: 38.86 % | Done: 61.14 %\n",
      "\n",
      "2022-04-20 13:15:36.884959\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000642.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 17 persons, 1 train\n",
      "Speed: 40.1ms pre-process, 175.9ms inference, 4.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 18 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8898 \tBbox: [ 426 \t 185 \t 559 \t 498 ]\n",
      "2 \tObject: person \tConfidence = 0.8796 \tBbox: [ 625 \t 153 \t 765 \t 462 ]\n",
      "3 \tObject: person \tConfidence = 0.8518 \tBbox: [ 511 \t 104 \t 606 \t 371 ]\n",
      "4 \tObject: person \tConfidence = 0.8486 \tBbox: [ 160 \t 618 \t 394 \t 1078 ]\n",
      "5 \tObject: person \tConfidence = 0.8394 \tBbox: [ 321 \t 180 \t 425 \t 451 ]\n",
      "6 \tObject: person \tConfidence = 0.8273 \tBbox: [ 377 \t 587 \t 574 \t 1068 ]\n",
      "7 \tObject: person \tConfidence = 0.7854 \tBbox: [ 606 \t 0 \t 667 \t 179 ]\n",
      "8 \tObject: person \tConfidence = 0.7562 \tBbox: [ 567 \t 97 \t 645 \t 334 ]\n",
      "9 \tObject: person \tConfidence = 0.7131 \tBbox: [ 286 \t 416 \t 443 \t 750 ]\n",
      "10 \tObject: person \tConfidence = 0.6385 \tBbox: [ 514 \t 0 \t 585 \t 149 ]\n",
      "11 \tObject: person \tConfidence = 0.6054 \tBbox: [ 1 \t 853 \t 125 \t 1078 ]\n",
      "12 \tObject: person \tConfidence = 0.5586 \tBbox: [ 0 \t 608 \t 172 \t 938 ]\n",
      "13 \tObject: train \tConfidence = 0.5492 \tBbox: [ 1 \t 2 \t 442 \t 797 ]\n",
      "14 \tObject: person \tConfidence = 0.5416 \tBbox: [ 325 \t 146 \t 423 \t 263 ]\n",
      "15 \tObject: person \tConfidence = 0.4397 \tBbox: [ 415 \t 81 \t 491 \t 252 ]\n",
      "16 \tObject: person \tConfidence = 0.3916 \tBbox: [ 438 \t 0 \t 492 \t 94 ]\n",
      "17 \tObject: person \tConfidence = 0.3203 \tBbox: [ 519 \t 0 \t 548 \t 39 ]\n",
      "18 \tObject: person \tConfidence = 0.3094 \tBbox: [ 353 \t 260 \t 408 \t 337 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    17\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000643 / 1050\n",
      "Frames to be processed: 407  | To do: 38.76 % | Done: 61.24 %\n",
      "\n",
      "2022-04-20 13:15:37.425763\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000643.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 27.7ms pre-process, 168.7ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8949 \tBbox: [ 627 \t 153 \t 766 \t 469 ]\n",
      "2 \tObject: person \tConfidence = 0.889 \tBbox: [ 427 \t 185 \t 557 \t 499 ]\n",
      "3 \tObject: person \tConfidence = 0.8753 \tBbox: [ 176 \t 618 \t 405 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8454 \tBbox: [ 321 \t 178 \t 424 \t 450 ]\n",
      "5 \tObject: person \tConfidence = 0.8375 \tBbox: [ 521 \t 105 \t 611 \t 375 ]\n",
      "6 \tObject: person \tConfidence = 0.8371 \tBbox: [ 607 \t 0 \t 671 \t 175 ]\n",
      "7 \tObject: person \tConfidence = 0.7754 \tBbox: [ 571 \t 98 \t 647 \t 333 ]\n",
      "8 \tObject: person \tConfidence = 0.7668 \tBbox: [ 385 \t 587 \t 582 \t 1070 ]\n",
      "9 \tObject: person \tConfidence = 0.6842 \tBbox: [ 510 \t 0 \t 588 \t 152 ]\n",
      "10 \tObject: person \tConfidence = 0.6369 \tBbox: [ 285 \t 417 \t 442 \t 777 ]\n",
      "11 \tObject: person \tConfidence = 0.5512 \tBbox: [ 1 \t 853 \t 127 \t 1079 ]\n",
      "12 \tObject: person \tConfidence = 0.5472 \tBbox: [ 1 \t 607 \t 202 \t 971 ]\n",
      "13 \tObject: person \tConfidence = 0.546 \tBbox: [ 324 \t 146 \t 423 \t 262 ]\n",
      "14 \tObject: train \tConfidence = 0.5178 \tBbox: [ 2 \t 0 \t 443 \t 922 ]\n",
      "15 \tObject: person \tConfidence = 0.4791 \tBbox: [ 417 \t 85 \t 495 \t 264 ]\n",
      "16 \tObject: person \tConfidence = 0.3674 \tBbox: [ 436 \t 0 \t 491 \t 109 ]\n",
      "17 \tObject: person \tConfidence = 0.3131 \tBbox: [ 353 \t 259 \t 407 \t 337 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000644 / 1050\n",
      "Frames to be processed: 406  | To do: 38.67 % | Done: 61.33 %\n",
      "\n",
      "2022-04-20 13:15:37.970452\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000644.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 17 persons, 1 train\n",
      "Speed: 40.7ms pre-process, 168.7ms inference, 7.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 18 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9026 \tBbox: [ 428 \t 185 \t 557 \t 497 ]\n",
      "2 \tObject: person \tConfidence = 0.8998 \tBbox: [ 631 \t 153 \t 766 \t 476 ]\n",
      "3 \tObject: person \tConfidence = 0.8452 \tBbox: [ 321 \t 177 \t 424 \t 450 ]\n",
      "4 \tObject: person \tConfidence = 0.8346 \tBbox: [ 179 \t 621 \t 417 \t 1078 ]\n",
      "5 \tObject: person \tConfidence = 0.7979 \tBbox: [ 394 \t 584 \t 598 \t 1076 ]\n",
      "6 \tObject: person \tConfidence = 0.7864 \tBbox: [ 576 \t 101 \t 653 \t 333 ]\n",
      "7 \tObject: person \tConfidence = 0.7783 \tBbox: [ 609 \t 0 \t 675 \t 182 ]\n",
      "8 \tObject: person \tConfidence = 0.6801 \tBbox: [ 524 \t 107 \t 617 \t 378 ]\n",
      "9 \tObject: person \tConfidence = 0.6672 \tBbox: [ 509 \t 1 \t 582 \t 166 ]\n",
      "10 \tObject: person \tConfidence = 0.6477 \tBbox: [ 283 \t 419 \t 439 \t 750 ]\n",
      "11 \tObject: person \tConfidence = 0.5362 \tBbox: [ 325 \t 147 \t 423 \t 262 ]\n",
      "12 \tObject: train \tConfidence = 0.5039 \tBbox: [ 1 \t 3 \t 443 \t 861 ]\n",
      "13 \tObject: person \tConfidence = 0.5005 \tBbox: [ 570 \t 0 \t 595 \t 47 ]\n",
      "14 \tObject: person \tConfidence = 0.4924 \tBbox: [ 422 \t 86 \t 499 \t 262 ]\n",
      "15 \tObject: person \tConfidence = 0.481 \tBbox: [ 1 \t 606 \t 186 \t 979 ]\n",
      "16 \tObject: person \tConfidence = 0.452 \tBbox: [ 1 \t 854 \t 127 \t 1078 ]\n",
      "17 \tObject: person \tConfidence = 0.4272 \tBbox: [ 436 \t 0 \t 488 \t 105 ]\n",
      "18 \tObject: person \tConfidence = 0.3 \tBbox: [ 353 \t 259 \t 407 \t 337 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    17\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000645 / 1050\n",
      "Frames to be processed: 405  | To do: 38.57 % | Done: 61.43 %\n",
      "\n",
      "2022-04-20 13:15:38.553928\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000645.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 18 persons, 1 train\n",
      "Speed: 29.1ms pre-process, 175.4ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 19 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8966 \tBbox: [ 637 \t 155 \t 766 \t 477 ]\n",
      "2 \tObject: person \tConfidence = 0.8894 \tBbox: [ 428 \t 185 \t 555 \t 497 ]\n",
      "3 \tObject: person \tConfidence = 0.8734 \tBbox: [ 534 \t 107 \t 629 \t 381 ]\n",
      "4 \tObject: person \tConfidence = 0.8409 \tBbox: [ 192 \t 623 \t 429 \t 1078 ]\n",
      "5 \tObject: person \tConfidence = 0.8175 \tBbox: [ 321 \t 173 \t 424 \t 450 ]\n",
      "6 \tObject: person \tConfidence = 0.7671 \tBbox: [ 581 \t 105 \t 652 \t 331 ]\n",
      "7 \tObject: person \tConfidence = 0.7565 \tBbox: [ 406 \t 586 \t 606 \t 1076 ]\n",
      "8 \tObject: person \tConfidence = 0.7455 \tBbox: [ 610 \t 0 \t 678 \t 182 ]\n",
      "9 \tObject: person \tConfidence = 0.7172 \tBbox: [ 511 \t 0 \t 584 \t 168 ]\n",
      "10 \tObject: train \tConfidence = 0.5066 \tBbox: [ 1 \t 4 \t 443 \t 831 ]\n",
      "11 \tObject: person \tConfidence = 0.4822 \tBbox: [ 325 \t 147 \t 425 \t 264 ]\n",
      "12 \tObject: person \tConfidence = 0.4731 \tBbox: [ 425 \t 84 \t 505 \t 262 ]\n",
      "13 \tObject: person \tConfidence = 0.4562 \tBbox: [ 277 \t 420 \t 437 \t 716 ]\n",
      "14 \tObject: person \tConfidence = 0.4403 \tBbox: [ 571 \t 0 \t 598 \t 57 ]\n",
      "15 \tObject: person \tConfidence = 0.3949 \tBbox: [ 509 \t 0 \t 533 \t 41 ]\n",
      "16 \tObject: person \tConfidence = 0.3891 \tBbox: [ 440 \t 0 \t 489 \t 109 ]\n",
      "17 \tObject: person \tConfidence = 0.3533 \tBbox: [ 1 \t 853 \t 145 \t 1078 ]\n",
      "18 \tObject: person \tConfidence = 0.3421 \tBbox: [ 354 \t 111 \t 404 \t 192 ]\n",
      "19 \tObject: person \tConfidence = 0.3368 \tBbox: [ 354 \t 260 \t 407 \t 336 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    18\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000646 / 1050\n",
      "Frames to be processed: 404  | To do: 38.48 % | Done: 61.52 %\n",
      "\n",
      "2022-04-20 13:15:39.032040\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000646.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 18 persons, 1 train\n",
      "Speed: 40.0ms pre-process, 176.8ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 19 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8979 \tBbox: [ 644 \t 157 \t 766 \t 477 ]\n",
      "2 \tObject: person \tConfidence = 0.8897 \tBbox: [ 428 \t 185 \t 556 \t 496 ]\n",
      "3 \tObject: person \tConfidence = 0.8807 \tBbox: [ 535 \t 107 \t 630 \t 381 ]\n",
      "4 \tObject: person \tConfidence = 0.867 \tBbox: [ 201 \t 626 \t 431 \t 1078 ]\n",
      "5 \tObject: person \tConfidence = 0.7773 \tBbox: [ 589 \t 104 \t 646 \t 335 ]\n",
      "6 \tObject: person \tConfidence = 0.7749 \tBbox: [ 322 \t 161 \t 424 \t 451 ]\n",
      "7 \tObject: person \tConfidence = 0.7714 \tBbox: [ 510 \t 0 \t 584 \t 175 ]\n",
      "8 \tObject: person \tConfidence = 0.7435 \tBbox: [ 614 \t 0 \t 686 \t 190 ]\n",
      "9 \tObject: person \tConfidence = 0.7139 \tBbox: [ 277 \t 424 \t 435 \t 705 ]\n",
      "10 \tObject: person \tConfidence = 0.6495 \tBbox: [ 411 \t 584 \t 631 \t 1077 ]\n",
      "11 \tObject: person \tConfidence = 0.5651 \tBbox: [ 573 \t 0 \t 601 \t 60 ]\n",
      "12 \tObject: train \tConfidence = 0.5633 \tBbox: [ 1 \t 3 \t 440 \t 740 ]\n",
      "13 \tObject: person \tConfidence = 0.5183 \tBbox: [ 428 \t 91 \t 505 \t 244 ]\n",
      "14 \tObject: person \tConfidence = 0.4709 \tBbox: [ 438 \t 0 \t 487 \t 119 ]\n",
      "15 \tObject: person \tConfidence = 0.4504 \tBbox: [ 324 \t 148 \t 425 \t 265 ]\n",
      "16 \tObject: person \tConfidence = 0.4342 \tBbox: [ 1 \t 852 \t 179 \t 1079 ]\n",
      "17 \tObject: person \tConfidence = 0.4306 \tBbox: [ 361 \t 113 \t 412 \t 196 ]\n",
      "18 \tObject: person \tConfidence = 0.3939 \tBbox: [ 354 \t 261 \t 407 \t 335 ]\n",
      "19 \tObject: person \tConfidence = 0.321 \tBbox: [ 510 \t 0 \t 535 \t 41 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    18\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000647 / 1050\n",
      "Frames to be processed: 403  | To do: 38.38 % | Done: 61.62 %\n",
      "\n",
      "2022-04-20 13:15:39.526393\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000647.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 18 persons, 1 train\n",
      "Speed: 27.8ms pre-process, 180.2ms inference, 3.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 19 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8974 \tBbox: [ 427 \t 186 \t 556 \t 494 ]\n",
      "2 \tObject: person \tConfidence = 0.8887 \tBbox: [ 656 \t 158 \t 766 \t 478 ]\n",
      "3 \tObject: person \tConfidence = 0.849 \tBbox: [ 536 \t 103 \t 632 \t 379 ]\n",
      "4 \tObject: person \tConfidence = 0.8353 \tBbox: [ 224 \t 631 \t 461 \t 1079 ]\n",
      "5 \tObject: person \tConfidence = 0.8162 \tBbox: [ 512 \t 0 \t 583 \t 179 ]\n",
      "6 \tObject: person \tConfidence = 0.7776 \tBbox: [ 9 \t 604 \t 226 \t 989 ]\n",
      "7 \tObject: person \tConfidence = 0.7669 \tBbox: [ 618 \t 1 \t 688 \t 190 ]\n",
      "8 \tObject: person \tConfidence = 0.7599 \tBbox: [ 321 \t 179 \t 427 \t 449 ]\n",
      "9 \tObject: person \tConfidence = 0.6963 \tBbox: [ 323 \t 148 \t 425 \t 265 ]\n",
      "10 \tObject: person \tConfidence = 0.6847 \tBbox: [ 603 \t 106 \t 655 \t 329 ]\n",
      "11 \tObject: train \tConfidence = 0.6131 \tBbox: [ 1 \t 2 \t 440 \t 848 ]\n",
      "12 \tObject: person \tConfidence = 0.5596 \tBbox: [ 369 \t 115 \t 421 \t 206 ]\n",
      "13 \tObject: person \tConfidence = 0.5468 \tBbox: [ 577 \t 0 \t 605 \t 63 ]\n",
      "14 \tObject: person \tConfidence = 0.5457 \tBbox: [ 434 \t 0 \t 483 \t 134 ]\n",
      "15 \tObject: person \tConfidence = 0.5201 \tBbox: [ 440 \t 83 \t 517 \t 250 ]\n",
      "16 \tObject: person \tConfidence = 0.494 \tBbox: [ 260 \t 428 \t 438 \t 732 ]\n",
      "17 \tObject: person \tConfidence = 0.488 \tBbox: [ 439 \t 578 \t 647 \t 1076 ]\n",
      "18 \tObject: person \tConfidence = 0.4859 \tBbox: [ 1 \t 850 \t 162 \t 1078 ]\n",
      "19 \tObject: person \tConfidence = 0.3023 \tBbox: [ 507 \t 706 \t 666 \t 947 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    18\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000648 / 1050\n",
      "Frames to be processed: 402  | To do: 38.29 % | Done: 61.71 %\n",
      "\n",
      "2022-04-20 13:15:40.070206\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000648.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 18 persons, 1 train\n",
      "Speed: 35.6ms pre-process, 185.4ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 19 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8919 \tBbox: [ 427 \t 187 \t 556 \t 494 ]\n",
      "2 \tObject: person \tConfidence = 0.8852 \tBbox: [ 663 \t 160 \t 766 \t 477 ]\n",
      "3 \tObject: person \tConfidence = 0.838 \tBbox: [ 253 \t 636 \t 465 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.8264 \tBbox: [ 509 \t 0 \t 581 \t 177 ]\n",
      "5 \tObject: person \tConfidence = 0.7944 \tBbox: [ 543 \t 102 \t 633 \t 379 ]\n",
      "6 \tObject: person \tConfidence = 0.7902 \tBbox: [ 13 \t 602 \t 234 \t 990 ]\n",
      "7 \tObject: person \tConfidence = 0.7708 \tBbox: [ 621 \t 2 \t 691 \t 191 ]\n",
      "8 \tObject: person \tConfidence = 0.7572 \tBbox: [ 321 \t 183 \t 427 \t 449 ]\n",
      "9 \tObject: person \tConfidence = 0.696 \tBbox: [ 608 \t 101 \t 660 \t 330 ]\n",
      "10 \tObject: person \tConfidence = 0.6485 \tBbox: [ 321 \t 148 \t 425 \t 268 ]\n",
      "11 \tObject: person \tConfidence = 0.6216 \tBbox: [ 578 \t 0 \t 607 \t 64 ]\n",
      "12 \tObject: person \tConfidence = 0.5894 \tBbox: [ 434 \t 0 \t 485 \t 136 ]\n",
      "13 \tObject: train \tConfidence = 0.5718 \tBbox: [ 1 \t 3 \t 438 \t 756 ]\n",
      "14 \tObject: person \tConfidence = 0.5515 \tBbox: [ 443 \t 83 \t 520 \t 251 ]\n",
      "15 \tObject: person \tConfidence = 0.5134 \tBbox: [ 451 \t 572 \t 658 \t 1063 ]\n",
      "16 \tObject: person \tConfidence = 0.4806 \tBbox: [ 253 \t 429 \t 452 \t 742 ]\n",
      "17 \tObject: person \tConfidence = 0.4703 \tBbox: [ 375 \t 118 \t 426 \t 218 ]\n",
      "18 \tObject: person \tConfidence = 0.46 \tBbox: [ 2 \t 853 \t 124 \t 1079 ]\n",
      "19 \tObject: person \tConfidence = 0.4491 \tBbox: [ 33 \t 865 \t 204 \t 1078 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    18\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000649 / 1050\n",
      "Frames to be processed: 401  | To do: 38.19 % | Done: 61.81 %\n",
      "\n",
      "2022-04-20 13:15:40.582013\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000649.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 19 persons, 1 train\n",
      "Speed: 23.9ms pre-process, 185.9ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 20 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9023 \tBbox: [ 427 \t 187 \t 554 \t 491 ]\n",
      "2 \tObject: person \tConfidence = 0.8994 \tBbox: [ 667 \t 163 \t 766 \t 477 ]\n",
      "3 \tObject: person \tConfidence = 0.8043 \tBbox: [ 13 \t 600 \t 242 \t 990 ]\n",
      "4 \tObject: person \tConfidence = 0.8007 \tBbox: [ 623 \t 11 \t 683 \t 192 ]\n",
      "5 \tObject: person \tConfidence = 0.7957 \tBbox: [ 250 \t 642 \t 487 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.7895 \tBbox: [ 509 \t 1 \t 577 \t 176 ]\n",
      "7 \tObject: person \tConfidence = 0.7258 \tBbox: [ 560 \t 103 \t 637 \t 379 ]\n",
      "8 \tObject: person \tConfidence = 0.6859 \tBbox: [ 610 \t 99 \t 665 \t 331 ]\n",
      "9 \tObject: person \tConfidence = 0.6631 \tBbox: [ 320 \t 181 \t 429 \t 448 ]\n",
      "10 \tObject: person \tConfidence = 0.6447 \tBbox: [ 318 \t 148 \t 423 \t 267 ]\n",
      "11 \tObject: person \tConfidence = 0.5912 \tBbox: [ 1 \t 846 \t 117 \t 1079 ]\n",
      "12 \tObject: person \tConfidence = 0.5879 \tBbox: [ 579 \t 0 \t 609 \t 64 ]\n",
      "13 \tObject: person \tConfidence = 0.5653 \tBbox: [ 249 \t 434 \t 420 \t 666 ]\n",
      "14 \tObject: person \tConfidence = 0.5626 \tBbox: [ 448 \t 85 \t 521 \t 223 ]\n",
      "15 \tObject: person \tConfidence = 0.5193 \tBbox: [ 459 \t 561 \t 680 \t 1030 ]\n",
      "16 \tObject: person \tConfidence = 0.4981 \tBbox: [ 65 \t 918 \t 200 \t 1079 ]\n",
      "17 \tObject: person \tConfidence = 0.4888 \tBbox: [ 433 \t 0 \t 482 \t 144 ]\n",
      "18 \tObject: person \tConfidence = 0.4687 \tBbox: [ 381 \t 120 \t 431 \t 231 ]\n",
      "19 \tObject: person \tConfidence = 0.408 \tBbox: [ 662 \t 0 \t 695 \t 95 ]\n",
      "20 \tObject: train \tConfidence = 0.3233 \tBbox: [ 3 \t 6 \t 441 \t 775 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    19\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000650 / 1050\n",
      "Frames to be processed: 400  | To do: 38.1 % | Done: 61.9 %\n",
      "\n",
      "2022-04-20 13:15:41.163679\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000650.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 17 persons\n",
      "Speed: 35.1ms pre-process, 185.6ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8851 \tBbox: [ 671 \t 167 \t 766 \t 487 ]\n",
      "2 \tObject: person \tConfidence = 0.8724 \tBbox: [ 428 \t 190 \t 552 \t 492 ]\n",
      "3 \tObject: person \tConfidence = 0.7899 \tBbox: [ 509 \t 0 \t 575 \t 177 ]\n",
      "4 \tObject: person \tConfidence = 0.786 \tBbox: [ 627 \t 8 \t 683 \t 192 ]\n",
      "5 \tObject: person \tConfidence = 0.7796 \tBbox: [ 565 \t 98 \t 642 \t 380 ]\n",
      "6 \tObject: person \tConfidence = 0.7149 \tBbox: [ 320 \t 184 \t 432 \t 448 ]\n",
      "7 \tObject: person \tConfidence = 0.6999 \tBbox: [ 238 \t 646 \t 494 \t 1078 ]\n",
      "8 \tObject: person \tConfidence = 0.6892 \tBbox: [ 38 \t 603 \t 248 \t 1003 ]\n",
      "9 \tObject: person \tConfidence = 0.6668 \tBbox: [ 617 \t 106 \t 670 \t 329 ]\n",
      "10 \tObject: person \tConfidence = 0.6521 \tBbox: [ 581 \t 0 \t 611 \t 65 ]\n",
      "11 \tObject: person \tConfidence = 0.6307 \tBbox: [ 452 \t 87 \t 530 \t 223 ]\n",
      "12 \tObject: person \tConfidence = 0.6195 \tBbox: [ 432 \t 0 \t 482 \t 146 ]\n",
      "13 \tObject: person \tConfidence = 0.612 \tBbox: [ 316 \t 149 \t 424 \t 269 ]\n",
      "14 \tObject: person \tConfidence = 0.5983 \tBbox: [ 467 \t 560 \t 685 \t 997 ]\n",
      "15 \tObject: person \tConfidence = 0.5074 \tBbox: [ 242 \t 439 \t 415 \t 821 ]\n",
      "16 \tObject: person \tConfidence = 0.493 \tBbox: [ 0 \t 845 \t 115 \t 1079 ]\n",
      "17 \tObject: person \tConfidence = 0.4247 \tBbox: [ 386 \t 123 \t 438 \t 272 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    17\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000651 / 1050\n",
      "Frames to be processed: 399  | To do: 38.0 % | Done: 62.0 %\n",
      "\n",
      "2022-04-20 13:15:41.685975\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000651.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 18 persons\n",
      "Speed: 27.3ms pre-process, 182.6ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 18 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8399 \tBbox: [ 428 \t 201 \t 552 \t 492 ]\n",
      "2 \tObject: person \tConfidence = 0.7599 \tBbox: [ 676 \t 172 \t 766 \t 500 ]\n",
      "3 \tObject: person \tConfidence = 0.7408 \tBbox: [ 322 \t 185 \t 432 \t 449 ]\n",
      "4 \tObject: person \tConfidence = 0.7397 \tBbox: [ 316 \t 149 \t 423 \t 266 ]\n",
      "5 \tObject: person \tConfidence = 0.7304 \tBbox: [ 515 \t 0 \t 578 \t 177 ]\n",
      "6 \tObject: person \tConfidence = 0.6826 \tBbox: [ 215 \t 653 \t 507 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.6747 \tBbox: [ 576 \t 101 \t 647 \t 380 ]\n",
      "8 \tObject: person \tConfidence = 0.6464 \tBbox: [ 51 \t 602 \t 257 \t 1060 ]\n",
      "9 \tObject: person \tConfidence = 0.6337 \tBbox: [ 455 \t 87 \t 532 \t 224 ]\n",
      "10 \tObject: person \tConfidence = 0.6315 \tBbox: [ 237 \t 441 \t 410 \t 811 ]\n",
      "11 \tObject: person \tConfidence = 0.5873 \tBbox: [ 496 \t 560 \t 683 \t 983 ]\n",
      "12 \tObject: person \tConfidence = 0.5651 \tBbox: [ 386 \t 123 \t 445 \t 272 ]\n",
      "13 \tObject: person \tConfidence = 0.5625 \tBbox: [ 630 \t 16 \t 685 \t 181 ]\n",
      "14 \tObject: person \tConfidence = 0.5533 \tBbox: [ 607 \t 100 \t 673 \t 333 ]\n",
      "15 \tObject: person \tConfidence = 0.4842 \tBbox: [ 1 \t 843 \t 118 \t 1078 ]\n",
      "16 \tObject: person \tConfidence = 0.4818 \tBbox: [ 585 \t 0 \t 614 \t 64 ]\n",
      "17 \tObject: person \tConfidence = 0.4419 \tBbox: [ 430 \t 0 \t 479 \t 139 ]\n",
      "18 \tObject: person \tConfidence = 0.3041 \tBbox: [ 550 \t 682 \t 718 \t 930 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    18\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000652 / 1050\n",
      "Frames to be processed: 398  | To do: 37.9 % | Done: 62.1 %\n",
      "\n",
      "2022-04-20 13:15:42.215020\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000652.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 17 persons, 1 train\n",
      "Speed: 40.0ms pre-process, 179.9ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 18 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8482 \tBbox: [ 291 \t 661 \t 528 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8276 \tBbox: [ 72 \t 606 \t 295 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8197 \tBbox: [ 425 \t 205 \t 550 \t 491 ]\n",
      "4 \tObject: person \tConfidence = 0.7795 \tBbox: [ 317 \t 147 \t 425 \t 265 ]\n",
      "5 \tObject: person \tConfidence = 0.7727 \tBbox: [ 507 \t 0 \t 575 \t 175 ]\n",
      "6 \tObject: person \tConfidence = 0.7186 \tBbox: [ 327 \t 183 \t 430 \t 449 ]\n",
      "7 \tObject: person \tConfidence = 0.6991 \tBbox: [ 685 \t 192 \t 766 \t 537 ]\n",
      "8 \tObject: person \tConfidence = 0.6863 \tBbox: [ 586 \t 103 \t 657 \t 379 ]\n",
      "9 \tObject: person \tConfidence = 0.6525 \tBbox: [ 510 \t 549 \t 723 \t 1076 ]\n",
      "10 \tObject: person \tConfidence = 0.6232 \tBbox: [ 465 \t 81 \t 542 \t 226 ]\n",
      "11 \tObject: person \tConfidence = 0.5791 \tBbox: [ 1 \t 842 \t 149 \t 1078 ]\n",
      "12 \tObject: train \tConfidence = 0.5427 \tBbox: [ 2 \t 3 \t 432 \t 847 ]\n",
      "13 \tObject: person \tConfidence = 0.5412 \tBbox: [ 624 \t 93 \t 679 \t 330 ]\n",
      "14 \tObject: person \tConfidence = 0.5337 \tBbox: [ 388 \t 124 \t 457 \t 273 ]\n",
      "15 \tObject: person \tConfidence = 0.4632 \tBbox: [ 428 \t 0 \t 474 \t 130 ]\n",
      "16 \tObject: person \tConfidence = 0.4269 \tBbox: [ 635 \t 10 \t 697 \t 150 ]\n",
      "17 \tObject: person \tConfidence = 0.3796 \tBbox: [ 590 \t 0 \t 622 \t 66 ]\n",
      "18 \tObject: person \tConfidence = 0.337 \tBbox: [ 561 \t 0 \t 607 \t 133 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    17\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000653 / 1050\n",
      "Frames to be processed: 397  | To do: 37.81 % | Done: 62.19 %\n",
      "\n",
      "2022-04-20 13:15:42.830159\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000653.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 17 persons, 1 train\n",
      "Speed: 29.3ms pre-process, 178.4ms inference, 10.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 18 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8603 \tBbox: [ 426 \t 208 \t 550 \t 489 ]\n",
      "2 \tObject: person \tConfidence = 0.8333 \tBbox: [ 89 \t 610 \t 298 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.7881 \tBbox: [ 506 \t 0 \t 575 \t 173 ]\n",
      "4 \tObject: person \tConfidence = 0.7652 \tBbox: [ 304 \t 667 \t 544 \t 1078 ]\n",
      "5 \tObject: person \tConfidence = 0.7253 \tBbox: [ 317 \t 148 \t 425 \t 264 ]\n",
      "6 \tObject: person \tConfidence = 0.724 \tBbox: [ 468 \t 79 \t 545 \t 227 ]\n",
      "7 \tObject: person \tConfidence = 0.7131 \tBbox: [ 328 \t 183 \t 427 \t 448 ]\n",
      "8 \tObject: person \tConfidence = 0.7 \tBbox: [ 588 \t 98 \t 672 \t 380 ]\n",
      "9 \tObject: person \tConfidence = 0.6635 \tBbox: [ 0 \t 842 \t 192 \t 1078 ]\n",
      "10 \tObject: person \tConfidence = 0.6001 \tBbox: [ 524 \t 548 \t 738 \t 1039 ]\n",
      "11 \tObject: person \tConfidence = 0.5809 \tBbox: [ 688 \t 193 \t 766 \t 518 ]\n",
      "12 \tObject: train \tConfidence = 0.5809 \tBbox: [ 1 \t 3 \t 439 \t 842 ]\n",
      "13 \tObject: person \tConfidence = 0.5609 \tBbox: [ 212 \t 451 \t 398 \t 753 ]\n",
      "14 \tObject: person \tConfidence = 0.4915 \tBbox: [ 636 \t 11 \t 701 \t 154 ]\n",
      "15 \tObject: person \tConfidence = 0.4659 \tBbox: [ 399 \t 127 \t 458 \t 271 ]\n",
      "16 \tObject: person \tConfidence = 0.4607 \tBbox: [ 428 \t 0 \t 471 \t 132 ]\n",
      "17 \tObject: person \tConfidence = 0.4392 \tBbox: [ 561 \t 0 \t 607 \t 133 ]\n",
      "18 \tObject: person \tConfidence = 0.3318 \tBbox: [ 593 \t 0 \t 623 \t 65 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    17\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000654 / 1050\n",
      "Frames to be processed: 396  | To do: 37.71 % | Done: 62.29 %\n",
      "\n",
      "2022-04-20 13:15:43.341632\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000654.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 17 persons, 1 train\n",
      "Speed: 31.1ms pre-process, 171.4ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 18 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8505 \tBbox: [ 98 \t 614 \t 299 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8446 \tBbox: [ 426 \t 205 \t 550 \t 488 ]\n",
      "3 \tObject: person \tConfidence = 0.8016 \tBbox: [ 314 \t 672 \t 559 \t 1080 ]\n",
      "4 \tObject: person \tConfidence = 0.755 \tBbox: [ 203 \t 458 \t 395 \t 750 ]\n",
      "5 \tObject: person \tConfidence = 0.7425 \tBbox: [ 505 \t 0 \t 576 \t 172 ]\n",
      "6 \tObject: person \tConfidence = 0.7044 \tBbox: [ 536 \t 547 \t 743 \t 1029 ]\n",
      "7 \tObject: person \tConfidence = 0.694 \tBbox: [ 0 \t 842 \t 198 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.6928 \tBbox: [ 326 \t 181 \t 425 \t 448 ]\n",
      "9 \tObject: person \tConfidence = 0.6897 \tBbox: [ 316 \t 149 \t 425 \t 262 ]\n",
      "10 \tObject: person \tConfidence = 0.6825 \tBbox: [ 690 \t 202 \t 766 \t 484 ]\n",
      "11 \tObject: person \tConfidence = 0.6787 \tBbox: [ 589 \t 102 \t 681 \t 380 ]\n",
      "12 \tObject: person \tConfidence = 0.6487 \tBbox: [ 472 \t 80 \t 548 \t 232 ]\n",
      "13 \tObject: train \tConfidence = 0.6258 \tBbox: [ 1 \t 3 \t 436 \t 845 ]\n",
      "14 \tObject: person \tConfidence = 0.5294 \tBbox: [ 638 \t 1 \t 703 \t 167 ]\n",
      "15 \tObject: person \tConfidence = 0.4911 \tBbox: [ 426 \t 0 \t 470 \t 129 ]\n",
      "16 \tObject: person \tConfidence = 0.4211 \tBbox: [ 401 \t 126 \t 463 \t 269 ]\n",
      "17 \tObject: person \tConfidence = 0.3926 \tBbox: [ 568 \t 0 \t 607 \t 134 ]\n",
      "18 \tObject: person \tConfidence = 0.3097 \tBbox: [ 597 \t 0 \t 626 \t 61 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    17\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000655 / 1050\n",
      "Frames to be processed: 395  | To do: 37.62 % | Done: 62.38 %\n",
      "\n",
      "2022-04-20 13:15:43.878522\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000655.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 18 persons, 1 train\n",
      "Speed: 46.4ms pre-process, 169.2ms inference, 11.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 19 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8534 \tBbox: [ 106 \t 616 \t 306 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8437 \tBbox: [ 426 \t 203 \t 549 \t 489 ]\n",
      "3 \tObject: person \tConfidence = 0.7908 \tBbox: [ 338 \t 674 \t 574 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.777 \tBbox: [ 589 \t 97 \t 691 \t 377 ]\n",
      "5 \tObject: person \tConfidence = 0.7488 \tBbox: [ 196 \t 460 \t 378 \t 748 ]\n",
      "6 \tObject: train \tConfidence = 0.7443 \tBbox: [ 1 \t 1 \t 433 \t 897 ]\n",
      "7 \tObject: person \tConfidence = 0.7435 \tBbox: [ 548 \t 544 \t 744 \t 1039 ]\n",
      "8 \tObject: person \tConfidence = 0.7388 \tBbox: [ 501 \t 1 \t 572 \t 171 ]\n",
      "9 \tObject: person \tConfidence = 0.7161 \tBbox: [ 323 \t 182 \t 431 \t 448 ]\n",
      "10 \tObject: person \tConfidence = 0.7146 \tBbox: [ 0 \t 844 \t 196 \t 1079 ]\n",
      "11 \tObject: person \tConfidence = 0.6816 \tBbox: [ 317 \t 149 \t 424 \t 261 ]\n",
      "12 \tObject: person \tConfidence = 0.6195 \tBbox: [ 553 \t 0 \t 610 \t 133 ]\n",
      "13 \tObject: person \tConfidence = 0.616 \tBbox: [ 641 \t 3 \t 708 \t 162 ]\n",
      "14 \tObject: person \tConfidence = 0.613 \tBbox: [ 690 \t 204 \t 765 \t 482 ]\n",
      "15 \tObject: person \tConfidence = 0.6032 \tBbox: [ 423 \t 0 \t 471 \t 134 ]\n",
      "16 \tObject: person \tConfidence = 0.59 \tBbox: [ 475 \t 80 \t 553 \t 240 ]\n",
      "17 \tObject: person \tConfidence = 0.4576 \tBbox: [ 600 \t 0 \t 628 \t 65 ]\n",
      "18 \tObject: person \tConfidence = 0.3577 \tBbox: [ 406 \t 125 \t 465 \t 278 ]\n",
      "19 \tObject: person \tConfidence = 0.3199 \tBbox: [ 553 \t 9 \t 584 \t 115 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    18\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000656 / 1050\n",
      "Frames to be processed: 394  | To do: 37.52 % | Done: 62.48 %\n",
      "\n",
      "2022-04-20 13:15:44.408630\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000656.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 18 persons, 1 train\n",
      "Speed: 31.0ms pre-process, 176.0ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 19 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8581 \tBbox: [ 113 \t 616 \t 317 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8554 \tBbox: [ 424 \t 179 \t 549 \t 489 ]\n",
      "3 \tObject: person \tConfidence = 0.8152 \tBbox: [ 557 \t 548 \t 759 \t 1037 ]\n",
      "4 \tObject: person \tConfidence = 0.8092 \tBbox: [ 590 \t 98 \t 696 \t 375 ]\n",
      "5 \tObject: person \tConfidence = 0.8066 \tBbox: [ 376 \t 678 \t 588 \t 1079 ]\n",
      "6 \tObject: train \tConfidence = 0.7567 \tBbox: [ 1 \t 2 \t 429 \t 902 ]\n",
      "7 \tObject: person \tConfidence = 0.7143 \tBbox: [ 324 \t 182 \t 436 \t 448 ]\n",
      "8 \tObject: person \tConfidence = 0.6598 \tBbox: [ 319 \t 148 \t 421 \t 260 ]\n",
      "9 \tObject: person \tConfidence = 0.6399 \tBbox: [ 480 \t 79 \t 557 \t 244 ]\n",
      "10 \tObject: person \tConfidence = 0.591 \tBbox: [ 691 \t 209 \t 765 \t 481 ]\n",
      "11 \tObject: person \tConfidence = 0.5801 \tBbox: [ 421 \t 0 \t 470 \t 129 ]\n",
      "12 \tObject: person \tConfidence = 0.576 \tBbox: [ 553 \t 0 \t 612 \t 133 ]\n",
      "13 \tObject: person \tConfidence = 0.574 \tBbox: [ 186 \t 463 \t 370 \t 743 ]\n",
      "14 \tObject: person \tConfidence = 0.5304 \tBbox: [ 1 \t 833 \t 185 \t 1078 ]\n",
      "15 \tObject: person \tConfidence = 0.4983 \tBbox: [ 604 \t 0 \t 632 \t 66 ]\n",
      "16 \tObject: person \tConfidence = 0.487 \tBbox: [ 501 \t 0 \t 568 \t 160 ]\n",
      "17 \tObject: person \tConfidence = 0.4717 \tBbox: [ 644 \t 8 \t 713 \t 179 ]\n",
      "18 \tObject: person \tConfidence = 0.4159 \tBbox: [ 410 \t 125 \t 469 \t 281 ]\n",
      "19 \tObject: person \tConfidence = 0.3497 \tBbox: [ 554 \t 6 \t 584 \t 122 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    18\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000657 / 1050\n",
      "Frames to be processed: 393  | To do: 37.43 % | Done: 62.57 %\n",
      "\n",
      "2022-04-20 13:15:44.984852\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000657.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 27.0ms pre-process, 180.1ms inference, 11.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8599 \tBbox: [ 424 \t 176 \t 547 \t 489 ]\n",
      "2 \tObject: person \tConfidence = 0.7875 \tBbox: [ 583 \t 549 \t 763 \t 1033 ]\n",
      "3 \tObject: person \tConfidence = 0.7872 \tBbox: [ 130 \t 618 \t 325 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.7773 \tBbox: [ 323 \t 179 \t 424 \t 450 ]\n",
      "5 \tObject: person \tConfidence = 0.7339 \tBbox: [ 593 \t 105 \t 703 \t 375 ]\n",
      "6 \tObject: person \tConfidence = 0.7161 \tBbox: [ 410 \t 679 \t 616 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.6896 \tBbox: [ 486 \t 77 \t 563 \t 262 ]\n",
      "8 \tObject: person \tConfidence = 0.6287 \tBbox: [ 320 \t 147 \t 419 \t 260 ]\n",
      "9 \tObject: person \tConfidence = 0.6138 \tBbox: [ 571 \t 0 \t 620 \t 133 ]\n",
      "10 \tObject: person \tConfidence = 0.5617 \tBbox: [ 173 \t 469 \t 363 \t 736 ]\n",
      "11 \tObject: person \tConfidence = 0.5509 \tBbox: [ 650 \t 7 \t 727 \t 153 ]\n",
      "12 \tObject: person \tConfidence = 0.5385 \tBbox: [ 0 \t 831 \t 193 \t 1079 ]\n",
      "13 \tObject: train \tConfidence = 0.4775 \tBbox: [ 1 \t 2 \t 425 \t 856 ]\n",
      "14 \tObject: person \tConfidence = 0.4484 \tBbox: [ 417 \t 0 \t 469 \t 131 ]\n",
      "15 \tObject: person \tConfidence = 0.4202 \tBbox: [ 609 \t 0 \t 640 \t 67 ]\n",
      "16 \tObject: person \tConfidence = 0.4148 \tBbox: [ 695 \t 235 \t 765 \t 480 ]\n",
      "17 \tObject: person \tConfidence = 0.3605 \tBbox: [ 419 \t 126 \t 476 \t 349 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000658 / 1050\n",
      "Frames to be processed: 392  | To do: 37.33 % | Done: 62.67 %\n",
      "\n",
      "2022-04-20 13:15:45.541115\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000658.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 30.5ms pre-process, 181.7ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8379 \tBbox: [ 425 \t 181 \t 547 \t 489 ]\n",
      "2 \tObject: person \tConfidence = 0.8092 \tBbox: [ 596 \t 552 \t 764 \t 1032 ]\n",
      "3 \tObject: person \tConfidence = 0.8013 \tBbox: [ 411 \t 678 \t 631 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.8002 \tBbox: [ 143 \t 618 \t 340 \t 1079 ]\n",
      "5 \tObject: person \tConfidence = 0.761 \tBbox: [ 322 \t 181 \t 426 \t 450 ]\n",
      "6 \tObject: person \tConfidence = 0.7241 \tBbox: [ 600 \t 110 \t 707 \t 374 ]\n",
      "7 \tObject: train \tConfidence = 0.6869 \tBbox: [ 2 \t 2 \t 423 \t 909 ]\n",
      "8 \tObject: person \tConfidence = 0.6473 \tBbox: [ 489 \t 79 \t 567 \t 299 ]\n",
      "9 \tObject: person \tConfidence = 0.6422 \tBbox: [ 169 \t 472 \t 353 \t 726 ]\n",
      "10 \tObject: person \tConfidence = 0.5656 \tBbox: [ 320 \t 147 \t 419 \t 259 ]\n",
      "11 \tObject: person \tConfidence = 0.5459 \tBbox: [ 0 \t 830 \t 192 \t 1079 ]\n",
      "12 \tObject: person \tConfidence = 0.5225 \tBbox: [ 413 \t 0 \t 469 \t 133 ]\n",
      "13 \tObject: person \tConfidence = 0.5048 \tBbox: [ 653 \t 6 \t 731 \t 140 ]\n",
      "14 \tObject: person \tConfidence = 0.5014 \tBbox: [ 579 \t 0 \t 622 \t 134 ]\n",
      "15 \tObject: person \tConfidence = 0.4144 \tBbox: [ 421 \t 124 \t 483 \t 355 ]\n",
      "16 \tObject: person \tConfidence = 0.357 \tBbox: [ 496 \t 0 \t 572 \t 108 ]\n",
      "17 \tObject: person \tConfidence = 0.3301 \tBbox: [ 613 \t 0 \t 648 \t 67 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000659 / 1050\n",
      "Frames to be processed: 391  | To do: 37.24 % | Done: 62.76 %\n",
      "\n",
      "2022-04-20 13:15:46.048427\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000659.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 23.3ms pre-process, 172.8ms inference, 11.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8352 \tBbox: [ 425 \t 177 \t 546 \t 489 ]\n",
      "2 \tObject: person \tConfidence = 0.833 \tBbox: [ 607 \t 554 \t 765 \t 1031 ]\n",
      "3 \tObject: person \tConfidence = 0.7972 \tBbox: [ 148 \t 618 \t 349 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.7813 \tBbox: [ 402 \t 679 \t 642 \t 1078 ]\n",
      "5 \tObject: train \tConfidence = 0.7575 \tBbox: [ 2 \t 3 \t 417 \t 916 ]\n",
      "6 \tObject: person \tConfidence = 0.7436 \tBbox: [ 494 \t 79 \t 571 \t 306 ]\n",
      "7 \tObject: person \tConfidence = 0.7357 \tBbox: [ 608 \t 115 \t 709 \t 351 ]\n",
      "8 \tObject: person \tConfidence = 0.7274 \tBbox: [ 324 \t 181 \t 427 \t 449 ]\n",
      "9 \tObject: person \tConfidence = 0.7 \tBbox: [ 154 \t 473 \t 348 \t 727 ]\n",
      "10 \tObject: person \tConfidence = 0.6515 \tBbox: [ 580 \t 0 \t 624 \t 134 ]\n",
      "11 \tObject: person \tConfidence = 0.5657 \tBbox: [ 318 \t 147 \t 418 \t 261 ]\n",
      "12 \tObject: person \tConfidence = 0.5269 \tBbox: [ 656 \t 10 \t 735 \t 124 ]\n",
      "13 \tObject: person \tConfidence = 0.4876 \tBbox: [ 426 \t 129 \t 486 \t 359 ]\n",
      "14 \tObject: person \tConfidence = 0.4755 \tBbox: [ 497 \t 0 \t 570 \t 125 ]\n",
      "15 \tObject: person \tConfidence = 0.4598 \tBbox: [ 404 \t 0 \t 468 \t 133 ]\n",
      "16 \tObject: person \tConfidence = 0.4259 \tBbox: [ 0 \t 832 \t 195 \t 1079 ]\n",
      "17 \tObject: person \tConfidence = 0.3777 \tBbox: [ 615 \t 0 \t 647 \t 69 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000660 / 1050\n",
      "Frames to be processed: 390  | To do: 37.14 % | Done: 62.86 %\n",
      "\n",
      "2022-04-20 13:15:46.537280\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000660.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 41.1ms pre-process, 170.9ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8677 \tBbox: [ 425 \t 178 \t 546 \t 489 ]\n",
      "2 \tObject: person \tConfidence = 0.8486 \tBbox: [ 161 \t 618 \t 364 \t 1079 ]\n",
      "3 \tObject: person \tConfidence = 0.8064 \tBbox: [ 319 \t 180 \t 428 \t 449 ]\n",
      "4 \tObject: person \tConfidence = 0.7943 \tBbox: [ 614 \t 558 \t 765 \t 1032 ]\n",
      "5 \tObject: person \tConfidence = 0.7578 \tBbox: [ 579 \t 0 \t 627 \t 133 ]\n",
      "6 \tObject: person \tConfidence = 0.7567 \tBbox: [ 436 \t 679 \t 655 \t 1080 ]\n",
      "7 \tObject: person \tConfidence = 0.7512 \tBbox: [ 498 \t 79 \t 579 \t 305 ]\n",
      "8 \tObject: person \tConfidence = 0.7289 \tBbox: [ 613 \t 124 \t 710 \t 347 ]\n",
      "9 \tObject: person \tConfidence = 0.7008 \tBbox: [ 142 \t 477 \t 339 \t 716 ]\n",
      "10 \tObject: train \tConfidence = 0.655 \tBbox: [ 2 \t 4 \t 418 \t 916 ]\n",
      "11 \tObject: person \tConfidence = 0.5649 \tBbox: [ 496 \t 0 \t 571 \t 117 ]\n",
      "12 \tObject: person \tConfidence = 0.5415 \tBbox: [ 659 \t 11 \t 739 \t 143 ]\n",
      "13 \tObject: person \tConfidence = 0.5033 \tBbox: [ 403 \t 0 \t 468 \t 138 ]\n",
      "14 \tObject: person \tConfidence = 0.4763 \tBbox: [ 619 \t 0 \t 649 \t 70 ]\n",
      "15 \tObject: person \tConfidence = 0.3976 \tBbox: [ 1 \t 832 \t 197 \t 1080 ]\n",
      "16 \tObject: person \tConfidence = 0.3973 \tBbox: [ 426 \t 130 \t 494 \t 365 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000661 / 1050\n",
      "Frames to be processed: 389  | To do: 37.05 % | Done: 62.95 %\n",
      "\n",
      "2022-04-20 13:15:47.065099\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000661.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 25.3ms pre-process, 168.5ms inference, 11.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8511 \tBbox: [ 425 \t 182 \t 545 \t 488 ]\n",
      "2 \tObject: person \tConfidence = 0.8129 \tBbox: [ 623 \t 559 \t 765 \t 1036 ]\n",
      "3 \tObject: person \tConfidence = 0.7931 \tBbox: [ 170 \t 613 \t 367 \t 1080 ]\n",
      "4 \tObject: person \tConfidence = 0.7848 \tBbox: [ 419 \t 680 \t 674 \t 1079 ]\n",
      "5 \tObject: person \tConfidence = 0.779 \tBbox: [ 579 \t 0 \t 631 \t 132 ]\n",
      "6 \tObject: person \tConfidence = 0.7746 \tBbox: [ 319 \t 179 \t 428 \t 450 ]\n",
      "7 \tObject: person \tConfidence = 0.7514 \tBbox: [ 614 \t 121 \t 716 \t 344 ]\n",
      "8 \tObject: person \tConfidence = 0.7237 \tBbox: [ 504 \t 77 \t 586 \t 305 ]\n",
      "9 \tObject: person \tConfidence = 0.5832 \tBbox: [ 129 \t 480 \t 314 \t 645 ]\n",
      "10 \tObject: train \tConfidence = 0.5401 \tBbox: [ 2 \t 2 \t 410 \t 812 ]\n",
      "11 \tObject: person \tConfidence = 0.5043 \tBbox: [ 661 \t 13 \t 742 \t 142 ]\n",
      "12 \tObject: person \tConfidence = 0.4711 \tBbox: [ 398 \t 0 \t 467 \t 139 ]\n",
      "13 \tObject: person \tConfidence = 0.4701 \tBbox: [ 496 \t 0 \t 569 \t 118 ]\n",
      "14 \tObject: person \tConfidence = 0.441 \tBbox: [ 621 \t 0 \t 651 \t 71 ]\n",
      "15 \tObject: person \tConfidence = 0.4012 \tBbox: [ 0 \t 832 \t 185 \t 1079 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000662 / 1050\n",
      "Frames to be processed: 388  | To do: 36.95 % | Done: 63.05 %\n",
      "\n",
      "2022-04-20 13:15:47.555118\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000662.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 47.7ms pre-process, 168.3ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8286 \tBbox: [ 424 \t 191 \t 544 \t 487 ]\n",
      "2 \tObject: person \tConfidence = 0.7952 \tBbox: [ 318 \t 177 \t 428 \t 450 ]\n",
      "3 \tObject: person \tConfidence = 0.7783 \tBbox: [ 188 \t 616 \t 397 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.7704 \tBbox: [ 511 \t 75 \t 596 \t 299 ]\n",
      "5 \tObject: person \tConfidence = 0.7469 \tBbox: [ 497 \t 0 \t 569 \t 126 ]\n",
      "6 \tObject: person \tConfidence = 0.7407 \tBbox: [ 624 \t 87 \t 729 \t 342 ]\n",
      "7 \tObject: person \tConfidence = 0.7222 \tBbox: [ 453 \t 684 \t 709 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.6673 \tBbox: [ 645 \t 511 \t 764 \t 1037 ]\n",
      "9 \tObject: person \tConfidence = 0.6578 \tBbox: [ 579 \t 0 \t 644 \t 132 ]\n",
      "10 \tObject: train \tConfidence = 0.6193 \tBbox: [ 2 \t 2 \t 405 \t 810 ]\n",
      "11 \tObject: person \tConfidence = 0.6013 \tBbox: [ 397 \t 0 \t 467 \t 137 ]\n",
      "12 \tObject: person \tConfidence = 0.5466 \tBbox: [ 0 \t 830 \t 188 \t 1079 ]\n",
      "13 \tObject: person \tConfidence = 0.4581 \tBbox: [ 0 \t 554 \t 109 \t 884 ]\n",
      "14 \tObject: person \tConfidence = 0.457 \tBbox: [ 108 \t 437 \t 299 \t 759 ]\n",
      "15 \tObject: person \tConfidence = 0.4473 \tBbox: [ 668 \t 14 \t 748 \t 128 ]\n",
      "16 \tObject: person \tConfidence = 0.3685 \tBbox: [ 448 \t 140 \t 512 \t 252 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000663 / 1050\n",
      "Frames to be processed: 387  | To do: 36.86 % | Done: 63.14 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:15:48.043172\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000663.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 26.3ms pre-process, 168.7ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8554 \tBbox: [ 425 \t 193 \t 545 \t 487 ]\n",
      "2 \tObject: person \tConfidence = 0.8007 \tBbox: [ 321 \t 178 \t 427 \t 450 ]\n",
      "3 \tObject: person \tConfidence = 0.7615 \tBbox: [ 515 \t 74 \t 597 \t 299 ]\n",
      "4 \tObject: person \tConfidence = 0.7341 \tBbox: [ 495 \t 0 \t 568 \t 132 ]\n",
      "5 \tObject: person \tConfidence = 0.7175 \tBbox: [ 632 \t 90 \t 733 \t 351 ]\n",
      "6 \tObject: person \tConfidence = 0.715 \tBbox: [ 461 \t 691 \t 722 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.6766 \tBbox: [ 192 \t 610 \t 410 \t 1080 ]\n",
      "8 \tObject: person \tConfidence = 0.6716 \tBbox: [ 579 \t 0 \t 649 \t 131 ]\n",
      "9 \tObject: person \tConfidence = 0.6047 \tBbox: [ 0 \t 829 \t 186 \t 1079 ]\n",
      "10 \tObject: train \tConfidence = 0.5867 \tBbox: [ 0 \t 3 \t 408 \t 836 ]\n",
      "11 \tObject: person \tConfidence = 0.5601 \tBbox: [ 0 \t 547 \t 119 \t 905 ]\n",
      "12 \tObject: person \tConfidence = 0.5395 \tBbox: [ 673 \t 15 \t 750 \t 126 ]\n",
      "13 \tObject: person \tConfidence = 0.4943 \tBbox: [ 398 \t 0 \t 467 \t 141 ]\n",
      "14 \tObject: person \tConfidence = 0.4831 \tBbox: [ 657 \t 569 \t 765 \t 1035 ]\n",
      "15 \tObject: person \tConfidence = 0.4264 \tBbox: [ 457 \t 142 \t 522 \t 234 ]\n",
      "16 \tObject: person \tConfidence = 0.3643 \tBbox: [ 106 \t 442 \t 291 \t 711 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000664 / 1050\n",
      "Frames to be processed: 386  | To do: 36.76 % | Done: 63.24 %\n",
      "\n",
      "2022-04-20 13:15:48.658596\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000664.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 48.4ms pre-process, 174.5ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8168 \tBbox: [ 425 \t 199 \t 545 \t 487 ]\n",
      "2 \tObject: person \tConfidence = 0.7816 \tBbox: [ 320 \t 178 \t 428 \t 451 ]\n",
      "3 \tObject: person \tConfidence = 0.7642 \tBbox: [ 193 \t 609 \t 422 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.7222 \tBbox: [ 484 \t 689 \t 746 \t 1079 ]\n",
      "5 \tObject: person \tConfidence = 0.7075 \tBbox: [ 519 \t 75 \t 598 \t 299 ]\n",
      "6 \tObject: train \tConfidence = 0.6641 \tBbox: [ 0 \t 3 \t 405 \t 837 ]\n",
      "7 \tObject: person \tConfidence = 0.654 \tBbox: [ 495 \t 0 \t 565 \t 140 ]\n",
      "8 \tObject: person \tConfidence = 0.6011 \tBbox: [ 580 \t 1 \t 650 \t 131 ]\n",
      "9 \tObject: person \tConfidence = 0.5427 \tBbox: [ 659 \t 88 \t 740 \t 346 ]\n",
      "10 \tObject: person \tConfidence = 0.5174 \tBbox: [ 463 \t 143 \t 530 \t 234 ]\n",
      "11 \tObject: person \tConfidence = 0.4831 \tBbox: [ 0 \t 829 \t 188 \t 1079 ]\n",
      "12 \tObject: person \tConfidence = 0.4581 \tBbox: [ 109 \t 437 \t 290 \t 739 ]\n",
      "13 \tObject: person \tConfidence = 0.404 \tBbox: [ 0 \t 545 \t 125 \t 901 ]\n",
      "14 \tObject: person \tConfidence = 0.399 \tBbox: [ 396 \t 0 \t 467 \t 141 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000665 / 1050\n",
      "Frames to be processed: 385  | To do: 36.67 % | Done: 63.33 %\n",
      "\n",
      "2022-04-20 13:15:49.136615\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000665.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 29.3ms pre-process, 175.6ms inference, 11.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8478 \tBbox: [ 425 \t 182 \t 549 \t 488 ]\n",
      "2 \tObject: person \tConfidence = 0.7672 \tBbox: [ 0 \t 543 \t 136 \t 917 ]\n",
      "3 \tObject: person \tConfidence = 0.7582 \tBbox: [ 327 \t 178 \t 427 \t 452 ]\n",
      "4 \tObject: person \tConfidence = 0.7465 \tBbox: [ 523 \t 76 \t 600 \t 299 ]\n",
      "5 \tObject: person \tConfidence = 0.7119 \tBbox: [ 491 \t 689 \t 761 \t 1079 ]\n",
      "6 \tObject: train \tConfidence = 0.7044 \tBbox: [ 0 \t 3 \t 402 \t 832 ]\n",
      "7 \tObject: person \tConfidence = 0.6861 \tBbox: [ 581 \t 1 \t 653 \t 130 ]\n",
      "8 \tObject: person \tConfidence = 0.676 \tBbox: [ 192 \t 606 \t 438 \t 1078 ]\n",
      "9 \tObject: person \tConfidence = 0.6736 \tBbox: [ 495 \t 0 \t 554 \t 139 ]\n",
      "10 \tObject: person \tConfidence = 0.6256 \tBbox: [ 652 \t 87 \t 744 \t 343 ]\n",
      "11 \tObject: person \tConfidence = 0.4864 \tBbox: [ 98 \t 436 \t 290 \t 813 ]\n",
      "12 \tObject: person \tConfidence = 0.4642 \tBbox: [ 392 \t 0 \t 467 \t 141 ]\n",
      "13 \tObject: person \tConfidence = 0.3408 \tBbox: [ 467 \t 142 \t 529 \t 229 ]\n",
      "14 \tObject: person \tConfidence = 0.33 \tBbox: [ 1 \t 826 \t 184 \t 1080 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000666 / 1050\n",
      "Frames to be processed: 384  | To do: 36.57 % | Done: 63.43 %\n",
      "\n",
      "2022-04-20 13:15:49.919062\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000666.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 30.1ms pre-process, 180.5ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8526 \tBbox: [ 425 \t 183 \t 551 \t 487 ]\n",
      "2 \tObject: person \tConfidence = 0.8169 \tBbox: [ 318 \t 177 \t 430 \t 451 ]\n",
      "3 \tObject: person \tConfidence = 0.7848 \tBbox: [ 510 \t 686 \t 766 \t 1077 ]\n",
      "4 \tObject: person \tConfidence = 0.7841 \tBbox: [ 0 \t 539 \t 144 \t 923 ]\n",
      "5 \tObject: person \tConfidence = 0.7705 \tBbox: [ 526 \t 74 \t 603 \t 299 ]\n",
      "6 \tObject: person \tConfidence = 0.7687 \tBbox: [ 585 \t 0 \t 654 \t 131 ]\n",
      "7 \tObject: person \tConfidence = 0.753 \tBbox: [ 495 \t 0 \t 551 \t 143 ]\n",
      "8 \tObject: person \tConfidence = 0.6676 \tBbox: [ 658 \t 89 \t 748 \t 345 ]\n",
      "9 \tObject: train \tConfidence = 0.6621 \tBbox: [ 1 \t 5 \t 397 \t 873 ]\n",
      "10 \tObject: person \tConfidence = 0.6564 \tBbox: [ 393 \t 0 \t 466 \t 142 ]\n",
      "11 \tObject: person \tConfidence = 0.6391 \tBbox: [ 200 \t 607 \t 452 \t 1078 ]\n",
      "12 \tObject: person \tConfidence = 0.3561 \tBbox: [ 469 \t 143 \t 535 \t 237 ]\n",
      "13 \tObject: person \tConfidence = 0.3385 \tBbox: [ 640 \t 382 \t 765 \t 690 ]\n",
      "14 \tObject: person \tConfidence = 0.3159 \tBbox: [ 685 \t 16 \t 751 \t 122 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000667 / 1050\n",
      "Frames to be processed: 383  | To do: 36.48 % | Done: 63.52 %\n",
      "\n",
      "2022-04-20 13:15:50.446828\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000667.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 30.0ms pre-process, 173.2ms inference, 3.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8559 \tBbox: [ 424 \t 180 \t 547 \t 487 ]\n",
      "2 \tObject: person \tConfidence = 0.8513 \tBbox: [ 0 \t 532 \t 161 \t 933 ]\n",
      "3 \tObject: person \tConfidence = 0.8412 \tBbox: [ 204 \t 609 \t 461 \t 1077 ]\n",
      "4 \tObject: person \tConfidence = 0.7912 \tBbox: [ 334 \t 176 \t 431 \t 452 ]\n",
      "5 \tObject: person \tConfidence = 0.7903 \tBbox: [ 665 \t 78 \t 760 \t 343 ]\n",
      "6 \tObject: person \tConfidence = 0.775 \tBbox: [ 495 \t 0 \t 550 \t 148 ]\n",
      "7 \tObject: person \tConfidence = 0.7171 \tBbox: [ 533 \t 70 \t 610 \t 298 ]\n",
      "8 \tObject: person \tConfidence = 0.711 \tBbox: [ 565 \t 384 \t 766 \t 755 ]\n",
      "9 \tObject: person \tConfidence = 0.6573 \tBbox: [ 541 \t 686 \t 764 \t 1078 ]\n",
      "10 \tObject: person \tConfidence = 0.6459 \tBbox: [ 82 \t 446 \t 286 \t 861 ]\n",
      "11 \tObject: person \tConfidence = 0.6046 \tBbox: [ 593 \t 0 \t 659 \t 128 ]\n",
      "12 \tObject: person \tConfidence = 0.5409 \tBbox: [ 395 \t 1 \t 465 \t 136 ]\n",
      "13 \tObject: train \tConfidence = 0.54 \tBbox: [ 1 \t 4 \t 397 \t 628 ]\n",
      "14 \tObject: person \tConfidence = 0.3906 \tBbox: [ 494 \t 140 \t 557 \t 258 ]\n",
      "15 \tObject: person \tConfidence = 0.3484 \tBbox: [ 695 \t 16 \t 750 \t 117 ]\n",
      "16 \tObject: person \tConfidence = 0.3343 \tBbox: [ 3 \t 871 \t 179 \t 1079 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000668 / 1050\n",
      "Frames to be processed: 382  | To do: 36.38 % | Done: 63.62 %\n",
      "\n",
      "2022-04-20 13:15:50.922012\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000668.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 26.8ms pre-process, 171.5ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8698 \tBbox: [ 424 \t 178 \t 542 \t 488 ]\n",
      "2 \tObject: person \tConfidence = 0.8069 \tBbox: [ 205 \t 609 \t 466 \t 1057 ]\n",
      "3 \tObject: person \tConfidence = 0.8062 \tBbox: [ 1 \t 527 \t 170 \t 931 ]\n",
      "4 \tObject: person \tConfidence = 0.7931 \tBbox: [ 332 \t 174 \t 433 \t 452 ]\n",
      "5 \tObject: person \tConfidence = 0.7708 \tBbox: [ 494 \t 0 \t 551 \t 147 ]\n",
      "6 \tObject: person \tConfidence = 0.769 \tBbox: [ 554 \t 387 \t 765 \t 757 ]\n",
      "7 \tObject: person \tConfidence = 0.7463 \tBbox: [ 535 \t 70 \t 613 \t 301 ]\n",
      "8 \tObject: person \tConfidence = 0.7331 \tBbox: [ 665 \t 78 \t 764 \t 343 ]\n",
      "9 \tObject: person \tConfidence = 0.6945 \tBbox: [ 82 \t 496 \t 282 \t 859 ]\n",
      "10 \tObject: person \tConfidence = 0.6865 \tBbox: [ 597 \t 0 \t 662 \t 128 ]\n",
      "11 \tObject: train \tConfidence = 0.5566 \tBbox: [ 1 \t 4 \t 392 \t 622 ]\n",
      "12 \tObject: person \tConfidence = 0.5468 \tBbox: [ 559 \t 649 \t 765 \t 1078 ]\n",
      "13 \tObject: person \tConfidence = 0.4423 \tBbox: [ 397 \t 0 \t 465 \t 136 ]\n",
      "14 \tObject: person \tConfidence = 0.4184 \tBbox: [ 498 \t 143 \t 568 \t 380 ]\n",
      "15 \tObject: person \tConfidence = 0.3231 \tBbox: [ 699 \t 16 \t 753 \t 118 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000669 / 1050\n",
      "Frames to be processed: 381  | To do: 36.29 % | Done: 63.71 %\n",
      "\n",
      "2022-04-20 13:15:51.448695\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000669.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 28.1ms pre-process, 172.6ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8688 \tBbox: [ 423 \t 178 \t 539 \t 487 ]\n",
      "2 \tObject: person \tConfidence = 0.865 \tBbox: [ 1 \t 523 \t 182 \t 930 ]\n",
      "3 \tObject: person \tConfidence = 0.8355 \tBbox: [ 214 \t 606 \t 471 \t 1039 ]\n",
      "4 \tObject: person \tConfidence = 0.7784 \tBbox: [ 333 \t 175 \t 431 \t 453 ]\n",
      "5 \tObject: person \tConfidence = 0.7675 \tBbox: [ 75 \t 494 \t 280 \t 847 ]\n",
      "6 \tObject: person \tConfidence = 0.7476 \tBbox: [ 536 \t 69 \t 616 \t 303 ]\n",
      "7 \tObject: person \tConfidence = 0.7172 \tBbox: [ 550 \t 391 \t 762 \t 758 ]\n",
      "8 \tObject: person \tConfidence = 0.7158 \tBbox: [ 493 \t 0 \t 553 \t 150 ]\n",
      "9 \tObject: person \tConfidence = 0.6645 \tBbox: [ 499 \t 148 \t 572 \t 398 ]\n",
      "10 \tObject: person \tConfidence = 0.6038 \tBbox: [ 666 \t 87 \t 765 \t 342 ]\n",
      "11 \tObject: person \tConfidence = 0.6033 \tBbox: [ 605 \t 0 \t 665 \t 128 ]\n",
      "12 \tObject: train \tConfidence = 0.5602 \tBbox: [ 0 \t 5 \t 396 \t 609 ]\n",
      "13 \tObject: person \tConfidence = 0.5404 \tBbox: [ 571 \t 672 \t 765 \t 1079 ]\n",
      "14 \tObject: person \tConfidence = 0.4795 \tBbox: [ 0 \t 819 \t 177 \t 1080 ]\n",
      "15 \tObject: person \tConfidence = 0.3345 \tBbox: [ 703 \t 15 \t 757 \t 122 ]\n",
      "16 \tObject: person \tConfidence = 0.3166 \tBbox: [ 281 \t 64 \t 335 \t 244 ]\n",
      "17 \tObject: person \tConfidence = 0.3162 \tBbox: [ 381 \t 90 \t 419 \t 212 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000670 / 1050\n",
      "Frames to be processed: 380  | To do: 36.19 % | Done: 63.81 %\n",
      "\n",
      "2022-04-20 13:15:51.954355\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000670.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 51.5ms pre-process, 170.3ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8526 \tBbox: [ 223 \t 602 \t 474 \t 1040 ]\n",
      "2 \tObject: person \tConfidence = 0.8473 \tBbox: [ 544 \t 393 \t 760 \t 764 ]\n",
      "3 \tObject: person \tConfidence = 0.8465 \tBbox: [ 422 \t 177 \t 537 \t 487 ]\n",
      "4 \tObject: person \tConfidence = 0.7798 \tBbox: [ 334 \t 173 \t 434 \t 455 ]\n",
      "5 \tObject: person \tConfidence = 0.7773 \tBbox: [ 0 \t 518 \t 188 \t 930 ]\n",
      "6 \tObject: person \tConfidence = 0.7653 \tBbox: [ 538 \t 69 \t 621 \t 301 ]\n",
      "7 \tObject: person \tConfidence = 0.6844 \tBbox: [ 493 \t 0 \t 555 \t 157 ]\n",
      "8 \tObject: person \tConfidence = 0.6731 \tBbox: [ 590 \t 674 \t 765 \t 1078 ]\n",
      "9 \tObject: person \tConfidence = 0.6581 \tBbox: [ 613 \t 0 \t 669 \t 128 ]\n",
      "10 \tObject: person \tConfidence = 0.6247 \tBbox: [ 501 \t 152 \t 573 \t 395 ]\n",
      "11 \tObject: person \tConfidence = 0.6222 \tBbox: [ 73 \t 500 \t 277 \t 844 ]\n",
      "12 \tObject: person \tConfidence = 0.577 \tBbox: [ 666 \t 85 \t 765 \t 339 ]\n",
      "13 \tObject: person \tConfidence = 0.5761 \tBbox: [ 353 \t 93 \t 429 \t 223 ]\n",
      "14 \tObject: train \tConfidence = 0.5751 \tBbox: [ 0 \t 4 \t 396 \t 609 ]\n",
      "15 \tObject: person \tConfidence = 0.4944 \tBbox: [ 302 \t 140 \t 370 \t 395 ]\n",
      "16 \tObject: person \tConfidence = 0.3114 \tBbox: [ 708 \t 16 \t 760 \t 123 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000671 / 1050\n",
      "Frames to be processed: 379  | To do: 36.1 % | Done: 63.9 %\n",
      "\n",
      "2022-04-20 13:15:52.714469\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000671.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 26.7ms pre-process, 168.6ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8919 \tBbox: [ 543 \t 391 \t 746 \t 765 ]\n",
      "2 \tObject: person \tConfidence = 0.8745 \tBbox: [ 247 \t 600 \t 480 \t 1038 ]\n",
      "3 \tObject: person \tConfidence = 0.8492 \tBbox: [ 421 \t 177 \t 537 \t 488 ]\n",
      "4 \tObject: person \tConfidence = 0.8402 \tBbox: [ 538 \t 67 \t 623 \t 304 ]\n",
      "5 \tObject: person \tConfidence = 0.8015 \tBbox: [ 336 \t 174 \t 434 \t 456 ]\n",
      "6 \tObject: person \tConfidence = 0.8 \tBbox: [ 621 \t 0 \t 671 \t 128 ]\n",
      "7 \tObject: person \tConfidence = 0.7679 \tBbox: [ 0 \t 506 \t 196 \t 927 ]\n",
      "8 \tObject: person \tConfidence = 0.71 \tBbox: [ 505 \t 148 \t 575 \t 398 ]\n",
      "9 \tObject: person \tConfidence = 0.7029 \tBbox: [ 359 \t 93 \t 435 \t 226 ]\n",
      "10 \tObject: person \tConfidence = 0.6678 \tBbox: [ 492 \t 0 \t 555 \t 161 ]\n",
      "11 \tObject: person \tConfidence = 0.6318 \tBbox: [ 303 \t 139 \t 371 \t 384 ]\n",
      "12 \tObject: person \tConfidence = 0.6177 \tBbox: [ 666 \t 85 \t 765 \t 337 ]\n",
      "13 \tObject: train \tConfidence = 0.5982 \tBbox: [ 1 \t 4 \t 397 \t 627 ]\n",
      "14 \tObject: person \tConfidence = 0.4393 \tBbox: [ 0 \t 821 \t 186 \t 1080 ]\n",
      "15 \tObject: person \tConfidence = 0.3529 \tBbox: [ 712 \t 17 \t 763 \t 125 ]\n",
      "16 \tObject: person \tConfidence = 0.3437 \tBbox: [ 622 \t 671 \t 765 \t 1076 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000672 / 1050\n",
      "Frames to be processed: 378  | To do: 36.0 % | Done: 64.0 %\n",
      "\n",
      "2022-04-20 13:15:53.214212\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000672.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 30.1ms pre-process, 173.4ms inference, 10.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8761 \tBbox: [ 543 \t 389 \t 721 \t 766 ]\n",
      "2 \tObject: person \tConfidence = 0.8564 \tBbox: [ 422 \t 176 \t 537 \t 488 ]\n",
      "3 \tObject: person \tConfidence = 0.8469 \tBbox: [ 513 \t 152 \t 595 \t 434 ]\n",
      "4 \tObject: person \tConfidence = 0.8381 \tBbox: [ 273 \t 595 \t 496 \t 1035 ]\n",
      "5 \tObject: person \tConfidence = 0.8188 \tBbox: [ 337 \t 172 \t 434 \t 454 ]\n",
      "6 \tObject: person \tConfidence = 0.802 \tBbox: [ 1 \t 499 \t 214 \t 980 ]\n",
      "7 \tObject: person \tConfidence = 0.7786 \tBbox: [ 541 \t 65 \t 628 \t 315 ]\n",
      "8 \tObject: person \tConfidence = 0.76 \tBbox: [ 300 \t 138 \t 373 \t 371 ]\n",
      "9 \tObject: person \tConfidence = 0.76 \tBbox: [ 627 \t 0 \t 677 \t 128 ]\n",
      "10 \tObject: person \tConfidence = 0.7592 \tBbox: [ 367 \t 95 \t 440 \t 242 ]\n",
      "11 \tObject: person \tConfidence = 0.6744 \tBbox: [ 491 \t 0 \t 557 \t 186 ]\n",
      "12 \tObject: person \tConfidence = 0.6661 \tBbox: [ 669 \t 89 \t 765 \t 333 ]\n",
      "13 \tObject: train \tConfidence = 0.5427 \tBbox: [ 1 \t 2 \t 397 \t 674 ]\n",
      "14 \tObject: person \tConfidence = 0.3985 \tBbox: [ 660 \t 683 \t 765 \t 1074 ]\n",
      "15 \tObject: person \tConfidence = 0.3813 \tBbox: [ 720 \t 18 \t 765 \t 127 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000673 / 1050\n",
      "Frames to be processed: 377  | To do: 35.9 % | Done: 64.1 %\n",
      "\n",
      "2022-04-20 13:15:53.721185\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000673.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 24.4ms pre-process, 175.9ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8625 \tBbox: [ 422 \t 175 \t 538 \t 489 ]\n",
      "2 \tObject: person \tConfidence = 0.8549 \tBbox: [ 518 \t 155 \t 598 \t 437 ]\n",
      "3 \tObject: person \tConfidence = 0.8317 \tBbox: [ 542 \t 387 \t 706 \t 766 ]\n",
      "4 \tObject: person \tConfidence = 0.8245 \tBbox: [ 307 \t 596 \t 503 \t 1028 ]\n",
      "5 \tObject: person \tConfidence = 0.8204 \tBbox: [ 338 \t 172 \t 435 \t 450 ]\n",
      "6 \tObject: person \tConfidence = 0.8165 \tBbox: [ 2 \t 501 \t 224 \t 1009 ]\n",
      "7 \tObject: person \tConfidence = 0.7743 \tBbox: [ 627 \t 0 \t 680 \t 126 ]\n",
      "8 \tObject: person \tConfidence = 0.758 \tBbox: [ 544 \t 65 \t 630 \t 315 ]\n",
      "9 \tObject: person \tConfidence = 0.7472 \tBbox: [ 298 \t 137 \t 373 \t 384 ]\n",
      "10 \tObject: person \tConfidence = 0.7449 \tBbox: [ 374 \t 95 \t 443 \t 251 ]\n",
      "11 \tObject: person \tConfidence = 0.6574 \tBbox: [ 490 \t 0 \t 556 \t 166 ]\n",
      "12 \tObject: person \tConfidence = 0.6292 \tBbox: [ 673 \t 95 \t 764 \t 316 ]\n",
      "13 \tObject: train \tConfidence = 0.5202 \tBbox: [ 0 \t 2 \t 388 \t 686 ]\n",
      "14 \tObject: person \tConfidence = 0.4766 \tBbox: [ 0 \t 792 \t 186 \t 1080 ]\n",
      "15 \tObject: person \tConfidence = 0.361 \tBbox: [ 660 \t 696 \t 766 \t 1075 ]\n",
      "16 \tObject: person \tConfidence = 0.3082 \tBbox: [ 723 \t 19 \t 765 \t 126 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000674 / 1050\n",
      "Frames to be processed: 376  | To do: 35.81 % | Done: 64.19 %\n",
      "\n",
      "2022-04-20 13:15:54.310798\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000674.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 27.4ms pre-process, 181.9ms inference, 12.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8818 \tBbox: [ 422 \t 176 \t 536 \t 488 ]\n",
      "2 \tObject: person \tConfidence = 0.8584 \tBbox: [ 522 \t 158 \t 601 \t 439 ]\n",
      "3 \tObject: person \tConfidence = 0.8295 \tBbox: [ 339 \t 173 \t 435 \t 446 ]\n",
      "4 \tObject: person \tConfidence = 0.8205 \tBbox: [ 628 \t 0 \t 684 \t 127 ]\n",
      "5 \tObject: person \tConfidence = 0.8171 \tBbox: [ 12 \t 512 \t 239 \t 1031 ]\n",
      "6 \tObject: person \tConfidence = 0.8069 \tBbox: [ 542 \t 387 \t 696 \t 766 ]\n",
      "7 \tObject: person \tConfidence = 0.8021 \tBbox: [ 331 \t 595 \t 512 \t 1054 ]\n",
      "8 \tObject: person \tConfidence = 0.7967 \tBbox: [ 296 \t 137 \t 373 \t 380 ]\n",
      "9 \tObject: person \tConfidence = 0.7419 \tBbox: [ 370 \t 98 \t 447 \t 257 ]\n",
      "10 \tObject: person \tConfidence = 0.7185 \tBbox: [ 547 \t 65 \t 633 \t 315 ]\n",
      "11 \tObject: person \tConfidence = 0.7084 \tBbox: [ 489 \t 0 \t 554 \t 155 ]\n",
      "12 \tObject: person \tConfidence = 0.6659 \tBbox: [ 0 \t 800 \t 187 \t 1080 ]\n",
      "13 \tObject: person \tConfidence = 0.6331 \tBbox: [ 671 \t 70 \t 764 \t 309 ]\n",
      "14 \tObject: person \tConfidence = 0.5341 \tBbox: [ 642 \t 665 \t 765 \t 1076 ]\n",
      "15 \tObject: train \tConfidence = 0.5053 \tBbox: [ 0 \t 2 \t 378 \t 710 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000675 / 1050\n",
      "Frames to be processed: 375  | To do: 35.71 % | Done: 64.29 %\n",
      "\n",
      "2022-04-20 13:15:54.805607\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000675.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 26.5ms pre-process, 172.8ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8797 \tBbox: [ 423 \t 176 \t 534 \t 489 ]\n",
      "2 \tObject: person \tConfidence = 0.8366 \tBbox: [ 18 \t 512 \t 246 \t 1020 ]\n",
      "3 \tObject: person \tConfidence = 0.8238 \tBbox: [ 350 \t 594 \t 523 \t 1067 ]\n",
      "4 \tObject: person \tConfidence = 0.8191 \tBbox: [ 341 \t 173 \t 435 \t 442 ]\n",
      "5 \tObject: person \tConfidence = 0.8117 \tBbox: [ 518 \t 162 \t 603 \t 441 ]\n",
      "6 \tObject: person \tConfidence = 0.8019 \tBbox: [ 0 \t 799 \t 188 \t 1080 ]\n",
      "7 \tObject: person \tConfidence = 0.7922 \tBbox: [ 542 \t 386 \t 684 \t 763 ]\n",
      "8 \tObject: person \tConfidence = 0.7652 \tBbox: [ 666 \t 455 \t 766 \t 803 ]\n",
      "9 \tObject: person \tConfidence = 0.7515 \tBbox: [ 630 \t 0 \t 686 \t 126 ]\n",
      "10 \tObject: person \tConfidence = 0.6969 \tBbox: [ 294 \t 137 \t 372 \t 362 ]\n",
      "11 \tObject: person \tConfidence = 0.6901 \tBbox: [ 376 \t 97 \t 454 \t 258 ]\n",
      "12 \tObject: train \tConfidence = 0.6262 \tBbox: [ 0 \t 3 \t 384 \t 713 ]\n",
      "13 \tObject: person \tConfidence = 0.5621 \tBbox: [ 488 \t 0 \t 552 \t 153 ]\n",
      "14 \tObject: person \tConfidence = 0.5319 \tBbox: [ 674 \t 65 \t 763 \t 310 ]\n",
      "15 \tObject: person \tConfidence = 0.4823 \tBbox: [ 545 \t 66 \t 635 \t 253 ]\n",
      "16 \tObject: person \tConfidence = 0.307 \tBbox: [ 283 \t 67 \t 345 \t 216 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000676 / 1050\n",
      "Frames to be processed: 374  | To do: 35.62 % | Done: 64.38 %\n",
      "\n",
      "2022-04-20 13:15:55.295294\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000676.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 47.7ms pre-process, 175.2ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8587 \tBbox: [ 0 \t 797 \t 190 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8532 \tBbox: [ 423 \t 177 \t 533 \t 487 ]\n",
      "3 \tObject: person \tConfidence = 0.8294 \tBbox: [ 360 \t 595 \t 536 \t 1072 ]\n",
      "4 \tObject: person \tConfidence = 0.8196 \tBbox: [ 25 \t 509 \t 258 \t 1068 ]\n",
      "5 \tObject: person \tConfidence = 0.7896 \tBbox: [ 341 \t 172 \t 435 \t 440 ]\n",
      "6 \tObject: person \tConfidence = 0.7583 \tBbox: [ 512 \t 167 \t 609 \t 425 ]\n",
      "7 \tObject: person \tConfidence = 0.746 \tBbox: [ 528 \t 385 \t 673 \t 764 ]\n",
      "8 \tObject: person \tConfidence = 0.7181 \tBbox: [ 488 \t 0 \t 550 \t 149 ]\n",
      "9 \tObject: person \tConfidence = 0.7129 \tBbox: [ 666 \t 440 \t 766 \t 808 ]\n",
      "10 \tObject: train \tConfidence = 0.7069 \tBbox: [ 0 \t 3 \t 402 \t 706 ]\n",
      "11 \tObject: person \tConfidence = 0.6973 \tBbox: [ 630 \t 0 \t 688 \t 127 ]\n",
      "12 \tObject: person \tConfidence = 0.6833 \tBbox: [ 382 \t 99 \t 461 \t 259 ]\n",
      "13 \tObject: person \tConfidence = 0.682 \tBbox: [ 294 \t 137 \t 371 \t 362 ]\n",
      "14 \tObject: person \tConfidence = 0.5702 \tBbox: [ 544 \t 66 \t 636 \t 256 ]\n",
      "15 \tObject: person \tConfidence = 0.4668 \tBbox: [ 675 \t 50 \t 764 \t 312 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000677 / 1050\n",
      "Frames to be processed: 373  | To do: 35.52 % | Done: 64.48 %\n",
      "\n",
      "2022-04-20 13:15:55.906854\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000677.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 32.0ms pre-process, 173.3ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8648 \tBbox: [ 421 \t 178 \t 533 \t 487 ]\n",
      "2 \tObject: person \tConfidence = 0.8511 \tBbox: [ 0 \t 798 \t 193 \t 1079 ]\n",
      "3 \tObject: person \tConfidence = 0.8465 \tBbox: [ 32 \t 510 \t 270 \t 1074 ]\n",
      "4 \tObject: person \tConfidence = 0.8178 \tBbox: [ 368 \t 598 \t 552 \t 1047 ]\n",
      "5 \tObject: person \tConfidence = 0.8158 \tBbox: [ 340 \t 172 \t 434 \t 439 ]\n",
      "6 \tObject: person \tConfidence = 0.8048 \tBbox: [ 522 \t 390 \t 656 \t 760 ]\n",
      "7 \tObject: person \tConfidence = 0.7854 \tBbox: [ 487 \t 0 \t 551 \t 147 ]\n",
      "8 \tObject: person \tConfidence = 0.7654 \tBbox: [ 660 \t 437 \t 766 \t 809 ]\n",
      "9 \tObject: person \tConfidence = 0.7422 \tBbox: [ 389 \t 99 \t 465 \t 253 ]\n",
      "10 \tObject: person \tConfidence = 0.7202 \tBbox: [ 516 \t 169 \t 618 \t 404 ]\n",
      "11 \tObject: train \tConfidence = 0.658 \tBbox: [ 0 \t 3 \t 394 \t 774 ]\n",
      "12 \tObject: person \tConfidence = 0.6282 \tBbox: [ 294 \t 140 \t 370 \t 372 ]\n",
      "13 \tObject: person \tConfidence = 0.6036 \tBbox: [ 546 \t 66 \t 636 \t 254 ]\n",
      "14 \tObject: person \tConfidence = 0.5687 \tBbox: [ 631 \t 0 \t 690 \t 126 ]\n",
      "15 \tObject: person \tConfidence = 0.4134 \tBbox: [ 683 \t 55 \t 764 \t 309 ]\n",
      "16 \tObject: person \tConfidence = 0.3923 \tBbox: [ 396 \t 1 \t 452 \t 130 ]\n",
      "17 \tObject: person \tConfidence = 0.3027 \tBbox: [ 562 \t 101 \t 618 \t 194 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000678 / 1050\n",
      "Frames to be processed: 372  | To do: 35.43 % | Done: 64.57 %\n",
      "\n",
      "2022-04-20 13:15:56.405912\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000678.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 26.3ms pre-process, 178.3ms inference, 10.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8708 \tBbox: [ 421 \t 178 \t 532 \t 487 ]\n",
      "2 \tObject: person \tConfidence = 0.8593 \tBbox: [ 37 \t 512 \t 283 \t 1078 ]\n",
      "3 \tObject: person \tConfidence = 0.8228 \tBbox: [ 0 \t 794 \t 194 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8109 \tBbox: [ 378 \t 598 \t 569 \t 1058 ]\n",
      "5 \tObject: person \tConfidence = 0.7939 \tBbox: [ 341 \t 171 \t 436 \t 439 ]\n",
      "6 \tObject: person \tConfidence = 0.7647 \tBbox: [ 487 \t 0 \t 548 \t 147 ]\n",
      "7 \tObject: person \tConfidence = 0.7504 \tBbox: [ 518 \t 391 \t 643 \t 762 ]\n",
      "8 \tObject: person \tConfidence = 0.6779 \tBbox: [ 390 \t 98 \t 472 \t 254 ]\n",
      "9 \tObject: train \tConfidence = 0.6702 \tBbox: [ 0 \t 3 \t 415 \t 766 ]\n",
      "10 \tObject: person \tConfidence = 0.6545 \tBbox: [ 655 \t 436 \t 765 \t 806 ]\n",
      "11 \tObject: person \tConfidence = 0.6382 \tBbox: [ 512 \t 174 \t 622 \t 401 ]\n",
      "12 \tObject: person \tConfidence = 0.6175 \tBbox: [ 293 \t 131 \t 370 \t 348 ]\n",
      "13 \tObject: person \tConfidence = 0.5051 \tBbox: [ 632 \t 0 \t 692 \t 126 ]\n",
      "14 \tObject: person \tConfidence = 0.4444 \tBbox: [ 547 \t 65 \t 638 \t 247 ]\n",
      "15 \tObject: person \tConfidence = 0.3595 \tBbox: [ 397 \t 1 \t 452 \t 133 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000679 / 1050\n",
      "Frames to be processed: 371  | To do: 35.33 % | Done: 64.67 %\n",
      "\n",
      "2022-04-20 13:15:56.881077\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000679.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 17 persons, 1 train\n",
      "Speed: 26.2ms pre-process, 177.7ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 18 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8816 \tBbox: [ 380 \t 603 \t 595 \t 1050 ]\n",
      "2 \tObject: person \tConfidence = 0.8704 \tBbox: [ 422 \t 178 \t 532 \t 489 ]\n",
      "3 \tObject: person \tConfidence = 0.8201 \tBbox: [ 38 \t 517 \t 294 \t 1075 ]\n",
      "4 \tObject: person \tConfidence = 0.819 \tBbox: [ 340 \t 169 \t 436 \t 438 ]\n",
      "5 \tObject: person \tConfidence = 0.8116 \tBbox: [ 0 \t 792 \t 195 \t 1078 ]\n",
      "6 \tObject: person \tConfidence = 0.8009 \tBbox: [ 486 \t 0 \t 546 \t 146 ]\n",
      "7 \tObject: person \tConfidence = 0.7525 \tBbox: [ 655 \t 434 \t 765 \t 835 ]\n",
      "8 \tObject: person \tConfidence = 0.6828 \tBbox: [ 504 \t 393 \t 645 \t 779 ]\n",
      "9 \tObject: person \tConfidence = 0.6669 \tBbox: [ 392 \t 97 \t 477 \t 255 ]\n",
      "10 \tObject: train \tConfidence = 0.6426 \tBbox: [ 0 \t 2 \t 419 \t 778 ]\n",
      "11 \tObject: person \tConfidence = 0.6368 \tBbox: [ 548 \t 65 \t 638 \t 249 ]\n",
      "12 \tObject: person \tConfidence = 0.6359 \tBbox: [ 292 \t 140 \t 369 \t 329 ]\n",
      "13 \tObject: person \tConfidence = 0.6157 \tBbox: [ 632 \t 0 \t 694 \t 126 ]\n",
      "14 \tObject: person \tConfidence = 0.5949 \tBbox: [ 514 \t 177 \t 630 \t 405 ]\n",
      "15 \tObject: person \tConfidence = 0.482 \tBbox: [ 287 \t 64 \t 370 \t 183 ]\n",
      "16 \tObject: person \tConfidence = 0.3457 \tBbox: [ 398 \t 1 \t 451 \t 134 ]\n",
      "17 \tObject: person \tConfidence = 0.3294 \tBbox: [ 696 \t 864 \t 765 \t 1080 ]\n",
      "18 \tObject: person \tConfidence = 0.3167 \tBbox: [ 564 \t 97 \t 622 \t 200 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    17\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000680 / 1050\n",
      "Frames to be processed: 370  | To do: 35.24 % | Done: 64.76 %\n",
      "\n",
      "2022-04-20 13:15:57.350143\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000680.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 41.0ms pre-process, 172.5ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.88 \tBbox: [ 423 \t 179 \t 531 \t 487 ]\n",
      "2 \tObject: person \tConfidence = 0.8458 \tBbox: [ 380 \t 606 \t 624 \t 1051 ]\n",
      "3 \tObject: person \tConfidence = 0.8286 \tBbox: [ 340 \t 168 \t 433 \t 437 ]\n",
      "4 \tObject: person \tConfidence = 0.8177 \tBbox: [ 57 \t 521 \t 299 \t 1071 ]\n",
      "5 \tObject: person \tConfidence = 0.8031 \tBbox: [ 486 \t 0 \t 546 \t 149 ]\n",
      "6 \tObject: person \tConfidence = 0.7586 \tBbox: [ 654 \t 431 \t 766 \t 822 ]\n",
      "7 \tObject: person \tConfidence = 0.7559 \tBbox: [ 1 \t 789 \t 194 \t 1077 ]\n",
      "8 \tObject: person \tConfidence = 0.7261 \tBbox: [ 399 \t 96 \t 482 \t 256 ]\n",
      "9 \tObject: person \tConfidence = 0.6371 \tBbox: [ 633 \t 0 \t 692 \t 125 ]\n",
      "10 \tObject: person \tConfidence = 0.625 \tBbox: [ 292 \t 141 \t 368 \t 344 ]\n",
      "11 \tObject: train \tConfidence = 0.6117 \tBbox: [ 0 \t 3 \t 423 \t 775 ]\n",
      "12 \tObject: person \tConfidence = 0.5933 \tBbox: [ 539 \t 175 \t 636 \t 439 ]\n",
      "13 \tObject: person \tConfidence = 0.5872 \tBbox: [ 492 \t 401 \t 631 \t 794 ]\n",
      "14 \tObject: person \tConfidence = 0.556 \tBbox: [ 550 \t 66 \t 640 \t 221 ]\n",
      "15 \tObject: person \tConfidence = 0.3316 \tBbox: [ 711 \t 79 \t 765 \t 285 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000681 / 1050\n",
      "Frames to be processed: 369  | To do: 35.14 % | Done: 64.86 %\n",
      "\n",
      "2022-04-20 13:15:57.883588\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000681.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 29.4ms pre-process, 166.5ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8752 \tBbox: [ 422 \t 183 \t 531 \t 488 ]\n",
      "2 \tObject: person \tConfidence = 0.8726 \tBbox: [ 378 \t 609 \t 645 \t 1051 ]\n",
      "3 \tObject: person \tConfidence = 0.8284 \tBbox: [ 341 \t 168 \t 433 \t 436 ]\n",
      "4 \tObject: person \tConfidence = 0.8202 \tBbox: [ 1 \t 787 \t 198 \t 1078 ]\n",
      "5 \tObject: person \tConfidence = 0.8193 \tBbox: [ 485 \t 0 \t 543 \t 151 ]\n",
      "6 \tObject: person \tConfidence = 0.7893 \tBbox: [ 63 \t 524 \t 314 \t 1073 ]\n",
      "7 \tObject: person \tConfidence = 0.7727 \tBbox: [ 405 \t 97 \t 487 \t 254 ]\n",
      "8 \tObject: person \tConfidence = 0.732 \tBbox: [ 551 \t 175 \t 645 \t 456 ]\n",
      "9 \tObject: person \tConfidence = 0.6882 \tBbox: [ 638 \t 433 \t 765 \t 804 ]\n",
      "10 \tObject: person \tConfidence = 0.6654 \tBbox: [ 635 \t 0 \t 694 \t 127 ]\n",
      "11 \tObject: person \tConfidence = 0.6278 \tBbox: [ 291 \t 117 \t 367 \t 387 ]\n",
      "12 \tObject: person \tConfidence = 0.5043 \tBbox: [ 481 \t 397 \t 626 \t 827 ]\n",
      "13 \tObject: person \tConfidence = 0.4951 \tBbox: [ 553 \t 65 \t 641 \t 251 ]\n",
      "14 \tObject: train \tConfidence = 0.3916 \tBbox: [ 3 \t 2 \t 447 \t 680 ]\n",
      "15 \tObject: person \tConfidence = 0.318 \tBbox: [ 297 \t 66 \t 371 \t 176 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000682 / 1050\n",
      "Frames to be processed: 368  | To do: 35.05 % | Done: 64.95 %\n",
      "\n",
      "2022-04-20 13:15:58.396685\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000682.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 45.3ms pre-process, 167.6ms inference, 8.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8629 \tBbox: [ 360 \t 411 \t 574 \t 762 ]\n",
      "2 \tObject: person \tConfidence = 0.8625 \tBbox: [ 379 \t 617 \t 656 \t 1065 ]\n",
      "3 \tObject: person \tConfidence = 0.8536 \tBbox: [ 417 \t 206 \t 532 \t 487 ]\n",
      "4 \tObject: person \tConfidence = 0.8473 \tBbox: [ 483 \t 0 \t 544 \t 149 ]\n",
      "5 \tObject: person \tConfidence = 0.8333 \tBbox: [ 339 \t 165 \t 431 \t 435 ]\n",
      "6 \tObject: person \tConfidence = 0.8292 \tBbox: [ 78 \t 536 \t 338 \t 1074 ]\n",
      "7 \tObject: person \tConfidence = 0.7963 \tBbox: [ 616 \t 435 \t 765 \t 810 ]\n",
      "8 \tObject: person \tConfidence = 0.7524 \tBbox: [ 566 \t 177 \t 657 \t 455 ]\n",
      "9 \tObject: person \tConfidence = 0.6704 \tBbox: [ 413 \t 98 \t 497 \t 257 ]\n",
      "10 \tObject: person \tConfidence = 0.6645 \tBbox: [ 288 \t 133 \t 366 \t 381 ]\n",
      "11 \tObject: person \tConfidence = 0.642 \tBbox: [ 0 \t 787 \t 200 \t 1078 ]\n",
      "12 \tObject: person \tConfidence = 0.5048 \tBbox: [ 641 \t 0 \t 695 \t 124 ]\n",
      "13 \tObject: person \tConfidence = 0.4206 \tBbox: [ 557 \t 63 \t 640 \t 238 ]\n",
      "14 \tObject: train \tConfidence = 0.3965 \tBbox: [ 2 \t 3 \t 424 \t 801 ]\n",
      "15 \tObject: person \tConfidence = 0.3847 \tBbox: [ 305 \t 67 \t 384 \t 201 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000683 / 1050\n",
      "Frames to be processed: 367  | To do: 34.95 % | Done: 65.05 %\n",
      "\n",
      "2022-04-20 13:15:58.889134\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000683.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 25.6ms pre-process, 170.3ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8775 \tBbox: [ 383 \t 621 \t 657 \t 1064 ]\n",
      "2 \tObject: person \tConfidence = 0.8689 \tBbox: [ 611 \t 438 \t 763 \t 804 ]\n",
      "3 \tObject: person \tConfidence = 0.8665 \tBbox: [ 357 \t 414 \t 557 \t 769 ]\n",
      "4 \tObject: person \tConfidence = 0.8431 \tBbox: [ 94 \t 538 \t 349 \t 1079 ]\n",
      "5 \tObject: person \tConfidence = 0.8332 \tBbox: [ 481 \t 0 \t 543 \t 150 ]\n",
      "6 \tObject: person \tConfidence = 0.8239 \tBbox: [ 339 \t 164 \t 431 \t 437 ]\n",
      "7 \tObject: person \tConfidence = 0.8057 \tBbox: [ 412 \t 204 \t 530 \t 497 ]\n",
      "8 \tObject: person \tConfidence = 0.7215 \tBbox: [ 0 \t 777 \t 155 \t 1079 ]\n",
      "9 \tObject: person \tConfidence = 0.712 \tBbox: [ 287 \t 131 \t 366 \t 385 ]\n",
      "10 \tObject: person \tConfidence = 0.6021 \tBbox: [ 573 \t 177 \t 658 \t 457 ]\n",
      "11 \tObject: person \tConfidence = 0.5998 \tBbox: [ 417 \t 98 \t 502 \t 258 ]\n",
      "12 \tObject: person \tConfidence = 0.4923 \tBbox: [ 645 \t 0 \t 695 \t 120 ]\n",
      "13 \tObject: person \tConfidence = 0.475 \tBbox: [ 309 \t 69 \t 376 \t 212 ]\n",
      "14 \tObject: person \tConfidence = 0.422 \tBbox: [ 558 \t 62 \t 645 \t 263 ]\n",
      "15 \tObject: person \tConfidence = 0.4106 \tBbox: [ 396 \t 0 \t 450 \t 122 ]\n",
      "16 \tObject: train \tConfidence = 0.4014 \tBbox: [ 1 \t 0 \t 411 \t 678 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000684 / 1050\n",
      "Frames to be processed: 366  | To do: 34.86 % | Done: 65.14 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 23.2ms pre-process, 169.9ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:15:59.397541\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000684.jpg ------------------------------ \n",
      "\n",
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8813 \tBbox: [ 98 \t 541 \t 354 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8611 \tBbox: [ 389 \t 623 \t 659 \t 1064 ]\n",
      "3 \tObject: person \tConfidence = 0.861 \tBbox: [ 604 \t 441 \t 753 \t 804 ]\n",
      "4 \tObject: person \tConfidence = 0.8442 \tBbox: [ 363 \t 412 \t 543 \t 771 ]\n",
      "5 \tObject: person \tConfidence = 0.8344 \tBbox: [ 481 \t 0 \t 542 \t 149 ]\n",
      "6 \tObject: person \tConfidence = 0.8304 \tBbox: [ 337 \t 163 \t 430 \t 437 ]\n",
      "7 \tObject: person \tConfidence = 0.787 \tBbox: [ 406 \t 202 \t 529 \t 495 ]\n",
      "8 \tObject: person \tConfidence = 0.7719 \tBbox: [ 576 \t 176 \t 671 \t 455 ]\n",
      "9 \tObject: person \tConfidence = 0.7628 \tBbox: [ 1 \t 782 \t 146 \t 1078 ]\n",
      "10 \tObject: person \tConfidence = 0.7593 \tBbox: [ 559 \t 60 \t 647 \t 272 ]\n",
      "11 \tObject: person \tConfidence = 0.7088 \tBbox: [ 285 \t 127 \t 365 \t 388 ]\n",
      "12 \tObject: person \tConfidence = 0.6865 \tBbox: [ 422 \t 100 \t 507 \t 242 ]\n",
      "13 \tObject: person \tConfidence = 0.6309 \tBbox: [ 309 \t 71 \t 378 \t 215 ]\n",
      "14 \tObject: person \tConfidence = 0.4766 \tBbox: [ 643 \t 0 \t 676 \t 86 ]\n",
      "15 \tObject: train \tConfidence = 0.468 \tBbox: [ 1 \t 4 \t 409 \t 804 ]\n",
      "16 \tObject: person \tConfidence = 0.3345 \tBbox: [ 647 \t 0 \t 695 \t 119 ]\n",
      "17 \tObject: person \tConfidence = 0.323 \tBbox: [ 395 \t 0 \t 455 \t 122 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000685 / 1050\n",
      "Frames to be processed: 365  | To do: 34.76 % | Done: 65.24 %\n",
      "\n",
      "2022-04-20 13:15:59.937906\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000685.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 28.3ms pre-process, 169.5ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8761 \tBbox: [ 108 \t 540 \t 366 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8743 \tBbox: [ 599 \t 441 \t 744 \t 802 ]\n",
      "3 \tObject: person \tConfidence = 0.8326 \tBbox: [ 362 \t 407 \t 536 \t 775 ]\n",
      "4 \tObject: person \tConfidence = 0.7977 \tBbox: [ 560 \t 58 \t 648 \t 275 ]\n",
      "5 \tObject: person \tConfidence = 0.7957 \tBbox: [ 337 \t 163 \t 430 \t 437 ]\n",
      "6 \tObject: person \tConfidence = 0.7928 \tBbox: [ 480 \t 0 \t 540 \t 150 ]\n",
      "7 \tObject: person \tConfidence = 0.7924 \tBbox: [ 397 \t 626 \t 664 \t 1065 ]\n",
      "8 \tObject: person \tConfidence = 0.7476 \tBbox: [ 580 \t 178 \t 676 \t 456 ]\n",
      "9 \tObject: person \tConfidence = 0.7198 \tBbox: [ 415 \t 209 \t 528 \t 484 ]\n",
      "10 \tObject: person \tConfidence = 0.695 \tBbox: [ 0 \t 782 \t 154 \t 1079 ]\n",
      "11 \tObject: person \tConfidence = 0.6193 \tBbox: [ 283 \t 127 \t 365 \t 386 ]\n",
      "12 \tObject: train \tConfidence = 0.5814 \tBbox: [ 1 \t 4 \t 404 \t 814 ]\n",
      "13 \tObject: person \tConfidence = 0.5298 \tBbox: [ 428 \t 102 \t 515 \t 242 ]\n",
      "14 \tObject: person \tConfidence = 0.4152 \tBbox: [ 643 \t 0 \t 677 \t 87 ]\n",
      "15 \tObject: person \tConfidence = 0.3608 \tBbox: [ 395 \t 0 \t 452 \t 121 ]\n",
      "16 \tObject: person \tConfidence = 0.3476 \tBbox: [ 307 \t 73 \t 383 \t 218 ]\n",
      "17 \tObject: person \tConfidence = 0.3077 \tBbox: [ 658 \t 1 \t 694 \t 118 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000686 / 1050\n",
      "Frames to be processed: 364  | To do: 34.67 % | Done: 65.33 %\n",
      "\n",
      "2022-04-20 13:16:00.417592\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000686.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 16 persons, 1 train\n",
      "Speed: 27.9ms pre-process, 173.6ms inference, 11.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 17 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8815 \tBbox: [ 120 \t 542 \t 377 \t 1080 ]\n",
      "2 \tObject: person \tConfidence = 0.8497 \tBbox: [ 585 \t 445 \t 742 \t 803 ]\n",
      "3 \tObject: person \tConfidence = 0.8334 \tBbox: [ 415 \t 623 \t 677 \t 1065 ]\n",
      "4 \tObject: person \tConfidence = 0.8309 \tBbox: [ 581 \t 178 \t 684 \t 456 ]\n",
      "5 \tObject: person \tConfidence = 0.8294 \tBbox: [ 563 \t 56 \t 649 \t 276 ]\n",
      "6 \tObject: person \tConfidence = 0.7915 \tBbox: [ 331 \t 163 \t 429 \t 438 ]\n",
      "7 \tObject: person \tConfidence = 0.6891 \tBbox: [ 362 \t 412 \t 523 \t 774 ]\n",
      "8 \tObject: person \tConfidence = 0.6812 \tBbox: [ 1 \t 782 \t 161 \t 1079 ]\n",
      "9 \tObject: person \tConfidence = 0.6738 \tBbox: [ 478 \t 0 \t 537 \t 150 ]\n",
      "10 \tObject: person \tConfidence = 0.6436 \tBbox: [ 286 \t 128 \t 365 \t 382 ]\n",
      "11 \tObject: person \tConfidence = 0.6418 \tBbox: [ 416 \t 207 \t 531 \t 453 ]\n",
      "12 \tObject: person \tConfidence = 0.4685 \tBbox: [ 433 \t 104 \t 524 \t 239 ]\n",
      "13 \tObject: person \tConfidence = 0.4616 \tBbox: [ 305 \t 73 \t 386 \t 223 ]\n",
      "14 \tObject: train \tConfidence = 0.4423 \tBbox: [ 2 \t 5 \t 350 \t 821 ]\n",
      "15 \tObject: person \tConfidence = 0.4232 \tBbox: [ 644 \t 0 \t 680 \t 86 ]\n",
      "16 \tObject: person \tConfidence = 0.3848 \tBbox: [ 395 \t 0 \t 462 \t 120 ]\n",
      "17 \tObject: person \tConfidence = 0.304 \tBbox: [ 658 \t 2 \t 693 \t 114 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    16\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000687 / 1050\n",
      "Frames to be processed: 363  | To do: 34.57 % | Done: 65.43 %\n",
      "\n",
      "2022-04-20 13:16:00.918961\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000687.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 41.2ms pre-process, 168.1ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8979 \tBbox: [ 140 \t 549 \t 414 \t 1080 ]\n",
      "2 \tObject: person \tConfidence = 0.8884 \tBbox: [ 566 \t 55 \t 651 \t 276 ]\n",
      "3 \tObject: person \tConfidence = 0.8503 \tBbox: [ 582 \t 186 \t 710 \t 474 ]\n",
      "4 \tObject: person \tConfidence = 0.8023 \tBbox: [ 447 \t 621 \t 716 \t 1067 ]\n",
      "5 \tObject: person \tConfidence = 0.7833 \tBbox: [ 332 \t 161 \t 434 \t 436 ]\n",
      "6 \tObject: person \tConfidence = 0.7805 \tBbox: [ 1 \t 780 \t 201 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.7749 \tBbox: [ 474 \t 0 \t 532 \t 114 ]\n",
      "8 \tObject: person \tConfidence = 0.7732 \tBbox: [ 445 \t 109 \t 572 \t 364 ]\n",
      "9 \tObject: person \tConfidence = 0.7731 \tBbox: [ 360 \t 403 \t 504 \t 776 ]\n",
      "10 \tObject: person \tConfidence = 0.7718 \tBbox: [ 412 \t 208 \t 523 \t 485 ]\n",
      "11 \tObject: person \tConfidence = 0.7596 \tBbox: [ 645 \t 0 \t 690 \t 88 ]\n",
      "12 \tObject: person \tConfidence = 0.6371 \tBbox: [ 314 \t 71 \t 396 \t 226 ]\n",
      "13 \tObject: person \tConfidence = 0.5965 \tBbox: [ 561 \t 448 \t 719 \t 779 ]\n",
      "14 \tObject: train \tConfidence = 0.402 \tBbox: [ 1 \t 4 \t 428 \t 806 ]\n",
      "15 \tObject: person \tConfidence = 0.3625 \tBbox: [ 290 \t 142 \t 339 \t 325 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000688 / 1050\n",
      "Frames to be processed: 362  | To do: 34.48 % | Done: 65.52 %\n",
      "\n",
      "2022-04-20 13:16:01.415504\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000688.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 28.9ms pre-process, 165.8ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8857 \tBbox: [ 150 \t 552 \t 413 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8712 \tBbox: [ 568 \t 55 \t 651 \t 276 ]\n",
      "3 \tObject: person \tConfidence = 0.8654 \tBbox: [ 411 \t 183 \t 525 \t 486 ]\n",
      "4 \tObject: person \tConfidence = 0.8292 \tBbox: [ 581 \t 189 \t 720 \t 485 ]\n",
      "5 \tObject: person \tConfidence = 0.8254 \tBbox: [ 457 \t 109 \t 577 \t 368 ]\n",
      "6 \tObject: person \tConfidence = 0.8182 \tBbox: [ 481 \t 623 \t 709 \t 1064 ]\n",
      "7 \tObject: person \tConfidence = 0.7927 \tBbox: [ 474 \t 0 \t 530 \t 114 ]\n",
      "8 \tObject: person \tConfidence = 0.7898 \tBbox: [ 332 \t 161 \t 428 \t 425 ]\n",
      "9 \tObject: person \tConfidence = 0.7872 \tBbox: [ 551 \t 450 \t 698 \t 658 ]\n",
      "10 \tObject: person \tConfidence = 0.7558 \tBbox: [ 357 \t 402 \t 497 \t 777 ]\n",
      "11 \tObject: person \tConfidence = 0.7556 \tBbox: [ 0 \t 780 \t 191 \t 1078 ]\n",
      "12 \tObject: person \tConfidence = 0.7058 \tBbox: [ 644 \t 0 \t 689 \t 88 ]\n",
      "13 \tObject: train \tConfidence = 0.6511 \tBbox: [ 3 \t 4 \t 455 \t 802 ]\n",
      "14 \tObject: person \tConfidence = 0.5467 \tBbox: [ 316 \t 69 \t 401 \t 233 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000689 / 1050\n",
      "Frames to be processed: 361  | To do: 34.38 % | Done: 65.62 %\n",
      "\n",
      "2022-04-20 13:16:02.063762\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000689.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 15 persons, 1 train\n",
      "Speed: 27.2ms pre-process, 168.4ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 16 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9111 \tBbox: [ 170 \t 554 \t 425 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8996 \tBbox: [ 410 \t 178 \t 520 \t 486 ]\n",
      "3 \tObject: person \tConfidence = 0.8905 \tBbox: [ 465 \t 112 \t 579 \t 372 ]\n",
      "4 \tObject: person \tConfidence = 0.8773 \tBbox: [ 569 \t 54 \t 653 \t 276 ]\n",
      "5 \tObject: person \tConfidence = 0.8699 \tBbox: [ 582 \t 192 \t 725 \t 490 ]\n",
      "6 \tObject: person \tConfidence = 0.8409 \tBbox: [ 514 \t 620 \t 723 \t 1064 ]\n",
      "7 \tObject: person \tConfidence = 0.8361 \tBbox: [ 538 \t 447 \t 687 \t 658 ]\n",
      "8 \tObject: person \tConfidence = 0.7905 \tBbox: [ 472 \t 0 \t 527 \t 119 ]\n",
      "9 \tObject: person \tConfidence = 0.7881 \tBbox: [ 332 \t 163 \t 428 \t 411 ]\n",
      "10 \tObject: person \tConfidence = 0.7697 \tBbox: [ 338 \t 404 \t 502 \t 782 ]\n",
      "11 \tObject: person \tConfidence = 0.7589 \tBbox: [ 0 \t 782 \t 161 \t 1078 ]\n",
      "12 \tObject: person \tConfidence = 0.7147 \tBbox: [ 645 \t 0 \t 690 \t 88 ]\n",
      "13 \tObject: train \tConfidence = 0.5663 \tBbox: [ 3 \t 4 \t 454 \t 830 ]\n",
      "14 \tObject: person \tConfidence = 0.5496 \tBbox: [ 315 \t 67 \t 420 \t 234 ]\n",
      "15 \tObject: person \tConfidence = 0.3406 \tBbox: [ 360 \t 240 \t 412 \t 312 ]\n",
      "16 \tObject: person \tConfidence = 0.3007 \tBbox: [ 290 \t 148 \t 350 \t 336 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    15\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000690 / 1050\n",
      "Frames to be processed: 360  | To do: 34.29 % | Done: 65.71 %\n",
      "\n",
      "2022-04-20 13:16:02.560819\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000690.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 36.9ms pre-process, 175.1ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9091 \tBbox: [ 177 \t 556 \t 433 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.9073 \tBbox: [ 470 \t 114 \t 580 \t 378 ]\n",
      "3 \tObject: person \tConfidence = 0.907 \tBbox: [ 407 \t 178 \t 519 \t 490 ]\n",
      "4 \tObject: person \tConfidence = 0.9049 \tBbox: [ 584 \t 194 \t 727 \t 492 ]\n",
      "5 \tObject: person \tConfidence = 0.8817 \tBbox: [ 507 \t 620 \t 732 \t 1064 ]\n",
      "6 \tObject: person \tConfidence = 0.8795 \tBbox: [ 570 \t 54 \t 655 \t 277 ]\n",
      "7 \tObject: person \tConfidence = 0.8551 \tBbox: [ 527 \t 447 \t 674 \t 670 ]\n",
      "8 \tObject: person \tConfidence = 0.7977 \tBbox: [ 646 \t 0 \t 691 \t 87 ]\n",
      "9 \tObject: person \tConfidence = 0.7824 \tBbox: [ 0 \t 782 \t 159 \t 1078 ]\n",
      "10 \tObject: person \tConfidence = 0.7512 \tBbox: [ 469 \t 0 \t 526 \t 123 ]\n",
      "11 \tObject: person \tConfidence = 0.7399 \tBbox: [ 335 \t 163 \t 424 \t 412 ]\n",
      "12 \tObject: train \tConfidence = 0.7165 \tBbox: [ 4 \t 3 \t 447 \t 828 ]\n",
      "13 \tObject: person \tConfidence = 0.4383 \tBbox: [ 348 \t 428 \t 480 \t 780 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000691 / 1050\n",
      "Frames to be processed: 359  | To do: 34.19 % | Done: 65.81 %\n",
      "\n",
      "2022-04-20 13:16:03.018490\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000691.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 32.4ms pre-process, 179.0ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9087 \tBbox: [ 477 \t 115 \t 582 \t 383 ]\n",
      "2 \tObject: person \tConfidence = 0.9021 \tBbox: [ 405 \t 178 \t 520 \t 492 ]\n",
      "3 \tObject: person \tConfidence = 0.8964 \tBbox: [ 190 \t 558 \t 452 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.8934 \tBbox: [ 587 \t 194 \t 728 \t 497 ]\n",
      "5 \tObject: person \tConfidence = 0.8795 \tBbox: [ 571 \t 54 \t 657 \t 274 ]\n",
      "6 \tObject: person \tConfidence = 0.8576 \tBbox: [ 500 \t 620 \t 744 \t 1065 ]\n",
      "7 \tObject: person \tConfidence = 0.8259 \tBbox: [ 515 \t 447 \t 665 \t 672 ]\n",
      "8 \tObject: person \tConfidence = 0.7919 \tBbox: [ 647 \t 0 \t 692 \t 87 ]\n",
      "9 \tObject: person \tConfidence = 0.7911 \tBbox: [ 466 \t 0 \t 525 \t 131 ]\n",
      "10 \tObject: person \tConfidence = 0.7271 \tBbox: [ 1 \t 783 \t 168 \t 1078 ]\n",
      "11 \tObject: train \tConfidence = 0.7096 \tBbox: [ 3 \t 3 \t 451 \t 843 ]\n",
      "12 \tObject: person \tConfidence = 0.6358 \tBbox: [ 347 \t 400 \t 454 \t 790 ]\n",
      "13 \tObject: person \tConfidence = 0.5908 \tBbox: [ 331 \t 156 \t 417 \t 409 ]\n",
      "14 \tObject: person \tConfidence = 0.3627 \tBbox: [ 322 \t 109 \t 413 \t 220 ]\n",
      "15 \tObject: person \tConfidence = 0.3454 \tBbox: [ 358 \t 237 \t 410 \t 307 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000692 / 1050\n",
      "Frames to be processed: 358  | To do: 34.1 % | Done: 65.9 %\n",
      "\n",
      "2022-04-20 13:16:03.501731\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000692.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 30.1ms pre-process, 178.8ms inference, 11.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8865 \tBbox: [ 482 \t 118 \t 583 \t 385 ]\n",
      "2 \tObject: person \tConfidence = 0.8824 \tBbox: [ 200 \t 560 \t 465 \t 1079 ]\n",
      "3 \tObject: person \tConfidence = 0.8804 \tBbox: [ 547 \t 620 \t 762 \t 1065 ]\n",
      "4 \tObject: person \tConfidence = 0.8639 \tBbox: [ 401 \t 177 \t 518 \t 495 ]\n",
      "5 \tObject: person \tConfidence = 0.8543 \tBbox: [ 574 \t 52 \t 661 \t 275 ]\n",
      "6 \tObject: person \tConfidence = 0.8281 \tBbox: [ 595 \t 197 \t 742 \t 497 ]\n",
      "7 \tObject: person \tConfidence = 0.8107 \tBbox: [ 0 \t 780 \t 214 \t 1078 ]\n",
      "8 \tObject: person \tConfidence = 0.8023 \tBbox: [ 491 \t 446 \t 646 \t 829 ]\n",
      "9 \tObject: person \tConfidence = 0.792 \tBbox: [ 650 \t 0 \t 696 \t 88 ]\n",
      "10 \tObject: person \tConfidence = 0.7596 \tBbox: [ 461 \t 0 \t 525 \t 141 ]\n",
      "11 \tObject: train \tConfidence = 0.7125 \tBbox: [ 3 \t 4 \t 455 \t 864 ]\n",
      "12 \tObject: person \tConfidence = 0.6295 \tBbox: [ 327 \t 412 \t 425 \t 765 ]\n",
      "13 \tObject: person \tConfidence = 0.5951 \tBbox: [ 331 \t 139 \t 412 \t 416 ]\n",
      "14 \tObject: person \tConfidence = 0.3527 \tBbox: [ 351 \t 68 \t 424 \t 215 ]\n",
      "15 \tObject: person \tConfidence = 0.3278 \tBbox: [ 356 \t 232 \t 406 \t 304 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000693 / 1050\n",
      "Frames to be processed: 357  | To do: 34.0 % | Done: 66.0 %\n",
      "\n",
      "2022-04-20 13:16:04.037041\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000693.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 41.2ms pre-process, 177.8ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8914 \tBbox: [ 218 \t 560 \t 477 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8656 \tBbox: [ 400 \t 176 \t 514 \t 491 ]\n",
      "3 \tObject: person \tConfidence = 0.8653 \tBbox: [ 481 \t 119 \t 584 \t 388 ]\n",
      "4 \tObject: person \tConfidence = 0.8554 \tBbox: [ 575 \t 51 \t 662 \t 274 ]\n",
      "5 \tObject: person \tConfidence = 0.8405 \tBbox: [ 467 \t 445 \t 638 \t 830 ]\n",
      "6 \tObject: person \tConfidence = 0.8187 \tBbox: [ 545 \t 621 \t 766 \t 1065 ]\n",
      "7 \tObject: person \tConfidence = 0.7884 \tBbox: [ 606 \t 200 \t 747 \t 497 ]\n",
      "8 \tObject: person \tConfidence = 0.7761 \tBbox: [ 1 \t 777 \t 217 \t 1077 ]\n",
      "9 \tObject: person \tConfidence = 0.7437 \tBbox: [ 328 \t 152 \t 411 \t 414 ]\n",
      "10 \tObject: person \tConfidence = 0.7007 \tBbox: [ 459 \t 0 \t 522 \t 146 ]\n",
      "11 \tObject: person \tConfidence = 0.6909 \tBbox: [ 652 \t 0 \t 696 \t 89 ]\n",
      "12 \tObject: person \tConfidence = 0.6305 \tBbox: [ 315 \t 412 \t 437 \t 797 ]\n",
      "13 \tObject: train \tConfidence = 0.595 \tBbox: [ 3 \t 2 \t 453 \t 859 ]\n",
      "14 \tObject: person \tConfidence = 0.5803 \tBbox: [ 357 \t 67 \t 427 \t 222 ]\n",
      "15 \tObject: person \tConfidence = 0.3161 \tBbox: [ 355 \t 233 \t 405 \t 303 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000694 / 1050\n",
      "Frames to be processed: 356  | To do: 33.9 % | Done: 66.1 %\n",
      "\n",
      "2022-04-20 13:16:04.540946\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000694.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 26.7ms pre-process, 176.4ms inference, 11.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9024 \tBbox: [ 225 \t 561 \t 487 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8647 \tBbox: [ 399 \t 177 \t 511 \t 486 ]\n",
      "3 \tObject: person \tConfidence = 0.8576 \tBbox: [ 577 \t 49 \t 664 \t 274 ]\n",
      "4 \tObject: person \tConfidence = 0.8397 \tBbox: [ 452 \t 447 \t 624 \t 829 ]\n",
      "5 \tObject: person \tConfidence = 0.8061 \tBbox: [ 481 \t 127 \t 583 \t 388 ]\n",
      "6 \tObject: person \tConfidence = 0.7991 \tBbox: [ 617 \t 201 \t 758 \t 498 ]\n",
      "7 \tObject: person \tConfidence = 0.7746 \tBbox: [ 460 \t 0 \t 526 \t 140 ]\n",
      "8 \tObject: train \tConfidence = 0.7398 \tBbox: [ 2 \t 3 \t 452 \t 871 ]\n",
      "9 \tObject: person \tConfidence = 0.6703 \tBbox: [ 325 \t 141 \t 411 \t 413 ]\n",
      "10 \tObject: person \tConfidence = 0.6595 \tBbox: [ 0 \t 764 \t 219 \t 1078 ]\n",
      "11 \tObject: person \tConfidence = 0.6426 \tBbox: [ 521 \t 601 \t 763 \t 1065 ]\n",
      "12 \tObject: person \tConfidence = 0.6402 \tBbox: [ 653 \t 0 \t 696 \t 89 ]\n",
      "13 \tObject: person \tConfidence = 0.5433 \tBbox: [ 302 \t 415 \t 422 \t 732 ]\n",
      "14 \tObject: person \tConfidence = 0.5305 \tBbox: [ 362 \t 68 \t 431 \t 228 ]\n",
      "15 \tObject: person \tConfidence = 0.3363 \tBbox: [ 354 \t 231 \t 405 \t 302 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000695 / 1050\n",
      "Frames to be processed: 355  | To do: 33.81 % | Done: 66.19 %\n",
      "\n",
      "2022-04-20 13:16:05.014491\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000695.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 22.5ms pre-process, 180.1ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9052 \tBbox: [ 230 \t 566 \t 503 \t 1080 ]\n",
      "2 \tObject: person \tConfidence = 0.8764 \tBbox: [ 444 \t 447 \t 615 \t 833 ]\n",
      "3 \tObject: person \tConfidence = 0.8705 \tBbox: [ 546 \t 620 \t 766 \t 1065 ]\n",
      "4 \tObject: person \tConfidence = 0.846 \tBbox: [ 631 \t 200 \t 762 \t 498 ]\n",
      "5 \tObject: person \tConfidence = 0.8423 \tBbox: [ 480 \t 123 \t 585 \t 389 ]\n",
      "6 \tObject: person \tConfidence = 0.8417 \tBbox: [ 579 \t 48 \t 665 \t 273 ]\n",
      "7 \tObject: person \tConfidence = 0.8278 \tBbox: [ 401 \t 177 \t 510 \t 487 ]\n",
      "8 \tObject: person \tConfidence = 0.7953 \tBbox: [ 1 \t 773 \t 214 \t 1078 ]\n",
      "9 \tObject: person \tConfidence = 0.7539 \tBbox: [ 458 \t 0 \t 514 \t 139 ]\n",
      "10 \tObject: person \tConfidence = 0.7073 \tBbox: [ 320 \t 145 \t 419 \t 412 ]\n",
      "11 \tObject: train \tConfidence = 0.7047 \tBbox: [ 3 \t 4 \t 455 \t 844 ]\n",
      "12 \tObject: person \tConfidence = 0.6812 \tBbox: [ 656 \t 0 \t 696 \t 89 ]\n",
      "13 \tObject: person \tConfidence = 0.6511 \tBbox: [ 365 \t 69 \t 433 \t 234 ]\n",
      "14 \tObject: person \tConfidence = 0.4714 \tBbox: [ 269 \t 423 \t 403 \t 640 ]\n",
      "15 \tObject: person \tConfidence = 0.3545 \tBbox: [ 353 \t 230 \t 404 \t 301 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000696 / 1050\n",
      "Frames to be processed: 354  | To do: 33.71 % | Done: 66.29 %\n",
      "\n",
      "2022-04-20 13:16:05.494841\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000696.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 25.4ms pre-process, 178.2ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8918 \tBbox: [ 243 \t 570 \t 509 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8894 \tBbox: [ 434 \t 448 \t 609 \t 832 ]\n",
      "3 \tObject: person \tConfidence = 0.8785 \tBbox: [ 547 \t 618 \t 765 \t 1065 ]\n",
      "4 \tObject: person \tConfidence = 0.8658 \tBbox: [ 483 \t 118 \t 598 \t 390 ]\n",
      "5 \tObject: person \tConfidence = 0.8565 \tBbox: [ 397 \t 177 \t 509 \t 485 ]\n",
      "6 \tObject: person \tConfidence = 0.8074 \tBbox: [ 584 \t 45 \t 667 \t 272 ]\n",
      "7 \tObject: person \tConfidence = 0.7853 \tBbox: [ 1 \t 770 \t 215 \t 1077 ]\n",
      "8 \tObject: person \tConfidence = 0.7328 \tBbox: [ 645 \t 203 \t 764 \t 501 ]\n",
      "9 \tObject: person \tConfidence = 0.729 \tBbox: [ 317 \t 152 \t 419 \t 412 ]\n",
      "10 \tObject: person \tConfidence = 0.7275 \tBbox: [ 456 \t 0 \t 511 \t 135 ]\n",
      "11 \tObject: train \tConfidence = 0.7262 \tBbox: [ 3 \t 2 \t 455 \t 844 ]\n",
      "12 \tObject: person \tConfidence = 0.7161 \tBbox: [ 368 \t 69 \t 436 \t 236 ]\n",
      "13 \tObject: person \tConfidence = 0.6236 \tBbox: [ 658 \t 0 \t 696 \t 90 ]\n",
      "14 \tObject: person \tConfidence = 0.4482 \tBbox: [ 274 \t 430 \t 393 \t 644 ]\n",
      "15 \tObject: person \tConfidence = 0.3151 \tBbox: [ 349 \t 214 \t 405 \t 317 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000697 / 1050\n",
      "Frames to be processed: 353  | To do: 33.62 % | Done: 66.38 %\n",
      "\n",
      "2022-04-20 13:16:06.041430\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000697.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 61.7ms pre-process, 170.4ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8854 \tBbox: [ 436 \t 446 \t 600 \t 831 ]\n",
      "2 \tObject: person \tConfidence = 0.8734 \tBbox: [ 491 \t 122 \t 606 \t 396 ]\n",
      "3 \tObject: person \tConfidence = 0.8587 \tBbox: [ 261 \t 569 \t 533 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.855 \tBbox: [ 393 \t 178 \t 505 \t 487 ]\n",
      "5 \tObject: person \tConfidence = 0.8332 \tBbox: [ 585 \t 47 \t 671 \t 261 ]\n",
      "6 \tObject: person \tConfidence = 0.7814 \tBbox: [ 316 \t 154 \t 402 \t 412 ]\n",
      "7 \tObject: person \tConfidence = 0.7641 \tBbox: [ 193 \t 435 \t 369 \t 864 ]\n",
      "8 \tObject: person \tConfidence = 0.7617 \tBbox: [ 676 \t 205 \t 766 \t 533 ]\n",
      "9 \tObject: person \tConfidence = 0.7439 \tBbox: [ 546 \t 612 \t 766 \t 1069 ]\n",
      "10 \tObject: person \tConfidence = 0.689 \tBbox: [ 370 \t 66 \t 464 \t 256 ]\n",
      "11 \tObject: person \tConfidence = 0.6663 \tBbox: [ 1 \t 748 \t 215 \t 1077 ]\n",
      "12 \tObject: train \tConfidence = 0.5889 \tBbox: [ 3 \t 2 \t 457 \t 830 ]\n",
      "13 \tObject: person \tConfidence = 0.56 \tBbox: [ 454 \t 0 \t 505 \t 128 ]\n",
      "14 \tObject: person \tConfidence = 0.4823 \tBbox: [ 665 \t 0 \t 696 \t 92 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000698 / 1050\n",
      "Frames to be processed: 352  | To do: 33.52 % | Done: 66.48 %\n",
      "\n",
      "2022-04-20 13:16:06.533764\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000698.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 26.7ms pre-process, 175.6ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9003 \tBbox: [ 430 \t 448 \t 590 \t 825 ]\n",
      "2 \tObject: person \tConfidence = 0.8988 \tBbox: [ 283 \t 569 \t 547 \t 1080 ]\n",
      "3 \tObject: person \tConfidence = 0.8561 \tBbox: [ 388 \t 207 \t 505 \t 502 ]\n",
      "4 \tObject: person \tConfidence = 0.8561 \tBbox: [ 495 \t 125 \t 617 \t 392 ]\n",
      "5 \tObject: person \tConfidence = 0.8044 \tBbox: [ 588 \t 46 \t 674 \t 252 ]\n",
      "6 \tObject: person \tConfidence = 0.798 \tBbox: [ 188 \t 439 \t 358 \t 864 ]\n",
      "7 \tObject: person \tConfidence = 0.7816 \tBbox: [ 316 \t 153 \t 404 \t 412 ]\n",
      "8 \tObject: person \tConfidence = 0.6744 \tBbox: [ 549 \t 613 \t 766 \t 1070 ]\n",
      "9 \tObject: person \tConfidence = 0.6668 \tBbox: [ 367 \t 68 \t 467 \t 241 ]\n",
      "10 \tObject: person \tConfidence = 0.6257 \tBbox: [ 0 \t 722 \t 212 \t 1078 ]\n",
      "11 \tObject: person \tConfidence = 0.6019 \tBbox: [ 678 \t 209 \t 766 \t 537 ]\n",
      "12 \tObject: train \tConfidence = 0.5672 \tBbox: [ 2 \t 3 \t 461 \t 814 ]\n",
      "13 \tObject: person \tConfidence = 0.4311 \tBbox: [ 668 \t 0 \t 696 \t 93 ]\n",
      "14 \tObject: person \tConfidence = 0.3597 \tBbox: [ 455 \t 0 \t 497 \t 124 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000699 / 1050\n",
      "Frames to be processed: 351  | To do: 33.43 % | Done: 66.57 %\n",
      "\n",
      "2022-04-20 13:16:06.969166\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000699.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 26.3ms pre-process, 178.3ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9061 \tBbox: [ 285 \t 565 \t 555 \t 1080 ]\n",
      "2 \tObject: person \tConfidence = 0.8856 \tBbox: [ 501 \t 127 \t 622 \t 415 ]\n",
      "3 \tObject: person \tConfidence = 0.869 \tBbox: [ 417 \t 448 \t 584 \t 811 ]\n",
      "4 \tObject: person \tConfidence = 0.8486 \tBbox: [ 386 \t 204 \t 507 \t 497 ]\n",
      "5 \tObject: person \tConfidence = 0.8359 \tBbox: [ 187 \t 442 \t 349 \t 862 ]\n",
      "6 \tObject: person \tConfidence = 0.8291 \tBbox: [ 591 \t 45 \t 677 \t 249 ]\n",
      "7 \tObject: person \tConfidence = 0.8159 \tBbox: [ 314 \t 152 \t 400 \t 411 ]\n",
      "8 \tObject: person \tConfidence = 0.6892 \tBbox: [ 558 \t 631 \t 765 \t 1067 ]\n",
      "9 \tObject: person \tConfidence = 0.6773 \tBbox: [ 680 \t 214 \t 765 \t 539 ]\n",
      "10 \tObject: person \tConfidence = 0.655 \tBbox: [ 1 \t 715 \t 196 \t 1078 ]\n",
      "11 \tObject: train \tConfidence = 0.6335 \tBbox: [ 3 \t 3 \t 461 \t 804 ]\n",
      "12 \tObject: person \tConfidence = 0.5902 \tBbox: [ 451 \t 0 \t 501 \t 125 ]\n",
      "13 \tObject: person \tConfidence = 0.4809 \tBbox: [ 381 \t 70 \t 465 \t 231 ]\n",
      "14 \tObject: person \tConfidence = 0.3864 \tBbox: [ 671 \t 0 \t 696 \t 96 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000700 / 1050\n",
      "Frames to be processed: 350  | To do: 33.33 % | Done: 66.67 %\n",
      "\n",
      "2022-04-20 13:16:07.521119\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000700.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 26.9ms pre-process, 181.2ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9017 \tBbox: [ 289 \t 562 \t 561 \t 1080 ]\n",
      "2 \tObject: person \tConfidence = 0.8879 \tBbox: [ 507 \t 129 \t 625 \t 420 ]\n",
      "3 \tObject: person \tConfidence = 0.865 \tBbox: [ 188 \t 444 \t 333 \t 862 ]\n",
      "4 \tObject: person \tConfidence = 0.86 \tBbox: [ 411 \t 448 \t 564 \t 811 ]\n",
      "5 \tObject: person \tConfidence = 0.8047 \tBbox: [ 312 \t 150 \t 397 \t 410 ]\n",
      "6 \tObject: person \tConfidence = 0.7961 \tBbox: [ 591 \t 44 \t 678 \t 250 ]\n",
      "7 \tObject: person \tConfidence = 0.7787 \tBbox: [ 388 \t 203 \t 505 \t 471 ]\n",
      "8 \tObject: person \tConfidence = 0.6519 \tBbox: [ 567 \t 626 \t 765 \t 1067 ]\n",
      "9 \tObject: person \tConfidence = 0.643 \tBbox: [ 0 \t 743 \t 204 \t 1078 ]\n",
      "10 \tObject: train \tConfidence = 0.5458 \tBbox: [ 3 \t 2 \t 461 \t 763 ]\n",
      "11 \tObject: person \tConfidence = 0.5351 \tBbox: [ 373 \t 76 \t 462 \t 222 ]\n",
      "12 \tObject: person \tConfidence = 0.5326 \tBbox: [ 451 \t 0 \t 498 \t 137 ]\n",
      "13 \tObject: person \tConfidence = 0.4812 \tBbox: [ 686 \t 219 \t 765 \t 541 ]\n",
      "14 \tObject: person \tConfidence = 0.3605 \tBbox: [ 673 \t 0 \t 696 \t 98 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000701 / 1050\n",
      "Frames to be processed: 349  | To do: 33.24 % | Done: 66.76 %\n",
      "\n",
      "2022-04-20 13:16:08.076795\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000701.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 27.2ms pre-process, 172.7ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8987 \tBbox: [ 291 \t 560 \t 572 \t 1080 ]\n",
      "2 \tObject: person \tConfidence = 0.883 \tBbox: [ 512 \t 132 \t 629 \t 424 ]\n",
      "3 \tObject: person \tConfidence = 0.8587 \tBbox: [ 310 \t 151 \t 397 \t 409 ]\n",
      "4 \tObject: person \tConfidence = 0.8568 \tBbox: [ 184 \t 441 \t 329 \t 862 ]\n",
      "5 \tObject: person \tConfidence = 0.7751 \tBbox: [ 387 \t 210 \t 507 \t 466 ]\n",
      "6 \tObject: person \tConfidence = 0.7713 \tBbox: [ 384 \t 447 \t 550 \t 824 ]\n",
      "7 \tObject: person \tConfidence = 0.7566 \tBbox: [ 592 \t 44 \t 680 \t 251 ]\n",
      "8 \tObject: person \tConfidence = 0.6685 \tBbox: [ 1 \t 747 \t 203 \t 1077 ]\n",
      "9 \tObject: train \tConfidence = 0.6424 \tBbox: [ 3 \t 3 \t 460 \t 756 ]\n",
      "10 \tObject: person \tConfidence = 0.6343 \tBbox: [ 450 \t 0 \t 497 \t 142 ]\n",
      "11 \tObject: person \tConfidence = 0.4997 \tBbox: [ 0 \t 610 \t 195 \t 878 ]\n",
      "12 \tObject: person \tConfidence = 0.4908 \tBbox: [ 587 \t 625 \t 766 \t 1064 ]\n",
      "13 \tObject: person \tConfidence = 0.4056 \tBbox: [ 375 \t 75 \t 489 \t 227 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000702 / 1050\n",
      "Frames to be processed: 348  | To do: 33.14 % | Done: 66.86 %\n",
      "\n",
      "2022-04-20 13:16:08.555674\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000702.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 27.2ms pre-process, 175.6ms inference, 11.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9045 \tBbox: [ 295 \t 545 \t 591 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8924 \tBbox: [ 522 \t 142 \t 639 \t 429 ]\n",
      "3 \tObject: person \tConfidence = 0.8901 \tBbox: [ 307 \t 146 \t 392 \t 404 ]\n",
      "4 \tObject: person \tConfidence = 0.8622 \tBbox: [ 0 \t 743 \t 210 \t 1078 ]\n",
      "5 \tObject: person \tConfidence = 0.8128 \tBbox: [ 594 \t 43 \t 681 \t 251 ]\n",
      "6 \tObject: person \tConfidence = 0.8016 \tBbox: [ 160 \t 447 \t 301 \t 856 ]\n",
      "7 \tObject: person \tConfidence = 0.7868 \tBbox: [ 371 \t 200 \t 496 \t 465 ]\n",
      "8 \tObject: train \tConfidence = 0.7484 \tBbox: [ 0 \t 2 \t 452 \t 719 ]\n",
      "9 \tObject: person \tConfidence = 0.7359 \tBbox: [ 4 \t 606 \t 206 \t 868 ]\n",
      "10 \tObject: person \tConfidence = 0.6459 \tBbox: [ 434 \t 0 \t 495 \t 139 ]\n",
      "11 \tObject: person \tConfidence = 0.6217 \tBbox: [ 377 \t 450 \t 531 \t 685 ]\n",
      "12 \tObject: person \tConfidence = 0.585 \tBbox: [ 379 \t 74 \t 477 \t 264 ]\n",
      "13 \tObject: person \tConfidence = 0.4232 \tBbox: [ 677 \t 0 \t 696 \t 92 ]\n",
      "14 \tObject: person \tConfidence = 0.4098 \tBbox: [ 627 \t 616 \t 765 \t 1056 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000703 / 1050\n",
      "Frames to be processed: 347  | To do: 33.05 % | Done: 66.95 %\n",
      "\n",
      "2022-04-20 13:16:09.045705\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000703.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 14 persons, 1 train\n",
      "Speed: 59.0ms pre-process, 180.6ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 15 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9176 \tBbox: [ 302 \t 542 \t 602 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8807 \tBbox: [ 306 \t 141 \t 388 \t 384 ]\n",
      "3 \tObject: person \tConfidence = 0.8708 \tBbox: [ 373 \t 201 \t 494 \t 482 ]\n",
      "4 \tObject: person \tConfidence = 0.8672 \tBbox: [ 526 \t 144 \t 648 \t 433 ]\n",
      "5 \tObject: person \tConfidence = 0.8518 \tBbox: [ 0 \t 737 \t 209 \t 1078 ]\n",
      "6 \tObject: person \tConfidence = 0.7809 \tBbox: [ 150 \t 447 \t 288 \t 875 ]\n",
      "7 \tObject: train \tConfidence = 0.7303 \tBbox: [ 4 \t 3 \t 453 \t 694 ]\n",
      "8 \tObject: person \tConfidence = 0.6913 \tBbox: [ 4 \t 606 \t 217 \t 852 ]\n",
      "9 \tObject: person \tConfidence = 0.674 \tBbox: [ 365 \t 454 \t 515 \t 640 ]\n",
      "10 \tObject: person \tConfidence = 0.6254 \tBbox: [ 594 \t 40 \t 682 \t 247 ]\n",
      "11 \tObject: person \tConfidence = 0.4767 \tBbox: [ 395 \t 77 \t 487 \t 225 ]\n",
      "12 \tObject: person \tConfidence = 0.3853 \tBbox: [ 650 \t 608 \t 765 \t 1051 ]\n",
      "13 \tObject: person \tConfidence = 0.373 \tBbox: [ 443 \t 0 \t 493 \t 135 ]\n",
      "14 \tObject: person \tConfidence = 0.307 \tBbox: [ 677 \t 0 \t 697 \t 92 ]\n",
      "15 \tObject: person \tConfidence = 0.3034 \tBbox: [ 684 \t 261 \t 765 \t 505 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    14\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000704 / 1050\n",
      "Frames to be processed: 346  | To do: 32.95 % | Done: 67.05 %\n",
      "\n",
      "2022-04-20 13:16:09.567817\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000704.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 55.9ms pre-process, 180.2ms inference, 10.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.907 \tBbox: [ 306 \t 536 \t 608 \t 1080 ]\n",
      "2 \tObject: person \tConfidence = 0.8801 \tBbox: [ 305 \t 142 \t 385 \t 373 ]\n",
      "3 \tObject: person \tConfidence = 0.8627 \tBbox: [ 0 \t 732 \t 208 \t 1078 ]\n",
      "4 \tObject: person \tConfidence = 0.8613 \tBbox: [ 379 \t 201 \t 492 \t 485 ]\n",
      "5 \tObject: person \tConfidence = 0.8485 \tBbox: [ 530 \t 147 \t 651 \t 436 ]\n",
      "6 \tObject: train \tConfidence = 0.8094 \tBbox: [ 0 \t 2 \t 453 \t 694 ]\n",
      "7 \tObject: person \tConfidence = 0.7377 \tBbox: [ 358 \t 457 \t 501 \t 672 ]\n",
      "8 \tObject: person \tConfidence = 0.6287 \tBbox: [ 140 \t 451 \t 277 \t 842 ]\n",
      "9 \tObject: person \tConfidence = 0.5911 \tBbox: [ 398 \t 77 \t 493 \t 225 ]\n",
      "10 \tObject: person \tConfidence = 0.5572 \tBbox: [ 8 \t 604 \t 221 \t 871 ]\n",
      "11 \tObject: person \tConfidence = 0.5288 \tBbox: [ 446 \t 0 \t 490 \t 78 ]\n",
      "12 \tObject: person \tConfidence = 0.4476 \tBbox: [ 686 \t 288 \t 764 \t 497 ]\n",
      "13 \tObject: person \tConfidence = 0.3301 \tBbox: [ 681 \t 603 \t 765 \t 1045 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000705 / 1050\n",
      "Frames to be processed: 345  | To do: 32.86 % | Done: 67.14 %\n",
      "\n",
      "2022-04-20 13:16:10.061111\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000705.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 23.0ms pre-process, 181.4ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8972 \tBbox: [ 322 \t 532 \t 619 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8498 \tBbox: [ 304 \t 142 \t 381 \t 369 ]\n",
      "3 \tObject: person \tConfidence = 0.8435 \tBbox: [ 384 \t 195 \t 490 \t 490 ]\n",
      "4 \tObject: person \tConfidence = 0.8078 \tBbox: [ 534 \t 148 \t 657 \t 444 ]\n",
      "5 \tObject: person \tConfidence = 0.8053 \tBbox: [ 0 \t 726 \t 203 \t 1078 ]\n",
      "6 \tObject: train \tConfidence = 0.7534 \tBbox: [ 0 \t 2 \t 453 \t 702 ]\n",
      "7 \tObject: person \tConfidence = 0.6719 \tBbox: [ 135 \t 454 \t 265 \t 764 ]\n",
      "8 \tObject: person \tConfidence = 0.6242 \tBbox: [ 336 \t 458 \t 489 \t 727 ]\n",
      "9 \tObject: person \tConfidence = 0.5748 \tBbox: [ 25 \t 602 \t 229 \t 978 ]\n",
      "10 \tObject: person \tConfidence = 0.4847 \tBbox: [ 445 \t 0 \t 490 \t 80 ]\n",
      "11 \tObject: person \tConfidence = 0.4262 \tBbox: [ 691 \t 299 \t 765 \t 499 ]\n",
      "12 \tObject: person \tConfidence = 0.422 \tBbox: [ 419 \t 72 \t 505 \t 279 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000706 / 1050\n",
      "Frames to be processed: 344  | To do: 32.76 % | Done: 67.24 %\n",
      "\n",
      "2022-04-20 13:16:10.601375\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000706.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 35.9ms pre-process, 173.8ms inference, 13.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8784 \tBbox: [ 0 \t 727 \t 196 \t 1078 ]\n",
      "2 \tObject: person \tConfidence = 0.8582 \tBbox: [ 383 \t 171 \t 488 \t 495 ]\n",
      "3 \tObject: person \tConfidence = 0.8547 \tBbox: [ 302 \t 138 \t 379 \t 372 ]\n",
      "4 \tObject: person \tConfidence = 0.847 \tBbox: [ 333 \t 535 \t 627 \t 1080 ]\n",
      "5 \tObject: person \tConfidence = 0.83 \tBbox: [ 543 \t 150 \t 659 \t 450 ]\n",
      "6 \tObject: train \tConfidence = 0.7494 \tBbox: [ 0 \t 3 \t 453 \t 717 ]\n",
      "7 \tObject: person \tConfidence = 0.7305 \tBbox: [ 321 \t 462 \t 483 \t 920 ]\n",
      "8 \tObject: person \tConfidence = 0.6556 \tBbox: [ 114 \t 458 \t 254 \t 736 ]\n",
      "9 \tObject: person \tConfidence = 0.6362 \tBbox: [ 38 \t 601 \t 258 \t 1040 ]\n",
      "10 \tObject: person \tConfidence = 0.5018 \tBbox: [ 427 \t 77 \t 507 \t 314 ]\n",
      "11 \tObject: person \tConfidence = 0.4288 \tBbox: [ 444 \t 0 \t 492 \t 87 ]\n",
      "12 \tObject: person \tConfidence = 0.3855 \tBbox: [ 598 \t 49 \t 674 \t 161 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000707 / 1050\n",
      "Frames to be processed: 343  | To do: 32.67 % | Done: 67.33 %\n",
      "\n",
      "2022-04-20 13:16:11.081469\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000707.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 25.2ms pre-process, 177.2ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9053 \tBbox: [ 384 \t 529 \t 648 \t 1080 ]\n",
      "2 \tObject: person \tConfidence = 0.8878 \tBbox: [ 0 \t 723 \t 186 \t 1077 ]\n",
      "3 \tObject: person \tConfidence = 0.8735 \tBbox: [ 381 \t 171 \t 485 \t 501 ]\n",
      "4 \tObject: person \tConfidence = 0.8529 \tBbox: [ 548 \t 152 \t 673 \t 451 ]\n",
      "5 \tObject: person \tConfidence = 0.8346 \tBbox: [ 299 \t 136 \t 372 \t 372 ]\n",
      "6 \tObject: person \tConfidence = 0.8293 \tBbox: [ 316 \t 470 \t 469 \t 887 ]\n",
      "7 \tObject: person \tConfidence = 0.7856 \tBbox: [ 63 \t 601 \t 273 \t 1051 ]\n",
      "8 \tObject: train \tConfidence = 0.7711 \tBbox: [ 0 \t 3 \t 443 \t 733 ]\n",
      "9 \tObject: person \tConfidence = 0.7456 \tBbox: [ 442 \t 66 \t 513 \t 327 ]\n",
      "10 \tObject: person \tConfidence = 0.6251 \tBbox: [ 91 \t 461 \t 235 \t 674 ]\n",
      "11 \tObject: person \tConfidence = 0.5274 \tBbox: [ 437 \t 0 \t 480 \t 94 ]\n",
      "12 \tObject: person \tConfidence = 0.4576 \tBbox: [ 597 \t 42 \t 680 \t 163 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000708 / 1050\n",
      "Frames to be processed: 342  | To do: 32.57 % | Done: 67.43 %\n",
      "\n",
      "2022-04-20 13:16:11.585885\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000708.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 12 persons, 1 train\n",
      "Speed: 40.3ms pre-process, 172.1ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 13 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8809 \tBbox: [ 415 \t 528 \t 657 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8808 \tBbox: [ 0 \t 718 \t 181 \t 1077 ]\n",
      "3 \tObject: person \tConfidence = 0.8639 \tBbox: [ 380 \t 171 \t 485 \t 495 ]\n",
      "4 \tObject: person \tConfidence = 0.862 \tBbox: [ 305 \t 475 \t 461 \t 886 ]\n",
      "5 \tObject: person \tConfidence = 0.8405 \tBbox: [ 297 \t 135 \t 371 \t 372 ]\n",
      "6 \tObject: person \tConfidence = 0.8002 \tBbox: [ 442 \t 66 \t 524 \t 328 ]\n",
      "7 \tObject: person \tConfidence = 0.7789 \tBbox: [ 68 \t 602 \t 291 \t 1074 ]\n",
      "8 \tObject: person \tConfidence = 0.7594 \tBbox: [ 557 \t 155 \t 678 \t 450 ]\n",
      "9 \tObject: train \tConfidence = 0.7539 \tBbox: [ 0 \t 3 \t 441 \t 737 ]\n",
      "10 \tObject: person \tConfidence = 0.6461 \tBbox: [ 75 \t 475 \t 224 \t 687 ]\n",
      "11 \tObject: person \tConfidence = 0.5035 \tBbox: [ 435 \t 0 \t 476 \t 93 ]\n",
      "12 \tObject: person \tConfidence = 0.4803 \tBbox: [ 598 \t 42 \t 680 \t 167 ]\n",
      "13 \tObject: person \tConfidence = 0.307 \tBbox: [ 322 \t 184 \t 381 \t 299 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    12\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000709 / 1050\n",
      "Frames to be processed: 341  | To do: 32.48 % | Done: 67.52 %\n",
      "\n",
      "2022-04-20 13:16:12.109687\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000709.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 25.1ms pre-process, 170.3ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8852 \tBbox: [ 441 \t 527 \t 663 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.882 \tBbox: [ 0 \t 716 \t 176 \t 1076 ]\n",
      "3 \tObject: person \tConfidence = 0.8793 \tBbox: [ 380 \t 171 \t 488 \t 497 ]\n",
      "4 \tObject: person \tConfidence = 0.8638 \tBbox: [ 295 \t 134 \t 371 \t 372 ]\n",
      "5 \tObject: person \tConfidence = 0.8545 \tBbox: [ 287 \t 474 \t 455 \t 885 ]\n",
      "6 \tObject: person \tConfidence = 0.8069 \tBbox: [ 575 \t 152 \t 684 \t 451 ]\n",
      "7 \tObject: person \tConfidence = 0.7907 \tBbox: [ 440 \t 64 \t 529 \t 328 ]\n",
      "8 \tObject: person \tConfidence = 0.7488 \tBbox: [ 78 \t 603 \t 299 \t 1073 ]\n",
      "9 \tObject: train \tConfidence = 0.7407 \tBbox: [ 0 \t 3 \t 441 \t 747 ]\n",
      "10 \tObject: person \tConfidence = 0.5939 \tBbox: [ 64 \t 463 \t 206 \t 668 ]\n",
      "11 \tObject: person \tConfidence = 0.5324 \tBbox: [ 600 \t 44 \t 679 \t 166 ]\n",
      "12 \tObject: person \tConfidence = 0.5246 \tBbox: [ 435 \t 0 \t 473 \t 109 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000710 / 1050\n",
      "Frames to be processed: 340  | To do: 32.38 % | Done: 67.62 %\n",
      "\n",
      "2022-04-20 13:16:12.589215\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000710.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 27.9ms pre-process, 168.4ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8893 \tBbox: [ 448 \t 527 \t 672 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8724 \tBbox: [ 380 \t 169 \t 484 \t 500 ]\n",
      "3 \tObject: person \tConfidence = 0.8721 \tBbox: [ 96 \t 604 \t 353 \t 1071 ]\n",
      "4 \tObject: person \tConfidence = 0.8584 \tBbox: [ 280 \t 475 \t 447 \t 885 ]\n",
      "5 \tObject: person \tConfidence = 0.8529 \tBbox: [ 0 \t 710 \t 174 \t 1079 ]\n",
      "6 \tObject: person \tConfidence = 0.8321 \tBbox: [ 294 \t 134 \t 372 \t 372 ]\n",
      "7 \tObject: person \tConfidence = 0.8251 \tBbox: [ 585 \t 151 \t 691 \t 451 ]\n",
      "8 \tObject: person \tConfidence = 0.7938 \tBbox: [ 438 \t 64 \t 528 \t 328 ]\n",
      "9 \tObject: person \tConfidence = 0.5819 \tBbox: [ 48 \t 479 \t 162 \t 774 ]\n",
      "10 \tObject: person \tConfidence = 0.5795 \tBbox: [ 434 \t 0 \t 473 \t 108 ]\n",
      "11 \tObject: person \tConfidence = 0.5182 \tBbox: [ 600 \t 43 \t 680 \t 168 ]\n",
      "12 \tObject: train \tConfidence = 0.4449 \tBbox: [ 4 \t 5 \t 441 \t 762 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000711 / 1050\n",
      "Frames to be processed: 339  | To do: 32.29 % | Done: 67.71 %\n",
      "\n",
      "2022-04-20 13:16:13.111769\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000711.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 13 persons, 1 train\n",
      "Speed: 33.3ms pre-process, 169.4ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 14 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9005 \tBbox: [ 451 \t 527 \t 678 \t 1079 ]\n",
      "2 \tObject: person \tConfidence = 0.8869 \tBbox: [ 555 \t 151 \t 695 \t 451 ]\n",
      "3 \tObject: person \tConfidence = 0.8726 \tBbox: [ 107 \t 606 \t 359 \t 1075 ]\n",
      "4 \tObject: person \tConfidence = 0.8725 \tBbox: [ 380 \t 168 \t 481 \t 493 ]\n",
      "5 \tObject: person \tConfidence = 0.862 \tBbox: [ 273 \t 476 \t 437 \t 888 ]\n",
      "6 \tObject: person \tConfidence = 0.8409 \tBbox: [ 291 \t 133 \t 370 \t 374 ]\n",
      "7 \tObject: person \tConfidence = 0.8313 \tBbox: [ 0 \t 708 \t 168 \t 1080 ]\n",
      "8 \tObject: person \tConfidence = 0.8278 \tBbox: [ 441 \t 64 \t 530 \t 329 ]\n",
      "9 \tObject: person \tConfidence = 0.7622 \tBbox: [ 34 \t 481 \t 151 \t 780 ]\n",
      "10 \tObject: person \tConfidence = 0.6315 \tBbox: [ 601 \t 39 \t 683 \t 174 ]\n",
      "11 \tObject: train \tConfidence = 0.5699 \tBbox: [ 2 \t 4 \t 435 \t 708 ]\n",
      "12 \tObject: person \tConfidence = 0.5007 \tBbox: [ 107 \t 443 \t 184 \t 608 ]\n",
      "13 \tObject: person \tConfidence = 0.4046 \tBbox: [ 435 \t 0 \t 474 \t 95 ]\n",
      "14 \tObject: person \tConfidence = 0.3947 \tBbox: [ 414 \t 64 \t 461 \t 132 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    13\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000712 / 1050\n",
      "Frames to be processed: 338  | To do: 32.19 % | Done: 67.81 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 11 persons, 1 train\n",
      "Speed: 22.9ms pre-process, 168.8ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:16:13.562178\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000712.jpg ------------------------------ \n",
      "\n",
      "\u001b[1;31;34mNumber of detected objects = 12 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9053 \tBbox: [ 555 \t 152 \t 701 \t 450 ]\n",
      "2 \tObject: person \tConfidence = 0.8949 \tBbox: [ 288 \t 133 \t 370 \t 372 ]\n",
      "3 \tObject: person \tConfidence = 0.8799 \tBbox: [ 459 \t 527 \t 690 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.8563 \tBbox: [ 114 \t 609 \t 363 \t 1078 ]\n",
      "5 \tObject: person \tConfidence = 0.8487 \tBbox: [ 380 \t 167 \t 482 \t 483 ]\n",
      "6 \tObject: person \tConfidence = 0.8479 \tBbox: [ 267 \t 477 \t 430 \t 886 ]\n",
      "7 \tObject: person \tConfidence = 0.807 \tBbox: [ 449 \t 65 \t 534 \t 327 ]\n",
      "8 \tObject: person \tConfidence = 0.7828 \tBbox: [ 0 \t 712 \t 159 \t 1077 ]\n",
      "9 \tObject: person \tConfidence = 0.7648 \tBbox: [ 18 \t 483 \t 149 \t 790 ]\n",
      "10 \tObject: person \tConfidence = 0.6388 \tBbox: [ 601 \t 37 \t 683 \t 175 ]\n",
      "11 \tObject: train \tConfidence = 0.5044 \tBbox: [ 2 \t 2 \t 428 \t 672 ]\n",
      "12 \tObject: person \tConfidence = 0.4768 \tBbox: [ 424 \t 0 \t 473 \t 92 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    11\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000713 / 1050\n",
      "Frames to be processed: 337  | To do: 32.1 % | Done: 67.9 %\n",
      "\n",
      "2022-04-20 13:16:14.159956\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000713.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 23.9ms pre-process, 175.3ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9139 \tBbox: [ 563 \t 156 \t 711 \t 459 ]\n",
      "2 \tObject: person \tConfidence = 0.871 \tBbox: [ 287 \t 132 \t 368 \t 370 ]\n",
      "3 \tObject: person \tConfidence = 0.8701 \tBbox: [ 453 \t 535 \t 715 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.8697 \tBbox: [ 378 \t 163 \t 480 \t 474 ]\n",
      "5 \tObject: person \tConfidence = 0.8662 \tBbox: [ 143 \t 610 \t 365 \t 1078 ]\n",
      "6 \tObject: person \tConfidence = 0.8654 \tBbox: [ 233 \t 482 \t 421 \t 884 ]\n",
      "7 \tObject: person \tConfidence = 0.8402 \tBbox: [ 464 \t 67 \t 543 \t 330 ]\n",
      "8 \tObject: person \tConfidence = 0.8235 \tBbox: [ 0 \t 699 \t 152 \t 1077 ]\n",
      "9 \tObject: person \tConfidence = 0.7135 \tBbox: [ 601 \t 32 \t 682 \t 195 ]\n",
      "10 \tObject: person \tConfidence = 0.6744 \tBbox: [ 1 \t 481 \t 138 \t 790 ]\n",
      "11 \tObject: train \tConfidence = 0.3136 \tBbox: [ 1 \t 5 \t 419 \t 806 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000714 / 1050\n",
      "Frames to be processed: 336  | To do: 32.0 % | Done: 68.0 %\n",
      "\n",
      "2022-04-20 13:16:14.594046\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000714.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 27.0ms pre-process, 179.5ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9159 \tBbox: [ 571 \t 158 \t 717 \t 469 ]\n",
      "2 \tObject: person \tConfidence = 0.8803 \tBbox: [ 243 \t 483 \t 417 \t 884 ]\n",
      "3 \tObject: person \tConfidence = 0.8778 \tBbox: [ 454 \t 540 \t 721 \t 1079 ]\n",
      "4 \tObject: person \tConfidence = 0.8777 \tBbox: [ 463 \t 67 \t 554 \t 330 ]\n",
      "5 \tObject: person \tConfidence = 0.8728 \tBbox: [ 377 \t 159 \t 478 \t 470 ]\n",
      "6 \tObject: person \tConfidence = 0.8676 \tBbox: [ 287 \t 132 \t 368 \t 368 ]\n",
      "7 \tObject: person \tConfidence = 0.8159 \tBbox: [ 151 \t 611 \t 366 \t 1074 ]\n",
      "8 \tObject: person \tConfidence = 0.8043 \tBbox: [ 0 \t 684 \t 150 \t 1079 ]\n",
      "9 \tObject: person \tConfidence = 0.7144 \tBbox: [ 601 \t 31 \t 683 \t 202 ]\n",
      "10 \tObject: person \tConfidence = 0.5166 \tBbox: [ 0 \t 484 \t 131 \t 772 ]\n",
      "11 \tObject: train \tConfidence = 0.4477 \tBbox: [ 2 \t 2 \t 421 \t 699 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000715 / 1050\n",
      "Frames to be processed: 335  | To do: 31.9 % | Done: 68.1 %\n",
      "\n",
      "2022-04-20 13:16:15.170396\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000715.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 59.9ms pre-process, 168.5ms inference, 3.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9164 \tBbox: [ 565 \t 164 \t 722 \t 471 ]\n",
      "2 \tObject: person \tConfidence = 0.8936 \tBbox: [ 452 \t 546 \t 733 \t 1080 ]\n",
      "3 \tObject: person \tConfidence = 0.8862 \tBbox: [ 467 \t 67 \t 559 \t 328 ]\n",
      "4 \tObject: person \tConfidence = 0.8785 \tBbox: [ 378 \t 155 \t 478 \t 466 ]\n",
      "5 \tObject: person \tConfidence = 0.8683 \tBbox: [ 285 \t 132 \t 368 \t 368 ]\n",
      "6 \tObject: person \tConfidence = 0.8233 \tBbox: [ 165 \t 611 \t 375 \t 1075 ]\n",
      "7 \tObject: person \tConfidence = 0.8053 \tBbox: [ 0 \t 679 \t 145 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.7613 \tBbox: [ 602 \t 30 \t 682 \t 210 ]\n",
      "9 \tObject: person \tConfidence = 0.7476 \tBbox: [ 230 \t 486 \t 404 \t 878 ]\n",
      "10 \tObject: train \tConfidence = 0.5615 \tBbox: [ 1 \t 3 \t 416 \t 783 ]\n",
      "11 \tObject: person \tConfidence = 0.3873 \tBbox: [ 417 \t 0 \t 467 \t 75 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000716 / 1050\n",
      "Frames to be processed: 334  | To do: 31.81 % | Done: 68.19 %\n",
      "\n",
      "2022-04-20 13:16:15.767600\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000716.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 56.2ms pre-process, 177.6ms inference, 4.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8947 \tBbox: [ 377 \t 153 \t 478 \t 454 ]\n",
      "2 \tObject: person \tConfidence = 0.8916 \tBbox: [ 452 \t 549 \t 748 \t 1080 ]\n",
      "3 \tObject: person \tConfidence = 0.8867 \tBbox: [ 469 \t 69 \t 567 \t 327 ]\n",
      "4 \tObject: person \tConfidence = 0.8417 \tBbox: [ 284 \t 133 \t 367 \t 365 ]\n",
      "5 \tObject: person \tConfidence = 0.7962 \tBbox: [ 603 \t 30 \t 683 \t 225 ]\n",
      "6 \tObject: person \tConfidence = 0.7478 \tBbox: [ 177 \t 611 \t 386 \t 1078 ]\n",
      "7 \tObject: person \tConfidence = 0.7446 \tBbox: [ 572 \t 170 \t 730 \t 479 ]\n",
      "8 \tObject: person \tConfidence = 0.7377 \tBbox: [ 0 \t 676 \t 142 \t 1079 ]\n",
      "9 \tObject: train \tConfidence = 0.5929 \tBbox: [ 1 \t 3 \t 413 \t 807 ]\n",
      "10 \tObject: person \tConfidence = 0.4766 \tBbox: [ 220 \t 485 \t 389 \t 745 ]\n",
      "11 \tObject: person \tConfidence = 0.4717 \tBbox: [ 417 \t 0 \t 466 \t 76 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000717 / 1050\n",
      "Frames to be processed: 333  | To do: 31.71 % | Done: 68.29 %\n",
      "\n",
      "2022-04-20 13:16:16.457685\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000717.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 28.2ms pre-process, 170.4ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9072 \tBbox: [ 375 \t 153 \t 477 \t 447 ]\n",
      "2 \tObject: person \tConfidence = 0.9051 \tBbox: [ 588 \t 173 \t 739 \t 484 ]\n",
      "3 \tObject: person \tConfidence = 0.9039 \tBbox: [ 470 \t 69 \t 568 \t 327 ]\n",
      "4 \tObject: person \tConfidence = 0.8998 \tBbox: [ 454 \t 554 \t 755 \t 1080 ]\n",
      "5 \tObject: person \tConfidence = 0.8358 \tBbox: [ 603 \t 30 \t 683 \t 225 ]\n",
      "6 \tObject: person \tConfidence = 0.794 \tBbox: [ 0 \t 681 \t 140 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.7356 \tBbox: [ 287 \t 135 \t 367 \t 363 ]\n",
      "8 \tObject: person \tConfidence = 0.7304 \tBbox: [ 189 \t 608 \t 383 \t 1072 ]\n",
      "9 \tObject: person \tConfidence = 0.6165 \tBbox: [ 208 \t 490 \t 377 \t 736 ]\n",
      "10 \tObject: train \tConfidence = 0.4477 \tBbox: [ 2 \t 4 \t 415 \t 834 ]\n",
      "11 \tObject: person \tConfidence = 0.4102 \tBbox: [ 416 \t 0 \t 464 \t 77 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000718 / 1050\n",
      "Frames to be processed: 332  | To do: 31.62 % | Done: 68.38 %\n",
      "\n",
      "2022-04-20 13:16:16.960117\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000718.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 26.6ms pre-process, 169.1ms inference, 4.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9093 \tBbox: [ 375 \t 150 \t 478 \t 437 ]\n",
      "2 \tObject: person \tConfidence = 0.9029 \tBbox: [ 608 \t 181 \t 750 \t 493 ]\n",
      "3 \tObject: person \tConfidence = 0.9019 \tBbox: [ 470 \t 68 \t 571 \t 326 ]\n",
      "4 \tObject: person \tConfidence = 0.8767 \tBbox: [ 460 \t 559 \t 765 \t 1079 ]\n",
      "5 \tObject: person \tConfidence = 0.8656 \tBbox: [ 603 \t 30 \t 683 \t 229 ]\n",
      "6 \tObject: person \tConfidence = 0.785 \tBbox: [ 0 \t 688 \t 131 \t 1079 ]\n",
      "7 \tObject: person \tConfidence = 0.7522 \tBbox: [ 291 \t 164 \t 363 \t 353 ]\n",
      "8 \tObject: person \tConfidence = 0.7501 \tBbox: [ 189 \t 613 \t 408 \t 1071 ]\n",
      "9 \tObject: train \tConfidence = 0.6974 \tBbox: [ 0 \t 1 \t 416 \t 848 ]\n",
      "10 \tObject: person \tConfidence = 0.6587 \tBbox: [ 187 \t 486 \t 357 \t 722 ]\n",
      "11 \tObject: person \tConfidence = 0.4073 \tBbox: [ 414 \t 0 \t 460 \t 77 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000719 / 1050\n",
      "Frames to be processed: 331  | To do: 31.52 % | Done: 68.48 %\n",
      "\n",
      "2022-04-20 13:16:17.515430\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000719.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 26.9ms pre-process, 171.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9052 \tBbox: [ 373 \t 148 \t 476 \t 434 ]\n",
      "2 \tObject: person \tConfidence = 0.8986 \tBbox: [ 470 \t 66 \t 573 \t 328 ]\n",
      "3 \tObject: person \tConfidence = 0.8831 \tBbox: [ 611 \t 184 \t 758 \t 509 ]\n",
      "4 \tObject: person \tConfidence = 0.8689 \tBbox: [ 603 \t 29 \t 684 \t 229 ]\n",
      "5 \tObject: person \tConfidence = 0.8523 \tBbox: [ 176 \t 485 \t 342 \t 719 ]\n",
      "6 \tObject: person \tConfidence = 0.822 \tBbox: [ 201 \t 608 \t 436 \t 1068 ]\n",
      "7 \tObject: person \tConfidence = 0.7717 \tBbox: [ 0 \t 692 \t 130 \t 1079 ]\n",
      "8 \tObject: person \tConfidence = 0.7356 \tBbox: [ 292 \t 160 \t 355 \t 345 ]\n",
      "9 \tObject: person \tConfidence = 0.6635 \tBbox: [ 467 \t 579 \t 761 \t 1076 ]\n",
      "10 \tObject: train \tConfidence = 0.5399 \tBbox: [ 0 \t 1 \t 417 \t 871 ]\n",
      "11 \tObject: person \tConfidence = 0.3721 \tBbox: [ 413 \t 0 \t 458 \t 76 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000720 / 1050\n",
      "Frames to be processed: 330  | To do: 31.43 % | Done: 68.57 %\n",
      "\n",
      "2022-04-20 13:16:17.923254\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 10 persons, 1 train\n",
      "Speed: 25.8ms pre-process, 167.2ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/captures/frame_000000720.jpg ------------------------------ \n",
      "\n",
      "\u001b[1;31;34mNumber of detected objects = 11 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8953 \tBbox: [ 374 \t 147 \t 475 \t 428 ]\n",
      "2 \tObject: person \tConfidence = 0.8903 \tBbox: [ 475 \t 65 \t 577 \t 329 ]\n",
      "3 \tObject: person \tConfidence = 0.8829 \tBbox: [ 613 \t 187 \t 765 \t 528 ]\n",
      "4 \tObject: person \tConfidence = 0.8519 \tBbox: [ 604 \t 29 \t 683 \t 229 ]\n",
      "5 \tObject: person \tConfidence = 0.78 \tBbox: [ 168 \t 487 \t 331 \t 730 ]\n",
      "6 \tObject: person \tConfidence = 0.7708 \tBbox: [ 237 \t 609 \t 442 \t 1064 ]\n",
      "7 \tObject: person \tConfidence = 0.6388 \tBbox: [ 479 \t 582 \t 756 \t 1067 ]\n",
      "8 \tObject: person \tConfidence = 0.6127 \tBbox: [ 0 \t 715 \t 122 \t 1079 ]\n",
      "9 \tObject: train \tConfidence = 0.4731 \tBbox: [ 1 \t 2 \t 415 \t 872 ]\n",
      "10 \tObject: person \tConfidence = 0.4127 \tBbox: [ 290 \t 159 \t 327 \t 330 ]\n",
      "11 \tObject: person \tConfidence = 0.4007 \tBbox: [ 411 \t 0 \t 455 \t 78 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    10\n",
      "train      1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000721 / 1050\n",
      "Frames to be processed: 329  | To do: 31.33 % | Done: 68.67 %\n",
      "\n",
      "2022-04-20 13:16:18.410593\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000721.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 9 persons, 1 train\n",
      "Speed: 24.4ms pre-process, 180.2ms inference, 5.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 10 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8819 \tBbox: [ 373 \t 148 \t 475 \t 422 ]\n",
      "2 \tObject: person \tConfidence = 0.8787 \tBbox: [ 617 \t 188 \t 765 \t 540 ]\n",
      "3 \tObject: person \tConfidence = 0.8752 \tBbox: [ 485 \t 63 \t 581 \t 328 ]\n",
      "4 \tObject: person \tConfidence = 0.862 \tBbox: [ 603 \t 29 \t 684 \t 228 ]\n",
      "5 \tObject: person \tConfidence = 0.8595 \tBbox: [ 251 \t 608 \t 456 \t 1064 ]\n",
      "6 \tObject: person \tConfidence = 0.7561 \tBbox: [ 157 \t 488 \t 320 \t 825 ]\n",
      "7 \tObject: person \tConfidence = 0.6988 \tBbox: [ 496 \t 575 \t 765 \t 1077 ]\n",
      "8 \tObject: train \tConfidence = 0.5952 \tBbox: [ 1 \t 1 \t 416 \t 899 ]\n",
      "9 \tObject: person \tConfidence = 0.4488 \tBbox: [ 1 \t 721 \t 114 \t 1079 ]\n",
      "10 \tObject: person \tConfidence = 0.3592 \tBbox: [ 409 \t 0 \t 454 \t 76 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    9\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000722 / 1050\n",
      "Frames to be processed: 328  | To do: 31.24 % | Done: 68.76 %\n",
      "\n",
      "2022-04-20 13:16:18.951886\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000722.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 25.9ms pre-process, 181.4ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8904 \tBbox: [ 256 \t 607 \t 472 \t 1063 ]\n",
      "2 \tObject: person \tConfidence = 0.8783 \tBbox: [ 372 \t 152 \t 474 \t 422 ]\n",
      "3 \tObject: person \tConfidence = 0.8749 \tBbox: [ 624 \t 189 \t 766 \t 536 ]\n",
      "4 \tObject: person \tConfidence = 0.8628 \tBbox: [ 603 \t 29 \t 684 \t 228 ]\n",
      "5 \tObject: person \tConfidence = 0.8531 \tBbox: [ 496 \t 63 \t 586 \t 316 ]\n",
      "6 \tObject: person \tConfidence = 0.7586 \tBbox: [ 146 \t 489 \t 312 \t 864 ]\n",
      "7 \tObject: train \tConfidence = 0.6666 \tBbox: [ 1 \t 1 \t 418 \t 995 ]\n",
      "8 \tObject: person \tConfidence = 0.6138 \tBbox: [ 519 \t 573 \t 765 \t 1077 ]\n",
      "9 \tObject: person \tConfidence = 0.482 \tBbox: [ 0 \t 701 \t 110 \t 1079 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000723 / 1050\n",
      "Frames to be processed: 327  | To do: 31.14 % | Done: 68.86 %\n",
      "\n",
      "2022-04-20 13:16:19.416404\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000723.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 23.7ms pre-process, 177.8ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8828 \tBbox: [ 511 \t 60 \t 594 \t 314 ]\n",
      "2 \tObject: person \tConfidence = 0.8653 \tBbox: [ 369 \t 152 \t 470 \t 421 ]\n",
      "3 \tObject: person \tConfidence = 0.858 \tBbox: [ 604 \t 27 \t 684 \t 228 ]\n",
      "4 \tObject: person \tConfidence = 0.8413 \tBbox: [ 640 \t 193 \t 766 \t 535 ]\n",
      "5 \tObject: person \tConfidence = 0.7988 \tBbox: [ 268 \t 607 \t 511 \t 1063 ]\n",
      "6 \tObject: person \tConfidence = 0.7705 \tBbox: [ 127 \t 492 \t 301 \t 921 ]\n",
      "7 \tObject: person \tConfidence = 0.6724 \tBbox: [ 562 \t 595 \t 764 \t 1078 ]\n",
      "8 \tObject: train \tConfidence = 0.626 \tBbox: [ 1 \t 3 \t 409 \t 833 ]\n",
      "9 \tObject: person \tConfidence = 0.3845 \tBbox: [ 404 \t 0 \t 450 \t 89 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000724 / 1050\n",
      "Frames to be processed: 326  | To do: 31.05 % | Done: 68.95 %\n",
      "\n",
      "2022-04-20 13:16:19.877640\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000724.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 27.3ms pre-process, 181.7ms inference, 4.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8751 \tBbox: [ 366 \t 145 \t 468 \t 421 ]\n",
      "2 \tObject: person \tConfidence = 0.8677 \tBbox: [ 651 \t 190 \t 765 \t 543 ]\n",
      "3 \tObject: person \tConfidence = 0.8658 \tBbox: [ 515 \t 59 \t 597 \t 314 ]\n",
      "4 \tObject: person \tConfidence = 0.8656 \tBbox: [ 605 \t 27 \t 685 \t 227 ]\n",
      "5 \tObject: person \tConfidence = 0.824 \tBbox: [ 122 \t 494 \t 305 \t 921 ]\n",
      "6 \tObject: train \tConfidence = 0.6622 \tBbox: [ 0 \t 1 \t 404 \t 876 ]\n",
      "7 \tObject: person \tConfidence = 0.6213 \tBbox: [ 582 \t 598 \t 765 \t 1078 ]\n",
      "8 \tObject: person \tConfidence = 0.5794 \tBbox: [ 270 \t 606 \t 518 \t 1063 ]\n",
      "9 \tObject: person \tConfidence = 0.3391 \tBbox: [ 400 \t 0 \t 448 \t 128 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000725 / 1050\n",
      "Frames to be processed: 325  | To do: 30.95 % | Done: 69.05 %\n",
      "\n",
      "2022-04-20 13:16:20.456921\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000725.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 50.0ms pre-process, 173.3ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8889 \tBbox: [ 357 \t 144 \t 467 \t 421 ]\n",
      "2 \tObject: person \tConfidence = 0.8607 \tBbox: [ 605 \t 25 \t 685 \t 228 ]\n",
      "3 \tObject: person \tConfidence = 0.8504 \tBbox: [ 661 \t 192 \t 766 \t 545 ]\n",
      "4 \tObject: person \tConfidence = 0.8379 \tBbox: [ 523 \t 58 \t 602 \t 316 ]\n",
      "5 \tObject: person \tConfidence = 0.8109 \tBbox: [ 113 \t 498 \t 317 \t 920 ]\n",
      "6 \tObject: train \tConfidence = 0.7244 \tBbox: [ 0 \t 3 \t 399 \t 841 ]\n",
      "7 \tObject: person \tConfidence = 0.6341 \tBbox: [ 606 \t 599 \t 765 \t 1077 ]\n",
      "8 \tObject: person \tConfidence = 0.5687 \tBbox: [ 269 \t 609 \t 522 \t 1065 ]\n",
      "9 \tObject: person \tConfidence = 0.4261 \tBbox: [ 398 \t 0 \t 445 \t 122 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000726 / 1050\n",
      "Frames to be processed: 324  | To do: 30.86 % | Done: 69.14 %\n",
      "\n",
      "2022-04-20 13:16:20.956775\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000726.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 26.3ms pre-process, 177.9ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.916 \tBbox: [ 99 \t 499 \t 320 \t 924 ]\n",
      "2 \tObject: person \tConfidence = 0.9048 \tBbox: [ 354 \t 144 \t 465 \t 421 ]\n",
      "3 \tObject: person \tConfidence = 0.8708 \tBbox: [ 674 \t 195 \t 766 \t 545 ]\n",
      "4 \tObject: person \tConfidence = 0.8666 \tBbox: [ 605 \t 26 \t 684 \t 221 ]\n",
      "5 \tObject: person \tConfidence = 0.836 \tBbox: [ 526 \t 57 \t 605 \t 318 ]\n",
      "6 \tObject: person \tConfidence = 0.7496 \tBbox: [ 270 \t 599 \t 531 \t 1064 ]\n",
      "7 \tObject: train \tConfidence = 0.7311 \tBbox: [ 0 \t 3 \t 403 \t 823 ]\n",
      "8 \tObject: person \tConfidence = 0.6457 \tBbox: [ 396 \t 0 \t 446 \t 131 ]\n",
      "9 \tObject: person \tConfidence = 0.6195 \tBbox: [ 633 \t 594 \t 764 \t 1078 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000727 / 1050\n",
      "Frames to be processed: 323  | To do: 30.76 % | Done: 69.24 %\n",
      "\n",
      "2022-04-20 13:16:21.531798\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000727.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 26.3ms pre-process, 182.5ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8975 \tBbox: [ 348 \t 144 \t 463 \t 421 ]\n",
      "2 \tObject: person \tConfidence = 0.8858 \tBbox: [ 605 \t 25 \t 684 \t 221 ]\n",
      "3 \tObject: person \tConfidence = 0.8697 \tBbox: [ 93 \t 502 \t 317 \t 923 ]\n",
      "4 \tObject: person \tConfidence = 0.8667 \tBbox: [ 685 \t 194 \t 765 \t 543 ]\n",
      "5 \tObject: person \tConfidence = 0.8193 \tBbox: [ 274 \t 595 \t 539 \t 1067 ]\n",
      "6 \tObject: person \tConfidence = 0.8043 \tBbox: [ 528 \t 56 \t 609 \t 314 ]\n",
      "7 \tObject: train \tConfidence = 0.697 \tBbox: [ 0 \t 3 \t 406 \t 845 ]\n",
      "8 \tObject: person \tConfidence = 0.6616 \tBbox: [ 643 \t 595 \t 764 \t 1078 ]\n",
      "9 \tObject: person \tConfidence = 0.4807 \tBbox: [ 396 \t 0 \t 444 \t 135 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000728 / 1050\n",
      "Frames to be processed: 322  | To do: 30.67 % | Done: 69.33 %\n",
      "\n",
      "2022-04-20 13:16:22.067943\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000728.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 26.3ms pre-process, 172.1ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9002 \tBbox: [ 343 \t 142 \t 459 \t 420 ]\n",
      "2 \tObject: person \tConfidence = 0.8936 \tBbox: [ 68 \t 504 \t 299 \t 923 ]\n",
      "3 \tObject: person \tConfidence = 0.8865 \tBbox: [ 536 \t 57 \t 626 \t 314 ]\n",
      "4 \tObject: person \tConfidence = 0.8826 \tBbox: [ 292 \t 588 \t 563 \t 1059 ]\n",
      "5 \tObject: person \tConfidence = 0.8531 \tBbox: [ 605 \t 20 \t 685 \t 214 ]\n",
      "6 \tObject: person \tConfidence = 0.7889 \tBbox: [ 694 \t 204 \t 765 \t 555 ]\n",
      "7 \tObject: train \tConfidence = 0.6508 \tBbox: [ 0 \t 1 \t 408 \t 811 ]\n",
      "8 \tObject: person \tConfidence = 0.5715 \tBbox: [ 661 \t 595 \t 764 \t 1078 ]\n",
      "9 \tObject: person \tConfidence = 0.3679 \tBbox: [ 396 \t 0 \t 442 \t 135 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000729 / 1050\n",
      "Frames to be processed: 321  | To do: 30.57 % | Done: 69.43 %\n",
      "\n",
      "2022-04-20 13:16:22.657463\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000729.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 26.8ms pre-process, 167.3ms inference, 10.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9003 \tBbox: [ 538 \t 58 \t 639 \t 314 ]\n",
      "2 \tObject: person \tConfidence = 0.8961 \tBbox: [ 345 \t 143 \t 456 \t 421 ]\n",
      "3 \tObject: person \tConfidence = 0.8788 \tBbox: [ 59 \t 505 \t 269 \t 924 ]\n",
      "4 \tObject: person \tConfidence = 0.8763 \tBbox: [ 307 \t 585 \t 561 \t 1056 ]\n",
      "5 \tObject: person \tConfidence = 0.8666 \tBbox: [ 606 \t 19 \t 686 \t 209 ]\n",
      "6 \tObject: train \tConfidence = 0.7085 \tBbox: [ 0 \t 1 \t 445 \t 802 ]\n",
      "7 \tObject: person \tConfidence = 0.6763 \tBbox: [ 699 \t 212 \t 765 \t 564 ]\n",
      "8 \tObject: person \tConfidence = 0.5438 \tBbox: [ 666 \t 595 \t 765 \t 1079 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000730 / 1050\n",
      "Frames to be processed: 320  | To do: 30.48 % | Done: 69.52 %\n",
      "\n",
      "2022-04-20 13:16:23.160064\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000730.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 8 persons, 1 train\n",
      "Speed: 23.3ms pre-process, 173.4ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 9 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9157 \tBbox: [ 343 \t 139 \t 453 \t 421 ]\n",
      "2 \tObject: person \tConfidence = 0.8969 \tBbox: [ 539 \t 58 \t 642 \t 314 ]\n",
      "3 \tObject: person \tConfidence = 0.8913 \tBbox: [ 328 \t 583 \t 570 \t 1053 ]\n",
      "4 \tObject: person \tConfidence = 0.859 \tBbox: [ 46 \t 509 \t 240 \t 924 ]\n",
      "5 \tObject: person \tConfidence = 0.854 \tBbox: [ 614 \t 18 \t 687 \t 210 ]\n",
      "6 \tObject: person \tConfidence = 0.7157 \tBbox: [ 701 \t 218 \t 765 \t 559 ]\n",
      "7 \tObject: train \tConfidence = 0.694 \tBbox: [ 0 \t 2 \t 418 \t 829 ]\n",
      "8 \tObject: person \tConfidence = 0.505 \tBbox: [ 397 \t 0 \t 441 \t 134 ]\n",
      "9 \tObject: person \tConfidence = 0.4868 \tBbox: [ 675 \t 601 \t 765 \t 1079 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    8\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000731 / 1050\n",
      "Frames to be processed: 319  | To do: 30.38 % | Done: 69.62 %\n",
      "\n",
      "2022-04-20 13:16:23.669037\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000731.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 58.7ms pre-process, 177.4ms inference, 10.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9139 \tBbox: [ 343 \t 139 \t 449 \t 416 ]\n",
      "2 \tObject: person \tConfidence = 0.8754 \tBbox: [ 540 \t 61 \t 643 \t 313 ]\n",
      "3 \tObject: person \tConfidence = 0.855 \tBbox: [ 618 \t 18 \t 686 \t 211 ]\n",
      "4 \tObject: person \tConfidence = 0.8531 \tBbox: [ 351 \t 582 \t 579 \t 1049 ]\n",
      "5 \tObject: person \tConfidence = 0.7943 \tBbox: [ 31 \t 512 \t 229 \t 923 ]\n",
      "6 \tObject: train \tConfidence = 0.7871 \tBbox: [ 0 \t 3 \t 465 \t 914 ]\n",
      "7 \tObject: person \tConfidence = 0.6839 \tBbox: [ 703 \t 223 \t 765 \t 546 ]\n",
      "8 \tObject: person \tConfidence = 0.5978 \tBbox: [ 681 \t 611 \t 765 \t 1079 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000732 / 1050\n",
      "Frames to be processed: 318  | To do: 30.29 % | Done: 69.71 %\n",
      "\n",
      "2022-04-20 13:16:24.129434\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000732.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 7 persons, 1 train\n",
      "Speed: 27.2ms pre-process, 181.5ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 8 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9027 \tBbox: [ 340 \t 139 \t 445 \t 411 ]\n",
      "2 \tObject: person \tConfidence = 0.9003 \tBbox: [ 540 \t 61 \t 643 \t 313 ]\n",
      "3 \tObject: person \tConfidence = 0.8595 \tBbox: [ 375 \t 581 \t 605 \t 1048 ]\n",
      "4 \tObject: person \tConfidence = 0.8506 \tBbox: [ 26 \t 509 \t 220 \t 925 ]\n",
      "5 \tObject: person \tConfidence = 0.8382 \tBbox: [ 621 \t 17 \t 685 \t 209 ]\n",
      "6 \tObject: train \tConfidence = 0.7901 \tBbox: [ 0 \t 3 \t 458 \t 909 ]\n",
      "7 \tObject: person \tConfidence = 0.654 \tBbox: [ 703 \t 237 \t 765 \t 545 ]\n",
      "8 \tObject: person \tConfidence = 0.5331 \tBbox: [ 685 \t 624 \t 765 \t 1079 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    7\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000733 / 1050\n",
      "Frames to be processed: 317  | To do: 30.19 % | Done: 69.81 %\n",
      "\n",
      "2022-04-20 13:16:24.613867\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000733.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 6 persons, 1 train\n",
      "Speed: 27.0ms pre-process, 180.8ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 7 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8942 \tBbox: [ 338 \t 133 \t 437 \t 402 ]\n",
      "2 \tObject: person \tConfidence = 0.8745 \tBbox: [ 541 \t 64 \t 646 \t 311 ]\n",
      "3 \tObject: person \tConfidence = 0.8721 \tBbox: [ 2 \t 503 \t 218 \t 925 ]\n",
      "4 \tObject: person \tConfidence = 0.8372 \tBbox: [ 417 \t 576 \t 604 \t 1061 ]\n",
      "5 \tObject: person \tConfidence = 0.7936 \tBbox: [ 626 \t 16 \t 685 \t 210 ]\n",
      "6 \tObject: train \tConfidence = 0.7787 \tBbox: [ 1 \t 3 \t 464 \t 881 ]\n",
      "7 \tObject: person \tConfidence = 0.3498 \tBbox: [ 706 \t 261 \t 765 \t 544 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    6\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000734 / 1050\n",
      "Frames to be processed: 316  | To do: 30.1 % | Done: 69.9 %\n",
      "\n",
      "2022-04-20 13:16:25.127456\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000734.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 5 persons, 1 train\n",
      "Speed: 60.3ms pre-process, 175.6ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 6 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8619 \tBbox: [ 335 \t 130 \t 433 \t 397 ]\n",
      "2 \tObject: person \tConfidence = 0.8599 \tBbox: [ 1 \t 483 \t 216 \t 927 ]\n",
      "3 \tObject: person \tConfidence = 0.8527 \tBbox: [ 545 \t 59 \t 645 \t 310 ]\n",
      "4 \tObject: train \tConfidence = 0.786 \tBbox: [ 0 \t 4 \t 464 \t 888 ]\n",
      "5 \tObject: person \tConfidence = 0.7564 \tBbox: [ 621 \t 16 \t 685 \t 209 ]\n",
      "6 \tObject: person \tConfidence = 0.5377 \tBbox: [ 425 \t 577 \t 610 \t 1032 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    5\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000735 / 1050\n",
      "Frames to be processed: 315  | To do: 30.0 % | Done: 70.0 %\n",
      "\n",
      "2022-04-20 13:16:25.766115\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000735.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 5 persons, 1 train\n",
      "Speed: 23.8ms pre-process, 179.6ms inference, 9.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 6 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8797 \tBbox: [ 334 \t 130 \t 431 \t 389 ]\n",
      "2 \tObject: person \tConfidence = 0.8749 \tBbox: [ 0 \t 482 \t 216 \t 927 ]\n",
      "3 \tObject: person \tConfidence = 0.8656 \tBbox: [ 431 \t 578 \t 620 \t 1028 ]\n",
      "4 \tObject: person \tConfidence = 0.8053 \tBbox: [ 551 \t 56 \t 648 \t 308 ]\n",
      "5 \tObject: train \tConfidence = 0.8013 \tBbox: [ 0 \t 4 \t 462 \t 914 ]\n",
      "6 \tObject: person \tConfidence = 0.7202 \tBbox: [ 622 \t 16 \t 685 \t 207 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    5\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000736 / 1050\n",
      "Frames to be processed: 314  | To do: 29.9 % | Done: 70.1 %\n",
      "\n",
      "2022-04-20 13:16:26.211386\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000736.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 5 persons, 1 train\n",
      "Speed: 25.2ms pre-process, 172.7ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 6 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8991 \tBbox: [ 332 \t 128 \t 425 \t 382 ]\n",
      "2 \tObject: person \tConfidence = 0.8965 \tBbox: [ 434 \t 580 \t 645 \t 1021 ]\n",
      "3 \tObject: person \tConfidence = 0.8495 \tBbox: [ 0 \t 481 \t 214 \t 924 ]\n",
      "4 \tObject: train \tConfidence = 0.8453 \tBbox: [ 0 \t 4 \t 464 \t 924 ]\n",
      "5 \tObject: person \tConfidence = 0.8168 \tBbox: [ 556 \t 50 \t 661 \t 303 ]\n",
      "6 \tObject: person \tConfidence = 0.5409 \tBbox: [ 614 \t 16 \t 685 \t 207 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    5\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000737 / 1050\n",
      "Frames to be processed: 313  | To do: 29.81 % | Done: 70.19 %\n",
      "\n",
      "2022-04-20 13:16:26.730666\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000737.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 6 persons, 1 train\n",
      "Speed: 25.7ms pre-process, 175.0ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 7 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8977 \tBbox: [ 332 \t 127 \t 417 \t 381 ]\n",
      "2 \tObject: person \tConfidence = 0.8959 \tBbox: [ 0 \t 478 \t 215 \t 926 ]\n",
      "3 \tObject: person \tConfidence = 0.8948 \tBbox: [ 434 \t 581 \t 667 \t 1016 ]\n",
      "4 \tObject: person \tConfidence = 0.8356 \tBbox: [ 564 \t 50 \t 663 \t 301 ]\n",
      "5 \tObject: train \tConfidence = 0.8311 \tBbox: [ 0 \t 4 \t 465 \t 915 ]\n",
      "6 \tObject: person \tConfidence = 0.4805 \tBbox: [ 633 \t 16 \t 684 \t 184 ]\n",
      "7 \tObject: person \tConfidence = 0.3781 \tBbox: [ 699 \t 778 \t 765 \t 1080 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    6\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000738 / 1050\n",
      "Frames to be processed: 312  | To do: 29.71 % | Done: 70.29 %\n",
      "\n",
      "2022-04-20 13:16:27.264649\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000738.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 5 persons, 1 train\n",
      "Speed: 33.7ms pre-process, 181.0ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 6 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8887 \tBbox: [ 0 \t 476 \t 213 \t 925 ]\n",
      "2 \tObject: person \tConfidence = 0.8792 \tBbox: [ 436 \t 586 \t 677 \t 1010 ]\n",
      "3 \tObject: person \tConfidence = 0.8749 \tBbox: [ 322 \t 124 \t 408 \t 381 ]\n",
      "4 \tObject: person \tConfidence = 0.8674 \tBbox: [ 580 \t 50 \t 667 \t 298 ]\n",
      "5 \tObject: train \tConfidence = 0.8576 \tBbox: [ 0 \t 4 \t 466 \t 910 ]\n",
      "6 \tObject: person \tConfidence = 0.5786 \tBbox: [ 618 \t 16 \t 682 \t 121 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    5\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000739 / 1050\n",
      "Frames to be processed: 311  | To do: 29.62 % | Done: 70.38 %\n",
      "\n",
      "2022-04-20 13:16:27.774042\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000739.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 5 persons, 1 train\n",
      "Speed: 42.2ms pre-process, 171.9ms inference, 16.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 6 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8733 \tBbox: [ 319 \t 123 \t 406 \t 382 ]\n",
      "2 \tObject: person \tConfidence = 0.8691 \tBbox: [ 587 \t 49 \t 671 \t 298 ]\n",
      "3 \tObject: train \tConfidence = 0.8591 \tBbox: [ 0 \t 5 \t 465 \t 908 ]\n",
      "4 \tObject: person \tConfidence = 0.8435 \tBbox: [ 437 \t 591 \t 682 \t 1011 ]\n",
      "5 \tObject: person \tConfidence = 0.8368 \tBbox: [ 0 \t 494 \t 208 \t 928 ]\n",
      "6 \tObject: person \tConfidence = 0.6788 \tBbox: [ 614 \t 16 \t 683 \t 115 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    5\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000740 / 1050\n",
      "Frames to be processed: 310  | To do: 29.52 % | Done: 70.48 %\n",
      "\n",
      "2022-04-20 13:16:28.274834\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000740.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 5 persons, 1 train\n",
      "Speed: 36.3ms pre-process, 168.4ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 6 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8998 \tBbox: [ 0 \t 532 \t 203 \t 926 ]\n",
      "2 \tObject: person \tConfidence = 0.8854 \tBbox: [ 591 \t 50 \t 676 \t 298 ]\n",
      "3 \tObject: person \tConfidence = 0.8672 \tBbox: [ 317 \t 123 \t 403 \t 381 ]\n",
      "4 \tObject: train \tConfidence = 0.8509 \tBbox: [ 0 \t 5 \t 465 \t 898 ]\n",
      "5 \tObject: person \tConfidence = 0.8297 \tBbox: [ 441 \t 592 \t 697 \t 1012 ]\n",
      "6 \tObject: person \tConfidence = 0.7231 \tBbox: [ 612 \t 15 \t 682 \t 115 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    5\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000741 / 1050\n",
      "Frames to be processed: 309  | To do: 29.43 % | Done: 70.57 %\n",
      "\n",
      "2022-04-20 13:16:28.793505\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000741.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 6 persons, 1 train\n",
      "Speed: 53.4ms pre-process, 174.3ms inference, 10.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 7 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8663 \tBbox: [ 593 \t 49 \t 678 \t 298 ]\n",
      "2 \tObject: train \tConfidence = 0.8643 \tBbox: [ 0 \t 3 \t 464 \t 912 ]\n",
      "3 \tObject: person \tConfidence = 0.8616 \tBbox: [ 313 \t 124 \t 400 \t 381 ]\n",
      "4 \tObject: person \tConfidence = 0.7275 \tBbox: [ 612 \t 14 \t 681 \t 115 ]\n",
      "5 \tObject: person \tConfidence = 0.4552 \tBbox: [ 0 \t 530 \t 101 \t 804 ]\n",
      "6 \tObject: person \tConfidence = 0.3729 \tBbox: [ 450 \t 590 \t 710 \t 1016 ]\n",
      "7 \tObject: person \tConfidence = 0.3707 \tBbox: [ 1 \t 526 \t 191 \t 924 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    6\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000742 / 1050\n",
      "Frames to be processed: 308  | To do: 29.33 % | Done: 70.67 %\n",
      "\n",
      "2022-04-20 13:16:29.322298\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000742.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 5 persons, 1 train\n",
      "Speed: 32.1ms pre-process, 169.6ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 6 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.899 \tBbox: [ 310 \t 122 \t 399 \t 381 ]\n",
      "2 \tObject: person \tConfidence = 0.8725 \tBbox: [ 596 \t 48 \t 682 \t 298 ]\n",
      "3 \tObject: train \tConfidence = 0.8476 \tBbox: [ 0 \t 5 \t 465 \t 896 ]\n",
      "4 \tObject: person \tConfidence = 0.7786 \tBbox: [ 465 \t 592 \t 725 \t 1014 ]\n",
      "5 \tObject: person \tConfidence = 0.7573 \tBbox: [ 0 \t 528 \t 175 \t 921 ]\n",
      "6 \tObject: person \tConfidence = 0.7511 \tBbox: [ 611 \t 14 \t 682 \t 112 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    5\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000743 / 1050\n",
      "Frames to be processed: 307  | To do: 29.24 % | Done: 70.76 %\n",
      "\n",
      "2022-04-20 13:16:29.813813\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000743.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 5 persons, 1 train\n",
      "Speed: 26.8ms pre-process, 169.3ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 6 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9047 \tBbox: [ 304 \t 125 \t 394 \t 381 ]\n",
      "2 \tObject: train \tConfidence = 0.8333 \tBbox: [ 0 \t 0 \t 465 \t 978 ]\n",
      "3 \tObject: person \tConfidence = 0.8177 \tBbox: [ 509 \t 593 \t 749 \t 1013 ]\n",
      "4 \tObject: person \tConfidence = 0.8061 \tBbox: [ 601 \t 32 \t 687 \t 299 ]\n",
      "5 \tObject: person \tConfidence = 0.5549 \tBbox: [ 0 \t 538 \t 106 \t 908 ]\n",
      "6 \tObject: person \tConfidence = 0.3335 \tBbox: [ 606 \t 9 \t 682 \t 113 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    5\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000744 / 1050\n",
      "Frames to be processed: 306  | To do: 29.14 % | Done: 70.86 %\n",
      "\n",
      "2022-04-20 13:16:30.330217\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000744.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 5 persons, 1 train\n",
      "Speed: 50.6ms pre-process, 169.4ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 6 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8971 \tBbox: [ 302 \t 126 \t 390 \t 381 ]\n",
      "2 \tObject: person \tConfidence = 0.8801 \tBbox: [ 604 \t 50 \t 691 \t 298 ]\n",
      "3 \tObject: person \tConfidence = 0.8654 \tBbox: [ 567 \t 593 \t 755 \t 1014 ]\n",
      "4 \tObject: train \tConfidence = 0.8384 \tBbox: [ 0 \t 2 \t 467 \t 1070 ]\n",
      "5 \tObject: person \tConfidence = 0.7183 \tBbox: [ 608 \t 9 \t 678 \t 107 ]\n",
      "6 \tObject: person \tConfidence = 0.3558 \tBbox: [ 0 \t 452 \t 82 \t 923 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    5\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000745 / 1050\n",
      "Frames to be processed: 305  | To do: 29.05 % | Done: 70.95 %\n",
      "\n",
      "2022-04-20 13:16:30.875803\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000745.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 4 persons, 1 train\n",
      "Speed: 25.8ms pre-process, 168.0ms inference, 13.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 5 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8954 \tBbox: [ 579 \t 594 \t 766 \t 1013 ]\n",
      "2 \tObject: person \tConfidence = 0.8919 \tBbox: [ 298 \t 124 \t 389 \t 381 ]\n",
      "3 \tObject: person \tConfidence = 0.8854 \tBbox: [ 607 \t 51 \t 694 \t 299 ]\n",
      "4 \tObject: train \tConfidence = 0.8625 \tBbox: [ 0 \t 2 \t 467 \t 1072 ]\n",
      "5 \tObject: person \tConfidence = 0.741 \tBbox: [ 608 \t 8 \t 672 \t 116 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    4\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000746 / 1050\n",
      "Frames to be processed: 304  | To do: 28.95 % | Done: 71.05 %\n",
      "\n",
      "2022-04-20 13:16:31.438940\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000746.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 4 persons, 1 train\n",
      "Speed: 26.0ms pre-process, 168.7ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 5 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9128 \tBbox: [ 586 \t 594 \t 766 \t 1014 ]\n",
      "2 \tObject: person \tConfidence = 0.8937 \tBbox: [ 296 \t 123 \t 386 \t 381 ]\n",
      "3 \tObject: person \tConfidence = 0.8927 \tBbox: [ 608 \t 50 \t 697 \t 299 ]\n",
      "4 \tObject: train \tConfidence = 0.8692 \tBbox: [ 0 \t 2 \t 467 \t 1072 ]\n",
      "5 \tObject: person \tConfidence = 0.7898 \tBbox: [ 609 \t 8 \t 673 \t 111 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    4\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000747 / 1050\n",
      "Frames to be processed: 303  | To do: 28.86 % | Done: 71.14 %\n",
      "\n",
      "2022-04-20 13:16:31.953036\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000747.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 4 persons, 1 train\n",
      "Speed: 27.4ms pre-process, 174.5ms inference, 10.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 5 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8885 \tBbox: [ 293 \t 122 \t 385 \t 381 ]\n",
      "2 \tObject: person \tConfidence = 0.8652 \tBbox: [ 610 \t 51 \t 697 \t 298 ]\n",
      "3 \tObject: train \tConfidence = 0.8366 \tBbox: [ 0 \t 2 \t 467 \t 1069 ]\n",
      "4 \tObject: person \tConfidence = 0.8168 \tBbox: [ 586 \t 595 \t 766 \t 1016 ]\n",
      "5 \tObject: person \tConfidence = 0.7644 \tBbox: [ 609 \t 8 \t 674 \t 110 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    4\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000748 / 1050\n",
      "Frames to be processed: 302  | To do: 28.76 % | Done: 71.24 %\n",
      "\n",
      "2022-04-20 13:16:32.502201\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000748.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 5 persons, 1 train\n",
      "Speed: 29.5ms pre-process, 175.4ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 6 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8953 \tBbox: [ 587 \t 595 \t 765 \t 1015 ]\n",
      "2 \tObject: person \tConfidence = 0.8854 \tBbox: [ 293 \t 117 \t 380 \t 378 ]\n",
      "3 \tObject: person \tConfidence = 0.8477 \tBbox: [ 611 \t 48 \t 702 \t 297 ]\n",
      "4 \tObject: train \tConfidence = 0.7915 \tBbox: [ 0 \t 3 \t 466 \t 1017 ]\n",
      "5 \tObject: person \tConfidence = 0.6618 \tBbox: [ 610 \t 8 \t 672 \t 120 ]\n",
      "6 \tObject: person \tConfidence = 0.3394 \tBbox: [ 0 \t 475 \t 53 \t 907 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    5\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000749 / 1050\n",
      "Frames to be processed: 301  | To do: 28.67 % | Done: 71.33 %\n",
      "\n",
      "2022-04-20 13:16:33.097178\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000749.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 5 persons, 1 train\n",
      "Speed: 27.2ms pre-process, 180.2ms inference, 10.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 6 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8723 \tBbox: [ 292 \t 115 \t 378 \t 376 ]\n",
      "2 \tObject: person \tConfidence = 0.8669 \tBbox: [ 616 \t 44 \t 704 \t 295 ]\n",
      "3 \tObject: person \tConfidence = 0.8588 \tBbox: [ 588 \t 597 \t 766 \t 1016 ]\n",
      "4 \tObject: train \tConfidence = 0.7997 \tBbox: [ 0 \t 4 \t 467 \t 1057 ]\n",
      "5 \tObject: person \tConfidence = 0.6995 \tBbox: [ 610 \t 8 \t 673 \t 139 ]\n",
      "6 \tObject: person \tConfidence = 0.3894 \tBbox: [ 0 \t 477 \t 52 \t 907 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    5\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000750 / 1050\n",
      "Frames to be processed: 300  | To do: 28.57 % | Done: 71.43 %\n",
      "\n",
      "2022-04-20 13:16:33.654401\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000750.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 5 persons, 1 train\n",
      "Speed: 31.0ms pre-process, 178.7ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 6 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.882 \tBbox: [ 619 \t 42 \t 705 \t 295 ]\n",
      "2 \tObject: person \tConfidence = 0.8716 \tBbox: [ 290 \t 114 \t 376 \t 376 ]\n",
      "3 \tObject: train \tConfidence = 0.7891 \tBbox: [ 0 \t 4 \t 469 \t 1042 ]\n",
      "4 \tObject: person \tConfidence = 0.7616 \tBbox: [ 588 \t 604 \t 766 \t 1016 ]\n",
      "5 \tObject: person \tConfidence = 0.7433 \tBbox: [ 611 \t 7 \t 670 \t 135 ]\n",
      "6 \tObject: person \tConfidence = 0.4532 \tBbox: [ 0 \t 471 \t 51 \t 910 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    5\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000751 / 1050\n",
      "Frames to be processed: 299  | To do: 28.48 % | Done: 71.52 %\n",
      "\n",
      "2022-04-20 13:16:34.113433\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000751.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 5 persons, 1 train\n",
      "Speed: 27.9ms pre-process, 179.4ms inference, 10.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 6 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8775 \tBbox: [ 621 \t 40 \t 706 \t 291 ]\n",
      "2 \tObject: person \tConfidence = 0.8703 \tBbox: [ 290 \t 115 \t 371 \t 375 ]\n",
      "3 \tObject: train \tConfidence = 0.8 \tBbox: [ 0 \t 3 \t 470 \t 1061 ]\n",
      "4 \tObject: person \tConfidence = 0.7904 \tBbox: [ 588 \t 614 \t 765 \t 1016 ]\n",
      "5 \tObject: person \tConfidence = 0.7134 \tBbox: [ 611 \t 9 \t 668 \t 111 ]\n",
      "6 \tObject: person \tConfidence = 0.5499 \tBbox: [ 0 \t 470 \t 52 \t 910 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    5\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000752 / 1050\n",
      "Frames to be processed: 298  | To do: 28.38 % | Done: 71.62 %\n",
      "\n",
      "2022-04-20 13:16:34.628407\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000752.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 5 persons, 1 train\n",
      "Speed: 30.5ms pre-process, 179.9ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 6 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8698 \tBbox: [ 288 \t 110 \t 369 \t 371 ]\n",
      "2 \tObject: person \tConfidence = 0.8612 \tBbox: [ 622 \t 40 \t 707 \t 288 ]\n",
      "3 \tObject: train \tConfidence = 0.7929 \tBbox: [ 0 \t 3 \t 472 \t 1063 ]\n",
      "4 \tObject: person \tConfidence = 0.7609 \tBbox: [ 590 \t 617 \t 765 \t 1015 ]\n",
      "5 \tObject: person \tConfidence = 0.6834 \tBbox: [ 612 \t 9 \t 669 \t 111 ]\n",
      "6 \tObject: person \tConfidence = 0.4967 \tBbox: [ 0 \t 469 \t 50 \t 910 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    5\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000753 / 1050\n",
      "Frames to be processed: 297  | To do: 28.29 % | Done: 71.71 %\n",
      "\n",
      "2022-04-20 13:16:35.175713\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000753.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 5 persons, 1 train\n",
      "Speed: 54.8ms pre-process, 181.9ms inference, 10.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 6 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8679 \tBbox: [ 624 \t 39 \t 708 \t 278 ]\n",
      "2 \tObject: person \tConfidence = 0.8118 \tBbox: [ 287 \t 107 \t 360 \t 350 ]\n",
      "3 \tObject: train \tConfidence = 0.8015 \tBbox: [ 0 \t 4 \t 475 \t 1060 ]\n",
      "4 \tObject: person \tConfidence = 0.791 \tBbox: [ 603 \t 633 \t 765 \t 1015 ]\n",
      "5 \tObject: person \tConfidence = 0.7003 \tBbox: [ 613 \t 8 \t 671 \t 111 ]\n",
      "6 \tObject: person \tConfidence = 0.4774 \tBbox: [ 0 \t 468 \t 47 \t 908 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    5\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000754 / 1050\n",
      "Frames to be processed: 296  | To do: 28.19 % | Done: 71.81 %\n",
      "\n",
      "2022-04-20 13:16:35.734811\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000754.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 5 persons, 1 train\n",
      "Speed: 53.9ms pre-process, 182.7ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 6 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8762 \tBbox: [ 628 \t 38 \t 711 \t 275 ]\n",
      "2 \tObject: person \tConfidence = 0.8167 \tBbox: [ 286 \t 106 \t 358 \t 344 ]\n",
      "3 \tObject: train \tConfidence = 0.8147 \tBbox: [ 0 \t 3 \t 475 \t 1065 ]\n",
      "4 \tObject: person \tConfidence = 0.7626 \tBbox: [ 614 \t 8 \t 671 \t 185 ]\n",
      "5 \tObject: person \tConfidence = 0.6639 \tBbox: [ 619 \t 631 \t 765 \t 1013 ]\n",
      "6 \tObject: person \tConfidence = 0.4206 \tBbox: [ 0 \t 469 \t 47 \t 907 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    5\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000755 / 1050\n",
      "Frames to be processed: 295  | To do: 28.1 % | Done: 71.9 %\n",
      "\n",
      "2022-04-20 13:16:36.274156\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000755.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 6 persons, 1 train\n",
      "Speed: 28.5ms pre-process, 173.3ms inference, 10.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 7 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8713 \tBbox: [ 628 \t 37 \t 711 \t 274 ]\n",
      "2 \tObject: train \tConfidence = 0.8554 \tBbox: [ 0 \t 2 \t 475 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.7793 \tBbox: [ 286 \t 116 \t 353 \t 346 ]\n",
      "4 \tObject: person \tConfidence = 0.7334 \tBbox: [ 615 \t 5 \t 674 \t 185 ]\n",
      "5 \tObject: person \tConfidence = 0.6696 \tBbox: [ 642 \t 636 \t 765 \t 1013 ]\n",
      "6 \tObject: person \tConfidence = 0.3556 \tBbox: [ 0 \t 470 \t 47 \t 903 ]\n",
      "7 \tObject: person \tConfidence = 0.3008 \tBbox: [ 285 \t 92 \t 306 \t 134 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    6\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000756 / 1050\n",
      "Frames to be processed: 294  | To do: 28.0 % | Done: 72.0 %\n",
      "\n",
      "2022-04-20 13:16:36.781477\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000756.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 4 persons, 1 train\n",
      "Speed: 25.4ms pre-process, 169.0ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 5 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8789 \tBbox: [ 627 \t 36 \t 712 \t 273 ]\n",
      "2 \tObject: train \tConfidence = 0.8598 \tBbox: [ 0 \t 2 \t 475 \t 1069 ]\n",
      "3 \tObject: person \tConfidence = 0.7899 \tBbox: [ 616 \t 3 \t 675 \t 183 ]\n",
      "4 \tObject: person \tConfidence = 0.679 \tBbox: [ 284 \t 105 \t 353 \t 350 ]\n",
      "5 \tObject: person \tConfidence = 0.5797 \tBbox: [ 662 \t 650 \t 766 \t 1021 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    4\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000757 / 1050\n",
      "Frames to be processed: 293  | To do: 27.9 % | Done: 72.1 %\n",
      "\n",
      "2022-04-20 13:16:37.266808\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000757.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 4 persons, 1 train\n",
      "Speed: 74.4ms pre-process, 168.7ms inference, 10.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 5 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8976 \tBbox: [ 625 \t 35 \t 713 \t 274 ]\n",
      "2 \tObject: train \tConfidence = 0.8681 \tBbox: [ 0 \t 2 \t 473 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.6829 \tBbox: [ 285 \t 102 \t 355 \t 332 ]\n",
      "4 \tObject: person \tConfidence = 0.66 \tBbox: [ 617 \t 2 \t 675 \t 182 ]\n",
      "5 \tObject: person \tConfidence = 0.3566 \tBbox: [ 686 \t 659 \t 765 \t 1027 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    4\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000758 / 1050\n",
      "Frames to be processed: 292  | To do: 27.81 % | Done: 72.19 %\n",
      "\n",
      "2022-04-20 13:16:37.997935\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000758.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 28.3ms pre-process, 172.1ms inference, 3.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8959 \tBbox: [ 625 \t 35 \t 714 \t 275 ]\n",
      "2 \tObject: train \tConfidence = 0.8703 \tBbox: [ 0 \t 2 \t 471 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.7086 \tBbox: [ 616 \t 0 \t 678 \t 154 ]\n",
      "4 \tObject: person \tConfidence = 0.6916 \tBbox: [ 287 \t 109 \t 352 \t 330 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000759 / 1050\n",
      "Frames to be processed: 291  | To do: 27.71 % | Done: 72.29 %\n",
      "\n",
      "2022-04-20 13:16:38.492896\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000759.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 61.7ms pre-process, 174.8ms inference, 4.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8733 \tBbox: [ 0 \t 2 \t 471 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8721 \tBbox: [ 629 \t 35 \t 714 \t 275 ]\n",
      "3 \tObject: person \tConfidence = 0.8023 \tBbox: [ 618 \t 0 \t 680 \t 169 ]\n",
      "4 \tObject: person \tConfidence = 0.6262 \tBbox: [ 288 \t 118 \t 350 \t 333 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000760 / 1050\n",
      "Frames to be processed: 290  | To do: 27.62 % | Done: 72.38 %\n",
      "\n",
      "2022-04-20 13:16:39.085370\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000760.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 49.7ms pre-process, 180.9ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8788 \tBbox: [ 0 \t 2 \t 472 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.868 \tBbox: [ 631 \t 36 \t 714 \t 275 ]\n",
      "3 \tObject: person \tConfidence = 0.8433 \tBbox: [ 618 \t 0 \t 681 \t 167 ]\n",
      "4 \tObject: person \tConfidence = 0.5758 \tBbox: [ 287 \t 118 \t 348 \t 334 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000761 / 1050\n",
      "Frames to be processed: 289  | To do: 27.52 % | Done: 72.48 %\n",
      "\n",
      "2022-04-20 13:16:39.587291\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000761.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 29.7ms pre-process, 170.0ms inference, 4.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8768 \tBbox: [ 0 \t 2 \t 472 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8679 \tBbox: [ 629 \t 36 \t 714 \t 274 ]\n",
      "3 \tObject: person \tConfidence = 0.8254 \tBbox: [ 618 \t 0 \t 681 \t 167 ]\n",
      "4 \tObject: person \tConfidence = 0.5518 \tBbox: [ 287 \t 120 \t 345 \t 334 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000762 / 1050\n",
      "Frames to be processed: 288  | To do: 27.43 % | Done: 72.57 %\n",
      "\n",
      "2022-04-20 13:16:40.158254\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000762.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 27.7ms pre-process, 175.3ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8756 \tBbox: [ 629 \t 36 \t 714 \t 274 ]\n",
      "2 \tObject: train \tConfidence = 0.8634 \tBbox: [ 0 \t 2 \t 473 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.815 \tBbox: [ 619 \t 0 \t 681 \t 166 ]\n",
      "4 \tObject: person \tConfidence = 0.5062 \tBbox: [ 288 \t 123 \t 343 \t 333 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000763 / 1050\n",
      "Frames to be processed: 287  | To do: 27.33 % | Done: 72.67 %\n",
      "\n",
      "2022-04-20 13:16:40.750975\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000763.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 26.0ms pre-process, 169.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8745 \tBbox: [ 627 \t 34 \t 715 \t 272 ]\n",
      "2 \tObject: train \tConfidence = 0.8712 \tBbox: [ 0 \t 2 \t 473 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.7825 \tBbox: [ 620 \t 0 \t 680 \t 162 ]\n",
      "4 \tObject: person \tConfidence = 0.5478 \tBbox: [ 289 \t 130 \t 331 \t 334 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000764 / 1050\n",
      "Frames to be processed: 286  | To do: 27.24 % | Done: 72.76 %\n",
      "\n",
      "2022-04-20 13:16:41.249741\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000764.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 28.7ms pre-process, 174.5ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8724 \tBbox: [ 0 \t 1 \t 474 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8307 \tBbox: [ 629 \t 37 \t 713 \t 269 ]\n",
      "3 \tObject: person \tConfidence = 0.7411 \tBbox: [ 620 \t 0 \t 681 \t 153 ]\n",
      "4 \tObject: person \tConfidence = 0.5154 \tBbox: [ 290 \t 135 \t 328 \t 332 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000765 / 1050\n",
      "Frames to be processed: 285  | To do: 27.14 % | Done: 72.86 %\n",
      "\n",
      "2022-04-20 13:16:41.826167\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000765.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 28.1ms pre-process, 180.6ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8785 \tBbox: [ 0 \t 1 \t 474 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8523 \tBbox: [ 632 \t 30 \t 715 \t 267 ]\n",
      "3 \tObject: person \tConfidence = 0.7267 \tBbox: [ 620 \t 0 \t 680 \t 155 ]\n",
      "4 \tObject: person \tConfidence = 0.4072 \tBbox: [ 291 \t 142 \t 324 \t 332 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000766 / 1050\n",
      "Frames to be processed: 284  | To do: 27.05 % | Done: 72.95 %\n",
      "\n",
      "2022-04-20 13:16:42.401002\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000766.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 28.7ms pre-process, 173.7ms inference, 11.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8704 \tBbox: [ 0 \t 1 \t 475 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.863 \tBbox: [ 631 \t 29 \t 715 \t 262 ]\n",
      "3 \tObject: person \tConfidence = 0.7498 \tBbox: [ 621 \t 0 \t 679 \t 154 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000767 / 1050\n",
      "Frames to be processed: 283  | To do: 26.95 % | Done: 73.05 %\n",
      "\n",
      "2022-04-20 13:16:42.911750\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000767.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 38.6ms pre-process, 176.2ms inference, 3.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8842 \tBbox: [ 0 \t 1 \t 476 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8762 \tBbox: [ 632 \t 28 \t 715 \t 255 ]\n",
      "3 \tObject: person \tConfidence = 0.7475 \tBbox: [ 621 \t 0 \t 678 \t 151 ]\n",
      "4 \tObject: person \tConfidence = 0.3089 \tBbox: [ 0 \t 471 \t 47 \t 836 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000768 / 1050\n",
      "Frames to be processed: 282  | To do: 26.86 % | Done: 73.14 %\n",
      "\n",
      "2022-04-20 13:16:43.462783\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000768.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 30.0ms pre-process, 179.2ms inference, 10.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8777 \tBbox: [ 0 \t 1 \t 475 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8772 \tBbox: [ 632 \t 25 \t 715 \t 245 ]\n",
      "3 \tObject: person \tConfidence = 0.6308 \tBbox: [ 623 \t 0 \t 676 \t 125 ]\n",
      "4 \tObject: person \tConfidence = 0.3221 \tBbox: [ 0 \t 472 \t 47 \t 835 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000769 / 1050\n",
      "Frames to be processed: 281  | To do: 26.76 % | Done: 73.24 %\n",
      "\n",
      "2022-04-20 13:16:44.058502\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000769.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 29.2ms pre-process, 177.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8811 \tBbox: [ 0 \t 1 \t 475 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.8582 \tBbox: [ 632 \t 23 \t 715 \t 243 ]\n",
      "3 \tObject: person \tConfidence = 0.6404 \tBbox: [ 623 \t 0 \t 676 \t 146 ]\n",
      "4 \tObject: person \tConfidence = 0.3223 \tBbox: [ 0 \t 472 \t 47 \t 836 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000770 / 1050\n",
      "Frames to be processed: 280  | To do: 26.67 % | Done: 73.33 %\n",
      "\n",
      "2022-04-20 13:16:44.618272\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000770.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 29.5ms pre-process, 172.1ms inference, 10.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8799 \tBbox: [ 0 \t 1 \t 475 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.833 \tBbox: [ 631 \t 21 \t 716 \t 243 ]\n",
      "3 \tObject: person \tConfidence = 0.5802 \tBbox: [ 625 \t 0 \t 677 \t 138 ]\n",
      "4 \tObject: person \tConfidence = 0.318 \tBbox: [ 0 \t 472 \t 47 \t 837 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000771 / 1050\n",
      "Frames to be processed: 279  | To do: 26.57 % | Done: 73.43 %\n",
      "\n",
      "2022-04-20 13:16:45.324816\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000771.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 63.0ms pre-process, 177.1ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8782 \tBbox: [ 0 \t 1 \t 473 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.8413 \tBbox: [ 632 \t 20 \t 716 \t 243 ]\n",
      "3 \tObject: person \tConfidence = 0.6352 \tBbox: [ 624 \t 0 \t 677 \t 157 ]\n",
      "4 \tObject: person \tConfidence = 0.3311 \tBbox: [ 0 \t 472 \t 47 \t 835 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000772 / 1050\n",
      "Frames to be processed: 278  | To do: 26.48 % | Done: 73.52 %\n",
      "\n",
      "2022-04-20 13:16:45.912504\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000772.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 28.1ms pre-process, 174.3ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8825 \tBbox: [ 0 \t 2 \t 474 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8408 \tBbox: [ 632 \t 19 \t 716 \t 244 ]\n",
      "3 \tObject: person \tConfidence = 0.5786 \tBbox: [ 624 \t 0 \t 679 \t 155 ]\n",
      "4 \tObject: person \tConfidence = 0.3318 \tBbox: [ 0 \t 472 \t 47 \t 836 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000773 / 1050\n",
      "Frames to be processed: 277  | To do: 26.38 % | Done: 73.62 %\n",
      "\n",
      "2022-04-20 13:16:46.476159\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000773.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 36.4ms pre-process, 171.5ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8784 \tBbox: [ 0 \t 2 \t 474 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8059 \tBbox: [ 635 \t 21 \t 716 \t 244 ]\n",
      "3 \tObject: person \tConfidence = 0.6452 \tBbox: [ 627 \t 0 \t 682 \t 156 ]\n",
      "4 \tObject: person \tConfidence = 0.3407 \tBbox: [ 0 \t 473 \t 47 \t 836 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000774 / 1050\n",
      "Frames to be processed: 276  | To do: 26.29 % | Done: 73.71 %\n",
      "\n",
      "2022-04-20 13:16:46.960320\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000774.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 37.8ms pre-process, 177.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8794 \tBbox: [ 0 \t 2 \t 473 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8217 \tBbox: [ 634 \t 20 \t 716 \t 244 ]\n",
      "3 \tObject: person \tConfidence = 0.5521 \tBbox: [ 628 \t 0 \t 682 \t 156 ]\n",
      "4 \tObject: person \tConfidence = 0.3487 \tBbox: [ 0 \t 473 \t 47 \t 835 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000775 / 1050\n",
      "Frames to be processed: 275  | To do: 26.19 % | Done: 73.81 %\n",
      "\n",
      "2022-04-20 13:16:47.537757\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000775.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 37.4ms pre-process, 180.2ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8799 \tBbox: [ 0 \t 2 \t 473 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.7887 \tBbox: [ 636 \t 20 \t 715 \t 244 ]\n",
      "3 \tObject: person \tConfidence = 0.5167 \tBbox: [ 630 \t 0 \t 685 \t 170 ]\n",
      "4 \tObject: person \tConfidence = 0.338 \tBbox: [ 0 \t 473 \t 47 \t 835 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000776 / 1050\n",
      "Frames to be processed: 274  | To do: 26.1 % | Done: 73.9 %\n",
      "\n",
      "2022-04-20 13:16:48.070184\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000776.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 28.0ms pre-process, 181.9ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8787 \tBbox: [ 0 \t 2 \t 471 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8258 \tBbox: [ 634 \t 20 \t 715 \t 244 ]\n",
      "3 \tObject: person \tConfidence = 0.4816 \tBbox: [ 630 \t 1 \t 683 \t 156 ]\n",
      "4 \tObject: person \tConfidence = 0.358 \tBbox: [ 0 \t 474 \t 47 \t 836 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000777 / 1050\n",
      "Frames to be processed: 273  | To do: 26.0 % | Done: 74.0 %\n",
      "\n",
      "2022-04-20 13:16:48.645731\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000777.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 35.9ms pre-process, 168.9ms inference, 9.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8781 \tBbox: [ 0 \t 2 \t 469 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8466 \tBbox: [ 633 \t 19 \t 714 \t 243 ]\n",
      "3 \tObject: person \tConfidence = 0.6231 \tBbox: [ 632 \t 0 \t 685 \t 74 ]\n",
      "4 \tObject: person \tConfidence = 0.3743 \tBbox: [ 0 \t 474 \t 47 \t 837 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000778 / 1050\n",
      "Frames to be processed: 272  | To do: 25.9 % | Done: 74.1 %\n",
      "\n",
      "2022-04-20 13:16:49.268831\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000778.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 26.6ms pre-process, 175.7ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8718 \tBbox: [ 0 \t 2 \t 469 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8683 \tBbox: [ 634 \t 18 \t 713 \t 241 ]\n",
      "3 \tObject: person \tConfidence = 0.6362 \tBbox: [ 636 \t 0 \t 691 \t 73 ]\n",
      "4 \tObject: person \tConfidence = 0.3696 \tBbox: [ 0 \t 474 \t 47 \t 837 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000779 / 1050\n",
      "Frames to be processed: 271  | To do: 25.81 % | Done: 74.19 %\n",
      "\n",
      "2022-04-20 13:16:49.872490\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000779.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 53.0ms pre-process, 172.3ms inference, 4.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8722 \tBbox: [ 0 \t 2 \t 469 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8375 \tBbox: [ 635 \t 15 \t 712 \t 240 ]\n",
      "3 \tObject: person \tConfidence = 0.5491 \tBbox: [ 637 \t 0 \t 693 \t 73 ]\n",
      "4 \tObject: person \tConfidence = 0.372 \tBbox: [ 0 \t 473 \t 47 \t 837 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000780 / 1050\n",
      "Frames to be processed: 270  | To do: 25.71 % | Done: 74.29 %\n",
      "\n",
      "2022-04-20 13:16:50.383815\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000780.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 29.7ms pre-process, 176.5ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8706 \tBbox: [ 0 \t 2 \t 469 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8602 \tBbox: [ 634 \t 13 \t 712 \t 235 ]\n",
      "3 \tObject: person \tConfidence = 0.4901 \tBbox: [ 639 \t 0 \t 696 \t 71 ]\n",
      "4 \tObject: person \tConfidence = 0.3706 \tBbox: [ 0 \t 473 \t 47 \t 837 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000781 / 1050\n",
      "Frames to be processed: 269  | To do: 25.62 % | Done: 74.38 %\n",
      "\n",
      "2022-04-20 13:16:50.981321\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000781.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 34.6ms pre-process, 177.8ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8803 \tBbox: [ 3 \t 3 \t 468 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.8704 \tBbox: [ 635 \t 13 \t 712 \t 231 ]\n",
      "3 \tObject: person \tConfidence = 0.4428 \tBbox: [ 640 \t 0 \t 698 \t 70 ]\n",
      "4 \tObject: person \tConfidence = 0.4228 \tBbox: [ 0 \t 473 \t 47 \t 837 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000782 / 1050\n",
      "Frames to be processed: 268  | To do: 25.52 % | Done: 74.48 %\n",
      "\n",
      "2022-04-20 13:16:51.551535\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000782.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 3 persons, 1 train\n",
      "Speed: 37.0ms pre-process, 172.3ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 4 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8812 \tBbox: [ 635 \t 11 \t 712 \t 227 ]\n",
      "2 \tObject: train \tConfidence = 0.8798 \tBbox: [ 0 \t 2 \t 469 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.4525 \tBbox: [ 641 \t 0 \t 701 \t 67 ]\n",
      "4 \tObject: person \tConfidence = 0.4043 \tBbox: [ 0 \t 473 \t 47 \t 837 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    3\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000783 / 1050\n",
      "Frames to be processed: 267  | To do: 25.43 % | Done: 74.57 %\n",
      "\n",
      "2022-04-20 13:16:52.136277\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000783.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 27.2ms pre-process, 180.7ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8893 \tBbox: [ 635 \t 5 \t 712 \t 219 ]\n",
      "2 \tObject: train \tConfidence = 0.8758 \tBbox: [ 0 \t 2 \t 469 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.4129 \tBbox: [ 0 \t 472 \t 47 \t 837 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000784 / 1050\n",
      "Frames to be processed: 266  | To do: 25.33 % | Done: 74.67 %\n",
      "\n",
      "2022-04-20 13:16:52.614201\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000784.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 53.2ms pre-process, 171.4ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9021 \tBbox: [ 635 \t 5 \t 711 \t 219 ]\n",
      "2 \tObject: train \tConfidence = 0.8794 \tBbox: [ 0 \t 2 \t 469 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.4042 \tBbox: [ 0 \t 472 \t 47 \t 837 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000785 / 1050\n",
      "Frames to be processed: 265  | To do: 25.24 % | Done: 74.76 %\n",
      "\n",
      "2022-04-20 13:16:53.180244\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000785.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 30.6ms pre-process, 171.4ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9022 \tBbox: [ 635 \t 6 \t 709 \t 219 ]\n",
      "2 \tObject: train \tConfidence = 0.8781 \tBbox: [ 0 \t 1 \t 469 \t 1072 ]\n",
      "3 \tObject: person \tConfidence = 0.4001 \tBbox: [ 0 \t 472 \t 47 \t 837 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000786 / 1050\n",
      "Frames to be processed: 264  | To do: 25.14 % | Done: 74.86 %\n",
      "\n",
      "2022-04-20 13:16:53.663130\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000786.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 32.3ms pre-process, 167.2ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9091 \tBbox: [ 634 \t 6 \t 708 \t 217 ]\n",
      "2 \tObject: train \tConfidence = 0.8783 \tBbox: [ 0 \t 2 \t 469 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.4025 \tBbox: [ 0 \t 472 \t 48 \t 837 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000787 / 1050\n",
      "Frames to be processed: 263  | To do: 25.05 % | Done: 74.95 %\n",
      "\n",
      "2022-04-20 13:16:54.217324\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000787.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 36.7ms pre-process, 167.5ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.908 \tBbox: [ 633 \t 5 \t 707 \t 218 ]\n",
      "2 \tObject: train \tConfidence = 0.8739 \tBbox: [ 0 \t 2 \t 469 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.3856 \tBbox: [ 0 \t 472 \t 48 \t 838 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000788 / 1050\n",
      "Frames to be processed: 262  | To do: 24.95 % | Done: 75.05 %\n",
      "\n",
      "2022-04-20 13:16:54.772090\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000788.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 31.8ms pre-process, 174.5ms inference, 10.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9077 \tBbox: [ 633 \t 5 \t 704 \t 219 ]\n",
      "2 \tObject: train \tConfidence = 0.8735 \tBbox: [ 0 \t 2 \t 469 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.4083 \tBbox: [ 0 \t 474 \t 48 \t 838 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000789 / 1050\n",
      "Frames to be processed: 261  | To do: 24.86 % | Done: 75.14 %\n",
      "\n",
      "2022-04-20 13:16:55.281090\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000789.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 35.2ms pre-process, 174.2ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9099 \tBbox: [ 632 \t 6 \t 703 \t 219 ]\n",
      "2 \tObject: train \tConfidence = 0.8755 \tBbox: [ 0 \t 2 \t 469 \t 1072 ]\n",
      "3 \tObject: person \tConfidence = 0.3878 \tBbox: [ 0 \t 475 \t 49 \t 838 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000790 / 1050\n",
      "Frames to be processed: 260  | To do: 24.76 % | Done: 75.24 %\n",
      "\n",
      "2022-04-20 13:16:55.869124\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000790.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 38.3ms pre-process, 175.9ms inference, 10.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9098 \tBbox: [ 631 \t 6 \t 702 \t 219 ]\n",
      "2 \tObject: train \tConfidence = 0.8749 \tBbox: [ 0 \t 2 \t 469 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.4321 \tBbox: [ 0 \t 476 \t 49 \t 838 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000791 / 1050\n",
      "Frames to be processed: 259  | To do: 24.67 % | Done: 75.33 %\n",
      "\n",
      "2022-04-20 13:16:56.443585\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000791.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 34.5ms pre-process, 170.0ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9061 \tBbox: [ 631 \t 6 \t 702 \t 217 ]\n",
      "2 \tObject: train \tConfidence = 0.8728 \tBbox: [ 0 \t 2 \t 470 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.4142 \tBbox: [ 0 \t 476 \t 50 \t 837 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000792 / 1050\n",
      "Frames to be processed: 258  | To do: 24.57 % | Done: 75.43 %\n",
      "\n",
      "2022-04-20 13:16:56.937217\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000792.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 32.2ms pre-process, 175.6ms inference, 14.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9105 \tBbox: [ 631 \t 7 \t 701 \t 216 ]\n",
      "2 \tObject: train \tConfidence = 0.8734 \tBbox: [ 0 \t 2 \t 469 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.4191 \tBbox: [ 0 \t 476 \t 51 \t 837 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000793 / 1050\n",
      "Frames to be processed: 257  | To do: 24.48 % | Done: 75.52 %\n",
      "\n",
      "2022-04-20 13:16:57.487895\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000793.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 33.7ms pre-process, 176.9ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9117 \tBbox: [ 630 \t 6 \t 700 \t 216 ]\n",
      "2 \tObject: train \tConfidence = 0.8722 \tBbox: [ 0 \t 2 \t 469 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.3983 \tBbox: [ 0 \t 477 \t 51 \t 837 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000794 / 1050\n",
      "Frames to be processed: 256  | To do: 24.38 % | Done: 75.62 %\n",
      "\n",
      "2022-04-20 13:16:57.954883\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000794.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 26.7ms pre-process, 180.6ms inference, 10.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9082 \tBbox: [ 630 \t 4 \t 699 \t 217 ]\n",
      "2 \tObject: train \tConfidence = 0.8772 \tBbox: [ 0 \t 1 \t 469 \t 1072 ]\n",
      "3 \tObject: person \tConfidence = 0.4311 \tBbox: [ 0 \t 473 \t 52 \t 837 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000795 / 1050\n",
      "Frames to be processed: 255  | To do: 24.29 % | Done: 75.71 %\n",
      "\n",
      "2022-04-20 13:16:58.415421\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000795.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 28.3ms pre-process, 181.8ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9123 \tBbox: [ 629 \t 3 \t 699 \t 210 ]\n",
      "2 \tObject: train \tConfidence = 0.8766 \tBbox: [ 0 \t 2 \t 469 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.4175 \tBbox: [ 0 \t 473 \t 52 \t 838 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000796 / 1050\n",
      "Frames to be processed: 254  | To do: 24.19 % | Done: 75.81 %\n",
      "\n",
      "2022-04-20 13:16:58.892287\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000796.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 27.2ms pre-process, 172.4ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9174 \tBbox: [ 629 \t 2 \t 699 \t 207 ]\n",
      "2 \tObject: train \tConfidence = 0.8797 \tBbox: [ 0 \t 2 \t 469 \t 1072 ]\n",
      "3 \tObject: person \tConfidence = 0.4562 \tBbox: [ 0 \t 474 \t 52 \t 837 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000797 / 1050\n",
      "Frames to be processed: 253  | To do: 24.1 % | Done: 75.9 %\n",
      "\n",
      "2022-04-20 13:16:59.382448\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000797.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 38.8ms pre-process, 173.4ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9168 \tBbox: [ 629 \t 1 \t 698 \t 207 ]\n",
      "2 \tObject: train \tConfidence = 0.8792 \tBbox: [ 0 \t 2 \t 469 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.4443 \tBbox: [ 0 \t 477 \t 52 \t 838 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000798 / 1050\n",
      "Frames to be processed: 252  | To do: 24.0 % | Done: 76.0 %\n",
      "\n",
      "2022-04-20 13:16:59.869129\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000798.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 25.7ms pre-process, 173.3ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.902 \tBbox: [ 628 \t 0 \t 698 \t 208 ]\n",
      "2 \tObject: train \tConfidence = 0.8636 \tBbox: [ 0 \t 1 \t 469 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.4505 \tBbox: [ 0 \t 475 \t 52 \t 837 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000799 / 1050\n",
      "Frames to be processed: 251  | To do: 23.9 % | Done: 76.1 %\n",
      "\n",
      "2022-04-20 13:17:00.281129\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000799.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 25.6ms pre-process, 179.4ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9021 \tBbox: [ 625 \t 0 \t 698 \t 207 ]\n",
      "2 \tObject: train \tConfidence = 0.8674 \tBbox: [ 0 \t 2 \t 469 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.4397 \tBbox: [ 0 \t 476 \t 52 \t 837 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000800 / 1050\n",
      "Frames to be processed: 250  | To do: 23.81 % | Done: 76.19 %\n",
      "\n",
      "2022-04-20 13:17:00.741412\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000800.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 25.4ms pre-process, 171.5ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8885 \tBbox: [ 623 \t 0 \t 697 \t 197 ]\n",
      "2 \tObject: train \tConfidence = 0.8667 \tBbox: [ 0 \t 1 \t 469 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.435 \tBbox: [ 0 \t 478 \t 52 \t 838 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000801 / 1050\n",
      "Frames to be processed: 249  | To do: 23.71 % | Done: 76.29 %\n",
      "\n",
      "2022-04-20 13:17:01.206204\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000801.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 89.3ms pre-process, 175.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9001 \tBbox: [ 619 \t 0 \t 696 \t 207 ]\n",
      "2 \tObject: train \tConfidence = 0.8693 \tBbox: [ 0 \t 1 \t 469 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.4464 \tBbox: [ 0 \t 478 \t 52 \t 839 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000802 / 1050\n",
      "Frames to be processed: 248  | To do: 23.62 % | Done: 76.38 %\n",
      "\n",
      "2022-04-20 13:17:01.751706\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000802.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 35.6ms pre-process, 168.3ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8828 \tBbox: [ 617 \t 0 \t 695 \t 203 ]\n",
      "2 \tObject: train \tConfidence = 0.8685 \tBbox: [ 0 \t 1 \t 469 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.461 \tBbox: [ 0 \t 479 \t 52 \t 839 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000803 / 1050\n",
      "Frames to be processed: 247  | To do: 23.52 % | Done: 76.48 %\n",
      "\n",
      "2022-04-20 13:17:02.206486\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000803.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 36.4ms pre-process, 174.1ms inference, 3.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8718 \tBbox: [ 0 \t 2 \t 470 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8687 \tBbox: [ 618 \t 0 \t 693 \t 193 ]\n",
      "3 \tObject: person \tConfidence = 0.4379 \tBbox: [ 0 \t 479 \t 52 \t 839 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000804 / 1050\n",
      "Frames to be processed: 246  | To do: 23.43 % | Done: 76.57 %\n",
      "\n",
      "2022-04-20 13:17:02.745402\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000804.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 39.5ms pre-process, 175.5ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8753 \tBbox: [ 619 \t 0 \t 693 \t 204 ]\n",
      "2 \tObject: train \tConfidence = 0.8726 \tBbox: [ 0 \t 2 \t 470 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.4286 \tBbox: [ 0 \t 479 \t 51 \t 840 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000805 / 1050\n",
      "Frames to be processed: 245  | To do: 23.33 % | Done: 76.67 %\n",
      "\n",
      "2022-04-20 13:17:03.250547\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000805.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 28.3ms pre-process, 179.7ms inference, 2.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8729 \tBbox: [ 0 \t 2 \t 470 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8695 \tBbox: [ 621 \t 0 \t 692 \t 201 ]\n",
      "3 \tObject: person \tConfidence = 0.3747 \tBbox: [ 0 \t 480 \t 51 \t 841 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000806 / 1050\n",
      "Frames to be processed: 244  | To do: 23.24 % | Done: 76.76 %\n",
      "\n",
      "2022-04-20 13:17:03.936299\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000806.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 26.3ms pre-process, 177.9ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8634 \tBbox: [ 621 \t 0 \t 690 \t 194 ]\n",
      "2 \tObject: train \tConfidence = 0.8592 \tBbox: [ 0 \t 2 \t 470 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.3991 \tBbox: [ 0 \t 480 \t 51 \t 840 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000807 / 1050\n",
      "Frames to be processed: 243  | To do: 23.14 % | Done: 76.86 %\n",
      "\n",
      "2022-04-20 13:17:04.426264\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000807.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 32.2ms pre-process, 179.2ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8678 \tBbox: [ 620 \t 0 \t 689 \t 193 ]\n",
      "2 \tObject: train \tConfidence = 0.8665 \tBbox: [ 0 \t 2 \t 470 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.3615 \tBbox: [ 0 \t 476 \t 52 \t 839 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000808 / 1050\n",
      "Frames to be processed: 242  | To do: 23.05 % | Done: 76.95 %\n",
      "\n",
      "2022-04-20 13:17:04.917332\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000808.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 26.9ms pre-process, 175.5ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8706 \tBbox: [ 0 \t 2 \t 470 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.8609 \tBbox: [ 621 \t 0 \t 687 \t 194 ]\n",
      "3 \tObject: person \tConfidence = 0.3467 \tBbox: [ 0 \t 480 \t 51 \t 840 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000809 / 1050\n",
      "Frames to be processed: 241  | To do: 22.95 % | Done: 77.05 %\n",
      "\n",
      "2022-04-20 13:17:05.438200\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000809.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 30.5ms pre-process, 176.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8682 \tBbox: [ 620 \t 0 \t 687 \t 205 ]\n",
      "2 \tObject: train \tConfidence = 0.866 \tBbox: [ 0 \t 2 \t 470 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.3744 \tBbox: [ 0 \t 481 \t 51 \t 840 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000810 / 1050\n",
      "Frames to be processed: 240  | To do: 22.86 % | Done: 77.14 %\n",
      "\n",
      "2022-04-20 13:17:05.901172\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000810.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 52.6ms pre-process, 175.4ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8935 \tBbox: [ 619 \t 0 \t 686 \t 183 ]\n",
      "2 \tObject: train \tConfidence = 0.8659 \tBbox: [ 0 \t 2 \t 470 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.3869 \tBbox: [ 0 \t 481 \t 51 \t 841 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000811 / 1050\n",
      "Frames to be processed: 239  | To do: 22.76 % | Done: 77.24 %\n",
      "\n",
      "2022-04-20 13:17:06.546144\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000811.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 31.7ms pre-process, 179.8ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9088 \tBbox: [ 620 \t 0 \t 686 \t 180 ]\n",
      "2 \tObject: train \tConfidence = 0.8664 \tBbox: [ 0 \t 2 \t 471 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.3751 \tBbox: [ 0 \t 483 \t 51 \t 840 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000812 / 1050\n",
      "Frames to be processed: 238  | To do: 22.67 % | Done: 77.33 %\n",
      "\n",
      "2022-04-20 13:17:07.035650\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000812.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 26.7ms pre-process, 181.1ms inference, 10.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9146 \tBbox: [ 619 \t 0 \t 686 \t 177 ]\n",
      "2 \tObject: train \tConfidence = 0.874 \tBbox: [ 0 \t 2 \t 471 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.3461 \tBbox: [ 0 \t 480 \t 51 \t 840 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000813 / 1050\n",
      "Frames to be processed: 237  | To do: 22.57 % | Done: 77.43 %\n",
      "\n",
      "2022-04-20 13:17:07.487144\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000813.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 26.9ms pre-process, 173.2ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9143 \tBbox: [ 619 \t 0 \t 685 \t 174 ]\n",
      "2 \tObject: train \tConfidence = 0.8724 \tBbox: [ 0 \t 2 \t 471 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.3096 \tBbox: [ 0 \t 481 \t 51 \t 841 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000814 / 1050\n",
      "Frames to be processed: 236  | To do: 22.48 % | Done: 77.52 %\n",
      "\n",
      "2022-04-20 13:17:08.018929\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000814.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 45.8ms pre-process, 175.3ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9131 \tBbox: [ 619 \t 0 \t 685 \t 174 ]\n",
      "2 \tObject: train \tConfidence = 0.8761 \tBbox: [ 0 \t 2 \t 471 \t 1071 ]\n",
      "3 \tObject: person \tConfidence = 0.3366 \tBbox: [ 0 \t 481 \t 50 \t 840 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000815 / 1050\n",
      "Frames to be processed: 235  | To do: 22.38 % | Done: 77.62 %\n",
      "\n",
      "2022-04-20 13:17:08.588772\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000815.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 29.6ms pre-process, 169.4ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9111 \tBbox: [ 619 \t 0 \t 685 \t 174 ]\n",
      "2 \tObject: train \tConfidence = 0.8712 \tBbox: [ 0 \t 2 \t 470 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.3604 \tBbox: [ 0 \t 481 \t 51 \t 842 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000816 / 1050\n",
      "Frames to be processed: 234  | To do: 22.29 % | Done: 77.71 %\n",
      "\n",
      "2022-04-20 13:17:09.088825\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000816.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 44.7ms pre-process, 175.6ms inference, 10.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9144 \tBbox: [ 619 \t 0 \t 685 \t 174 ]\n",
      "2 \tObject: train \tConfidence = 0.866 \tBbox: [ 0 \t 2 \t 471 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.3845 \tBbox: [ 0 \t 483 \t 50 \t 841 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000817 / 1050\n",
      "Frames to be processed: 233  | To do: 22.19 % | Done: 77.81 %\n",
      "\n",
      "2022-04-20 13:17:09.568358\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000817.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 27.4ms pre-process, 180.5ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9124 \tBbox: [ 619 \t 0 \t 685 \t 174 ]\n",
      "2 \tObject: train \tConfidence = 0.8656 \tBbox: [ 0 \t 2 \t 471 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.3817 \tBbox: [ 0 \t 483 \t 50 \t 841 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000818 / 1050\n",
      "Frames to be processed: 232  | To do: 22.1 % | Done: 77.9 %\n",
      "\n",
      "2022-04-20 13:17:10.016804\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000818.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 28.5ms pre-process, 172.5ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.915 \tBbox: [ 620 \t 0 \t 685 \t 175 ]\n",
      "2 \tObject: train \tConfidence = 0.8617 \tBbox: [ 0 \t 2 \t 471 \t 1069 ]\n",
      "3 \tObject: person \tConfidence = 0.3695 \tBbox: [ 0 \t 484 \t 49 \t 841 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000819 / 1050\n",
      "Frames to be processed: 231  | To do: 22.0 % | Done: 78.0 %\n",
      "\n",
      "2022-04-20 13:17:10.461327\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000819.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 34.0ms pre-process, 175.4ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9135 \tBbox: [ 620 \t 0 \t 685 \t 175 ]\n",
      "2 \tObject: train \tConfidence = 0.8649 \tBbox: [ 0 \t 2 \t 470 \t 1070 ]\n",
      "3 \tObject: person \tConfidence = 0.3207 \tBbox: [ 0 \t 483 \t 49 \t 841 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000820 / 1050\n",
      "Frames to be processed: 230  | To do: 21.9 % | Done: 78.1 %\n",
      "\n",
      "2022-04-20 13:17:10.910875\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000820.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 26.5ms pre-process, 180.9ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9129 \tBbox: [ 620 \t 0 \t 686 \t 175 ]\n",
      "2 \tObject: train \tConfidence = 0.8671 \tBbox: [ 0 \t 2 \t 471 \t 1070 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000821 / 1050\n",
      "Frames to be processed: 229  | To do: 21.81 % | Done: 78.19 %\n",
      "\n",
      "2022-04-20 13:17:11.436304\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000821.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.5ms pre-process, 172.1ms inference, 2.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9134 \tBbox: [ 619 \t 0 \t 687 \t 175 ]\n",
      "2 \tObject: train \tConfidence = 0.8759 \tBbox: [ 0 \t 2 \t 471 \t 1071 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000822 / 1050\n",
      "Frames to be processed: 228  | To do: 21.71 % | Done: 78.29 %\n",
      "\n",
      "2022-04-20 13:17:11.922349\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000822.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 52.9ms pre-process, 166.9ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9128 \tBbox: [ 620 \t 0 \t 688 \t 173 ]\n",
      "2 \tObject: train \tConfidence = 0.8787 \tBbox: [ 0 \t 2 \t 471 \t 1071 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000823 / 1050\n",
      "Frames to be processed: 227  | To do: 21.62 % | Done: 78.38 %\n",
      "\n",
      "2022-04-20 13:17:12.519601\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000823.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 25.2ms pre-process, 169.4ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.912 \tBbox: [ 620 \t 0 \t 689 \t 173 ]\n",
      "2 \tObject: train \tConfidence = 0.8653 \tBbox: [ 0 \t 2 \t 471 \t 1071 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000824 / 1050\n",
      "Frames to be processed: 226  | To do: 21.52 % | Done: 78.48 %\n",
      "\n",
      "2022-04-20 13:17:12.965475\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000824.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 27.1ms pre-process, 175.7ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9138 \tBbox: [ 620 \t 0 \t 692 \t 171 ]\n",
      "2 \tObject: train \tConfidence = 0.8782 \tBbox: [ 3 \t 4 \t 470 \t 1069 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000825 / 1050\n",
      "Frames to be processed: 225  | To do: 21.43 % | Done: 78.57 %\n",
      "\n",
      "2022-04-20 13:17:13.427658\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000825.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 26.2ms pre-process, 168.9ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9138 \tBbox: [ 620 \t 0 \t 693 \t 168 ]\n",
      "2 \tObject: train \tConfidence = 0.8756 \tBbox: [ 3 \t 3 \t 471 \t 1068 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000826 / 1050\n",
      "Frames to be processed: 224  | To do: 21.33 % | Done: 78.67 %\n",
      "\n",
      "2022-04-20 13:17:13.916159\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000826.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 26.6ms pre-process, 175.1ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9145 \tBbox: [ 621 \t 0 \t 694 \t 162 ]\n",
      "2 \tObject: train \tConfidence = 0.8723 \tBbox: [ 0 \t 2 \t 470 \t 1071 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000827 / 1050\n",
      "Frames to be processed: 223  | To do: 21.24 % | Done: 78.76 %\n",
      "\n",
      "2022-04-20 13:17:14.406400\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000827.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 50.7ms pre-process, 177.1ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.914 \tBbox: [ 622 \t 0 \t 694 \t 160 ]\n",
      "2 \tObject: train \tConfidence = 0.8759 \tBbox: [ 0 \t 2 \t 470 \t 1071 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000828 / 1050\n",
      "Frames to be processed: 222  | To do: 21.14 % | Done: 78.86 %\n",
      "\n",
      "2022-04-20 13:17:14.898485\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000828.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 50.0ms pre-process, 179.8ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9176 \tBbox: [ 628 \t 0 \t 696 \t 158 ]\n",
      "2 \tObject: train \tConfidence = 0.8772 \tBbox: [ 0 \t 2 \t 470 \t 1071 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000829 / 1050\n",
      "Frames to be processed: 221  | To do: 21.05 % | Done: 78.95 %\n",
      "\n",
      "2022-04-20 13:17:15.382141\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000829.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 27.9ms pre-process, 180.5ms inference, 8.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9091 \tBbox: [ 630 \t 0 \t 696 \t 158 ]\n",
      "2 \tObject: train \tConfidence = 0.8712 \tBbox: [ 0 \t 2 \t 470 \t 1070 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000830 / 1050\n",
      "Frames to be processed: 220  | To do: 20.95 % | Done: 79.05 %\n",
      "\n",
      "2022-04-20 13:17:15.965878\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000830.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 31.3ms pre-process, 181.0ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9017 \tBbox: [ 635 \t 0 \t 696 \t 158 ]\n",
      "2 \tObject: train \tConfidence = 0.8732 \tBbox: [ 0 \t 2 \t 470 \t 1071 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000831 / 1050\n",
      "Frames to be processed: 219  | To do: 20.86 % | Done: 79.14 %\n",
      "\n",
      "2022-04-20 13:17:16.450329\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000831.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.3ms pre-process, 171.6ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8992 \tBbox: [ 639 \t 0 \t 697 \t 158 ]\n",
      "2 \tObject: train \tConfidence = 0.8704 \tBbox: [ 0 \t 2 \t 470 \t 1071 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000832 / 1050\n",
      "Frames to be processed: 218  | To do: 20.76 % | Done: 79.24 %\n",
      "\n",
      "2022-04-20 13:17:17.044209\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000832.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.1ms pre-process, 177.1ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.9038 \tBbox: [ 642 \t 0 \t 697 \t 158 ]\n",
      "2 \tObject: train \tConfidence = 0.8649 \tBbox: [ 0 \t 1 \t 470 \t 1070 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000833 / 1050\n",
      "Frames to be processed: 217  | To do: 20.67 % | Done: 79.33 %\n",
      "\n",
      "2022-04-20 13:17:17.559339\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000833.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 24.8ms pre-process, 172.3ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8983 \tBbox: [ 642 \t 0 \t 698 \t 158 ]\n",
      "2 \tObject: train \tConfidence = 0.8612 \tBbox: [ 0 \t 2 \t 471 \t 1069 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000834 / 1050\n",
      "Frames to be processed: 216  | To do: 20.57 % | Done: 79.43 %\n",
      "\n",
      "2022-04-20 13:17:18.103558\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000834.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 27.1ms pre-process, 177.7ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8951 \tBbox: [ 642 \t 0 \t 698 \t 158 ]\n",
      "2 \tObject: train \tConfidence = 0.8522 \tBbox: [ 0 \t 2 \t 471 \t 1069 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000835 / 1050\n",
      "Frames to be processed: 215  | To do: 20.48 % | Done: 79.52 %\n",
      "\n",
      "2022-04-20 13:17:18.676717\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000835.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 27.0ms pre-process, 178.6ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8923 \tBbox: [ 643 \t 0 \t 699 \t 158 ]\n",
      "2 \tObject: train \tConfidence = 0.8464 \tBbox: [ 0 \t 2 \t 471 \t 1069 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000836 / 1050\n",
      "Frames to be processed: 214  | To do: 20.38 % | Done: 79.62 %\n",
      "\n",
      "2022-04-20 13:17:19.266797\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000836.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 55.6ms pre-process, 171.6ms inference, 3.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.887 \tBbox: [ 644 \t 0 \t 699 \t 158 ]\n",
      "2 \tObject: train \tConfidence = 0.8526 \tBbox: [ 0 \t 2 \t 471 \t 1070 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000837 / 1050\n",
      "Frames to be processed: 213  | To do: 20.29 % | Done: 79.71 %\n",
      "\n",
      "2022-04-20 13:17:19.784702\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000837.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.6ms pre-process, 175.2ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: person \tConfidence = 0.8757 \tBbox: [ 643 \t 0 \t 699 \t 157 ]\n",
      "2 \tObject: train \tConfidence = 0.8454 \tBbox: [ 0 \t 2 \t 471 \t 1069 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000838 / 1050\n",
      "Frames to be processed: 212  | To do: 20.19 % | Done: 79.81 %\n",
      "\n",
      "2022-04-20 13:17:20.421220\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000838.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.5ms pre-process, 178.3ms inference, 4.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8207 \tBbox: [ 0 \t 2 \t 472 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.8198 \tBbox: [ 648 \t 0 \t 699 \t 157 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000839 / 1050\n",
      "Frames to be processed: 211  | To do: 20.1 % | Done: 79.9 %\n",
      "\n",
      "2022-04-20 13:17:20.951524\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000839.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 26.2ms pre-process, 176.2ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8064 \tBbox: [ 1 \t 3 \t 473 \t 1067 ]\n",
      "2 \tObject: person \tConfidence = 0.7471 \tBbox: [ 649 \t 0 \t 700 \t 154 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000840 / 1050\n",
      "Frames to be processed: 210  | To do: 20.0 % | Done: 80.0 %\n",
      "\n",
      "2022-04-20 13:17:21.463312\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000840.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 26.6ms pre-process, 180.0ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8184 \tBbox: [ 1 \t 3 \t 472 \t 1067 ]\n",
      "2 \tObject: person \tConfidence = 0.7677 \tBbox: [ 654 \t 0 \t 700 \t 152 ]\n",
      "3 \tObject: person \tConfidence = 0.3421 \tBbox: [ 0 \t 486 \t 46 \t 873 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000841 / 1050\n",
      "Frames to be processed: 209  | To do: 19.9 % | Done: 80.1 %\n",
      "\n",
      "2022-04-20 13:17:22.021728\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000841.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 57.0ms pre-process, 179.7ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8285 \tBbox: [ 1 \t 2 \t 472 \t 1067 ]\n",
      "2 \tObject: person \tConfidence = 0.7676 \tBbox: [ 658 \t 0 \t 699 \t 144 ]\n",
      "3 \tObject: person \tConfidence = 0.3817 \tBbox: [ 0 \t 486 \t 46 \t 876 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000842 / 1050\n",
      "Frames to be processed: 208  | To do: 19.81 % | Done: 80.19 %\n",
      "\n",
      "2022-04-20 13:17:22.631121\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000842.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 33.6ms pre-process, 178.2ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8359 \tBbox: [ 1 \t 2 \t 471 \t 1067 ]\n",
      "2 \tObject: person \tConfidence = 0.7659 \tBbox: [ 661 \t 0 \t 699 \t 143 ]\n",
      "3 \tObject: person \tConfidence = 0.3839 \tBbox: [ 0 \t 486 \t 47 \t 880 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000843 / 1050\n",
      "Frames to be processed: 207  | To do: 19.71 % | Done: 80.29 %\n",
      "\n",
      "2022-04-20 13:17:23.119806\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000843.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 26.8ms pre-process, 181.6ms inference, 10.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8266 \tBbox: [ 1 \t 2 \t 472 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.7478 \tBbox: [ 664 \t 0 \t 698 \t 142 ]\n",
      "3 \tObject: person \tConfidence = 0.3907 \tBbox: [ 0 \t 486 \t 46 \t 881 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000844 / 1050\n",
      "Frames to be processed: 206  | To do: 19.62 % | Done: 80.38 %\n",
      "\n",
      "2022-04-20 13:17:23.590472\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000844.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 38.1ms pre-process, 175.1ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8307 \tBbox: [ 1 \t 2 \t 471 \t 1067 ]\n",
      "2 \tObject: person \tConfidence = 0.7582 \tBbox: [ 665 \t 0 \t 697 \t 142 ]\n",
      "3 \tObject: person \tConfidence = 0.4386 \tBbox: [ 0 \t 486 \t 47 \t 881 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000845 / 1050\n",
      "Frames to be processed: 205  | To do: 19.52 % | Done: 80.48 %\n",
      "\n",
      "2022-04-20 13:17:24.083471\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000845.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 28.7ms pre-process, 169.4ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8281 \tBbox: [ 0 \t 2 \t 472 \t 1067 ]\n",
      "2 \tObject: person \tConfidence = 0.7608 \tBbox: [ 666 \t 0 \t 697 \t 142 ]\n",
      "3 \tObject: person \tConfidence = 0.4673 \tBbox: [ 0 \t 486 \t 46 \t 882 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000846 / 1050\n",
      "Frames to be processed: 204  | To do: 19.43 % | Done: 80.57 %\n",
      "\n",
      "2022-04-20 13:17:24.738787\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000846.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 39.7ms pre-process, 174.6ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8306 \tBbox: [ 0 \t 2 \t 472 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.7522 \tBbox: [ 666 \t 0 \t 698 \t 143 ]\n",
      "3 \tObject: person \tConfidence = 0.4663 \tBbox: [ 0 \t 485 \t 46 \t 882 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000847 / 1050\n",
      "Frames to be processed: 203  | To do: 19.33 % | Done: 80.67 %\n",
      "\n",
      "2022-04-20 13:17:25.284937\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000847.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 28.0ms pre-process, 178.0ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8312 \tBbox: [ 0 \t 2 \t 472 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.7544 \tBbox: [ 667 \t 0 \t 698 \t 143 ]\n",
      "3 \tObject: person \tConfidence = 0.4916 \tBbox: [ 0 \t 485 \t 46 \t 883 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000848 / 1050\n",
      "Frames to be processed: 202  | To do: 19.24 % | Done: 80.76 %\n",
      "\n",
      "2022-04-20 13:17:25.741342\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000848.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 30.4ms pre-process, 169.2ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8261 \tBbox: [ 0 \t 2 \t 472 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.6368 \tBbox: [ 667 \t 0 \t 698 \t 142 ]\n",
      "3 \tObject: person \tConfidence = 0.5085 \tBbox: [ 0 \t 484 \t 46 \t 883 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000849 / 1050\n",
      "Frames to be processed: 201  | To do: 19.14 % | Done: 80.86 %\n",
      "\n",
      "2022-04-20 13:17:26.255965\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000849.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 29.1ms pre-process, 176.3ms inference, 10.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8227 \tBbox: [ 0 \t 2 \t 472 \t 1067 ]\n",
      "2 \tObject: person \tConfidence = 0.4995 \tBbox: [ 0 \t 484 \t 46 \t 883 ]\n",
      "3 \tObject: person \tConfidence = 0.4442 \tBbox: [ 668 \t 1 \t 698 \t 142 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000850 / 1050\n",
      "Frames to be processed: 200  | To do: 19.05 % | Done: 80.95 %\n",
      "\n",
      "2022-04-20 13:17:26.833219\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000850.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 54.7ms pre-process, 180.3ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8192 \tBbox: [ 0 \t 2 \t 472 \t 1067 ]\n",
      "2 \tObject: person \tConfidence = 0.5053 \tBbox: [ 0 \t 484 \t 46 \t 883 ]\n",
      "3 \tObject: person \tConfidence = 0.3987 \tBbox: [ 668 \t 2 \t 698 \t 141 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000851 / 1050\n",
      "Frames to be processed: 199  | To do: 18.95 % | Done: 81.05 %\n",
      "\n",
      "2022-04-20 13:17:27.414517\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000851.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 2 persons, 1 train\n",
      "Speed: 32.2ms pre-process, 180.5ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 3 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8252 \tBbox: [ 0 \t 2 \t 472 \t 1067 ]\n",
      "2 \tObject: person \tConfidence = 0.4878 \tBbox: [ 0 \t 484 \t 46 \t 882 ]\n",
      "3 \tObject: person \tConfidence = 0.3317 \tBbox: [ 668 \t 2 \t 699 \t 142 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "person    2\n",
      "train     1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000852 / 1050\n",
      "Frames to be processed: 198  | To do: 18.86 % | Done: 81.14 %\n",
      "\n",
      "2022-04-20 13:17:27.936540\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000852.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 158.1ms pre-process, 182.0ms inference, 3.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8225 \tBbox: [ 0 \t 2 \t 472 \t 1067 ]\n",
      "2 \tObject: person \tConfidence = 0.5122 \tBbox: [ 0 \t 484 \t 46 \t 883 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000853 / 1050\n",
      "Frames to be processed: 197  | To do: 18.76 % | Done: 81.24 %\n",
      "\n",
      "2022-04-20 13:17:28.498941\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000853.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.4ms pre-process, 182.0ms inference, 3.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8132 \tBbox: [ 0 \t 2 \t 474 \t 1067 ]\n",
      "2 \tObject: person \tConfidence = 0.5044 \tBbox: [ 0 \t 484 \t 46 \t 883 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000854 / 1050\n",
      "Frames to be processed: 196  | To do: 18.67 % | Done: 81.33 %\n",
      "\n",
      "2022-04-20 13:17:28.959655\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000854.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 53.7ms pre-process, 172.2ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8217 \tBbox: [ 0 \t 2 \t 473 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.4903 \tBbox: [ 0 \t 483 \t 46 \t 883 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000855 / 1050\n",
      "Frames to be processed: 195  | To do: 18.57 % | Done: 81.43 %\n",
      "\n",
      "2022-04-20 13:17:29.534575\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000855.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 54.8ms pre-process, 176.3ms inference, 4.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8202 \tBbox: [ 1 \t 2 \t 474 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.4692 \tBbox: [ 0 \t 483 \t 46 \t 882 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000856 / 1050\n",
      "Frames to be processed: 194  | To do: 18.48 % | Done: 81.52 %\n",
      "\n",
      "2022-04-20 13:17:30.010436\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000856.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.6ms pre-process, 175.9ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.83 \tBbox: [ 1 \t 2 \t 473 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.5045 \tBbox: [ 0 \t 483 \t 47 \t 882 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000857 / 1050\n",
      "Frames to be processed: 193  | To do: 18.38 % | Done: 81.62 %\n",
      "\n",
      "2022-04-20 13:17:30.421105\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000857.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 35.3ms pre-process, 167.6ms inference, 5.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8221 \tBbox: [ 1 \t 2 \t 473 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.4976 \tBbox: [ 0 \t 484 \t 47 \t 883 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000858 / 1050\n",
      "Frames to be processed: 192  | To do: 18.29 % | Done: 81.71 %\n",
      "\n",
      "2022-04-20 13:17:30.948038\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000858.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 30.1ms pre-process, 174.0ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8184 \tBbox: [ 1 \t 2 \t 474 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.5227 \tBbox: [ 0 \t 484 \t 47 \t 883 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000859 / 1050\n",
      "Frames to be processed: 191  | To do: 18.19 % | Done: 81.81 %\n",
      "\n",
      "2022-04-20 13:17:31.478767\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000859.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 39.9ms pre-process, 177.7ms inference, 4.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8076 \tBbox: [ 1 \t 2 \t 475 \t 1067 ]\n",
      "2 \tObject: person \tConfidence = 0.5345 \tBbox: [ 0 \t 484 \t 47 \t 884 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000860 / 1050\n",
      "Frames to be processed: 190  | To do: 18.1 % | Done: 81.9 %\n",
      "\n",
      "2022-04-20 13:17:32.129492\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000860.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 41.0ms pre-process, 179.4ms inference, 3.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8087 \tBbox: [ 1 \t 2 \t 476 \t 1067 ]\n",
      "2 \tObject: person \tConfidence = 0.5374 \tBbox: [ 0 \t 484 \t 47 \t 884 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000861 / 1050\n",
      "Frames to be processed: 189  | To do: 18.0 % | Done: 82.0 %\n",
      "\n",
      "2022-04-20 13:17:32.714691\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000861.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 26.8ms pre-process, 178.3ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8105 \tBbox: [ 1 \t 2 \t 476 \t 1067 ]\n",
      "2 \tObject: person \tConfidence = 0.5489 \tBbox: [ 0 \t 484 \t 47 \t 885 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000862 / 1050\n",
      "Frames to be processed: 188  | To do: 17.9 % | Done: 82.1 %\n",
      "\n",
      "2022-04-20 13:17:33.249029\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000862.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 26.6ms pre-process, 169.5ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8184 \tBbox: [ 1 \t 2 \t 476 \t 1066 ]\n",
      "2 \tObject: person \tConfidence = 0.5608 \tBbox: [ 0 \t 485 \t 47 \t 885 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000863 / 1050\n",
      "Frames to be processed: 187  | To do: 17.81 % | Done: 82.19 %\n",
      "\n",
      "2022-04-20 13:17:33.768630\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000863.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 30.1ms pre-process, 167.0ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8165 \tBbox: [ 1 \t 2 \t 476 \t 1066 ]\n",
      "2 \tObject: person \tConfidence = 0.5692 \tBbox: [ 0 \t 484 \t 47 \t 884 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000864 / 1050\n",
      "Frames to be processed: 186  | To do: 17.71 % | Done: 82.29 %\n",
      "\n",
      "2022-04-20 13:17:34.384460\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000864.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 33.9ms pre-process, 169.3ms inference, 10.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8141 \tBbox: [ 1 \t 2 \t 476 \t 1066 ]\n",
      "2 \tObject: person \tConfidence = 0.5607 \tBbox: [ 0 \t 484 \t 47 \t 884 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000865 / 1050\n",
      "Frames to be processed: 185  | To do: 17.62 % | Done: 82.38 %\n",
      "\n",
      "2022-04-20 13:17:34.863053\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000865.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.8ms pre-process, 176.1ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8194 \tBbox: [ 1 \t 2 \t 476 \t 1066 ]\n",
      "2 \tObject: person \tConfidence = 0.5701 \tBbox: [ 0 \t 485 \t 47 \t 884 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000866 / 1050\n",
      "Frames to be processed: 184  | To do: 17.52 % | Done: 82.48 %\n",
      "\n",
      "2022-04-20 13:17:35.338725\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000866.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 33.5ms pre-process, 175.5ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8233 \tBbox: [ 1 \t 2 \t 476 \t 1067 ]\n",
      "2 \tObject: person \tConfidence = 0.5709 \tBbox: [ 0 \t 484 \t 47 \t 884 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000867 / 1050\n",
      "Frames to be processed: 183  | To do: 17.43 % | Done: 82.57 %\n",
      "\n",
      "2022-04-20 13:17:35.858602\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000867.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.8ms pre-process, 180.6ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8264 \tBbox: [ 1 \t 2 \t 476 \t 1066 ]\n",
      "2 \tObject: person \tConfidence = 0.5855 \tBbox: [ 0 \t 485 \t 47 \t 884 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000868 / 1050\n",
      "Frames to be processed: 182  | To do: 17.33 % | Done: 82.67 %\n",
      "\n",
      "2022-04-20 13:17:36.297882\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000868.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 27.4ms pre-process, 184.5ms inference, 2.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.828 \tBbox: [ 1 \t 2 \t 476 \t 1067 ]\n",
      "2 \tObject: person \tConfidence = 0.5538 \tBbox: [ 0 \t 484 \t 47 \t 884 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000869 / 1050\n",
      "Frames to be processed: 181  | To do: 17.24 % | Done: 82.76 %\n",
      "\n",
      "2022-04-20 13:17:36.789812\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000869.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 27.9ms pre-process, 173.8ms inference, 3.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8339 \tBbox: [ 1 \t 1 \t 475 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.5413 \tBbox: [ 0 \t 485 \t 47 \t 883 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000870 / 1050\n",
      "Frames to be processed: 180  | To do: 17.14 % | Done: 82.86 %\n",
      "\n",
      "2022-04-20 13:17:37.266969\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000870.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 38.0ms pre-process, 169.1ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8293 \tBbox: [ 1 \t 2 \t 475 \t 1067 ]\n",
      "2 \tObject: person \tConfidence = 0.5577 \tBbox: [ 0 \t 484 \t 47 \t 884 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000871 / 1050\n",
      "Frames to be processed: 179  | To do: 17.05 % | Done: 82.95 %\n",
      "\n",
      "2022-04-20 13:17:37.703317\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000871.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 31.1ms pre-process, 173.2ms inference, 3.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8335 \tBbox: [ 1 \t 2 \t 475 \t 1067 ]\n",
      "2 \tObject: person \tConfidence = 0.5493 \tBbox: [ 0 \t 485 \t 48 \t 883 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000872 / 1050\n",
      "Frames to be processed: 178  | To do: 16.95 % | Done: 83.05 %\n",
      "\n",
      "2022-04-20 13:17:38.182824\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000872.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 42.6ms pre-process, 175.1ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.83 \tBbox: [ 1 \t 2 \t 477 \t 1067 ]\n",
      "2 \tObject: person \tConfidence = 0.5399 \tBbox: [ 0 \t 484 \t 48 \t 883 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000873 / 1050\n",
      "Frames to be processed: 177  | To do: 16.86 % | Done: 83.14 %\n",
      "\n",
      "2022-04-20 13:17:38.686212\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000873.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.5ms pre-process, 180.5ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8317 \tBbox: [ 1 \t 2 \t 476 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.556 \tBbox: [ 0 \t 484 \t 48 \t 882 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000874 / 1050\n",
      "Frames to be processed: 176  | To do: 16.76 % | Done: 83.24 %\n",
      "\n",
      "2022-04-20 13:17:39.203598\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000874.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 44.0ms pre-process, 173.7ms inference, 6.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8366 \tBbox: [ 1 \t 2 \t 475 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.5424 \tBbox: [ 0 \t 483 \t 48 \t 882 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000875 / 1050\n",
      "Frames to be processed: 175  | To do: 16.67 % | Done: 83.33 %\n",
      "\n",
      "2022-04-20 13:17:39.780857\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000875.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 26.6ms pre-process, 175.9ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8458 \tBbox: [ 1 \t 1 \t 475 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.5332 \tBbox: [ 0 \t 484 \t 48 \t 882 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000876 / 1050\n",
      "Frames to be processed: 174  | To do: 16.57 % | Done: 83.43 %\n",
      "\n",
      "2022-04-20 13:17:40.268570\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000876.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 32.5ms pre-process, 178.5ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8446 \tBbox: [ 1 \t 1 \t 475 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.557 \tBbox: [ 0 \t 482 \t 48 \t 882 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000877 / 1050\n",
      "Frames to be processed: 173  | To do: 16.48 % | Done: 83.52 %\n",
      "\n",
      "2022-04-20 13:17:40.702412\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000877.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 30.2ms pre-process, 178.2ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.847 \tBbox: [ 1 \t 1 \t 475 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.5769 \tBbox: [ 0 \t 483 \t 49 \t 882 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000878 / 1050\n",
      "Frames to be processed: 172  | To do: 16.38 % | Done: 83.62 %\n",
      "\n",
      "2022-04-20 13:17:41.150745\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000878.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 33.8ms pre-process, 170.1ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8415 \tBbox: [ 1 \t 1 \t 476 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.5737 \tBbox: [ 0 \t 482 \t 49 \t 883 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000879 / 1050\n",
      "Frames to be processed: 171  | To do: 16.29 % | Done: 83.71 %\n",
      "\n",
      "2022-04-20 13:17:41.688734\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000879.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 26.8ms pre-process, 175.8ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8448 \tBbox: [ 1 \t 2 \t 476 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.568 \tBbox: [ 0 \t 482 \t 49 \t 882 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000880 / 1050\n",
      "Frames to be processed: 170  | To do: 16.19 % | Done: 83.81 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:17:42.109463\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000880.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 28.0ms pre-process, 167.6ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8373 \tBbox: [ 0 \t 2 \t 476 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.5677 \tBbox: [ 0 \t 482 \t 50 \t 882 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000881 / 1050\n",
      "Frames to be processed: 169  | To do: 16.1 % | Done: 83.9 %\n",
      "\n",
      "2022-04-20 13:17:42.534247\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000881.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.1ms pre-process, 175.3ms inference, 10.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8341 \tBbox: [ 1 \t 1 \t 476 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.5827 \tBbox: [ 0 \t 482 \t 49 \t 882 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000882 / 1050\n",
      "Frames to be processed: 168  | To do: 16.0 % | Done: 84.0 %\n",
      "\n",
      "2022-04-20 13:17:42.964863\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000882.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.2ms pre-process, 168.4ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8375 \tBbox: [ 1 \t 2 \t 476 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.5896 \tBbox: [ 0 \t 482 \t 50 \t 882 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000883 / 1050\n",
      "Frames to be processed: 167  | To do: 15.9 % | Done: 84.1 %\n",
      "\n",
      "2022-04-20 13:17:43.362768\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000883.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 44.7ms pre-process, 175.1ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8465 \tBbox: [ 1 \t 1 \t 475 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.5916 \tBbox: [ 0 \t 482 \t 50 \t 882 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000884 / 1050\n",
      "Frames to be processed: 166  | To do: 15.81 % | Done: 84.19 %\n",
      "\n",
      "2022-04-20 13:17:43.854876\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000884.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.6ms pre-process, 169.0ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8465 \tBbox: [ 1 \t 1 \t 476 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.5902 \tBbox: [ 0 \t 482 \t 50 \t 882 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000885 / 1050\n",
      "Frames to be processed: 165  | To do: 15.71 % | Done: 84.29 %\n",
      "\n",
      "2022-04-20 13:17:44.282977\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000885.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 26.5ms pre-process, 175.5ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8485 \tBbox: [ 1 \t 1 \t 476 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.6038 \tBbox: [ 0 \t 482 \t 50 \t 881 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000886 / 1050\n",
      "Frames to be processed: 164  | To do: 15.62 % | Done: 84.38 %\n",
      "\n",
      "2022-04-20 13:17:44.706839\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000886.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 25.8ms pre-process, 178.2ms inference, 4.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8503 \tBbox: [ 1 \t 1 \t 476 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.614 \tBbox: [ 0 \t 481 \t 50 \t 881 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000887 / 1050\n",
      "Frames to be processed: 163  | To do: 15.52 % | Done: 84.48 %\n",
      "\n",
      "2022-04-20 13:17:45.126809\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000887.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.3ms pre-process, 181.6ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8564 \tBbox: [ 1 \t 1 \t 476 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.6075 \tBbox: [ 0 \t 481 \t 50 \t 881 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000888 / 1050\n",
      "Frames to be processed: 162  | To do: 15.43 % | Done: 84.57 %\n",
      "\n",
      "2022-04-20 13:17:45.602074\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000888.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 36.1ms pre-process, 182.0ms inference, 11.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8416 \tBbox: [ 1 \t 1 \t 476 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.5792 \tBbox: [ 0 \t 479 \t 50 \t 882 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000889 / 1050\n",
      "Frames to be processed: 161  | To do: 15.33 % | Done: 84.67 %\n",
      "\n",
      "2022-04-20 13:17:46.059460\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000889.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 35.6ms pre-process, 173.2ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8399 \tBbox: [ 1 \t 1 \t 476 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.594 \tBbox: [ 0 \t 478 \t 51 \t 882 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000890 / 1050\n",
      "Frames to be processed: 160  | To do: 15.24 % | Done: 84.76 %\n",
      "\n",
      "2022-04-20 13:17:46.471712\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000890.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 27.9ms pre-process, 173.9ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8387 \tBbox: [ 1 \t 1 \t 476 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.6116 \tBbox: [ 0 \t 478 \t 51 \t 881 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000891 / 1050\n",
      "Frames to be processed: 159  | To do: 15.14 % | Done: 84.86 %\n",
      "\n",
      "2022-04-20 13:17:46.896504\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000891.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 39.4ms pre-process, 175.3ms inference, 4.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8452 \tBbox: [ 1 \t 1 \t 475 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.6139 \tBbox: [ 0 \t 477 \t 51 \t 882 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000892 / 1050\n",
      "Frames to be processed: 158  | To do: 15.05 % | Done: 84.95 %\n",
      "\n",
      "2022-04-20 13:17:47.397043\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000892.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.1ms pre-process, 181.0ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8489 \tBbox: [ 1 \t 1 \t 475 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.6213 \tBbox: [ 0 \t 477 \t 51 \t 882 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000893 / 1050\n",
      "Frames to be processed: 157  | To do: 14.95 % | Done: 85.05 %\n",
      "\n",
      "2022-04-20 13:17:47.847532\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000893.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.0ms pre-process, 183.5ms inference, 3.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8424 \tBbox: [ 1 \t 1 \t 477 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.6101 \tBbox: [ 0 \t 476 \t 52 \t 881 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000894 / 1050\n",
      "Frames to be processed: 156  | To do: 14.86 % | Done: 85.14 %\n",
      "\n",
      "2022-04-20 13:17:48.299871\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000894.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.6ms pre-process, 181.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8385 \tBbox: [ 1 \t 1 \t 476 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.594 \tBbox: [ 0 \t 475 \t 53 \t 882 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000895 / 1050\n",
      "Frames to be processed: 155  | To do: 14.76 % | Done: 85.24 %\n",
      "\n",
      "2022-04-20 13:17:48.729590\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000895.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 31.5ms pre-process, 171.5ms inference, 10.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8376 \tBbox: [ 1 \t 2 \t 476 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.5908 \tBbox: [ 0 \t 475 \t 52 \t 881 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000896 / 1050\n",
      "Frames to be processed: 154  | To do: 14.67 % | Done: 85.33 %\n",
      "\n",
      "2022-04-20 13:17:49.194617\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000896.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.3ms pre-process, 174.5ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8333 \tBbox: [ 1 \t 1 \t 476 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.6169 \tBbox: [ 0 \t 474 \t 52 \t 881 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000897 / 1050\n",
      "Frames to be processed: 153  | To do: 14.57 % | Done: 85.43 %\n",
      "\n",
      "2022-04-20 13:17:49.603360\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000897.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.6ms pre-process, 176.0ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8255 \tBbox: [ 1 \t 1 \t 476 \t 1067 ]\n",
      "2 \tObject: person \tConfidence = 0.6151 \tBbox: [ 0 \t 474 \t 51 \t 881 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000898 / 1050\n",
      "Frames to be processed: 152  | To do: 14.48 % | Done: 85.52 %\n",
      "\n",
      "2022-04-20 13:17:50.042873\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000898.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 35.7ms pre-process, 180.1ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8279 \tBbox: [ 1 \t 1 \t 476 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.6011 \tBbox: [ 0 \t 474 \t 51 \t 882 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000899 / 1050\n",
      "Frames to be processed: 151  | To do: 14.38 % | Done: 85.62 %\n",
      "\n",
      "2022-04-20 13:17:50.522779\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000899.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.0ms pre-process, 181.7ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8355 \tBbox: [ 1 \t 1 \t 476 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.6044 \tBbox: [ 0 \t 473 \t 51 \t 882 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000900 / 1050\n",
      "Frames to be processed: 150  | To do: 14.29 % | Done: 85.71 %\n",
      "\n",
      "2022-04-20 13:17:50.928897\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000900.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 30.4ms pre-process, 173.5ms inference, 4.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8362 \tBbox: [ 1 \t 1 \t 477 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.5552 \tBbox: [ 0 \t 474 \t 53 \t 880 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000901 / 1050\n",
      "Frames to be processed: 149  | To do: 14.19 % | Done: 85.81 %\n",
      "\n",
      "2022-04-20 13:17:51.399486\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000901.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.1ms pre-process, 177.6ms inference, 3.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.84 \tBbox: [ 1 \t 1 \t 477 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.5681 \tBbox: [ 0 \t 473 \t 52 \t 881 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000902 / 1050\n",
      "Frames to be processed: 148  | To do: 14.1 % | Done: 85.9 %\n",
      "\n",
      "2022-04-20 13:17:51.889133\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000902.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 55.2ms pre-process, 180.1ms inference, 3.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8453 \tBbox: [ 1 \t 1 \t 476 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.5364 \tBbox: [ 0 \t 473 \t 53 \t 881 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000903 / 1050\n",
      "Frames to be processed: 147  | To do: 14.0 % | Done: 86.0 %\n",
      "\n",
      "2022-04-20 13:17:52.370365\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000903.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 35.9ms pre-process, 182.8ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8403 \tBbox: [ 1 \t 1 \t 477 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.549 \tBbox: [ 0 \t 472 \t 53 \t 881 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000904 / 1050\n",
      "Frames to be processed: 146  | To do: 13.9 % | Done: 86.1 %\n",
      "\n",
      "2022-04-20 13:17:52.858345\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000904.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.7ms pre-process, 179.9ms inference, 10.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8333 \tBbox: [ 1 \t 1 \t 477 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.5436 \tBbox: [ 0 \t 472 \t 53 \t 881 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000905 / 1050\n",
      "Frames to be processed: 145  | To do: 13.81 % | Done: 86.19 %\n",
      "\n",
      "2022-04-20 13:17:53.335541\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000905.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 65.0ms pre-process, 173.5ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8391 \tBbox: [ 1 \t 1 \t 476 \t 1068 ]\n",
      "2 \tObject: person \tConfidence = 0.5336 \tBbox: [ 0 \t 471 \t 53 \t 881 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000906 / 1050\n",
      "Frames to be processed: 144  | To do: 13.71 % | Done: 86.29 %\n",
      "\n",
      "2022-04-20 13:17:53.803545\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000906.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 26.7ms pre-process, 168.5ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8462 \tBbox: [ 1 \t 1 \t 476 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.556 \tBbox: [ 0 \t 471 \t 53 \t 881 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000907 / 1050\n",
      "Frames to be processed: 143  | To do: 13.62 % | Done: 86.38 %\n",
      "\n",
      "2022-04-20 13:17:54.223970\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000907.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 30.3ms pre-process, 175.6ms inference, 4.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8407 \tBbox: [ 1 \t 1 \t 476 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.5736 \tBbox: [ 0 \t 470 \t 53 \t 881 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000908 / 1050\n",
      "Frames to be processed: 142  | To do: 13.52 % | Done: 86.48 %\n",
      "\n",
      "2022-04-20 13:17:54.687658\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000908.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 36.9ms pre-process, 169.3ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.843 \tBbox: [ 1 \t 1 \t 476 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.5255 \tBbox: [ 0 \t 470 \t 52 \t 881 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000909 / 1050\n",
      "Frames to be processed: 141  | To do: 13.43 % | Done: 86.57 %\n",
      "\n",
      "2022-04-20 13:17:55.098214\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000909.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.3ms pre-process, 173.0ms inference, 10.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8426 \tBbox: [ 1 \t 1 \t 476 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.5427 \tBbox: [ 0 \t 464 \t 54 \t 880 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000910 / 1050\n",
      "Frames to be processed: 140  | To do: 13.33 % | Done: 86.67 %\n",
      "\n",
      "2022-04-20 13:17:55.514494\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000910.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 39.3ms pre-process, 172.3ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8445 \tBbox: [ 1 \t 1 \t 476 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.5308 \tBbox: [ 0 \t 463 \t 53 \t 880 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000911 / 1050\n",
      "Frames to be processed: 139  | To do: 13.24 % | Done: 86.76 %\n",
      "\n",
      "2022-04-20 13:17:55.922650\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000911.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 26.8ms pre-process, 177.9ms inference, 9.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8491 \tBbox: [ 1 \t 1 \t 476 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.5021 \tBbox: [ 0 \t 463 \t 53 \t 880 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000912 / 1050\n",
      "Frames to be processed: 138  | To do: 13.14 % | Done: 86.86 %\n",
      "\n",
      "2022-04-20 13:17:56.390627\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000912.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 27.3ms pre-process, 173.3ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8498 \tBbox: [ 1 \t 1 \t 476 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.4922 \tBbox: [ 0 \t 463 \t 53 \t 880 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000913 / 1050\n",
      "Frames to be processed: 137  | To do: 13.05 % | Done: 86.95 %\n",
      "\n",
      "2022-04-20 13:17:56.812602\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000913.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.5ms pre-process, 168.4ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8454 \tBbox: [ 1 \t 2 \t 476 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.4867 \tBbox: [ 0 \t 462 \t 54 \t 879 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000914 / 1050\n",
      "Frames to be processed: 136  | To do: 12.95 % | Done: 87.05 %\n",
      "\n",
      "2022-04-20 13:17:57.263273\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000914.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.7ms pre-process, 175.1ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8517 \tBbox: [ 1 \t 2 \t 476 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.489 \tBbox: [ 0 \t 462 \t 54 \t 879 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000915 / 1050\n",
      "Frames to be processed: 135  | To do: 12.86 % | Done: 87.14 %\n",
      "\n",
      "2022-04-20 13:17:57.699274\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000915.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 31.3ms pre-process, 169.9ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8591 \tBbox: [ 1 \t 2 \t 476 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.5263 \tBbox: [ 0 \t 461 \t 55 \t 878 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000916 / 1050\n",
      "Frames to be processed: 134  | To do: 12.76 % | Done: 87.24 %\n",
      "\n",
      "2022-04-20 13:17:58.103495\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000916.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 44.8ms pre-process, 175.4ms inference, 3.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8536 \tBbox: [ 1 \t 2 \t 476 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.5176 \tBbox: [ 0 \t 461 \t 55 \t 878 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000917 / 1050\n",
      "Frames to be processed: 133  | To do: 12.67 % | Done: 87.33 %\n",
      "\n",
      "2022-04-20 13:17:58.524633\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000917.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 31.8ms pre-process, 168.9ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8605 \tBbox: [ 1 \t 2 \t 476 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.5147 \tBbox: [ 0 \t 460 \t 55 \t 879 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000918 / 1050\n",
      "Frames to be processed: 132  | To do: 12.57 % | Done: 87.43 %\n",
      "\n",
      "2022-04-20 13:17:58.937636\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000918.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 41.9ms pre-process, 176.8ms inference, 9.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8743 \tBbox: [ 3 \t 3 \t 479 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.5132 \tBbox: [ 0 \t 458 \t 56 \t 880 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000919 / 1050\n",
      "Frames to be processed: 131  | To do: 12.48 % | Done: 87.52 %\n",
      "\n",
      "2022-04-20 13:17:59.409605\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000919.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.4ms pre-process, 171.2ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8739 \tBbox: [ 3 \t 3 \t 479 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.5191 \tBbox: [ 0 \t 458 \t 55 \t 879 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000920 / 1050\n",
      "Frames to be processed: 130  | To do: 12.38 % | Done: 87.62 %\n",
      "\n",
      "2022-04-20 13:17:59.828354\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000920.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 30.0ms pre-process, 177.7ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8754 \tBbox: [ 3 \t 3 \t 479 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.5439 \tBbox: [ 0 \t 458 \t 55 \t 879 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000921 / 1050\n",
      "Frames to be processed: 129  | To do: 12.29 % | Done: 87.71 %\n",
      "\n",
      "2022-04-20 13:18:00.295191\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000921.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 26.7ms pre-process, 174.7ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8723 \tBbox: [ 0 \t 2 \t 477 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.5747 \tBbox: [ 0 \t 457 \t 56 \t 879 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000922 / 1050\n",
      "Frames to be processed: 128  | To do: 12.19 % | Done: 87.81 %\n",
      "\n",
      "2022-04-20 13:18:00.692365\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000922.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.3ms pre-process, 171.6ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8769 \tBbox: [ 3 \t 3 \t 478 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.572 \tBbox: [ 0 \t 461 \t 55 \t 878 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000923 / 1050\n",
      "Frames to be processed: 127  | To do: 12.1 % | Done: 87.9 %\n",
      "\n",
      "2022-04-20 13:18:01.107209\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000923.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 41.2ms pre-process, 175.8ms inference, 3.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8619 \tBbox: [ 3 \t 3 \t 478 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.5576 \tBbox: [ 0 \t 468 \t 54 \t 878 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000924 / 1050\n",
      "Frames to be processed: 126  | To do: 12.0 % | Done: 88.0 %\n",
      "\n",
      "2022-04-20 13:18:01.525592\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000924.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.6ms pre-process, 172.3ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8653 \tBbox: [ 1 \t 2 \t 478 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.5542 \tBbox: [ 0 \t 461 \t 54 \t 878 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000925 / 1050\n",
      "Frames to be processed: 125  | To do: 11.9 % | Done: 88.1 %\n",
      "\n",
      "2022-04-20 13:18:01.931799\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000925.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 38.2ms pre-process, 174.0ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8609 \tBbox: [ 1 \t 2 \t 478 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.5713 \tBbox: [ 0 \t 462 \t 54 \t 878 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000926 / 1050\n",
      "Frames to be processed: 124  | To do: 11.81 % | Done: 88.19 %\n",
      "\n",
      "2022-04-20 13:18:02.366344\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000926.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 38.0ms pre-process, 176.5ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8624 \tBbox: [ 0 \t 2 \t 479 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.584 \tBbox: [ 0 \t 461 \t 53 \t 878 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000927 / 1050\n",
      "Frames to be processed: 123  | To do: 11.71 % | Done: 88.29 %\n",
      "\n",
      "2022-04-20 13:18:02.834499\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000927.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 27.6ms pre-process, 180.8ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8646 \tBbox: [ 0 \t 2 \t 479 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.5563 \tBbox: [ 0 \t 459 \t 53 \t 878 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000928 / 1050\n",
      "Frames to be processed: 122  | To do: 11.62 % | Done: 88.38 %\n",
      "\n",
      "2022-04-20 13:18:03.314206\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000928.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.3ms pre-process, 173.3ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8712 \tBbox: [ 1 \t 2 \t 479 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.58 \tBbox: [ 0 \t 458 \t 53 \t 879 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000929 / 1050\n",
      "Frames to be processed: 121  | To do: 11.52 % | Done: 88.48 %\n",
      "\n",
      "2022-04-20 13:18:03.783117\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000929.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 26.5ms pre-process, 175.4ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8799 \tBbox: [ 3 \t 3 \t 481 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.5586 \tBbox: [ 0 \t 455 \t 52 \t 878 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000930 / 1050\n",
      "Frames to be processed: 120  | To do: 11.43 % | Done: 88.57 %\n",
      "\n",
      "2022-04-20 13:18:04.244331\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000930.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 33.4ms pre-process, 180.2ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8827 \tBbox: [ 3 \t 3 \t 481 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.4828 \tBbox: [ 0 \t 453 \t 52 \t 879 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000931 / 1050\n",
      "Frames to be processed: 119  | To do: 11.33 % | Done: 88.67 %\n",
      "\n",
      "2022-04-20 13:18:04.715265\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000931.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 30.5ms pre-process, 180.6ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8696 \tBbox: [ 3 \t 3 \t 481 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.4918 \tBbox: [ 0 \t 456 \t 53 \t 878 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000932 / 1050\n",
      "Frames to be processed: 118  | To do: 11.24 % | Done: 88.76 %\n",
      "\n",
      "2022-04-20 13:18:05.178484\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000932.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.2ms pre-process, 174.1ms inference, 4.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8729 \tBbox: [ 3 \t 3 \t 480 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.4394 \tBbox: [ 0 \t 461 \t 53 \t 878 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000933 / 1050\n",
      "Frames to be processed: 117  | To do: 11.14 % | Done: 88.86 %\n",
      "\n",
      "2022-04-20 13:18:05.671108\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000933.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 37.6ms pre-process, 174.6ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8525 \tBbox: [ 1 \t 2 \t 479 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.4387 \tBbox: [ 0 \t 462 \t 52 \t 878 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000934 / 1050\n",
      "Frames to be processed: 116  | To do: 11.05 % | Done: 88.95 %\n",
      "\n",
      "2022-04-20 13:18:06.136523\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000934.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 33.1ms pre-process, 178.0ms inference, 4.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.848 \tBbox: [ 0 \t 2 \t 479 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.3966 \tBbox: [ 0 \t 471 \t 51 \t 877 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000935 / 1050\n",
      "Frames to be processed: 115  | To do: 10.95 % | Done: 89.05 %\n",
      "\n",
      "2022-04-20 13:18:06.606876\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000935.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.6ms pre-process, 174.6ms inference, 2.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8414 \tBbox: [ 0 \t 2 \t 479 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.3897 \tBbox: [ 0 \t 463 \t 53 \t 878 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000936 / 1050\n",
      "Frames to be processed: 114  | To do: 10.86 % | Done: 89.14 %\n",
      "\n",
      "2022-04-20 13:18:07.025973\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000936.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 26.8ms pre-process, 180.8ms inference, 11.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.847 \tBbox: [ 0 \t 2 \t 479 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.3768 \tBbox: [ 0 \t 464 \t 53 \t 878 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000937 / 1050\n",
      "Frames to be processed: 113  | To do: 10.76 % | Done: 89.24 %\n",
      "\n",
      "2022-04-20 13:18:07.492314\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000937.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 34.5ms pre-process, 179.5ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8486 \tBbox: [ 0 \t 2 \t 480 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.4057 \tBbox: [ 0 \t 464 \t 53 \t 878 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000938 / 1050\n",
      "Frames to be processed: 112  | To do: 10.67 % | Done: 89.33 %\n",
      "\n",
      "2022-04-20 13:18:07.906256\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000938.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 27.6ms pre-process, 175.7ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8544 \tBbox: [ 0 \t 2 \t 480 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.488 \tBbox: [ 0 \t 457 \t 54 \t 878 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000939 / 1050\n",
      "Frames to be processed: 111  | To do: 10.57 % | Done: 89.43 %\n",
      "\n",
      "2022-04-20 13:18:08.396138\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000939.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 27.6ms pre-process, 169.6ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8578 \tBbox: [ 0 \t 2 \t 480 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.5287 \tBbox: [ 0 \t 455 \t 55 \t 878 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000940 / 1050\n",
      "Frames to be processed: 110  | To do: 10.48 % | Done: 89.52 %\n",
      "\n",
      "2022-04-20 13:18:08.828809\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000940.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.4ms pre-process, 170.6ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.858 \tBbox: [ 0 \t 2 \t 480 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.5936 \tBbox: [ 0 \t 455 \t 54 \t 877 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000941 / 1050\n",
      "Frames to be processed: 109  | To do: 10.38 % | Done: 89.62 %\n",
      "\n",
      "2022-04-20 13:18:09.267768\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000941.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 54.0ms pre-process, 176.4ms inference, 4.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8651 \tBbox: [ 0 \t 2 \t 480 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.6079 \tBbox: [ 0 \t 452 \t 55 \t 877 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000942 / 1050\n",
      "Frames to be processed: 108  | To do: 10.29 % | Done: 89.71 %\n",
      "\n",
      "2022-04-20 13:18:09.696307\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000942.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 53.4ms pre-process, 179.5ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8677 \tBbox: [ 3 \t 3 \t 481 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.5849 \tBbox: [ 0 \t 461 \t 56 \t 876 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000943 / 1050\n",
      "Frames to be processed: 107  | To do: 10.19 % | Done: 89.81 %\n",
      "\n",
      "2022-04-20 13:18:10.131459\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000943.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.6ms pre-process, 182.3ms inference, 10.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8581 \tBbox: [ 1 \t 2 \t 480 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.5967 \tBbox: [ 0 \t 459 \t 56 \t 876 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000944 / 1050\n",
      "Frames to be processed: 106  | To do: 10.1 % | Done: 89.9 %\n",
      "\n",
      "2022-04-20 13:18:10.611737\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000944.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 26.1ms pre-process, 176.0ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8501 \tBbox: [ 1 \t 2 \t 480 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.6714 \tBbox: [ 0 \t 464 \t 55 \t 873 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000945 / 1050\n",
      "Frames to be processed: 105  | To do: 10.0 % | Done: 90.0 %\n",
      "\n",
      "2022-04-20 13:18:11.117438\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000945.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.0ms pre-process, 169.6ms inference, 1.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8547 \tBbox: [ 1 \t 2 \t 481 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.6566 \tBbox: [ 0 \t 461 \t 56 \t 874 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000946 / 1050\n",
      "Frames to be processed: 104  | To do: 9.9 % | Done: 90.1 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 13:18:11.539221\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000946.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 25.6ms pre-process, 168.2ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.853 \tBbox: [ 1 \t 2 \t 481 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.6215 \tBbox: [ 0 \t 462 \t 57 \t 875 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000947 / 1050\n",
      "Frames to be processed: 103  | To do: 9.81 % | Done: 90.19 %\n",
      "\n",
      "2022-04-20 13:18:11.928271\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000947.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 26.4ms pre-process, 175.9ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8531 \tBbox: [ 1 \t 2 \t 481 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.6098 \tBbox: [ 0 \t 462 \t 57 \t 875 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000948 / 1050\n",
      "Frames to be processed: 102  | To do: 9.71 % | Done: 90.29 %\n",
      "\n",
      "2022-04-20 13:18:12.352150\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000948.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 32.4ms pre-process, 177.5ms inference, 4.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.855 \tBbox: [ 1 \t 2 \t 480 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.4457 \tBbox: [ 0 \t 452 \t 57 \t 876 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000949 / 1050\n",
      "Frames to be processed: 101  | To do: 9.62 % | Done: 90.38 %\n",
      "\n",
      "2022-04-20 13:18:12.780442\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000949.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 30.0ms pre-process, 180.2ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8533 \tBbox: [ 1 \t 2 \t 480 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.5064 \tBbox: [ 0 \t 457 \t 57 \t 876 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000950 / 1050\n",
      "Frames to be processed: 100  | To do: 9.52 % | Done: 90.48 %\n",
      "\n",
      "2022-04-20 13:18:13.223537\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000950.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 39.9ms pre-process, 179.2ms inference, 11.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.856 \tBbox: [ 1 \t 2 \t 479 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.4618 \tBbox: [ 0 \t 451 \t 57 \t 876 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000951 / 1050\n",
      "Frames to be processed: 99  | To do: 9.43 % | Done: 90.57 %\n",
      "\n",
      "2022-04-20 13:18:13.671519\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000951.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 31.8ms pre-process, 186.0ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8619 \tBbox: [ 1 \t 2 \t 480 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.4269 \tBbox: [ 0 \t 448 \t 57 \t 875 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000952 / 1050\n",
      "Frames to be processed: 98  | To do: 9.33 % | Done: 90.67 %\n",
      "\n",
      "2022-04-20 13:18:14.173236\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000952.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 30.9ms pre-process, 175.5ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8625 \tBbox: [ 3 \t 3 \t 480 \t 1069 ]\n",
      "2 \tObject: person \tConfidence = 0.6304 \tBbox: [ 0 \t 466 \t 57 \t 873 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000953 / 1050\n",
      "Frames to be processed: 97  | To do: 9.24 % | Done: 90.76 %\n",
      "\n",
      "2022-04-20 13:18:14.744157\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000953.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 41.5ms pre-process, 170.2ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8507 \tBbox: [ 1 \t 2 \t 479 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.5827 \tBbox: [ 0 \t 464 \t 58 \t 873 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000954 / 1050\n",
      "Frames to be processed: 96  | To do: 9.14 % | Done: 90.86 %\n",
      "\n",
      "2022-04-20 13:18:15.279993\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000954.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 31.4ms pre-process, 176.5ms inference, 10.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.848 \tBbox: [ 1 \t 2 \t 480 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.5709 \tBbox: [ 0 \t 462 \t 58 \t 873 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000955 / 1050\n",
      "Frames to be processed: 95  | To do: 9.05 % | Done: 90.95 %\n",
      "\n",
      "2022-04-20 13:18:15.718029\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000955.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 50.0ms pre-process, 177.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8535 \tBbox: [ 1 \t 2 \t 480 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.5803 \tBbox: [ 0 \t 463 \t 58 \t 873 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000956 / 1050\n",
      "Frames to be processed: 94  | To do: 8.95 % | Done: 91.05 %\n",
      "\n",
      "2022-04-20 13:18:16.163461\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000956.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 56.0ms pre-process, 181.3ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8487 \tBbox: [ 0 \t 2 \t 481 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.5678 \tBbox: [ 0 \t 461 \t 58 \t 873 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000957 / 1050\n",
      "Frames to be processed: 93  | To do: 8.86 % | Done: 91.14 %\n",
      "\n",
      "2022-04-20 13:18:16.630543\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000957.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 27.1ms pre-process, 170.5ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8534 \tBbox: [ 0 \t 2 \t 481 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.5573 \tBbox: [ 0 \t 462 \t 58 \t 873 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000958 / 1050\n",
      "Frames to be processed: 92  | To do: 8.76 % | Done: 91.24 %\n",
      "\n",
      "2022-04-20 13:18:17.013636\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000958.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 26.7ms pre-process, 173.7ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.851 \tBbox: [ 0 \t 2 \t 481 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.513 \tBbox: [ 0 \t 447 \t 58 \t 875 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000959 / 1050\n",
      "Frames to be processed: 91  | To do: 8.67 % | Done: 91.33 %\n",
      "\n",
      "2022-04-20 13:18:17.431966\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000959.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.4ms pre-process, 175.5ms inference, 10.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.854 \tBbox: [ 0 \t 2 \t 481 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.4425 \tBbox: [ 0 \t 444 \t 58 \t 874 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000960 / 1050\n",
      "Frames to be processed: 90  | To do: 8.57 % | Done: 91.43 %\n",
      "\n",
      "2022-04-20 13:18:17.936150\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000960.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.7ms pre-process, 180.2ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8515 \tBbox: [ 0 \t 2 \t 481 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.4629 \tBbox: [ 0 \t 448 \t 58 \t 874 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000961 / 1050\n",
      "Frames to be processed: 89  | To do: 8.48 % | Done: 91.52 %\n",
      "\n",
      "2022-04-20 13:18:18.444041\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000961.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.7ms pre-process, 180.8ms inference, 10.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8522 \tBbox: [ 0 \t 2 \t 481 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.4884 \tBbox: [ 0 \t 446 \t 58 \t 875 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000962 / 1050\n",
      "Frames to be processed: 88  | To do: 8.38 % | Done: 91.62 %\n",
      "\n",
      "2022-04-20 13:18:18.903919\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000962.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.5ms pre-process, 181.9ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8533 \tBbox: [ 0 \t 2 \t 481 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.4765 \tBbox: [ 0 \t 460 \t 59 \t 874 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000963 / 1050\n",
      "Frames to be processed: 87  | To do: 8.29 % | Done: 91.71 %\n",
      "\n",
      "2022-04-20 13:18:19.349167\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000963.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 54.7ms pre-process, 173.3ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8484 \tBbox: [ 0 \t 2 \t 481 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.4395 \tBbox: [ 0 \t 459 \t 59 \t 875 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000964 / 1050\n",
      "Frames to be processed: 86  | To do: 8.19 % | Done: 91.81 %\n",
      "\n",
      "2022-04-20 13:18:19.875972\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000964.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 45.1ms pre-process, 175.4ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8422 \tBbox: [ 0 \t 2 \t 481 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.5098 \tBbox: [ 0 \t 461 \t 59 \t 874 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000965 / 1050\n",
      "Frames to be processed: 85  | To do: 8.1 % | Done: 91.9 %\n",
      "\n",
      "2022-04-20 13:18:20.394343\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000965.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 35.3ms pre-process, 173.6ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8435 \tBbox: [ 0 \t 2 \t 481 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.5378 \tBbox: [ 0 \t 466 \t 59 \t 873 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000966 / 1050\n",
      "Frames to be processed: 84  | To do: 8.0 % | Done: 92.0 %\n",
      "\n",
      "2022-04-20 13:18:20.924751\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000966.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 31.4ms pre-process, 172.5ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8422 \tBbox: [ 0 \t 2 \t 480 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.5371 \tBbox: [ 0 \t 467 \t 59 \t 874 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000967 / 1050\n",
      "Frames to be processed: 83  | To do: 7.9 % | Done: 92.1 %\n",
      "\n",
      "2022-04-20 13:18:21.357455\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000967.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 30.5ms pre-process, 167.5ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8438 \tBbox: [ 0 \t 2 \t 480 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.5532 \tBbox: [ 0 \t 468 \t 59 \t 874 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000968 / 1050\n",
      "Frames to be processed: 82  | To do: 7.81 % | Done: 92.19 %\n",
      "\n",
      "2022-04-20 13:18:21.841095\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000968.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 41.7ms pre-process, 178.4ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.862 \tBbox: [ 0 \t 2 \t 480 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.5759 \tBbox: [ 0 \t 457 \t 60 \t 875 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000969 / 1050\n",
      "Frames to be processed: 81  | To do: 7.71 % | Done: 92.29 %\n",
      "\n",
      "2022-04-20 13:18:22.284044\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000969.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 27.0ms pre-process, 181.5ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8586 \tBbox: [ 0 \t 2 \t 480 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.6054 \tBbox: [ 0 \t 458 \t 60 \t 875 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000970 / 1050\n",
      "Frames to be processed: 80  | To do: 7.62 % | Done: 92.38 %\n",
      "\n",
      "2022-04-20 13:18:22.677625\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000970.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.6ms pre-process, 173.5ms inference, 3.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8573 \tBbox: [ 0 \t 2 \t 481 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.5922 \tBbox: [ 0 \t 458 \t 60 \t 875 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000971 / 1050\n",
      "Frames to be processed: 79  | To do: 7.52 % | Done: 92.48 %\n",
      "\n",
      "2022-04-20 13:18:23.095605\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000971.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.3ms pre-process, 176.1ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8578 \tBbox: [ 0 \t 2 \t 481 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.627 \tBbox: [ 0 \t 458 \t 59 \t 876 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000972 / 1050\n",
      "Frames to be processed: 78  | To do: 7.43 % | Done: 92.57 %\n",
      "\n",
      "2022-04-20 13:18:23.575304\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000972.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.0ms pre-process, 177.2ms inference, 10.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8611 \tBbox: [ 0 \t 2 \t 481 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.5984 \tBbox: [ 0 \t 460 \t 59 \t 876 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000973 / 1050\n",
      "Frames to be processed: 77  | To do: 7.33 % | Done: 92.67 %\n",
      "\n",
      "2022-04-20 13:18:24.036715\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000973.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 25.9ms pre-process, 179.1ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8386 \tBbox: [ 0 \t 2 \t 481 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.5555 \tBbox: [ 0 \t 457 \t 59 \t 877 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000974 / 1050\n",
      "Frames to be processed: 76  | To do: 7.24 % | Done: 92.76 %\n",
      "\n",
      "2022-04-20 13:18:24.459695\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000974.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.1ms pre-process, 180.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.844 \tBbox: [ 0 \t 2 \t 481 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.5575 \tBbox: [ 0 \t 459 \t 59 \t 877 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000975 / 1050\n",
      "Frames to be processed: 75  | To do: 7.14 % | Done: 92.86 %\n",
      "\n",
      "2022-04-20 13:18:24.905061\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000975.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.5ms pre-process, 168.6ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8369 \tBbox: [ 0 \t 2 \t 481 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.5607 \tBbox: [ 0 \t 458 \t 59 \t 877 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000976 / 1050\n",
      "Frames to be processed: 74  | To do: 7.05 % | Done: 92.95 %\n",
      "\n",
      "2022-04-20 13:18:25.350106\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000976.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.0ms pre-process, 174.3ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8489 \tBbox: [ 0 \t 2 \t 481 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.6354 \tBbox: [ 0 \t 457 \t 59 \t 877 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000977 / 1050\n",
      "Frames to be processed: 73  | To do: 6.95 % | Done: 93.05 %\n",
      "\n",
      "2022-04-20 13:18:25.808582\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000977.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 81.3ms pre-process, 171.2ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8575 \tBbox: [ 0 \t 2 \t 481 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.6249 \tBbox: [ 0 \t 458 \t 59 \t 876 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000978 / 1050\n",
      "Frames to be processed: 72  | To do: 6.86 % | Done: 93.14 %\n",
      "\n",
      "2022-04-20 13:18:26.272906\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000978.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 53.2ms pre-process, 173.2ms inference, 3.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8575 \tBbox: [ 0 \t 2 \t 482 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.626 \tBbox: [ 0 \t 455 \t 59 \t 876 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000979 / 1050\n",
      "Frames to be processed: 71  | To do: 6.76 % | Done: 93.24 %\n",
      "\n",
      "2022-04-20 13:18:26.741064\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000979.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 33.0ms pre-process, 175.7ms inference, 3.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8696 \tBbox: [ 1 \t 1 \t 481 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.6676 \tBbox: [ 0 \t 455 \t 60 \t 877 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000980 / 1050\n",
      "Frames to be processed: 70  | To do: 6.67 % | Done: 93.33 %\n",
      "\n",
      "2022-04-20 13:18:27.187228\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000980.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 35.5ms pre-process, 180.5ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8713 \tBbox: [ 1 \t 1 \t 482 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.6756 \tBbox: [ 0 \t 453 \t 60 \t 877 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000981 / 1050\n",
      "Frames to be processed: 69  | To do: 6.57 % | Done: 93.43 %\n",
      "\n",
      "2022-04-20 13:18:27.688392\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000981.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 34.8ms pre-process, 172.9ms inference, 11.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8715 \tBbox: [ 1 \t 1 \t 481 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.6654 \tBbox: [ 0 \t 453 \t 60 \t 876 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000982 / 1050\n",
      "Frames to be processed: 68  | To do: 6.48 % | Done: 93.52 %\n",
      "\n",
      "2022-04-20 13:18:28.107290\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000982.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 27.0ms pre-process, 169.9ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8698 \tBbox: [ 1 \t 1 \t 481 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.6333 \tBbox: [ 0 \t 457 \t 60 \t 876 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000983 / 1050\n",
      "Frames to be processed: 67  | To do: 6.38 % | Done: 93.62 %\n",
      "\n",
      "2022-04-20 13:18:28.561702\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000983.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 30.6ms pre-process, 175.6ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8724 \tBbox: [ 1 \t 1 \t 481 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.5916 \tBbox: [ 0 \t 457 \t 60 \t 876 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000984 / 1050\n",
      "Frames to be processed: 66  | To do: 6.29 % | Done: 93.71 %\n",
      "\n",
      "2022-04-20 13:18:29.010792\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000984.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.9ms pre-process, 170.1ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.861 \tBbox: [ 1 \t 1 \t 482 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.5973 \tBbox: [ 0 \t 457 \t 60 \t 876 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000985 / 1050\n",
      "Frames to be processed: 65  | To do: 6.19 % | Done: 93.81 %\n",
      "\n",
      "2022-04-20 13:18:29.451563\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000985.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.9ms pre-process, 175.3ms inference, 2.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8654 \tBbox: [ 1 \t 1 \t 482 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.5882 \tBbox: [ 0 \t 457 \t 60 \t 876 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000986 / 1050\n",
      "Frames to be processed: 64  | To do: 6.1 % | Done: 93.9 %\n",
      "\n",
      "2022-04-20 13:18:29.881703\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000986.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 32.7ms pre-process, 178.1ms inference, 3.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8642 \tBbox: [ 0 \t 2 \t 482 \t 1070 ]\n",
      "2 \tObject: person \tConfidence = 0.5868 \tBbox: [ 0 \t 456 \t 61 \t 876 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000987 / 1050\n",
      "Frames to be processed: 63  | To do: 6.0 % | Done: 94.0 %\n",
      "\n",
      "2022-04-20 13:18:30.326082\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000987.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 35.7ms pre-process, 170.5ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8694 \tBbox: [ 1 \t 1 \t 482 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.5308 \tBbox: [ 0 \t 456 \t 62 \t 875 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000988 / 1050\n",
      "Frames to be processed: 62  | To do: 5.9 % | Done: 94.1 %\n",
      "\n",
      "2022-04-20 13:18:30.786891\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000988.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 26.6ms pre-process, 177.9ms inference, 11.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8761 \tBbox: [ 1 \t 1 \t 482 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.5229 \tBbox: [ 0 \t 457 \t 63 \t 876 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000989 / 1050\n",
      "Frames to be processed: 61  | To do: 5.81 % | Done: 94.19 %\n",
      "\n",
      "2022-04-20 13:18:31.236508\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000989.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 34.2ms pre-process, 179.9ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8756 \tBbox: [ 1 \t 1 \t 482 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.5246 \tBbox: [ 0 \t 456 \t 64 \t 877 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000990 / 1050\n",
      "Frames to be processed: 60  | To do: 5.71 % | Done: 94.29 %\n",
      "\n",
      "2022-04-20 13:18:31.724940\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000990.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 124.6ms pre-process, 171.6ms inference, 10.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8885 \tBbox: [ 1 \t 0 \t 482 \t 1073 ]\n",
      "2 \tObject: person \tConfidence = 0.4856 \tBbox: [ 0 \t 457 \t 65 \t 876 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000991 / 1050\n",
      "Frames to be processed: 59  | To do: 5.62 % | Done: 94.38 %\n",
      "\n",
      "2022-04-20 13:18:32.272601\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000991.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 27.6ms pre-process, 175.0ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.891 \tBbox: [ 1 \t 0 \t 483 \t 1073 ]\n",
      "2 \tObject: person \tConfidence = 0.4413 \tBbox: [ 0 \t 456 \t 64 \t 875 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000992 / 1050\n",
      "Frames to be processed: 58  | To do: 5.52 % | Done: 94.48 %\n",
      "\n",
      "2022-04-20 13:18:32.739614\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000992.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 35.2ms pre-process, 171.6ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8867 \tBbox: [ 1 \t 0 \t 483 \t 1073 ]\n",
      "2 \tObject: person \tConfidence = 0.5099 \tBbox: [ 0 \t 457 \t 64 \t 874 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000993 / 1050\n",
      "Frames to be processed: 57  | To do: 5.43 % | Done: 94.57 %\n",
      "\n",
      "2022-04-20 13:18:33.169838\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000993.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 35.9ms pre-process, 172.3ms inference, 5.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8904 \tBbox: [ 1 \t 0 \t 481 \t 1073 ]\n",
      "2 \tObject: person \tConfidence = 0.4993 \tBbox: [ 0 \t 454 \t 64 \t 875 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000994 / 1050\n",
      "Frames to be processed: 56  | To do: 5.33 % | Done: 94.67 %\n",
      "\n",
      "2022-04-20 13:18:33.645313\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000994.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 34.9ms pre-process, 176.4ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8943 \tBbox: [ 1 \t 0 \t 481 \t 1073 ]\n",
      "2 \tObject: person \tConfidence = 0.4923 \tBbox: [ 1 \t 447 \t 64 \t 874 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000995 / 1050\n",
      "Frames to be processed: 55  | To do: 5.24 % | Done: 94.76 %\n",
      "\n",
      "2022-04-20 13:18:34.073649\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000995.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.9ms pre-process, 176.1ms inference, 4.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8923 \tBbox: [ 1 \t 1 \t 481 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.5179 \tBbox: [ 1 \t 446 \t 64 \t 874 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000996 / 1050\n",
      "Frames to be processed: 54  | To do: 5.14 % | Done: 94.86 %\n",
      "\n",
      "2022-04-20 13:18:34.620868\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000996.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 26.0ms pre-process, 180.1ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8878 \tBbox: [ 1 \t 2 \t 481 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.5012 \tBbox: [ 0 \t 439 \t 65 \t 876 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000997 / 1050\n",
      "Frames to be processed: 53  | To do: 5.05 % | Done: 94.95 %\n",
      "\n",
      "2022-04-20 13:18:35.075982\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000997.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 27.7ms pre-process, 172.7ms inference, 4.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8806 \tBbox: [ 1 \t 2 \t 480 \t 1072 ]\n",
      "2 \tObject: person \tConfidence = 0.502 \tBbox: [ 0 \t 445 \t 61 \t 874 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000998 / 1050\n",
      "Frames to be processed: 52  | To do: 4.95 % | Done: 95.05 %\n",
      "\n",
      "2022-04-20 13:18:35.523182\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000998.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 24.9ms pre-process, 175.7ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8808 \tBbox: [ 1 \t 1 \t 480 \t 1071 ]\n",
      "2 \tObject: person \tConfidence = 0.4781 \tBbox: [ 0 \t 450 \t 60 \t 875 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000000999 / 1050\n",
      "Frames to be processed: 51  | To do: 4.86 % | Done: 95.14 %\n",
      "\n",
      "2022-04-20 13:18:35.962880\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000000999.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 35.9ms pre-process, 182.1ms inference, 10.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8659 \tBbox: [ 1 \t 2 \t 482 \t 1073 ]\n",
      "2 \tObject: person \tConfidence = 0.5859 \tBbox: [ 0 \t 449 \t 59 \t 877 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001000 / 1050\n",
      "Frames to be processed: 50  | To do: 4.76 % | Done: 95.24 %\n",
      "\n",
      "2022-04-20 13:18:36.494794\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001000.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 29.3ms pre-process, 172.9ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8839 \tBbox: [ 1 \t 2 \t 482 \t 1073 ]\n",
      "2 \tObject: person \tConfidence = 0.4672 \tBbox: [ 0 \t 447 \t 59 \t 876 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001001 / 1050\n",
      "Frames to be processed: 49  | To do: 4.67 % | Done: 95.33 %\n",
      "\n",
      "2022-04-20 13:18:36.935685\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001001.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 31.0ms pre-process, 170.1ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8923 \tBbox: [ 1 \t 1 \t 482 \t 1073 ]\n",
      "2 \tObject: person \tConfidence = 0.4186 \tBbox: [ 0 \t 451 \t 59 \t 874 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001002 / 1050\n",
      "Frames to be processed: 48  | To do: 4.57 % | Done: 95.43 %\n",
      "\n",
      "2022-04-20 13:18:37.370397\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001002.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 person, 1 train\n",
      "Speed: 28.7ms pre-process, 175.6ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 2 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8716 \tBbox: [ 1 \t 2 \t 483 \t 1073 ]\n",
      "2 \tObject: person \tConfidence = 0.3226 \tBbox: [ 0 \t 448 \t 59 \t 873 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train     1\n",
      "person    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001003 / 1050\n",
      "Frames to be processed: 47  | To do: 4.48 % | Done: 95.52 %\n",
      "\n",
      "2022-04-20 13:18:37.844692\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001003.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 30.5ms pre-process, 181.2ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8708 \tBbox: [ 3 \t 3 \t 482 \t 1070 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001004 / 1050\n",
      "Frames to be processed: 46  | To do: 4.38 % | Done: 95.62 %\n",
      "\n",
      "2022-04-20 13:18:38.307305\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001004.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 32.8ms pre-process, 172.3ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.8516 \tBbox: [ 3 \t 3 \t 485 \t 1070 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001005 / 1050\n",
      "Frames to be processed: 45  | To do: 4.29 % | Done: 95.71 %\n",
      "\n",
      "2022-04-20 13:18:38.751530\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001005.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 26.8ms pre-process, 175.5ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.7995 \tBbox: [ 3 \t 3 \t 483 \t 1070 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001006 / 1050\n",
      "Frames to be processed: 44  | To do: 4.19 % | Done: 95.81 %\n",
      "\n",
      "2022-04-20 13:18:39.162163\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001006.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 31.6ms pre-process, 177.5ms inference, 4.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.7179 \tBbox: [ 3 \t 3 \t 485 \t 1069 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001007 / 1050\n",
      "Frames to be processed: 43  | To do: 4.1 % | Done: 95.9 %\n",
      "\n",
      "2022-04-20 13:18:39.589149\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001007.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 29.5ms pre-process, 177.3ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.7739 \tBbox: [ 4 \t 3 \t 483 \t 1069 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001008 / 1050\n",
      "Frames to be processed: 42  | To do: 4.0 % | Done: 96.0 %\n",
      "\n",
      "2022-04-20 13:18:40.059878\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001008.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 27.6ms pre-process, 181.5ms inference, 10.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.7256 \tBbox: [ 4 \t 3 \t 484 \t 1069 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001009 / 1050\n",
      "Frames to be processed: 41  | To do: 3.9 % | Done: 96.1 %\n",
      "\n",
      "2022-04-20 13:18:40.541173\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001009.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 26.7ms pre-process, 171.9ms inference, 2.6ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.592 \tBbox: [ 4 \t 3 \t 484 \t 1069 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001010 / 1050\n",
      "Frames to be processed: 40  | To do: 3.81 % | Done: 96.19 %\n",
      "\n",
      "2022-04-20 13:18:40.915235\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001010.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 24.8ms pre-process, 171.5ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.5692 \tBbox: [ 4 \t 3 \t 484 \t 1069 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001011 / 1050\n",
      "Frames to be processed: 39  | To do: 3.71 % | Done: 96.29 %\n",
      "\n",
      "2022-04-20 13:18:41.297376\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001011.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 28.4ms pre-process, 168.9ms inference, 3.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.528 \tBbox: [ 1 \t 2 \t 482 \t 1072 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001012 / 1050\n",
      "Frames to be processed: 38  | To do: 3.62 % | Done: 96.38 %\n",
      "\n",
      "2022-04-20 13:18:41.747180\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001012.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 27.4ms pre-process, 175.6ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.5954 \tBbox: [ 0 \t 2 \t 482 \t 1072 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001013 / 1050\n",
      "Frames to be processed: 37  | To do: 3.52 % | Done: 96.48 %\n",
      "\n",
      "2022-04-20 13:18:42.156414\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001013.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 26.7ms pre-process, 170.3ms inference, 13.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.5524 \tBbox: [ 0 \t 2 \t 483 \t 1072 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001014 / 1050\n",
      "Frames to be processed: 36  | To do: 3.43 % | Done: 96.57 %\n",
      "\n",
      "2022-04-20 13:18:42.647172\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001014.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 30.1ms pre-process, 175.5ms inference, 3.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.5515 \tBbox: [ 0 \t 2 \t 482 \t 1072 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001015 / 1050\n",
      "Frames to be processed: 35  | To do: 3.33 % | Done: 96.67 %\n",
      "\n",
      "2022-04-20 13:18:43.048432\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001015.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 27.7ms pre-process, 179.7ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.5476 \tBbox: [ 3 \t 2 \t 484 \t 1069 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001016 / 1050\n",
      "Frames to be processed: 34  | To do: 3.24 % | Done: 96.76 %\n",
      "\n",
      "2022-04-20 13:18:43.525946\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001016.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 35.6ms pre-process, 183.9ms inference, 3.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.6083 \tBbox: [ 3 \t 3 \t 483 \t 1069 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001017 / 1050\n",
      "Frames to be processed: 33  | To do: 3.14 % | Done: 96.86 %\n",
      "\n",
      "2022-04-20 13:18:43.956577\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001017.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 31.6ms pre-process, 181.8ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.6572 \tBbox: [ 3 \t 3 \t 483 \t 1069 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001018 / 1050\n",
      "Frames to be processed: 32  | To do: 3.05 % | Done: 96.95 %\n",
      "\n",
      "2022-04-20 13:18:44.410030\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001018.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 24.7ms pre-process, 176.4ms inference, 4.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.6058 \tBbox: [ 3 \t 3 \t 483 \t 1069 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001019 / 1050\n",
      "Frames to be processed: 31  | To do: 2.95 % | Done: 97.05 %\n",
      "\n",
      "2022-04-20 13:18:44.841839\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001019.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 45.2ms pre-process, 181.3ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.5984 \tBbox: [ 3 \t 3 \t 483 \t 1068 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001020 / 1050\n",
      "Frames to be processed: 30  | To do: 2.86 % | Done: 97.14 %\n",
      "\n",
      "2022-04-20 13:18:45.315139\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001020.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 29.3ms pre-process, 181.9ms inference, 3.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.6441 \tBbox: [ 3 \t 4 \t 483 \t 1068 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001021 / 1050\n",
      "Frames to be processed: 29  | To do: 2.76 % | Done: 97.24 %\n",
      "\n",
      "2022-04-20 13:18:45.775333\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001021.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 28.7ms pre-process, 175.1ms inference, 2.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.6394 \tBbox: [ 0 \t 2 \t 483 \t 1072 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001022 / 1050\n",
      "Frames to be processed: 28  | To do: 2.67 % | Done: 97.33 %\n",
      "\n",
      "2022-04-20 13:18:46.207957\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001022.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 26.8ms pre-process, 168.4ms inference, 12.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.6068 \tBbox: [ 3 \t 4 \t 484 \t 1069 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001023 / 1050\n",
      "Frames to be processed: 27  | To do: 2.57 % | Done: 97.43 %\n",
      "\n",
      "2022-04-20 13:18:46.638864\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001023.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 29.4ms pre-process, 175.9ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.5568 \tBbox: [ 3 \t 4 \t 483 \t 1069 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001024 / 1050\n",
      "Frames to be processed: 26  | To do: 2.48 % | Done: 97.52 %\n",
      "\n",
      "2022-04-20 13:18:47.088327\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001024.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 27.4ms pre-process, 168.8ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.5857 \tBbox: [ 0 \t 2 \t 482 \t 1072 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001025 / 1050\n",
      "Frames to be processed: 25  | To do: 2.38 % | Done: 97.62 %\n",
      "\n",
      "2022-04-20 13:18:47.510254\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001025.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 31.9ms pre-process, 175.3ms inference, 3.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.5407 \tBbox: [ 3 \t 4 \t 484 \t 1069 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001026 / 1050\n",
      "Frames to be processed: 24  | To do: 2.29 % | Done: 97.71 %\n",
      "\n",
      "2022-04-20 13:18:47.951035\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001026.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 24.9ms pre-process, 174.7ms inference, 2.8ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.4653 \tBbox: [ 0 \t 2 \t 483 \t 1072 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001027 / 1050\n",
      "Frames to be processed: 23  | To do: 2.19 % | Done: 97.81 %\n",
      "\n",
      "2022-04-20 13:18:48.385407\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001027.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 (no detections)\n",
      "Speed: 33.5ms pre-process, 177.8ms inference, 3.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 0 \n",
      "\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "Series([], Name: name, dtype: int64)\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001028 / 1050\n",
      "Frames to be processed: 22  | To do: 2.1 % | Done: 97.9 %\n",
      "\n",
      "2022-04-20 13:18:48.829864\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001028.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 32.6ms pre-process, 180.4ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.5903 \tBbox: [ 0 \t 2 \t 482 \t 1072 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001029 / 1050\n",
      "Frames to be processed: 21  | To do: 2.0 % | Done: 98.0 %\n",
      "\n",
      "2022-04-20 13:18:49.292810\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001029.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 26.2ms pre-process, 172.7ms inference, 13.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.7105 \tBbox: [ 0 \t 2 \t 482 \t 1072 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001030 / 1050\n",
      "Frames to be processed: 20  | To do: 1.9 % | Done: 98.1 %\n",
      "\n",
      "2022-04-20 13:18:49.739062\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001030.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 27.3ms pre-process, 176.1ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.6395 \tBbox: [ 0 \t 2 \t 483 \t 1072 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001031 / 1050\n",
      "Frames to be processed: 19  | To do: 1.81 % | Done: 98.19 %\n",
      "\n",
      "2022-04-20 13:18:50.260811\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001031.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 44.4ms pre-process, 177.1ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.6977 \tBbox: [ 0 \t 2 \t 483 \t 1073 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001032 / 1050\n",
      "Frames to be processed: 18  | To do: 1.71 % | Done: 98.29 %\n",
      "\n",
      "2022-04-20 13:18:50.855816\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001032.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 26.8ms pre-process, 184.4ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.7273 \tBbox: [ 0 \t 2 \t 483 \t 1072 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001033 / 1050\n",
      "Frames to be processed: 17  | To do: 1.62 % | Done: 98.38 %\n",
      "\n",
      "2022-04-20 13:18:51.294105\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001033.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 47.6ms pre-process, 174.0ms inference, 11.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.7083 \tBbox: [ 0 \t 2 \t 483 \t 1072 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001034 / 1050\n",
      "Frames to be processed: 16  | To do: 1.52 % | Done: 98.48 %\n",
      "\n",
      "2022-04-20 13:18:51.828132\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001034.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 27.0ms pre-process, 175.3ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.7213 \tBbox: [ 0 \t 2 \t 483 \t 1073 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001035 / 1050\n",
      "Frames to be processed: 15  | To do: 1.43 % | Done: 98.57 %\n",
      "\n",
      "2022-04-20 13:18:52.237866\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001035.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 27.8ms pre-process, 180.6ms inference, 2.4ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.7322 \tBbox: [ 0 \t 2 \t 482 \t 1073 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001036 / 1050\n",
      "Frames to be processed: 14  | To do: 1.33 % | Done: 98.67 %\n",
      "\n",
      "2022-04-20 13:18:52.710758\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001036.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 31.2ms pre-process, 171.8ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.7111 \tBbox: [ 0 \t 2 \t 482 \t 1073 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001037 / 1050\n",
      "Frames to be processed: 13  | To do: 1.24 % | Done: 98.76 %\n",
      "\n",
      "2022-04-20 13:18:53.116063\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001037.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 29.3ms pre-process, 169.1ms inference, 1.9ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.734 \tBbox: [ 0 \t 2 \t 482 \t 1073 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001038 / 1050\n",
      "Frames to be processed: 12  | To do: 1.14 % | Done: 98.86 %\n",
      "\n",
      "2022-04-20 13:18:53.717950\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001038.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 29.8ms pre-process, 175.9ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.682 \tBbox: [ 0 \t 2 \t 482 \t 1072 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001039 / 1050\n",
      "Frames to be processed: 11  | To do: 1.05 % | Done: 98.95 %\n",
      "\n",
      "2022-04-20 13:18:54.272576\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001039.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 26.1ms pre-process, 170.9ms inference, 2.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.7098 \tBbox: [ 0 \t 2 \t 482 \t 1072 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001040 / 1050\n",
      "Frames to be processed: 10  | To do: 0.95 % | Done: 99.05 %\n",
      "\n",
      "2022-04-20 13:18:54.744532\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001040.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 27.1ms pre-process, 170.2ms inference, 2.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.7264 \tBbox: [ 0 \t 2 \t 483 \t 1072 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001041 / 1050\n",
      "Frames to be processed: 9  | To do: 0.86 % | Done: 99.14 %\n",
      "\n",
      "2022-04-20 13:18:55.200199\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001041.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 27.8ms pre-process, 167.7ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.6758 \tBbox: [ 0 \t 2 \t 483 \t 1072 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001042 / 1050\n",
      "Frames to be processed: 8  | To do: 0.76 % | Done: 99.24 %\n",
      "\n",
      "2022-04-20 13:18:55.648693\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001042.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 47.7ms pre-process, 175.0ms inference, 2.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.6717 \tBbox: [ 0 \t 2 \t 483 \t 1073 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001043 / 1050\n",
      "Frames to be processed: 7  | To do: 0.67 % | Done: 99.33 %\n",
      "\n",
      "2022-04-20 13:18:56.085484\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001043.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 25.0ms pre-process, 175.1ms inference, 2.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.6567 \tBbox: [ 0 \t 2 \t 483 \t 1073 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001044 / 1050\n",
      "Frames to be processed: 6  | To do: 0.57 % | Done: 99.43 %\n",
      "\n",
      "2022-04-20 13:18:56.639481\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001044.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 28.6ms pre-process, 174.2ms inference, 3.1ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.661 \tBbox: [ 0 \t 2 \t 483 \t 1073 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001045 / 1050\n",
      "Frames to be processed: 5  | To do: 0.48 % | Done: 99.52 %\n",
      "\n",
      "2022-04-20 13:18:57.104200\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001045.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 27.4ms pre-process, 169.2ms inference, 2.3ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.7346 \tBbox: [ 0 \t 2 \t 483 \t 1073 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001046 / 1050\n",
      "Frames to be processed: 4  | To do: 0.38 % | Done: 99.62 %\n",
      "\n",
      "2022-04-20 13:18:57.550975\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001046.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 26.9ms pre-process, 168.9ms inference, 4.5ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.7123 \tBbox: [ 0 \t 2 \t 483 \t 1073 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001047 / 1050\n",
      "Frames to be processed: 3  | To do: 0.29 % | Done: 99.71 %\n",
      "\n",
      "2022-04-20 13:18:58.054372\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001047.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 29.5ms pre-process, 169.6ms inference, 3.2ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.6828 \tBbox: [ 0 \t 2 \t 483 \t 1073 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001048 / 1050\n",
      "Frames to be processed: 2  | To do: 0.19 % | Done: 99.81 %\n",
      "\n",
      "2022-04-20 13:18:58.507181\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001048.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 29.8ms pre-process, 175.5ms inference, 4.0ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.6674 \tBbox: [ 0 \t 2 \t 483 \t 1073 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\u001b[1;31;34m \n",
      "Processing frame: 000001049 / 1050\n",
      "Frames to be processed: 1  | To do: 0.1 % | Done: 99.9 %\n",
      "\n",
      "2022-04-20 13:18:58.923091\n",
      "\u001b[1;31;34m\n",
      "------------------------------ Analyzing images/captures/frame_000001049.jpg ------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 1080x766 1 train\n",
      "Speed: 25.5ms pre-process, 177.8ms inference, 3.7ms NMS per image at shape (1, 3, 640, 512)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mNumber of detected objects = 1 \n",
      "\n",
      "1 \tObject: train \tConfidence = 0.6975 \tBbox: [ 0 \t 2 \t 484 \t 1073 ]\n",
      "\u001b[1;31;91m\n",
      "Results:\n",
      "train    1\n",
      "Name: name, dtype: int64\n",
      "\n",
      "\n",
      " \u001b[1;31;34m\n",
      "-------------------- End of job --------------------\n",
      "Done in 0:08:30.499330 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "capture = cv2.VideoCapture(WEBCAM)\n",
    "\n",
    "print('\\033[1;31;34mProcessing the video: ', WEBCAM, 'for every', \n",
    "      sampling_frames, \"frame(s)\", '\\n')\n",
    "\n",
    "t1 = datetime.datetime.now() # Current datetime\n",
    "framenumber = 1\n",
    "\n",
    "while True:\n",
    "    check, frame = capture.read()\n",
    "        \n",
    "    if framenumber%sampling_frames == 0: # sampling frame    \n",
    "        currentdate = str(datetime.datetime.now())\n",
    "\n",
    "        # Just to have the same length for the filenames\n",
    "        framenumberstr = filenameordernumber()\n",
    "                \n",
    "        remainingframes = nbframes - framenumber\n",
    "        pctleft = round(remainingframes / nbframes * 100, 2)\n",
    "        pctdone = round((100 - pctleft), 2)\n",
    "        \n",
    "        print('\\033[1;31;34m', \"\\nProcessing frame:\", framenumberstr, '/', nbframes)\n",
    "        print(\"Frames to be processed:\", remainingframes, ' | To do:', \n",
    "              pctleft, '% | Done:', pctdone, '%')\n",
    "        print()\n",
    "        \n",
    "        # Saving captured frame\n",
    "        capturedframe = CAPTURES_DIR + '/frame_' + framenumberstr + '.jpg'    \n",
    "        cv2.imwrite(capturedframe, frame)\n",
    "                \n",
    "        # Calling the CV model on the captured frame and saving results into Azure ML\n",
    "        getresults = calling_yolov5_model(capturedframe) # Calling the model\n",
    "        img = getresults[0]\n",
    "        nbpersons = getresults[1]\n",
    "        trainstatus = getresults[2]\n",
    "                \n",
    "        # Logging values to Azure ML\n",
    "        run.log('Date', currentdate)\n",
    "        run.log('Frame', framenumberstr)\n",
    "        run.log('nbpersons', nbpersons)\n",
    "        run.log('trainstatus', trainstatus)\n",
    "        \n",
    "        # Saving results\n",
    "        outputframe = IMAGES_DIR + '/processed_frame_' + str(framenumberstr) + '.jpg'\n",
    "        cv2.imwrite(outputframe, img)\n",
    "    \n",
    "        framenumber += 1\n",
    "\n",
    "        if framenumber == int(nbprocessedframes):\n",
    "            print('\\n', '\\033[1;31;34m')\n",
    "            print(\"-\" * 20, \"End of job\", \"-\" * 20)\n",
    "            print('Done in', datetime.datetime.now() - t1, '\\n')\n",
    "            run.complete() # Stop Azure ML experiment\n",
    "            capture.release()\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some processed images from the video stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: images has 1049 files\n",
      "Directory: images/captures has 1049 files\n"
     ]
    }
   ],
   "source": [
    "nbfiles(IMAGES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: images/processed_frame_000000001.jpg w = 766 h = 1080 c = 3 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "image/jpeg": {
       "width": 400
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_frame = IMAGES_DIR + '/' + 'processed_frame_000000001.jpg'\n",
    "image_info(sample_frame)\n",
    "Image(filename=sample_frame, width=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: images/processed_frame_000000120.jpg w = 766 h = 1080 c = 3 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "image/jpeg": {
       "width": 400
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_frame = IMAGES_DIR + '/' + 'processed_frame_000000120.jpg'\n",
    "image_info(sample_frame)\n",
    "Image(filename=sample_frame, width=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: images/processed_frame_000000700.jpg w = 766 h = 1080 c = 3 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "image/jpeg": {
       "width": 400
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_frame = IMAGES_DIR + '/' + 'processed_frame_000000700.jpg'\n",
    "image_info(sample_frame)\n",
    "Image(filename=sample_frame, width=400)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: images/processed_frame_000000770.jpg w = 766 h = 1080 c = 3 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "image/jpeg": {
       "width": 400
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_frame = IMAGES_DIR + '/' + 'processed_frame_000000770.jpg'\n",
    "image_info(sample_frame)\n",
    "Image(filename=sample_frame, width=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: images/processed_frame_000001049.jpg w = 766 h = 1080 c = 3 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "image/jpeg": {
       "width": 400
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_frame = IMAGES_DIR + '/' + 'processed_frame_000001049.jpg'\n",
    "image_info(sample_frame)\n",
    "Image(filename=sample_frame, width=400) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Saving the processed frames into a new video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: images has 1049 files\n",
      "Directory: images/captures has 1049 files\n"
     ]
    }
   ],
   "source": [
    "video_output = 'processed_' + os.path.basename(SAMPLEVIDEO_FILENAME) # should be a MP4 file\n",
    "nbfiles(IMAGES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's save the processed video into the directory: results\n",
      "Building video file: results/processed_sample_subway.mp4 \n",
      "\n",
      "Writing video file...\n",
      "Moviepy - Building video results/processed_sample_subway.mp4.\n",
      "Moviepy - Writing video results/processed_sample_subway.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready results/processed_sample_subway.mp4\n",
      "\n",
      "Done in: 0:01:25.339864\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's save the processed video into the directory:\", RESULTS_DIR)\n",
    "\n",
    "import moviepy.video.io.ImageSequenceClip\n",
    "t1 = datetime.datetime.now()\n",
    "\n",
    "fps_output = 25 # FPS for the video to generate\n",
    "video_outputfilename = RESULTS_DIR + '/' + video_output # result video file\n",
    "\n",
    "print(\"Building video file:\", video_outputfilename, '\\n')\n",
    "image_files = [os.path.join(IMAGES_DIR, img)\n",
    "\n",
    "for img in os.listdir(IMAGES_DIR) if img.endswith(\".jpg\")]\n",
    "clip = moviepy.video.io.ImageSequenceClip.ImageSequenceClip(image_files, fps = fps_output)\n",
    "print(\"Writing video file...\")\n",
    "clip.write_videofile(video_outputfilename)\n",
    "\n",
    "print('\\nDone in:', datetime.datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 root root 9.2M Apr 20 13:23 results/processed_sample_subway.mp4\r\n",
      "-rwxrwxrwx 1 root root 8.4M Apr 20 13:08 results/sample_subway.mp4\r\n"
     ]
    }
   ],
   "source": [
    "!ls results/*.* -lth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's concatenate the two videos side by side into results/final.mp4 ... \n",
      "\n",
      "Moviepy - Building video results/final.mp4.\n",
      "MoviePy - Writing audio in finalTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video results/final.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1048/1051 [00:36<00:00, 29.76it/s, now=None]/anaconda/envs/azureml_py38/lib/python3.8/site-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file results/sample_subway.mp4, 2481840 bytes wanted but 0 bytes read,at frame 1050/1051, at time 42.00/42.03 sec. Using the last valid frame instead.\n",
      "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
      "\n",
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready results/final.mp4\n",
      "\n",
      "Video file is available: results/final.mp4\n",
      "\n",
      "Done in: 0:00:38.325508\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import *\n",
    "t1 = datetime.datetime.now()\n",
    "\n",
    "FINAL_CLIP = RESULTS_DIR + '/final.mp4' # Video to generate\n",
    "\n",
    "print(\"Let's concatenate the two videos side by side into\", FINAL_CLIP, '...', '\\n')\n",
    "clip1 = VideoFileClip(SAMPLEVIDEO_FILENAME) # Initial video\n",
    "clip2 = VideoFileClip(video_outputfilename) # Processed video\n",
    "clips = [[clip1, clip2]] # side by side videos\n",
    "sidebyside_clips = clips_array(clips)\n",
    "sidebyside_clips.write_videofile(FINAL_CLIP)\n",
    "print(\"\\nVideo file is available:\", FINAL_CLIP)\n",
    "print('\\nDone in:', datetime.datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 root root  18M Apr 20 13:25 results/final.mp4\r\n",
      "-rwxrwxrwx 1 root root 9.2M Apr 20 13:23 results/processed_sample_subway.mp4\r\n",
      "-rwxrwxrwx 1 root root 8.4M Apr 20 13:08 results/sample_subway.mp4\r\n"
     ]
    }
   ],
   "source": [
    "!ls results/*.* -lth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import Video\n",
    "#Video(FINAL_CLIP, embed = True, width = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Metrics have been saved into an Azure ML experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>TrainPlatform</td><td>azuremlvision</td><td><a href=\"https://ml.azure.com/experiments/id/3ca29690-d32d-4cdf-8c52-610318ce7c7e?wsid=/subscriptions/70b8f39e-8863-49f7-b6ba-34a80799550c/resourcegroups/azuremlvision-rg/workspaces/azuremlvision&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: TrainPlatform,\n",
       "Workspace: azuremlvision)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
